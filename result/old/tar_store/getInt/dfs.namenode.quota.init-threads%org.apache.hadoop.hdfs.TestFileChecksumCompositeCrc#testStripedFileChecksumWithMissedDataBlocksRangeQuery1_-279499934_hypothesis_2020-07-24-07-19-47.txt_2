reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 2
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 2
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478249483-172.17.0.7-1595575203723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41715,DS-bcee9091-c1e8-4c1e-9075-ba0662472751,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-34f59908-f53a-4221-b4c6-2d77f134cf08,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-d38dfdcf-1cd0-4287-95ae-3944ce106995,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-a4eeef39-9c84-48e9-81cf-27d4112f2a86,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-855ea399-ab1e-4f8d-b93e-51337a55d982,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-e11eaae1-e693-4015-9319-2bc27c81c611,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-bdbbbbbd-8727-4660-a535-b6732e28cb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-4c11d0b0-0d94-4f45-a62b-3a741a01a453,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478249483-172.17.0.7-1595575203723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41715,DS-bcee9091-c1e8-4c1e-9075-ba0662472751,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-34f59908-f53a-4221-b4c6-2d77f134cf08,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-d38dfdcf-1cd0-4287-95ae-3944ce106995,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-a4eeef39-9c84-48e9-81cf-27d4112f2a86,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-855ea399-ab1e-4f8d-b93e-51337a55d982,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-e11eaae1-e693-4015-9319-2bc27c81c611,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-bdbbbbbd-8727-4660-a535-b6732e28cb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-4c11d0b0-0d94-4f45-a62b-3a741a01a453,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 2
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188952852-172.17.0.7-1595575395633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35664,DS-426d86e8-1b67-412c-b8a7-5c4a262941ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-4866695e-a72d-4392-8bed-5cfd0882a438,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-dac59fc1-adeb-417f-8ef1-ea3a72fedd89,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-3d7f4952-666b-49e7-bc28-0830bd6a96aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-3c1b4f6d-892b-47cd-ba5d-732b73032ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-85c222cc-519f-4777-84c7-e20d674c93df,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-c5cb1a10-5441-4a15-86d8-f26eb8ed8b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-926bf019-3346-4834-9d49-8c28f70e11c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188952852-172.17.0.7-1595575395633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35664,DS-426d86e8-1b67-412c-b8a7-5c4a262941ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-4866695e-a72d-4392-8bed-5cfd0882a438,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-dac59fc1-adeb-417f-8ef1-ea3a72fedd89,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-3d7f4952-666b-49e7-bc28-0830bd6a96aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-3c1b4f6d-892b-47cd-ba5d-732b73032ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-85c222cc-519f-4777-84c7-e20d674c93df,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-c5cb1a10-5441-4a15-86d8-f26eb8ed8b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-926bf019-3346-4834-9d49-8c28f70e11c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 2
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131810323-172.17.0.7-1595575469799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42193,DS-3255a09b-660c-448f-b686-a48e2632c04f,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-1c6dea65-ad98-4efd-b8b2-c668400f3911,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-466bdb31-7d4c-4965-8315-1f34f398b4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-e421c1f9-542f-482f-94f6-1461f6c771f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-4efc9a4d-ef04-4e18-867d-47214dc2a7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-31347f34-edc5-4725-9778-1dafbe134505,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-54bc6661-0f61-4531-9a39-969fd6be0d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-84861e12-0a8f-422f-aaae-a87196af5afe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131810323-172.17.0.7-1595575469799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42193,DS-3255a09b-660c-448f-b686-a48e2632c04f,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-1c6dea65-ad98-4efd-b8b2-c668400f3911,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-466bdb31-7d4c-4965-8315-1f34f398b4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-e421c1f9-542f-482f-94f6-1461f6c771f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-4efc9a4d-ef04-4e18-867d-47214dc2a7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-31347f34-edc5-4725-9778-1dafbe134505,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-54bc6661-0f61-4531-9a39-969fd6be0d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-84861e12-0a8f-422f-aaae-a87196af5afe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 2
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405196242-172.17.0.7-1595575814825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42121,DS-2e5e30dd-b790-4aed-ba36-80d8cd7bde20,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-5c818f09-aad9-4edc-a952-5edbf79a8b54,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-fc2247ef-5718-44b8-aaa1-eec1312bab7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-d4efcbad-a746-4733-8db9-d7db082c868b,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-80eb3a0a-b035-4e5f-a014-e4dbb7b2f542,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-ebc8c397-1f1c-40c4-8264-d33877f579f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-14b2bb5a-237c-4083-8619-4a64e3e93775,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-2dc97842-1b8d-4569-85e3-38d2cf7ba61c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405196242-172.17.0.7-1595575814825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42121,DS-2e5e30dd-b790-4aed-ba36-80d8cd7bde20,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-5c818f09-aad9-4edc-a952-5edbf79a8b54,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-fc2247ef-5718-44b8-aaa1-eec1312bab7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-d4efcbad-a746-4733-8db9-d7db082c868b,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-80eb3a0a-b035-4e5f-a014-e4dbb7b2f542,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-ebc8c397-1f1c-40c4-8264-d33877f579f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-14b2bb5a-237c-4083-8619-4a64e3e93775,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-2dc97842-1b8d-4569-85e3-38d2cf7ba61c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 2
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-824719788-172.17.0.7-1595576224945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36727,DS-94a35005-87d8-4031-8828-9b723751e922,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-1b9a3e89-bcb2-4c85-bdd7-d09f15152758,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-bc62c999-e75e-4e52-a785-e3c388181722,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-370eb6b3-80a3-4fd6-b8f7-cfa24a525782,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-fef3a836-9395-4546-8f61-f0c7a5f13b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-9ab54c79-66fa-4157-85fe-00dfb6d60d00,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-3edbd1e5-785a-4e8a-89ab-9719df0d0b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-d31cd604-cbac-48e7-a15e-d91e37774fae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-824719788-172.17.0.7-1595576224945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36727,DS-94a35005-87d8-4031-8828-9b723751e922,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-1b9a3e89-bcb2-4c85-bdd7-d09f15152758,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-bc62c999-e75e-4e52-a785-e3c388181722,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-370eb6b3-80a3-4fd6-b8f7-cfa24a525782,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-fef3a836-9395-4546-8f61-f0c7a5f13b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-9ab54c79-66fa-4157-85fe-00dfb6d60d00,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-3edbd1e5-785a-4e8a-89ab-9719df0d0b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-d31cd604-cbac-48e7-a15e-d91e37774fae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 2
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-513363511-172.17.0.7-1595576312564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35000,DS-f7c5f45b-7494-46c2-b884-5329d2ddeed6,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-d9686752-a38e-4819-ad2e-22497d363988,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-81790904-a1ea-49df-a7c0-70dd2dedab15,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-91c9b88d-a311-4db5-9d3d-0c04fa4f1585,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-0eda7097-d937-4927-900c-c75e44dbafad,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-c055baea-40ae-43f6-94c2-b8c604b9c362,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-4c2c6c01-1872-4777-809b-5a24dca99ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-3c776610-87b4-4cd0-abed-e65cc2835581,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-513363511-172.17.0.7-1595576312564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35000,DS-f7c5f45b-7494-46c2-b884-5329d2ddeed6,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-d9686752-a38e-4819-ad2e-22497d363988,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-81790904-a1ea-49df-a7c0-70dd2dedab15,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-91c9b88d-a311-4db5-9d3d-0c04fa4f1585,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-0eda7097-d937-4927-900c-c75e44dbafad,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-c055baea-40ae-43f6-94c2-b8c604b9c362,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-4c2c6c01-1872-4777-809b-5a24dca99ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-3c776610-87b4-4cd0-abed-e65cc2835581,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 2
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351762516-172.17.0.7-1595576664458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44374,DS-4cf8ece2-fa3f-47d0-8b44-79d67a000985,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-da55dd74-b6c7-47ce-8548-9121e2f23b66,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-97b67a6b-f8c6-4481-bb34-ae9656322591,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-5d826095-1407-4d92-ac12-8d307890fa60,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-0ef91aa4-18b9-46d7-b9a4-d9eecc2a384c,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-aa652e23-90fb-4e69-a195-0628bad6a88f,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-83c534f9-e0b0-4a5f-be58-8db801c82476,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-6ed9a392-81b3-4ce0-b07e-b736d96ddf1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351762516-172.17.0.7-1595576664458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44374,DS-4cf8ece2-fa3f-47d0-8b44-79d67a000985,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-da55dd74-b6c7-47ce-8548-9121e2f23b66,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-97b67a6b-f8c6-4481-bb34-ae9656322591,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-5d826095-1407-4d92-ac12-8d307890fa60,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-0ef91aa4-18b9-46d7-b9a4-d9eecc2a384c,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-aa652e23-90fb-4e69-a195-0628bad6a88f,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-83c534f9-e0b0-4a5f-be58-8db801c82476,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-6ed9a392-81b3-4ce0-b07e-b736d96ddf1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 2
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275223887-172.17.0.7-1595576778202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45320,DS-435949d3-4d57-49fa-82bc-119e4b84b7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-86acd69f-5bfe-4338-a231-626d3219b1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-29e5c80e-7975-4808-950e-c81b876a7bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-d5359ee7-25c7-471f-b3fc-0c4499afd6da,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-f4033790-8a1c-4229-9291-39d1f4292068,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-a23346f3-4c0f-4cf6-a203-28a4820b3a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-03ba0b17-28f6-4eb6-83e1-f07d50f5a808,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-91cd984d-2ce0-4287-a1a8-ad5408ec4e2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275223887-172.17.0.7-1595576778202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45320,DS-435949d3-4d57-49fa-82bc-119e4b84b7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-86acd69f-5bfe-4338-a231-626d3219b1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-29e5c80e-7975-4808-950e-c81b876a7bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-d5359ee7-25c7-471f-b3fc-0c4499afd6da,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-f4033790-8a1c-4229-9291-39d1f4292068,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-a23346f3-4c0f-4cf6-a203-28a4820b3a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-03ba0b17-28f6-4eb6-83e1-f07d50f5a808,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-91cd984d-2ce0-4287-a1a8-ad5408ec4e2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 2
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-32104149-172.17.0.7-1595578460127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35706,DS-c3c58a0b-1990-442c-975f-aa2d48c46557,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-567cec20-931a-4976-93b6-699c030bcadb,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-59a7fd1a-3d12-4a4e-b990-f8d41b3c628c,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-24207a3b-8c69-4c91-a09d-8316e1867596,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-aa67bada-57b4-44f1-906b-7d9cb57c5a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-4d649673-885d-4660-a841-be83a108405f,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-b191c7c3-d7ac-4c89-a302-e83e5862f6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-70cefab8-2737-419b-8f23-70630419fc6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-32104149-172.17.0.7-1595578460127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35706,DS-c3c58a0b-1990-442c-975f-aa2d48c46557,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-567cec20-931a-4976-93b6-699c030bcadb,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-59a7fd1a-3d12-4a4e-b990-f8d41b3c628c,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-24207a3b-8c69-4c91-a09d-8316e1867596,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-aa67bada-57b4-44f1-906b-7d9cb57c5a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-4d649673-885d-4660-a841-be83a108405f,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-b191c7c3-d7ac-4c89-a302-e83e5862f6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-70cefab8-2737-419b-8f23-70630419fc6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 2
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1274185898-172.17.0.7-1595578985631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44906,DS-39f48836-6b92-4f0c-b575-1fe0e19e80d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-f300f553-408a-4af8-b5e6-129ddfb53abd,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-2096e55a-98a3-4e94-b5f3-d7b1350eeb61,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-ebe9266c-f54a-4d9a-b12c-4543c6096a40,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-5ff29dc0-fe81-4712-8805-f11b7e34dfde,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-ae7653f6-a93c-40b3-a266-c718ff18036d,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-2698021c-b02b-494d-8471-5ed7ac14e329,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-f190fc1e-3ef1-4554-b06b-0dacd8db1060,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1274185898-172.17.0.7-1595578985631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44906,DS-39f48836-6b92-4f0c-b575-1fe0e19e80d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-f300f553-408a-4af8-b5e6-129ddfb53abd,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-2096e55a-98a3-4e94-b5f3-d7b1350eeb61,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-ebe9266c-f54a-4d9a-b12c-4543c6096a40,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-5ff29dc0-fe81-4712-8805-f11b7e34dfde,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-ae7653f6-a93c-40b3-a266-c718ff18036d,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-2698021c-b02b-494d-8471-5ed7ac14e329,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-f190fc1e-3ef1-4554-b06b-0dacd8db1060,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 2
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185712163-172.17.0.7-1595579022957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35869,DS-a8fa751b-5059-4169-955b-e394e0b5ebd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-205e3055-b12e-403b-bb9d-fbf833f4e67d,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-b4cc111a-9bf6-492d-b294-9fa4ca6d21d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-7bad5bb9-8679-41ba-a9e1-4cb36f8030cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-dfdf9435-24c3-41c1-9d25-d3850e54d643,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-675b83b7-6810-42d3-8c4e-b8a0c81739d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-b4d75c58-a363-4c35-9263-ba9322c8a934,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-e89185b2-4286-4916-be2a-abbab1df72c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185712163-172.17.0.7-1595579022957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35869,DS-a8fa751b-5059-4169-955b-e394e0b5ebd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-205e3055-b12e-403b-bb9d-fbf833f4e67d,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-b4cc111a-9bf6-492d-b294-9fa4ca6d21d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-7bad5bb9-8679-41ba-a9e1-4cb36f8030cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-dfdf9435-24c3-41c1-9d25-d3850e54d643,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-675b83b7-6810-42d3-8c4e-b8a0c81739d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-b4d75c58-a363-4c35-9263-ba9322c8a934,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-e89185b2-4286-4916-be2a-abbab1df72c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 2
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280115627-172.17.0.7-1595579420296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33870,DS-ac8a8783-4188-448a-ba29-b8b16abd46ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-d32e085c-f95f-4af6-8852-b92fc029769f,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-6811662c-63a4-4a6e-a681-0c08e18806be,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-ef08865b-ca9f-4443-b4f8-46cea89ba1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-fc1451b7-9d36-47a2-b8a6-d56cdd5ca074,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-141ed450-97c2-4d0e-911a-63043eca2769,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-49f93261-f6fb-4a76-8d2c-89e9617bdaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-5863f4e4-b3f8-4345-bd32-1c0f9c45cd14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280115627-172.17.0.7-1595579420296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33870,DS-ac8a8783-4188-448a-ba29-b8b16abd46ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-d32e085c-f95f-4af6-8852-b92fc029769f,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-6811662c-63a4-4a6e-a681-0c08e18806be,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-ef08865b-ca9f-4443-b4f8-46cea89ba1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-fc1451b7-9d36-47a2-b8a6-d56cdd5ca074,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-141ed450-97c2-4d0e-911a-63043eca2769,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-49f93261-f6fb-4a76-8d2c-89e9617bdaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-5863f4e4-b3f8-4345-bd32-1c0f9c45cd14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 2
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-45398667-172.17.0.7-1595579528104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38252,DS-fa47c5da-de33-49d6-b8b9-91f353b54f30,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-e973aec2-fd7c-468b-ad03-c7caf74da0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-63093b55-6bc6-41e1-bb32-498a94987815,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-b29e2588-d3f7-485f-9475-d772bad82718,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-74c87ac0-116b-4436-80fa-fc75493a6d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-0e85bfce-2d7c-4cf2-b7c7-05aefb85dfb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-7689d914-82de-4502-b8a6-ab4915e5ebc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-e4b8e927-b9a3-420c-a7da-a7b3cb79b8b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-45398667-172.17.0.7-1595579528104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38252,DS-fa47c5da-de33-49d6-b8b9-91f353b54f30,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-e973aec2-fd7c-468b-ad03-c7caf74da0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-63093b55-6bc6-41e1-bb32-498a94987815,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-b29e2588-d3f7-485f-9475-d772bad82718,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-74c87ac0-116b-4436-80fa-fc75493a6d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-0e85bfce-2d7c-4cf2-b7c7-05aefb85dfb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-7689d914-82de-4502-b8a6-ab4915e5ebc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-e4b8e927-b9a3-420c-a7da-a7b3cb79b8b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 2
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80273268-172.17.0.7-1595580072089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41372,DS-8c3a2ff4-09cf-4afe-ba6a-4d4c49753f28,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-0ca034cb-00a2-42a3-ae0b-0e563506e4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-d5035ae2-e1dc-4a66-be27-74cc6d8bd72b,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-63945cdd-79f4-4297-bf02-e0c53644bd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-7bab6574-56ec-4859-8927-b2097cb3e550,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-f13256c8-91bd-4567-ac52-92b856ccb53b,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-3a9cfb2d-ef34-4c75-8960-2e1fb278a7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-111845e7-82b5-4a96-bd82-0eb2f44764e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80273268-172.17.0.7-1595580072089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41372,DS-8c3a2ff4-09cf-4afe-ba6a-4d4c49753f28,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-0ca034cb-00a2-42a3-ae0b-0e563506e4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-d5035ae2-e1dc-4a66-be27-74cc6d8bd72b,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-63945cdd-79f4-4297-bf02-e0c53644bd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-7bab6574-56ec-4859-8927-b2097cb3e550,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-f13256c8-91bd-4567-ac52-92b856ccb53b,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-3a9cfb2d-ef34-4c75-8960-2e1fb278a7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-111845e7-82b5-4a96-bd82-0eb2f44764e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 2
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400763987-172.17.0.7-1595580096898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42955,DS-f0a47af4-4ce2-48c6-803a-e8e8fd167434,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-3590c6f2-1f5e-4ae5-afd3-b87b33a094cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-d7ac9290-e34d-4dea-8305-7dcdd4f59b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-4a530cea-10fa-4272-8899-0d569a7cb184,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-955843a2-1086-4f61-b825-aa344b1083f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-051b74c4-a145-4c77-925e-36b6ebbcffce,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-dea072b3-9b80-464b-b5c0-487f7a65f4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-c50f10b3-1041-43c5-9594-71fdd8c9811f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400763987-172.17.0.7-1595580096898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42955,DS-f0a47af4-4ce2-48c6-803a-e8e8fd167434,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-3590c6f2-1f5e-4ae5-afd3-b87b33a094cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-d7ac9290-e34d-4dea-8305-7dcdd4f59b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-4a530cea-10fa-4272-8899-0d569a7cb184,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-955843a2-1086-4f61-b825-aa344b1083f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-051b74c4-a145-4c77-925e-36b6ebbcffce,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-dea072b3-9b80-464b-b5c0-487f7a65f4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-c50f10b3-1041-43c5-9594-71fdd8c9811f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 2
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2002267006-172.17.0.7-1595580161105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43527,DS-981d86f9-d34f-4edf-8e02-d4be2de0e986,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-566de2a0-f2de-40df-8257-cf08d5f5811f,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-0f6bdf94-93c4-48d3-bc0b-17888ec75445,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-06ec2301-ef93-45a2-8a75-e5690d2cb9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-e77e30d2-e745-490a-bc32-0ebbbb4cedac,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-2caecabb-66c3-477a-80c6-6883a9fba776,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-9c1d2368-f6ee-4c44-9bb4-47820968b047,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-7cfc4873-353e-453f-9b5c-3c9ed6f8ec4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2002267006-172.17.0.7-1595580161105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43527,DS-981d86f9-d34f-4edf-8e02-d4be2de0e986,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-566de2a0-f2de-40df-8257-cf08d5f5811f,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-0f6bdf94-93c4-48d3-bc0b-17888ec75445,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-06ec2301-ef93-45a2-8a75-e5690d2cb9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-e77e30d2-e745-490a-bc32-0ebbbb4cedac,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-2caecabb-66c3-477a-80c6-6883a9fba776,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-9c1d2368-f6ee-4c44-9bb4-47820968b047,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-7cfc4873-353e-453f-9b5c-3c9ed6f8ec4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 2
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-32435146-172.17.0.7-1595580258200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39801,DS-6f3803ec-51a4-4925-a922-d164cf64fa65,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-2d1e4ac9-e81a-4674-93ad-faf946ebbf41,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-baf8b084-6c6a-459f-9700-613568866bce,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-bda11064-b22c-4bd1-aa26-182f8e665ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-187f0157-3590-4851-81fe-90a76b76f732,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-147a53e0-948f-4e43-83a7-28c602295cad,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-0a1d11c6-e35d-4493-92db-52507236f8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-0fbaaa24-e3fe-4264-8813-a809649c413f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-32435146-172.17.0.7-1595580258200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39801,DS-6f3803ec-51a4-4925-a922-d164cf64fa65,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-2d1e4ac9-e81a-4674-93ad-faf946ebbf41,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-baf8b084-6c6a-459f-9700-613568866bce,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-bda11064-b22c-4bd1-aa26-182f8e665ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-187f0157-3590-4851-81fe-90a76b76f732,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-147a53e0-948f-4e43-83a7-28c602295cad,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-0a1d11c6-e35d-4493-92db-52507236f8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-0fbaaa24-e3fe-4264-8813-a809649c413f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 2
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1068529755-172.17.0.7-1595580423525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40252,DS-d9bcbe30-e0b6-4600-967f-4f799dbeb86f,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-7341c6bd-9e02-4cbc-9fd2-b48a071c606a,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-70360e18-b8f3-4233-9b96-ba274896033a,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-19d26a02-a88d-47ec-815b-12f0af88fcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-c99a0009-16a7-4db3-a233-d6b6f6206cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-ba7c2070-d995-4719-91c5-b265367b2775,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-10269a4b-12e8-4e15-a08a-7ddd7413c90c,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-7fe89f05-be6e-4327-a678-8b17bb2fcdad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1068529755-172.17.0.7-1595580423525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40252,DS-d9bcbe30-e0b6-4600-967f-4f799dbeb86f,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-7341c6bd-9e02-4cbc-9fd2-b48a071c606a,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-70360e18-b8f3-4233-9b96-ba274896033a,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-19d26a02-a88d-47ec-815b-12f0af88fcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-c99a0009-16a7-4db3-a233-d6b6f6206cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-ba7c2070-d995-4719-91c5-b265367b2775,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-10269a4b-12e8-4e15-a08a-7ddd7413c90c,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-7fe89f05-be6e-4327-a678-8b17bb2fcdad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5554
