reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-810878558-172.17.0.18-1595962165467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42597,DS-b399a6c0-03f3-474e-94a5-61c84f491658,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-ad5d622e-8531-4f5d-9a2b-f09e0ee222e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-943a624c-1b9a-41ca-baf4-295413fbcb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-97a588c6-800d-4c5e-ae6b-35611ff958d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-de18f132-f448-434c-8646-51bee7743396,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-71ac9d52-0237-4922-871d-74c39f5c60e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-c445f677-6034-4539-ab10-7088466ff97f,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-f6c8e5b9-4598-4654-866c-357883827749,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-810878558-172.17.0.18-1595962165467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42597,DS-b399a6c0-03f3-474e-94a5-61c84f491658,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-ad5d622e-8531-4f5d-9a2b-f09e0ee222e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-943a624c-1b9a-41ca-baf4-295413fbcb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-97a588c6-800d-4c5e-ae6b-35611ff958d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-de18f132-f448-434c-8646-51bee7743396,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-71ac9d52-0237-4922-871d-74c39f5c60e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-c445f677-6034-4539-ab10-7088466ff97f,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-f6c8e5b9-4598-4654-866c-357883827749,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1737881847-172.17.0.18-1595962426247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35394,DS-fef88f43-d70d-45d4-8e54-5e78d09cfc63,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-122147aa-4340-422f-80a5-01e051a7bcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-35d10871-7400-4597-996b-186a0282f024,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-b944b840-ae34-4fc7-a11a-eac7cc379ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-03bcb1a6-7bb5-4c85-a4aa-6b9c76c5d4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-acc89d9a-9404-4341-b4c0-e0f2e2d2ba9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-5d283cbc-1070-4d7e-92cf-300ab2e2752a,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-bde661b8-c982-40a5-86e4-e3a2ecabc7b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1737881847-172.17.0.18-1595962426247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35394,DS-fef88f43-d70d-45d4-8e54-5e78d09cfc63,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-122147aa-4340-422f-80a5-01e051a7bcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-35d10871-7400-4597-996b-186a0282f024,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-b944b840-ae34-4fc7-a11a-eac7cc379ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-03bcb1a6-7bb5-4c85-a4aa-6b9c76c5d4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-acc89d9a-9404-4341-b4c0-e0f2e2d2ba9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-5d283cbc-1070-4d7e-92cf-300ab2e2752a,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-bde661b8-c982-40a5-86e4-e3a2ecabc7b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2112053256-172.17.0.18-1595962531476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33842,DS-801bc0c2-fc67-49ec-955a-5e7c94f0afd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-220b4792-2ac1-4c73-9c6e-9c11c1706dec,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-8b17b1a4-45f3-4e5f-96ef-e99c8277916b,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-49f374d9-1889-4b78-a064-d6349e355e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-d555781e-1e79-4c55-8035-7828ad07f1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-5177da37-0868-4f18-9c9a-75cb4ea743f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-eb6d6838-697d-4d1a-8b10-4d4b5b4ad6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-aa0e2ef1-1437-415a-8b23-697e575cbc1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2112053256-172.17.0.18-1595962531476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33842,DS-801bc0c2-fc67-49ec-955a-5e7c94f0afd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-220b4792-2ac1-4c73-9c6e-9c11c1706dec,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-8b17b1a4-45f3-4e5f-96ef-e99c8277916b,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-49f374d9-1889-4b78-a064-d6349e355e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-d555781e-1e79-4c55-8035-7828ad07f1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-5177da37-0868-4f18-9c9a-75cb4ea743f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-eb6d6838-697d-4d1a-8b10-4d4b5b4ad6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-aa0e2ef1-1437-415a-8b23-697e575cbc1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588951092-172.17.0.18-1595962674541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37493,DS-b9b15233-0219-4570-ab38-9b82e1db7161,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-1935033d-566f-47d6-b61c-eb57d2dfdd00,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-2b12805a-a199-46a7-bbf8-a9bb6fdea7db,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-cc71527f-219b-4305-b42a-5b1375ed0f88,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-8fd64fd8-5bcd-4ca5-8e92-f99df8878aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-f7c34945-113d-4a66-b24d-29f2913c0f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-4b4bcd47-19af-49d7-8ccf-44c652b3a80d,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-5d6f5ece-fbb9-47e0-85fd-9507687941ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588951092-172.17.0.18-1595962674541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37493,DS-b9b15233-0219-4570-ab38-9b82e1db7161,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-1935033d-566f-47d6-b61c-eb57d2dfdd00,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-2b12805a-a199-46a7-bbf8-a9bb6fdea7db,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-cc71527f-219b-4305-b42a-5b1375ed0f88,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-8fd64fd8-5bcd-4ca5-8e92-f99df8878aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-f7c34945-113d-4a66-b24d-29f2913c0f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-4b4bcd47-19af-49d7-8ccf-44c652b3a80d,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-5d6f5ece-fbb9-47e0-85fd-9507687941ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951045855-172.17.0.18-1595962702984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34489,DS-c65b48fe-9060-46c5-9f6a-db051d4fc2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-ae35b375-4d47-4750-aff3-ee4571a54899,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-783563f2-de3c-4876-9ce8-4f80dae11874,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-0d6e738b-c8c0-4490-940c-3621ff6bd6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-06a92283-9328-44bf-a324-82ed7cda8256,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-5da18bd9-7093-450d-9ac1-b52e11fe332e,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-daeb5cfd-80ec-4f7a-9f51-0edd38cacc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-01eecd41-314f-4550-af73-323165653527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951045855-172.17.0.18-1595962702984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34489,DS-c65b48fe-9060-46c5-9f6a-db051d4fc2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-ae35b375-4d47-4750-aff3-ee4571a54899,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-783563f2-de3c-4876-9ce8-4f80dae11874,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-0d6e738b-c8c0-4490-940c-3621ff6bd6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-06a92283-9328-44bf-a324-82ed7cda8256,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-5da18bd9-7093-450d-9ac1-b52e11fe332e,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-daeb5cfd-80ec-4f7a-9f51-0edd38cacc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-01eecd41-314f-4550-af73-323165653527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1513432583-172.17.0.18-1595962773951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38430,DS-133f7e98-cc93-4b1b-ac65-a1a061d83ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-0f5609bb-6ab4-4c97-a36e-062fbf987c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-e9449a70-9bd8-461f-9bf8-603d471a3037,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-e7f05c33-9652-4dde-976e-be7b4e10c5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-02e60501-2800-465f-9c03-192793ca101d,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-22a63085-d599-40a4-9d6a-fce8b152ceea,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-8a06ec89-5c9b-4dce-b201-09be346e7ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-b910f9ed-1beb-41bb-b2ba-f24c73dfff17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1513432583-172.17.0.18-1595962773951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38430,DS-133f7e98-cc93-4b1b-ac65-a1a061d83ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-0f5609bb-6ab4-4c97-a36e-062fbf987c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-e9449a70-9bd8-461f-9bf8-603d471a3037,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-e7f05c33-9652-4dde-976e-be7b4e10c5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-02e60501-2800-465f-9c03-192793ca101d,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-22a63085-d599-40a4-9d6a-fce8b152ceea,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-8a06ec89-5c9b-4dce-b201-09be346e7ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-b910f9ed-1beb-41bb-b2ba-f24c73dfff17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239762782-172.17.0.18-1595963302233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33887,DS-2ee700a3-87c8-427a-a421-4467113c14db,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-72316319-3106-4566-9be7-5fbfeab4d3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-87644e16-f9e2-4d6d-b69e-feffd5a01d20,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-40ca89cb-043b-404b-8959-206ae1656550,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-b51b500c-32ad-481b-a05e-cca39652212e,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-247b5d33-d65d-4197-b45c-7265ce660d31,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-c90ac91e-b48c-4476-91ea-8d2f9f54d3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-fec22182-c228-4181-b1e9-cdc5788b6793,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239762782-172.17.0.18-1595963302233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33887,DS-2ee700a3-87c8-427a-a421-4467113c14db,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-72316319-3106-4566-9be7-5fbfeab4d3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-87644e16-f9e2-4d6d-b69e-feffd5a01d20,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-40ca89cb-043b-404b-8959-206ae1656550,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-b51b500c-32ad-481b-a05e-cca39652212e,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-247b5d33-d65d-4197-b45c-7265ce660d31,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-c90ac91e-b48c-4476-91ea-8d2f9f54d3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-fec22182-c228-4181-b1e9-cdc5788b6793,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-853552673-172.17.0.18-1595963409382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39059,DS-913a3b53-b5e0-4520-95ab-c0b3d55723d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-f0e60898-dce0-4960-b16c-e6bc83eb0811,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-48815b0a-b113-45fe-93f9-dc5ce585209e,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-818d4cf5-ab1b-4588-8af5-4f3116114748,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-4fecdc80-acae-44d2-82f8-72fcb71d33c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-0dc15265-8caf-4500-8e07-cebc7d9956f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-77052525-6ced-42a7-a3dc-b5ab2c11deef,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-2f73f8ec-501e-44e9-aede-aff9c2063e79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-853552673-172.17.0.18-1595963409382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39059,DS-913a3b53-b5e0-4520-95ab-c0b3d55723d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-f0e60898-dce0-4960-b16c-e6bc83eb0811,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-48815b0a-b113-45fe-93f9-dc5ce585209e,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-818d4cf5-ab1b-4588-8af5-4f3116114748,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-4fecdc80-acae-44d2-82f8-72fcb71d33c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-0dc15265-8caf-4500-8e07-cebc7d9956f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-77052525-6ced-42a7-a3dc-b5ab2c11deef,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-2f73f8ec-501e-44e9-aede-aff9c2063e79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1432575448-172.17.0.18-1595963506354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37864,DS-3aeb344b-be50-4833-8faf-58acfc00d77b,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-11c2cc4d-2d55-4d2f-b370-f62e1ce97f50,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-f8bcb2e2-f990-4962-ae4d-93ddfa037526,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-6d993402-45f1-47d3-9b7b-f9b9a37a381f,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-2ca179fa-6099-4d5a-9bc0-cb674f45d606,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-c970cbcc-b5c6-40bc-835e-889251adbd93,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-72c97606-b1a8-442b-af1b-e9d88a910480,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-99a77db8-f91f-4dd0-96bf-2bc4711c891b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1432575448-172.17.0.18-1595963506354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37864,DS-3aeb344b-be50-4833-8faf-58acfc00d77b,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-11c2cc4d-2d55-4d2f-b370-f62e1ce97f50,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-f8bcb2e2-f990-4962-ae4d-93ddfa037526,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-6d993402-45f1-47d3-9b7b-f9b9a37a381f,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-2ca179fa-6099-4d5a-9bc0-cb674f45d606,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-c970cbcc-b5c6-40bc-835e-889251adbd93,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-72c97606-b1a8-442b-af1b-e9d88a910480,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-99a77db8-f91f-4dd0-96bf-2bc4711c891b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1186622724-172.17.0.18-1595963811952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33782,DS-5a9282ef-5715-4045-b54d-fdc6b71095bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-95f9b363-bd90-4de6-9d38-21cd769f1996,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-c48473b3-2764-4490-b5ab-8373a2c51ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-bf92861e-ec12-470b-aeef-922c264bfcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-ad86758d-f641-4cde-8821-1b6a33e7639a,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-4c0f3caa-ae19-428f-b198-e802fbc4efbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-046507b1-ebeb-44a2-a947-ed582c47a189,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-7788ffac-ff8e-4407-84ff-812b2212bdab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1186622724-172.17.0.18-1595963811952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33782,DS-5a9282ef-5715-4045-b54d-fdc6b71095bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-95f9b363-bd90-4de6-9d38-21cd769f1996,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-c48473b3-2764-4490-b5ab-8373a2c51ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-bf92861e-ec12-470b-aeef-922c264bfcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-ad86758d-f641-4cde-8821-1b6a33e7639a,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-4c0f3caa-ae19-428f-b198-e802fbc4efbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-046507b1-ebeb-44a2-a947-ed582c47a189,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-7788ffac-ff8e-4407-84ff-812b2212bdab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1777377448-172.17.0.18-1595964379563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43388,DS-95757645-4604-4b30-84e1-901a9e7561a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-2d84a6db-15a3-4090-a1dd-47123746660f,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-28e4b76e-30a1-44b7-a0f9-079e8fde1d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-34d061c1-b609-45b6-9070-c526fbb414e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-7b2a9bf0-7c40-4cbe-953a-8ea18213fb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-07d46e2a-3d04-49d0-ba48-7840d5dca210,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-aac18933-af4b-40a4-a4db-a33185cf8974,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-97a3198f-6ab1-40b2-8495-a089deafc438,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1777377448-172.17.0.18-1595964379563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43388,DS-95757645-4604-4b30-84e1-901a9e7561a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-2d84a6db-15a3-4090-a1dd-47123746660f,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-28e4b76e-30a1-44b7-a0f9-079e8fde1d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-34d061c1-b609-45b6-9070-c526fbb414e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-7b2a9bf0-7c40-4cbe-953a-8ea18213fb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-07d46e2a-3d04-49d0-ba48-7840d5dca210,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-aac18933-af4b-40a4-a4db-a33185cf8974,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-97a3198f-6ab1-40b2-8495-a089deafc438,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1375322300-172.17.0.18-1595964551468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46587,DS-bfb07c3d-381c-47a8-b5df-1141aba657f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-d8570d14-afe4-4431-908d-2f8795ce8f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-aee84493-89a7-4df4-872b-75318e636c69,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-a1b90ebf-ff0d-4afc-9692-55de26ff6b61,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-a17b72b2-9980-43d5-bffe-2d43695b25a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-58413579-de4a-462f-bf86-4d5431639c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-57a82d26-f1b0-49df-8e56-207ad0d5befb,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-10dd6678-2619-474e-8a28-48be10a0f0ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1375322300-172.17.0.18-1595964551468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46587,DS-bfb07c3d-381c-47a8-b5df-1141aba657f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-d8570d14-afe4-4431-908d-2f8795ce8f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-aee84493-89a7-4df4-872b-75318e636c69,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-a1b90ebf-ff0d-4afc-9692-55de26ff6b61,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-a17b72b2-9980-43d5-bffe-2d43695b25a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-58413579-de4a-462f-bf86-4d5431639c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-57a82d26-f1b0-49df-8e56-207ad0d5befb,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-10dd6678-2619-474e-8a28-48be10a0f0ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46636383-172.17.0.18-1595964620498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44049,DS-5cf0155f-6fec-4f1a-8d6e-4c4010390249,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-d3ef1d59-01be-4c9e-81ae-5b5132be8e13,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-6dfd48a9-6c8b-4085-8dfa-4e6b8667cdca,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-f8d3c288-e641-4641-9a29-c57eeccdff2e,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-50daf702-d675-4864-b21d-a7f1ed3de6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-da4c4461-30a0-4925-a523-45f6a4c28993,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-c5980d87-6e6a-4a19-bcbb-3fc3160093f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-5f353023-3948-481e-9767-5944938d1ad8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46636383-172.17.0.18-1595964620498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44049,DS-5cf0155f-6fec-4f1a-8d6e-4c4010390249,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-d3ef1d59-01be-4c9e-81ae-5b5132be8e13,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-6dfd48a9-6c8b-4085-8dfa-4e6b8667cdca,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-f8d3c288-e641-4641-9a29-c57eeccdff2e,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-50daf702-d675-4864-b21d-a7f1ed3de6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-da4c4461-30a0-4925-a523-45f6a4c28993,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-c5980d87-6e6a-4a19-bcbb-3fc3160093f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-5f353023-3948-481e-9767-5944938d1ad8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1870900073-172.17.0.18-1595965137397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45282,DS-54d4dd29-e65c-483b-a2d0-5072e2308cef,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-ae362ee0-858b-4d4e-aab6-cc3d3ac83ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-86b85028-1f85-42c8-9772-a50240088615,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-96976944-5b3a-491a-8227-73637b57fcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-40f4372d-81f2-4859-9c66-93f954cc2f41,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-cbc3afd0-1b23-43f0-b722-2314b46b7600,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-5514d28f-38f9-4ade-8abd-9592effdf543,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-f2e43a4a-4a3e-4eea-ba6e-79949704451b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1870900073-172.17.0.18-1595965137397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45282,DS-54d4dd29-e65c-483b-a2d0-5072e2308cef,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-ae362ee0-858b-4d4e-aab6-cc3d3ac83ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-86b85028-1f85-42c8-9772-a50240088615,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-96976944-5b3a-491a-8227-73637b57fcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-40f4372d-81f2-4859-9c66-93f954cc2f41,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-cbc3afd0-1b23-43f0-b722-2314b46b7600,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-5514d28f-38f9-4ade-8abd-9592effdf543,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-f2e43a4a-4a3e-4eea-ba6e-79949704451b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1100819040-172.17.0.18-1595965553080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44379,DS-616b8e41-f3ac-4872-863f-20a576f280ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-dbaa530a-acbf-480f-b9ad-2d85801905dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-07bd5642-46cb-477e-8107-c976655b0ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-20a6e70b-fe92-4ab5-b4d9-05b0422b4d22,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-4d185a9f-e1c1-4d1b-9094-5a3f99f3c8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-12192ad7-2610-4ec8-ab7f-bfbd58fe8e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-da757838-1097-40ac-8c1c-4f57499be9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-0ba00072-b6f8-49aa-b33d-4e120411dc8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1100819040-172.17.0.18-1595965553080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44379,DS-616b8e41-f3ac-4872-863f-20a576f280ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-dbaa530a-acbf-480f-b9ad-2d85801905dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-07bd5642-46cb-477e-8107-c976655b0ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-20a6e70b-fe92-4ab5-b4d9-05b0422b4d22,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-4d185a9f-e1c1-4d1b-9094-5a3f99f3c8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-12192ad7-2610-4ec8-ab7f-bfbd58fe8e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-da757838-1097-40ac-8c1c-4f57499be9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-0ba00072-b6f8-49aa-b33d-4e120411dc8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1040030623-172.17.0.18-1595965614763:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38184,DS-022d9b47-7f21-4133-bcdd-15befe9ff117,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-64173de2-7f01-4edb-8b68-41da4d7ef81c,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-c3f2988c-c25a-40ae-a2fe-b4e5107f09e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-1a7d0df5-bc19-40a9-b468-66390fec2b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-46400542-3ed7-424f-83f9-046c6244964a,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-c4f47ca3-35b9-4aee-9650-837ca975b917,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-28896f6e-3ad3-4e63-a82c-d97f36996e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-9977550b-e743-4c5e-b485-d9da576202c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1040030623-172.17.0.18-1595965614763:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38184,DS-022d9b47-7f21-4133-bcdd-15befe9ff117,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-64173de2-7f01-4edb-8b68-41da4d7ef81c,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-c3f2988c-c25a-40ae-a2fe-b4e5107f09e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-1a7d0df5-bc19-40a9-b468-66390fec2b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-46400542-3ed7-424f-83f9-046c6244964a,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-c4f47ca3-35b9-4aee-9650-837ca975b917,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-28896f6e-3ad3-4e63-a82c-d97f36996e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-9977550b-e743-4c5e-b485-d9da576202c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1877626624-172.17.0.18-1595965641777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35531,DS-d0f53cda-f519-4980-a91d-087906aca21e,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-9d47f634-32e3-4870-9f67-e82175084043,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-42318f14-d979-4a77-8f0e-6e2d57abebbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-dbf4ccb3-bcbf-4b7f-aa1c-ff88cc1aa9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-f15a56fe-3a2d-4384-b3dc-b7efb309038b,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-ddbf3083-4954-4eb1-8c22-b6ed77551213,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-4bfc96d6-61c4-4d19-9870-e7711b71aaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-7fc2a234-53e3-4984-8eee-2a8494fa0b65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1877626624-172.17.0.18-1595965641777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35531,DS-d0f53cda-f519-4980-a91d-087906aca21e,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-9d47f634-32e3-4870-9f67-e82175084043,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-42318f14-d979-4a77-8f0e-6e2d57abebbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-dbf4ccb3-bcbf-4b7f-aa1c-ff88cc1aa9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-f15a56fe-3a2d-4384-b3dc-b7efb309038b,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-ddbf3083-4954-4eb1-8c22-b6ed77551213,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-4bfc96d6-61c4-4d19-9870-e7711b71aaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-7fc2a234-53e3-4984-8eee-2a8494fa0b65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701827778-172.17.0.18-1595965986634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45896,DS-33d60dc4-c187-4834-b458-cb2975faaec0,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-785a5fae-b735-48ab-a2bf-f25669a712d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-478a3d2f-b207-402c-89b2-e639361f7ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-fa275828-153a-43b4-8999-f9370ac2faa5,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-4cce2135-169a-41c3-bf73-1e62c39c56c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-b1e6fafd-e849-4f90-9898-836d7a1ad155,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-4f339b58-7f3b-451a-88e9-9b0fd0160f95,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-cd01b204-7f3a-4331-b202-5e4521cef57c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701827778-172.17.0.18-1595965986634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45896,DS-33d60dc4-c187-4834-b458-cb2975faaec0,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-785a5fae-b735-48ab-a2bf-f25669a712d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-478a3d2f-b207-402c-89b2-e639361f7ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-fa275828-153a-43b4-8999-f9370ac2faa5,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-4cce2135-169a-41c3-bf73-1e62c39c56c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-b1e6fafd-e849-4f90-9898-836d7a1ad155,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-4f339b58-7f3b-451a-88e9-9b0fd0160f95,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-cd01b204-7f3a-4331-b202-5e4521cef57c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1982506003-172.17.0.18-1595966824140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42572,DS-bf3c0a28-49ab-4f0d-a1be-e74df6d056e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-3946b188-11fa-4985-bb9a-962e8948627b,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-96354b40-770e-41b7-9a49-638f014270ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-23e5dc9a-613c-4151-ab71-9d0a3b711216,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-14c95eea-1c98-4f6f-9c80-ac7e4117d465,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-546979f2-8533-426f-a648-b028ba9032d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-4f256c77-a646-42d0-99a8-6750e5657151,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-d701307b-f2e3-4511-be23-d21333e91475,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1982506003-172.17.0.18-1595966824140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42572,DS-bf3c0a28-49ab-4f0d-a1be-e74df6d056e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-3946b188-11fa-4985-bb9a-962e8948627b,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-96354b40-770e-41b7-9a49-638f014270ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-23e5dc9a-613c-4151-ab71-9d0a3b711216,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-14c95eea-1c98-4f6f-9c80-ac7e4117d465,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-546979f2-8533-426f-a648-b028ba9032d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-4f256c77-a646-42d0-99a8-6750e5657151,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-d701307b-f2e3-4511-be23-d21333e91475,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-275533983-172.17.0.18-1595966883599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40055,DS-c82e0208-43db-4028-99a6-562800c7c0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-638374d8-d875-4d67-9f59-676ab5de112e,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-ca4389eb-3dba-42f8-9919-8cfe34e1d122,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-952af119-678d-4d13-9360-7e170bdee68d,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-2289d587-3a66-4ec9-b89a-fbebea47524b,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-8978a5cd-092f-468f-9e26-e964b95c590e,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-aedd3bfe-281e-4e71-b610-043493ae1c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-6f3ef89f-ad75-4b2b-90f5-79c8c61e1634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-275533983-172.17.0.18-1595966883599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40055,DS-c82e0208-43db-4028-99a6-562800c7c0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-638374d8-d875-4d67-9f59-676ab5de112e,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-ca4389eb-3dba-42f8-9919-8cfe34e1d122,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-952af119-678d-4d13-9360-7e170bdee68d,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-2289d587-3a66-4ec9-b89a-fbebea47524b,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-8978a5cd-092f-468f-9e26-e964b95c590e,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-aedd3bfe-281e-4e71-b610-043493ae1c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-6f3ef89f-ad75-4b2b-90f5-79c8c61e1634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-719828389-172.17.0.18-1595967083434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33013,DS-4592d981-73b2-4e23-b3af-e7f6ad8cc567,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-ed0bd84a-b1b3-44f1-baca-68facc88884c,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-6bfecd0d-7c1e-40ce-9044-1d24ff62518d,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-cc4c6120-a77c-43b7-9ddb-206d36c3b4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-e55b0c19-2723-49e1-a576-b91c71f70b56,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-46060a66-6187-4a07-9bc3-40ebc5af65d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-2afd3b6b-b1d9-4086-afaa-31ba6754f247,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-2b296fd5-d4fb-45a7-be13-4ca55bfb13fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-719828389-172.17.0.18-1595967083434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33013,DS-4592d981-73b2-4e23-b3af-e7f6ad8cc567,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-ed0bd84a-b1b3-44f1-baca-68facc88884c,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-6bfecd0d-7c1e-40ce-9044-1d24ff62518d,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-cc4c6120-a77c-43b7-9ddb-206d36c3b4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-e55b0c19-2723-49e1-a576-b91c71f70b56,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-46060a66-6187-4a07-9bc3-40ebc5af65d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-2afd3b6b-b1d9-4086-afaa-31ba6754f247,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-2b296fd5-d4fb-45a7-be13-4ca55bfb13fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5239
