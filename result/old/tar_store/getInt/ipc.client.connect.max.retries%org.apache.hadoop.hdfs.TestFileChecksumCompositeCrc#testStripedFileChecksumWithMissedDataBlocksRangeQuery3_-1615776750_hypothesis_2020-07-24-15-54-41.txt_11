reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348197277-172.17.0.21-1595606251093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44720,DS-5e1c35a0-bbe6-4b6f-9a46-db9b94bc92d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-fede6d85-ab32-4937-a97a-2ac0bb7e204a,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-89569d64-929c-40fa-b201-ecc2a86f5ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-aff716ab-8f20-4b97-95f4-e45ff145607c,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-c11cf1ef-ee9e-46ff-b4d8-61a21c21dc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-1ab96078-58ea-4262-8579-97c04c353a74,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-d0316174-ee02-4aa5-8fbe-4657eb1e3cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-a53ba89c-e7ba-45ff-b185-504c64d7a9fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348197277-172.17.0.21-1595606251093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44720,DS-5e1c35a0-bbe6-4b6f-9a46-db9b94bc92d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-fede6d85-ab32-4937-a97a-2ac0bb7e204a,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-89569d64-929c-40fa-b201-ecc2a86f5ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-aff716ab-8f20-4b97-95f4-e45ff145607c,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-c11cf1ef-ee9e-46ff-b4d8-61a21c21dc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-1ab96078-58ea-4262-8579-97c04c353a74,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-d0316174-ee02-4aa5-8fbe-4657eb1e3cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-a53ba89c-e7ba-45ff-b185-504c64d7a9fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-466236210-172.17.0.21-1595606486401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33658,DS-70246ba5-7f1f-44b0-927e-003414349ead,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-d7835360-69dd-4a84-9067-a2a948a6fee4,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-3bc4456f-3dc1-4f1f-924e-34f24a985fca,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-185f910e-b167-4018-90a6-c8c6d829d1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-78a22788-b5bd-4ed4-9c3f-532f4ed190d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36240,DS-a4a0eb1d-bfc5-4b3d-94e7-f2090ff422b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-aa09585c-f897-4063-be74-e193c7afda4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-682095a9-3b26-4e09-9501-70f37c3740ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-466236210-172.17.0.21-1595606486401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33658,DS-70246ba5-7f1f-44b0-927e-003414349ead,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-d7835360-69dd-4a84-9067-a2a948a6fee4,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-3bc4456f-3dc1-4f1f-924e-34f24a985fca,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-185f910e-b167-4018-90a6-c8c6d829d1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-78a22788-b5bd-4ed4-9c3f-532f4ed190d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36240,DS-a4a0eb1d-bfc5-4b3d-94e7-f2090ff422b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-aa09585c-f897-4063-be74-e193c7afda4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-682095a9-3b26-4e09-9501-70f37c3740ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171465723-172.17.0.21-1595606770318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35234,DS-57f1501f-ff48-4af1-b6e0-e3e9a27dcb61,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-129e4d81-884c-4c59-8eb0-a4bf9dad8db7,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-061b4718-3826-4d00-a46f-0e7f89b3fbab,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-437880cb-05bb-48ad-bce3-19fc72f52764,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-ef35bb92-b6a3-473f-90f1-78ce3fa0914c,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-74567a19-8646-4663-8e08-b3acce183c97,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-29c9641a-d9f8-4dff-9a30-09d162114ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-e4b49a4a-ae5c-4b63-bc0a-fbd40b91eace,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171465723-172.17.0.21-1595606770318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35234,DS-57f1501f-ff48-4af1-b6e0-e3e9a27dcb61,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-129e4d81-884c-4c59-8eb0-a4bf9dad8db7,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-061b4718-3826-4d00-a46f-0e7f89b3fbab,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-437880cb-05bb-48ad-bce3-19fc72f52764,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-ef35bb92-b6a3-473f-90f1-78ce3fa0914c,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-74567a19-8646-4663-8e08-b3acce183c97,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-29c9641a-d9f8-4dff-9a30-09d162114ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-e4b49a4a-ae5c-4b63-bc0a-fbd40b91eace,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484578566-172.17.0.21-1595606957494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38674,DS-41e7b352-4bed-40a0-a62e-cbc63f9f080e,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-31c13250-bef8-4dae-9527-beb61d5c09c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-b8063830-8324-4713-9cd0-d6d837f148d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-0c6a3410-e078-43e9-b5e7-8ad563a64992,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-82e8db47-009c-4636-815a-a8717473b4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-0c55dfa6-d906-4c66-877f-912647d701df,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-34128eb5-e009-48a6-8571-a2bf89e52659,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-3b5bd343-a9d0-4976-a1ff-def8fa1e5ad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484578566-172.17.0.21-1595606957494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38674,DS-41e7b352-4bed-40a0-a62e-cbc63f9f080e,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-31c13250-bef8-4dae-9527-beb61d5c09c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-b8063830-8324-4713-9cd0-d6d837f148d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-0c6a3410-e078-43e9-b5e7-8ad563a64992,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-82e8db47-009c-4636-815a-a8717473b4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-0c55dfa6-d906-4c66-877f-912647d701df,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-34128eb5-e009-48a6-8571-a2bf89e52659,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-3b5bd343-a9d0-4976-a1ff-def8fa1e5ad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-708869704-172.17.0.21-1595607115555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35565,DS-18e38abb-434a-4c77-b75d-dde292d88523,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-077a2434-45b4-468d-b552-56e883d12822,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-7371e972-6619-452b-8e21-80587ed1b03a,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-2f2b637f-400c-4e2f-9fe6-bdcb5f0a8cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-574092e3-9008-4308-b351-78daf83d315a,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-8c510c33-218b-40a5-8ae9-9550fb92fddd,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-305d32c5-1a78-458c-a4e7-10d2fad712e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-6f23f9fc-af52-4a62-84f3-5f1a4a43c4a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-708869704-172.17.0.21-1595607115555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35565,DS-18e38abb-434a-4c77-b75d-dde292d88523,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-077a2434-45b4-468d-b552-56e883d12822,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-7371e972-6619-452b-8e21-80587ed1b03a,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-2f2b637f-400c-4e2f-9fe6-bdcb5f0a8cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-574092e3-9008-4308-b351-78daf83d315a,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-8c510c33-218b-40a5-8ae9-9550fb92fddd,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-305d32c5-1a78-458c-a4e7-10d2fad712e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-6f23f9fc-af52-4a62-84f3-5f1a4a43c4a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1273417594-172.17.0.21-1595607556260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44594,DS-4bbbc8e5-ffcf-432c-9f24-515e624da29d,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-62d6a83c-b0fc-42e3-b0e8-a5a638c930ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-ad4c2a4e-2759-4e2c-a230-2d2f9bb61367,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-6537dc6f-c996-4dc3-ae87-e3a04754b8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-d909837d-a962-40a8-887e-4cfbd8eaaf29,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-d951780f-5d84-43f8-af57-3d089fc6ccd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-84d633e1-827a-4712-abac-de4595983c72,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-13d742da-505a-466d-99f5-ba1a2a62fd3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1273417594-172.17.0.21-1595607556260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44594,DS-4bbbc8e5-ffcf-432c-9f24-515e624da29d,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-62d6a83c-b0fc-42e3-b0e8-a5a638c930ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-ad4c2a4e-2759-4e2c-a230-2d2f9bb61367,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-6537dc6f-c996-4dc3-ae87-e3a04754b8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-d909837d-a962-40a8-887e-4cfbd8eaaf29,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-d951780f-5d84-43f8-af57-3d089fc6ccd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-84d633e1-827a-4712-abac-de4595983c72,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-13d742da-505a-466d-99f5-ba1a2a62fd3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541916670-172.17.0.21-1595607682268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41876,DS-4f3576c9-daf4-4983-9d78-ae9af02e8732,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-83d9b892-46fe-4695-bb60-ddeb48058ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-c2a69de7-5a83-4dea-9f6c-046e55bb2e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-f52235e9-1157-4e52-ae4a-18ae5a9969d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-aac078df-059f-4e40-b230-95e1a5685124,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-ccfe84e4-5238-4fce-a371-e349e5417677,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-ede3f608-82cb-4404-98d4-02c998efff2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-07de0b5d-969e-41ba-84a8-c8ba0dc187e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541916670-172.17.0.21-1595607682268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41876,DS-4f3576c9-daf4-4983-9d78-ae9af02e8732,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-83d9b892-46fe-4695-bb60-ddeb48058ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-c2a69de7-5a83-4dea-9f6c-046e55bb2e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-f52235e9-1157-4e52-ae4a-18ae5a9969d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-aac078df-059f-4e40-b230-95e1a5685124,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-ccfe84e4-5238-4fce-a371-e349e5417677,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-ede3f608-82cb-4404-98d4-02c998efff2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-07de0b5d-969e-41ba-84a8-c8ba0dc187e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975217362-172.17.0.21-1595608002811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44439,DS-239278fa-16f4-4132-9d2d-d0a7a586435b,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-489b7e42-4e0c-497a-9620-624a23872688,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-51ebd534-f29a-4582-ba68-032b8f332037,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-d55fe041-990b-483a-9df6-31089df15e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-c1e9118e-0a6a-4608-bb00-dc5121a7e6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-e1129c7a-3189-4d6e-9bef-32408e4f09f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-9d47db7c-4839-4a6a-b357-1833256e511a,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-d57876ad-d807-4932-8d9c-e5367c03fcaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975217362-172.17.0.21-1595608002811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44439,DS-239278fa-16f4-4132-9d2d-d0a7a586435b,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-489b7e42-4e0c-497a-9620-624a23872688,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-51ebd534-f29a-4582-ba68-032b8f332037,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-d55fe041-990b-483a-9df6-31089df15e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-c1e9118e-0a6a-4608-bb00-dc5121a7e6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-e1129c7a-3189-4d6e-9bef-32408e4f09f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-9d47db7c-4839-4a6a-b357-1833256e511a,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-d57876ad-d807-4932-8d9c-e5367c03fcaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1530880388-172.17.0.21-1595608041279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45484,DS-fc926cae-0ca0-4428-ac4a-bc8e9779151c,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-9221f8c5-5ed0-4863-b12f-1d336a574cae,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-57b835ca-86f7-4650-8036-73032360ec39,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-71add578-3990-4ac5-aedc-e9fc452a4ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-6dcfac7d-81b9-4571-976b-6eee7129a4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-50ae18fe-1671-4a8d-b5de-7aa0917f9ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-ce068487-fb9f-41f4-8140-cb363c71ac43,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-19d964f5-2db3-47ac-8469-b59948cd35d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1530880388-172.17.0.21-1595608041279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45484,DS-fc926cae-0ca0-4428-ac4a-bc8e9779151c,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-9221f8c5-5ed0-4863-b12f-1d336a574cae,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-57b835ca-86f7-4650-8036-73032360ec39,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-71add578-3990-4ac5-aedc-e9fc452a4ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-6dcfac7d-81b9-4571-976b-6eee7129a4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-50ae18fe-1671-4a8d-b5de-7aa0917f9ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-ce068487-fb9f-41f4-8140-cb363c71ac43,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-19d964f5-2db3-47ac-8469-b59948cd35d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484690304-172.17.0.21-1595608308697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32909,DS-86594199-fea1-427a-b368-ccdad307fed6,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-a78820e6-b481-4892-bf1b-bab4112f0df8,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-dccbd04c-f459-4489-8531-785ac79c9340,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-d03e8065-a883-4cb4-82e8-23fa9d5415b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-f6807652-670d-434b-8f04-605792532c07,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-568e8a1c-8c04-4b08-9b61-57ffb94ecbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-f94cea2d-c202-4a0d-b455-f484ff6e0508,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-f6978f87-606a-474b-b64b-76e88a44d57e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484690304-172.17.0.21-1595608308697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32909,DS-86594199-fea1-427a-b368-ccdad307fed6,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-a78820e6-b481-4892-bf1b-bab4112f0df8,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-dccbd04c-f459-4489-8531-785ac79c9340,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-d03e8065-a883-4cb4-82e8-23fa9d5415b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-f6807652-670d-434b-8f04-605792532c07,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-568e8a1c-8c04-4b08-9b61-57ffb94ecbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-f94cea2d-c202-4a0d-b455-f484ff6e0508,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-f6978f87-606a-474b-b64b-76e88a44d57e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718101275-172.17.0.21-1595608757963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42273,DS-9131f2d6-abc9-4437-9f64-e021208f77e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-eb5b1f99-3e06-40ce-8036-f6d1e82112c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-0f55c5b1-2409-404a-bab4-45296bb88814,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-8c2dbf0e-1012-4bc2-b4f2-de385137f50b,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-7ea0fc6f-3ed0-4819-b256-00395f18199e,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-7db3cd45-8ca4-4f22-9e7a-c51d2152c2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-93b779cc-344d-40e0-a460-0cd313a6e77c,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-da866594-1bf7-4bd7-9919-6c04ee04e620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718101275-172.17.0.21-1595608757963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42273,DS-9131f2d6-abc9-4437-9f64-e021208f77e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-eb5b1f99-3e06-40ce-8036-f6d1e82112c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-0f55c5b1-2409-404a-bab4-45296bb88814,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-8c2dbf0e-1012-4bc2-b4f2-de385137f50b,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-7ea0fc6f-3ed0-4819-b256-00395f18199e,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-7db3cd45-8ca4-4f22-9e7a-c51d2152c2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-93b779cc-344d-40e0-a460-0cd313a6e77c,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-da866594-1bf7-4bd7-9919-6c04ee04e620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470585184-172.17.0.21-1595609064598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44120,DS-28392ade-51e6-4c26-86ea-00d88cead0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-98bd7d28-23c7-457e-a8b5-5d7c69616042,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-cf5f436e-d54e-4907-ab30-3aba8d0af6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-c2b1d869-d857-45b3-adf7-170daeda2d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-586b6a86-172f-4a03-b079-d1ac3fbff04f,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-a4b434bf-48cd-4ae5-a6e1-178b4e82d881,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-ca1ced06-50d2-4928-be9e-a5c48572146b,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-7056445f-b475-426d-8588-a759036410e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470585184-172.17.0.21-1595609064598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44120,DS-28392ade-51e6-4c26-86ea-00d88cead0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-98bd7d28-23c7-457e-a8b5-5d7c69616042,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-cf5f436e-d54e-4907-ab30-3aba8d0af6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-c2b1d869-d857-45b3-adf7-170daeda2d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-586b6a86-172f-4a03-b079-d1ac3fbff04f,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-a4b434bf-48cd-4ae5-a6e1-178b4e82d881,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-ca1ced06-50d2-4928-be9e-a5c48572146b,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-7056445f-b475-426d-8588-a759036410e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973236361-172.17.0.21-1595609685850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37436,DS-5d992673-88c5-41ae-a11e-3deadcae3320,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-7170d3b1-7633-4301-9e8c-4fd613e71d96,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-dbc00398-3569-4e7f-b06d-ddbd2f13c8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-9ca65dcb-e3b6-499d-99e7-13d2161f7903,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-fbc7f4f8-6b88-45f0-a02a-67ed1ffd812c,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-3c3f13d5-e9f6-4fe4-9475-b2c95a303c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-3a283715-eb8f-490e-a288-9bf853460a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-b63668a0-dfed-4669-9708-9e3a8005b79d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973236361-172.17.0.21-1595609685850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37436,DS-5d992673-88c5-41ae-a11e-3deadcae3320,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-7170d3b1-7633-4301-9e8c-4fd613e71d96,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-dbc00398-3569-4e7f-b06d-ddbd2f13c8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-9ca65dcb-e3b6-499d-99e7-13d2161f7903,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-fbc7f4f8-6b88-45f0-a02a-67ed1ffd812c,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-3c3f13d5-e9f6-4fe4-9475-b2c95a303c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-3a283715-eb8f-490e-a288-9bf853460a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-b63668a0-dfed-4669-9708-9e3a8005b79d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504657996-172.17.0.21-1595609986746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40730,DS-2d94776b-742c-4438-bd67-aec4aecacb30,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-0934a8dd-088a-4348-bd38-ee483edcb205,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-75ab6a2d-05ed-488d-a8d4-719b5c23fac2,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-c3fe96ae-02f1-4072-a01e-ef60c78585b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-3eb41eac-61d3-4a74-b855-dd570505f9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-6de04f51-33ea-464a-b8f6-6063d3f3f551,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-8c13411f-8cbc-4e6f-bd9c-cf12bb512297,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-4df72230-d86e-47fd-a380-5c2b401f2a13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504657996-172.17.0.21-1595609986746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40730,DS-2d94776b-742c-4438-bd67-aec4aecacb30,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-0934a8dd-088a-4348-bd38-ee483edcb205,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-75ab6a2d-05ed-488d-a8d4-719b5c23fac2,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-c3fe96ae-02f1-4072-a01e-ef60c78585b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-3eb41eac-61d3-4a74-b855-dd570505f9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-6de04f51-33ea-464a-b8f6-6063d3f3f551,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-8c13411f-8cbc-4e6f-bd9c-cf12bb512297,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-4df72230-d86e-47fd-a380-5c2b401f2a13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-384459170-172.17.0.21-1595610063227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34557,DS-40c574e0-e999-492a-8122-7b2d0b3cc0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-ade1d33b-a625-4251-a74c-1938c0cace85,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-2b8ab3dd-e8b6-44a7-9250-05007fd7555f,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-639daf32-0157-463f-aa10-d610f4267d36,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-984a1e3a-cacd-479f-8621-4aa0a02a0217,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-e4c3ecd5-2544-4949-85d6-d60a72bc3cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-5f0c86a7-aefd-4904-bc79-5759a9266db4,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-aceaf1cf-a44d-4a2f-92fa-e034301efe7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-384459170-172.17.0.21-1595610063227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34557,DS-40c574e0-e999-492a-8122-7b2d0b3cc0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-ade1d33b-a625-4251-a74c-1938c0cace85,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-2b8ab3dd-e8b6-44a7-9250-05007fd7555f,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-639daf32-0157-463f-aa10-d610f4267d36,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-984a1e3a-cacd-479f-8621-4aa0a02a0217,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-e4c3ecd5-2544-4949-85d6-d60a72bc3cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-5f0c86a7-aefd-4904-bc79-5759a9266db4,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-aceaf1cf-a44d-4a2f-92fa-e034301efe7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454322645-172.17.0.21-1595610696650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33382,DS-9e98ef4b-8e3c-402f-b69c-cc5353c87ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-babbdb3e-f053-40f8-bbf0-1cafbc30f303,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-23d37184-0ce8-47e4-a791-cb2a7b2013c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-fb3b932e-3135-4ce9-b2d0-844c34944af9,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-d73a5401-3de1-4e13-af52-c1eb713b13f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-b97eb667-d867-48ac-b68a-b5fa5d3fc8df,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-f370a46a-265c-4324-a2e5-dd9a2483308e,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-50f594e4-2e5d-4f5c-866c-114132151d47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454322645-172.17.0.21-1595610696650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33382,DS-9e98ef4b-8e3c-402f-b69c-cc5353c87ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-babbdb3e-f053-40f8-bbf0-1cafbc30f303,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-23d37184-0ce8-47e4-a791-cb2a7b2013c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-fb3b932e-3135-4ce9-b2d0-844c34944af9,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-d73a5401-3de1-4e13-af52-c1eb713b13f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-b97eb667-d867-48ac-b68a-b5fa5d3fc8df,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-f370a46a-265c-4324-a2e5-dd9a2483308e,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-50f594e4-2e5d-4f5c-866c-114132151d47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 4929
