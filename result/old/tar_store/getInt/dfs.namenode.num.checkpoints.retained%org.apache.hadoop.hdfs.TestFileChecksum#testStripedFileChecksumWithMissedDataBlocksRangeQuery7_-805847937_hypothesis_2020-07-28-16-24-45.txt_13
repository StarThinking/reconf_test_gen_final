reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-97874328-172.17.0.18-1595953541365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39746,DS-efae76ca-8da7-43ac-a0b2-af9a6eecec32,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-f7cbcee6-e9c7-4590-acf0-85f700cf88c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-f0faebc4-39f2-4c37-bc79-69a8f7172e18,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-269adbf0-6bd5-4c2d-9104-f0c6a5c0d2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-db6a797e-8b37-4c2a-b4fb-591ae8b89f42,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-e83ae9af-119d-4b5a-8bc7-ae57b88303ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-998cb3ee-c575-45e0-ab70-fe467d6357ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-e9bddd80-352f-4e02-ab85-be2f947e912b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-97874328-172.17.0.18-1595953541365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39746,DS-efae76ca-8da7-43ac-a0b2-af9a6eecec32,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-f7cbcee6-e9c7-4590-acf0-85f700cf88c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-f0faebc4-39f2-4c37-bc79-69a8f7172e18,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-269adbf0-6bd5-4c2d-9104-f0c6a5c0d2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-db6a797e-8b37-4c2a-b4fb-591ae8b89f42,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-e83ae9af-119d-4b5a-8bc7-ae57b88303ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-998cb3ee-c575-45e0-ab70-fe467d6357ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-e9bddd80-352f-4e02-ab85-be2f947e912b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1464075600-172.17.0.18-1595953578649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37878,DS-9fb6e2bc-9701-4417-bbfc-78e02e69a1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-09846c6d-2b63-4748-92ab-1ea249c96b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-e622403b-d7b3-4336-a7ef-29f0292d0960,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-5f578322-cdf2-4237-b711-60316561813c,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-200c3ae4-5a41-45b1-b573-8f82beee0c53,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-87efdf2c-acfd-4a27-b8b0-7ec2844a706f,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-932602fe-60e7-4dae-8a7a-a05d77439fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-b9fef537-7953-484f-b0d7-141d4ed57c2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1464075600-172.17.0.18-1595953578649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37878,DS-9fb6e2bc-9701-4417-bbfc-78e02e69a1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-09846c6d-2b63-4748-92ab-1ea249c96b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-e622403b-d7b3-4336-a7ef-29f0292d0960,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-5f578322-cdf2-4237-b711-60316561813c,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-200c3ae4-5a41-45b1-b573-8f82beee0c53,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-87efdf2c-acfd-4a27-b8b0-7ec2844a706f,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-932602fe-60e7-4dae-8a7a-a05d77439fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-b9fef537-7953-484f-b0d7-141d4ed57c2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1946975418-172.17.0.18-1595953801026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37513,DS-b7b3e2ea-36be-45f3-bf8d-bb01a88cc624,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-18e25e91-f45f-4385-a2fe-c6ca0f89c2df,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-ba2394b0-86e7-4a10-833c-aa9ec621f3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-81c3375f-0b16-4437-858d-0d2321bc56ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-2ea36b07-e540-4fcc-a1e3-3fc2868cb9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-be095603-f34d-48c1-8ddc-9f5c0fbb10d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-a678790d-072b-4ba0-8028-436d7d0f7562,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-c20d4236-b015-4f01-af84-7a72a9997d05,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1946975418-172.17.0.18-1595953801026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37513,DS-b7b3e2ea-36be-45f3-bf8d-bb01a88cc624,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-18e25e91-f45f-4385-a2fe-c6ca0f89c2df,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-ba2394b0-86e7-4a10-833c-aa9ec621f3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-81c3375f-0b16-4437-858d-0d2321bc56ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-2ea36b07-e540-4fcc-a1e3-3fc2868cb9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-be095603-f34d-48c1-8ddc-9f5c0fbb10d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-a678790d-072b-4ba0-8028-436d7d0f7562,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-c20d4236-b015-4f01-af84-7a72a9997d05,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685727001-172.17.0.18-1595953873258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33672,DS-e9011e96-8e47-4fd7-9e36-a284bf0747ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-733926ad-6991-4193-ac3b-7e7e06f83949,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-9c271691-1f5e-4c7e-b0da-cf96b4858ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-726223ad-9767-4c4a-a317-38ca28559a42,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-7fa6d7de-b2a9-4532-a3ef-89d6d109def5,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-8ca469db-3db2-4cb7-afbc-cce74035c3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-b44405bc-8632-46c9-b51e-d1c96cfc9c63,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-e55a7b90-55c5-486c-9b42-27e77060404f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685727001-172.17.0.18-1595953873258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33672,DS-e9011e96-8e47-4fd7-9e36-a284bf0747ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-733926ad-6991-4193-ac3b-7e7e06f83949,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-9c271691-1f5e-4c7e-b0da-cf96b4858ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-726223ad-9767-4c4a-a317-38ca28559a42,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-7fa6d7de-b2a9-4532-a3ef-89d6d109def5,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-8ca469db-3db2-4cb7-afbc-cce74035c3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-b44405bc-8632-46c9-b51e-d1c96cfc9c63,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-e55a7b90-55c5-486c-9b42-27e77060404f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176550640-172.17.0.18-1595954094543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34350,DS-d6524f24-1d12-440b-babf-caf841549864,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-e319e021-92f3-44de-a9ba-7e9a2ac6a14e,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-fb9a58cf-a7e8-4aaa-a72a-43581fc033a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-f32c83dc-da66-413f-85b2-58e56fdf2d56,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-1da7bb62-379f-4aab-a90a-6bcf85ad2645,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-69bd4075-fcfe-4051-92a7-4531a462bfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-2b713ed9-96a6-45a7-b1a0-e183368eceb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-b655058c-01f6-42b9-991e-8e320fc5e8a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176550640-172.17.0.18-1595954094543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34350,DS-d6524f24-1d12-440b-babf-caf841549864,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-e319e021-92f3-44de-a9ba-7e9a2ac6a14e,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-fb9a58cf-a7e8-4aaa-a72a-43581fc033a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-f32c83dc-da66-413f-85b2-58e56fdf2d56,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-1da7bb62-379f-4aab-a90a-6bcf85ad2645,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-69bd4075-fcfe-4051-92a7-4531a462bfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-2b713ed9-96a6-45a7-b1a0-e183368eceb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-b655058c-01f6-42b9-991e-8e320fc5e8a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-550113666-172.17.0.18-1595954454491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38620,DS-1eb05492-cb03-4e6d-b914-c49bd5754081,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-275ec4d1-c650-4445-99f1-6c02e228d254,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-14dd1174-0554-439c-9267-d5c506878583,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-a9e79d57-3ea6-472a-8a8e-967deae612ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-508324c6-003f-4e86-9ab8-5c7e11c4b7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-83fad544-cc1a-47e2-9bf8-d83adb5a6d77,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-63f866e6-b840-4908-b5c8-2ea028c1580e,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-8fd756c7-1fb0-4697-9a2e-23de76c84ace,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-550113666-172.17.0.18-1595954454491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38620,DS-1eb05492-cb03-4e6d-b914-c49bd5754081,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-275ec4d1-c650-4445-99f1-6c02e228d254,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-14dd1174-0554-439c-9267-d5c506878583,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-a9e79d57-3ea6-472a-8a8e-967deae612ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-508324c6-003f-4e86-9ab8-5c7e11c4b7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-83fad544-cc1a-47e2-9bf8-d83adb5a6d77,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-63f866e6-b840-4908-b5c8-2ea028c1580e,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-8fd756c7-1fb0-4697-9a2e-23de76c84ace,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-122607440-172.17.0.18-1595954521362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39295,DS-a6b6f44d-a761-42aa-8aa7-f2ba581fcf90,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-3731a2a8-0965-4d6d-8099-e1544d5cb35e,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-c3b7a9a9-9040-4005-9cbd-ec1ccf0fd96b,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-c09587c9-90ee-4481-8726-5efa89ae194d,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-e0a9e60e-e3ca-4998-aca7-df63a4644a87,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-86eea0bf-9a84-42a0-8d90-1c6cd1415b83,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-0c25b2ac-86d1-4aea-8165-2f734568778f,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-99bcfe6e-9c54-48d6-b7ad-00337c128f56,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-122607440-172.17.0.18-1595954521362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39295,DS-a6b6f44d-a761-42aa-8aa7-f2ba581fcf90,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-3731a2a8-0965-4d6d-8099-e1544d5cb35e,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-c3b7a9a9-9040-4005-9cbd-ec1ccf0fd96b,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-c09587c9-90ee-4481-8726-5efa89ae194d,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-e0a9e60e-e3ca-4998-aca7-df63a4644a87,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-86eea0bf-9a84-42a0-8d90-1c6cd1415b83,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-0c25b2ac-86d1-4aea-8165-2f734568778f,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-99bcfe6e-9c54-48d6-b7ad-00337c128f56,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689949269-172.17.0.18-1595954702162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38254,DS-6941bb61-060f-4aa6-ac34-844655f268b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-93ad5df8-033e-4d3d-9ca6-6f90bd427826,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-91e183e4-87b5-4dbc-b1d0-cf7afd6eb19c,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-9ce9b628-550f-47c8-8c91-21b7f6e896be,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-f25d0008-df2e-488d-a105-009d28006c07,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-2ca2b82f-baf5-4e57-acdf-9adf0a8e001c,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-11b30c7b-abc3-4f33-a720-c3a82cede82b,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-1c09e64d-4467-49cb-b063-d9c23d7a3bae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689949269-172.17.0.18-1595954702162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38254,DS-6941bb61-060f-4aa6-ac34-844655f268b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-93ad5df8-033e-4d3d-9ca6-6f90bd427826,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-91e183e4-87b5-4dbc-b1d0-cf7afd6eb19c,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-9ce9b628-550f-47c8-8c91-21b7f6e896be,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-f25d0008-df2e-488d-a105-009d28006c07,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-2ca2b82f-baf5-4e57-acdf-9adf0a8e001c,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-11b30c7b-abc3-4f33-a720-c3a82cede82b,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-1c09e64d-4467-49cb-b063-d9c23d7a3bae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-97074319-172.17.0.18-1595954776017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46167,DS-4600c395-5d6e-43cd-ae0f-46dbe21c0ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-45f3641c-42c9-4c69-afd1-04426cf86521,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-f16dc84e-9e70-4257-a7eb-1844f73a751d,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-ae02b4e6-6568-4751-952f-dadaf97bc7de,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-b8b5b98d-9a0a-4bbe-adb3-142e09bef6da,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-2c01f10b-8cdb-477a-b56f-e0d670234fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-b0bafca9-1902-411b-8575-99908637a09e,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-e9b2ba47-fd02-44da-aa6b-eaa0bd1932c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-97074319-172.17.0.18-1595954776017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46167,DS-4600c395-5d6e-43cd-ae0f-46dbe21c0ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-45f3641c-42c9-4c69-afd1-04426cf86521,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-f16dc84e-9e70-4257-a7eb-1844f73a751d,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-ae02b4e6-6568-4751-952f-dadaf97bc7de,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-b8b5b98d-9a0a-4bbe-adb3-142e09bef6da,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-2c01f10b-8cdb-477a-b56f-e0d670234fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-b0bafca9-1902-411b-8575-99908637a09e,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-e9b2ba47-fd02-44da-aa6b-eaa0bd1932c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258251912-172.17.0.18-1595954894513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43974,DS-6190425e-8708-4d25-9927-80692b3df00b,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-48fd4192-13bc-43e9-a36d-41d8ced2a0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-cac864b2-c335-463c-baf8-2c8678e3f75f,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-57d18169-031d-4ce5-934c-5165e42fc88a,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-636c49fb-807d-49ae-b6b1-576a718e2286,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-300738d8-679d-4fb5-bf73-52c63fdf3f09,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-aede9fba-a8a2-4aad-a434-4b6586b54352,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-5f93a377-3810-46eb-94c3-ab5506c3b167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258251912-172.17.0.18-1595954894513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43974,DS-6190425e-8708-4d25-9927-80692b3df00b,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-48fd4192-13bc-43e9-a36d-41d8ced2a0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-cac864b2-c335-463c-baf8-2c8678e3f75f,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-57d18169-031d-4ce5-934c-5165e42fc88a,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-636c49fb-807d-49ae-b6b1-576a718e2286,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-300738d8-679d-4fb5-bf73-52c63fdf3f09,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-aede9fba-a8a2-4aad-a434-4b6586b54352,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-5f93a377-3810-46eb-94c3-ab5506c3b167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2059298584-172.17.0.18-1595955064460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39377,DS-f000b1ca-3a34-48e0-87bd-abb22e0c253c,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-10d6d926-7a53-40c5-8ae1-08d41032f0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-49ab2b23-aab5-48d6-841b-7976b2b8559c,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-ce217205-7def-4f81-9994-7ddd946964a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-50acac07-2105-4a56-a772-84029346ca1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-0bb09f31-efd9-4c98-bbd4-58925bb7baf9,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-b7578a7b-0343-42ac-8afa-ab9b94927e58,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-1be95149-3647-4080-8748-8b20366d118d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2059298584-172.17.0.18-1595955064460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39377,DS-f000b1ca-3a34-48e0-87bd-abb22e0c253c,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-10d6d926-7a53-40c5-8ae1-08d41032f0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-49ab2b23-aab5-48d6-841b-7976b2b8559c,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-ce217205-7def-4f81-9994-7ddd946964a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-50acac07-2105-4a56-a772-84029346ca1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-0bb09f31-efd9-4c98-bbd4-58925bb7baf9,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-b7578a7b-0343-42ac-8afa-ab9b94927e58,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-1be95149-3647-4080-8748-8b20366d118d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797984071-172.17.0.18-1595955138881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34413,DS-7ada41bf-75b1-41a9-89c5-0a75c2a5d514,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-80dcb5c8-6816-4508-abda-66a4ba8106c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-717c7c0a-fb4c-4131-abb6-73be60287222,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-aff9a736-8a85-4e7f-95ae-2e446e549b40,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-1c15ebd5-81ce-4f9b-9fe7-9d99dfc71094,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-3af944c4-e9cb-45d1-be03-b91f9793a482,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-e573892b-9f28-4647-a47b-db2f161eb0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-12cd3688-9495-4aed-8cb9-6e1c0900f1b6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797984071-172.17.0.18-1595955138881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34413,DS-7ada41bf-75b1-41a9-89c5-0a75c2a5d514,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-80dcb5c8-6816-4508-abda-66a4ba8106c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-717c7c0a-fb4c-4131-abb6-73be60287222,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-aff9a736-8a85-4e7f-95ae-2e446e549b40,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-1c15ebd5-81ce-4f9b-9fe7-9d99dfc71094,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-3af944c4-e9cb-45d1-be03-b91f9793a482,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-e573892b-9f28-4647-a47b-db2f161eb0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-12cd3688-9495-4aed-8cb9-6e1c0900f1b6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753064003-172.17.0.18-1595955758962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35753,DS-f40652e3-48f7-4808-8bca-37fb3b14ef17,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-9e011db3-d4ce-496d-8809-a5530cb5d4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-3ccb68a7-e66a-42f3-a813-4a18aa166234,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-11732e58-c1ed-411a-ba5f-16a571f66e18,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-8e9f1c5f-eb91-4ec5-8127-4992253935f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-2db9bc57-1613-47d1-bea3-13c7e519e102,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-1c8cd1f6-65e3-4efb-99ba-b61290b7c245,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-530aadc1-78c5-4449-8e9f-78ac7837f0e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753064003-172.17.0.18-1595955758962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35753,DS-f40652e3-48f7-4808-8bca-37fb3b14ef17,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-9e011db3-d4ce-496d-8809-a5530cb5d4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-3ccb68a7-e66a-42f3-a813-4a18aa166234,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-11732e58-c1ed-411a-ba5f-16a571f66e18,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-8e9f1c5f-eb91-4ec5-8127-4992253935f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-2db9bc57-1613-47d1-bea3-13c7e519e102,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-1c8cd1f6-65e3-4efb-99ba-b61290b7c245,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-530aadc1-78c5-4449-8e9f-78ac7837f0e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683062279-172.17.0.18-1595955983079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35857,DS-47da6c42-2713-4b39-997b-3e3212dcafdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-fcf091ef-16df-47f6-a1bc-132e5623e61a,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-f8854e45-9205-467c-95cb-59407d5c4acf,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-0ffe909f-6c19-4325-b37a-10b2bdb548ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-301f84c9-b731-427d-a26d-3ce476f9f6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-c01b565e-16f5-4402-8f02-fa79a7c19adc,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-965db8fc-95f4-416d-b6e0-62a4fb47ef93,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-686c06bc-45f4-49f7-a9b7-711438bcd9cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683062279-172.17.0.18-1595955983079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35857,DS-47da6c42-2713-4b39-997b-3e3212dcafdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-fcf091ef-16df-47f6-a1bc-132e5623e61a,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-f8854e45-9205-467c-95cb-59407d5c4acf,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-0ffe909f-6c19-4325-b37a-10b2bdb548ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-301f84c9-b731-427d-a26d-3ce476f9f6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-c01b565e-16f5-4402-8f02-fa79a7c19adc,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-965db8fc-95f4-416d-b6e0-62a4fb47ef93,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-686c06bc-45f4-49f7-a9b7-711438bcd9cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1908794040-172.17.0.18-1595956226439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41379,DS-b64c2973-6e6c-4881-8731-6d781aca82ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-019cfe65-d1f0-4d5b-ae90-00bc208c0b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-47d9125c-695a-4742-8c21-b9b9505c686d,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-c7667b60-c9ad-4dae-bb92-894a68a03641,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-1c3c47d4-888b-45d5-9a2f-927e6430577c,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-a2aa26de-7c39-4119-a5ad-e9cbb467327f,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-b78a9bd7-9939-494c-ad6a-71b7b9e8276a,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-22c8e892-6caf-4a30-9829-719b8a632013,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1908794040-172.17.0.18-1595956226439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41379,DS-b64c2973-6e6c-4881-8731-6d781aca82ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-019cfe65-d1f0-4d5b-ae90-00bc208c0b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-47d9125c-695a-4742-8c21-b9b9505c686d,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-c7667b60-c9ad-4dae-bb92-894a68a03641,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-1c3c47d4-888b-45d5-9a2f-927e6430577c,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-a2aa26de-7c39-4119-a5ad-e9cbb467327f,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-b78a9bd7-9939-494c-ad6a-71b7b9e8276a,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-22c8e892-6caf-4a30-9829-719b8a632013,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1217898461-172.17.0.18-1595956506546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40036,DS-210e85d0-4bc1-474f-8a48-d9069b0f0274,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-d11fb688-db91-4229-8306-12b8225c24b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-1e17b171-1387-4f50-b2af-b538ffa66e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-a690e3e2-2c83-4060-bcda-c43653225303,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-80974406-13e1-4d7b-9c7f-f134d4bb0163,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-3dcc7577-3ce1-4193-b114-8b566906a4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-46e83bcf-6d5d-4812-8357-3a987de4050c,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-0ae884f3-9ca7-4f57-bec4-be5b1e2b33ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1217898461-172.17.0.18-1595956506546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40036,DS-210e85d0-4bc1-474f-8a48-d9069b0f0274,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-d11fb688-db91-4229-8306-12b8225c24b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-1e17b171-1387-4f50-b2af-b538ffa66e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-a690e3e2-2c83-4060-bcda-c43653225303,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-80974406-13e1-4d7b-9c7f-f134d4bb0163,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-3dcc7577-3ce1-4193-b114-8b566906a4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-46e83bcf-6d5d-4812-8357-3a987de4050c,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-0ae884f3-9ca7-4f57-bec4-be5b1e2b33ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-554961241-172.17.0.18-1595956643831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45464,DS-145de390-e7fa-4213-9fcc-5d71eeffbb03,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-f695a4d1-3538-470e-9b46-f7bb23bddbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-ba553d90-65ee-42ee-b5de-9610d502e6db,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-4438e66f-952a-4bd2-aaad-b6dff0428d52,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-a30a4e18-3018-4cc9-ba98-2f0efe010572,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-71c6b94c-945e-4c95-bdc6-6df7e11bb645,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-963b5f42-60a5-4102-9025-77225fbf61f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-3bed19b7-8c8f-4e78-b3d3-ac03683b4116,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-554961241-172.17.0.18-1595956643831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45464,DS-145de390-e7fa-4213-9fcc-5d71eeffbb03,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-f695a4d1-3538-470e-9b46-f7bb23bddbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-ba553d90-65ee-42ee-b5de-9610d502e6db,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-4438e66f-952a-4bd2-aaad-b6dff0428d52,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-a30a4e18-3018-4cc9-ba98-2f0efe010572,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-71c6b94c-945e-4c95-bdc6-6df7e11bb645,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-963b5f42-60a5-4102-9025-77225fbf61f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-3bed19b7-8c8f-4e78-b3d3-ac03683b4116,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82993263-172.17.0.18-1595956898639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37006,DS-0768e7ca-cd00-4bd2-8573-f558aa355d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-8ab90a2f-8c28-4592-8675-83c4f2142660,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-ae294884-ac5e-4ad2-8fde-7174bbb9fc94,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-7b7c769c-c661-401e-a14d-a9b9f3a5e5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-f9710c39-202e-41b5-8e2c-310efd47a8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-c76c5480-4c22-462e-8776-6a59bcf80765,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-63e8f72c-9df1-49c0-9b6c-4475ce0eb757,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-87c4baee-8bc4-4c90-9416-f23f4d63851c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82993263-172.17.0.18-1595956898639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37006,DS-0768e7ca-cd00-4bd2-8573-f558aa355d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-8ab90a2f-8c28-4592-8675-83c4f2142660,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-ae294884-ac5e-4ad2-8fde-7174bbb9fc94,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-7b7c769c-c661-401e-a14d-a9b9f3a5e5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-f9710c39-202e-41b5-8e2c-310efd47a8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-c76c5480-4c22-462e-8776-6a59bcf80765,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-63e8f72c-9df1-49c0-9b6c-4475ce0eb757,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-87c4baee-8bc4-4c90-9416-f23f4d63851c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045222122-172.17.0.18-1595956940572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38809,DS-cbb65c1d-2267-4318-b711-39c1e33f06b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-cf2ba658-0e59-4af3-9e24-88ddee6a7781,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-83e845ae-fdfb-4148-aa5c-b05015ba01df,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-cf2c7a72-b89b-4d73-b9c9-0cfe1baa02d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-ca635030-a9e2-4a5f-a26b-745a1d4da146,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-b3497b85-f628-40ad-840d-eadf0a861215,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-e76a5588-41a5-4989-8b8b-67ec94c89242,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-2ac9258b-a019-468f-a3f3-3ec50c0abe22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045222122-172.17.0.18-1595956940572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38809,DS-cbb65c1d-2267-4318-b711-39c1e33f06b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-cf2ba658-0e59-4af3-9e24-88ddee6a7781,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-83e845ae-fdfb-4148-aa5c-b05015ba01df,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-cf2c7a72-b89b-4d73-b9c9-0cfe1baa02d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-ca635030-a9e2-4a5f-a26b-745a1d4da146,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-b3497b85-f628-40ad-840d-eadf0a861215,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-e76a5588-41a5-4989-8b8b-67ec94c89242,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-2ac9258b-a019-468f-a3f3-3ec50c0abe22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927498736-172.17.0.18-1595957077940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44574,DS-7673572b-6298-4d30-afc0-af4db7f2ef9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-fb1777b7-8231-4ab0-81d2-ce975ac1deae,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-7c1a8c12-a715-4d2a-8a77-d03c59d09508,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-3839f43c-dc12-4354-bc75-f1e1cedfb874,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-1a25f60c-3294-45cd-8150-695bcf8d5744,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-81c91676-a68c-422e-ab21-17d33437f3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-a158bcb9-f490-4136-b107-04d43f29318b,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-fae81088-8d69-4a64-9b59-91116745b0fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927498736-172.17.0.18-1595957077940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44574,DS-7673572b-6298-4d30-afc0-af4db7f2ef9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-fb1777b7-8231-4ab0-81d2-ce975ac1deae,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-7c1a8c12-a715-4d2a-8a77-d03c59d09508,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-3839f43c-dc12-4354-bc75-f1e1cedfb874,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-1a25f60c-3294-45cd-8150-695bcf8d5744,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-81c91676-a68c-422e-ab21-17d33437f3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-a158bcb9-f490-4136-b107-04d43f29318b,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-fae81088-8d69-4a64-9b59-91116745b0fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1908747184-172.17.0.18-1595957149156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40768,DS-b173999f-e75f-453c-ad86-b806de8f0cee,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-41fbb2b4-e28e-4052-b823-ecc575b19b24,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-f8b7ed4a-a0e2-4fa9-b5be-4beae6a0205c,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-5acc1570-1191-489b-9c8c-a467c59544cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-daa5c5d0-9829-445c-aeba-679d5e443129,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-6993a8eb-3b2f-4c19-8c49-e05a858d6cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-55518d40-0b77-4d73-b67f-8daa850f1a41,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-48ca3a6b-aae8-428f-83e6-6807a00f20fc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1908747184-172.17.0.18-1595957149156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40768,DS-b173999f-e75f-453c-ad86-b806de8f0cee,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-41fbb2b4-e28e-4052-b823-ecc575b19b24,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-f8b7ed4a-a0e2-4fa9-b5be-4beae6a0205c,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-5acc1570-1191-489b-9c8c-a467c59544cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-daa5c5d0-9829-445c-aeba-679d5e443129,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-6993a8eb-3b2f-4c19-8c49-e05a858d6cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-55518d40-0b77-4d73-b67f-8daa850f1a41,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-48ca3a6b-aae8-428f-83e6-6807a00f20fc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1506019084-172.17.0.18-1595957687515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36234,DS-f5ed9ed4-d8b8-4dc1-aaf3-a2148622d424,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-358971c1-1d36-4cb4-a230-ae6da3a4b7af,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-f4495b0d-e6fd-4764-bff9-877713e08f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-8e81783a-a1df-4de1-b1c0-403ed6ce1f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-f05e1136-160c-42f1-a323-4fdd7d3983fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-751fcd25-c2ec-4de7-a944-fda43d07080a,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-f656854d-1780-4a95-ae20-2e55cc6fe4be,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-2c00ff6e-6962-496b-9165-9c30981470a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1506019084-172.17.0.18-1595957687515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36234,DS-f5ed9ed4-d8b8-4dc1-aaf3-a2148622d424,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-358971c1-1d36-4cb4-a230-ae6da3a4b7af,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-f4495b0d-e6fd-4764-bff9-877713e08f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-8e81783a-a1df-4de1-b1c0-403ed6ce1f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-f05e1136-160c-42f1-a323-4fdd7d3983fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-751fcd25-c2ec-4de7-a944-fda43d07080a,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-f656854d-1780-4a95-ae20-2e55cc6fe4be,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-2c00ff6e-6962-496b-9165-9c30981470a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006641387-172.17.0.18-1595957790471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39183,DS-972cef49-ffbb-4f62-982f-ee301ea3a1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-3cd34a02-3249-41f8-841c-876107e83f29,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-32b6b880-66c4-4d83-8128-6c36e4089764,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-105809dd-2f20-405e-b781-9eb5250b39ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-9335ea0d-659e-403f-8831-47c14894fb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-d228d38f-b6c8-4836-9ef4-7628d4c79389,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-b7b4a66b-9cf9-4caa-aee0-ad7047a63024,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-9e5cf1fc-a3d5-4986-a5f9-60035b4ad9d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006641387-172.17.0.18-1595957790471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39183,DS-972cef49-ffbb-4f62-982f-ee301ea3a1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-3cd34a02-3249-41f8-841c-876107e83f29,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-32b6b880-66c4-4d83-8128-6c36e4089764,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-105809dd-2f20-405e-b781-9eb5250b39ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-9335ea0d-659e-403f-8831-47c14894fb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-d228d38f-b6c8-4836-9ef4-7628d4c79389,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-b7b4a66b-9cf9-4caa-aee0-ad7047a63024,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-9e5cf1fc-a3d5-4986-a5f9-60035b4ad9d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-557891747-172.17.0.18-1595958072376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38820,DS-6dbb9312-f666-4658-96fb-33ecc3344255,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-9fcd4167-b413-45e8-9908-1233fcf54f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-56db4d8b-3c8c-4c56-a77f-f92c2355ff10,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-ab8af802-5538-4f69-99b4-265947480d54,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-9b35b0dc-a6f2-45fe-a26b-b7347bf82f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-7907f920-13c1-405b-b44e-da4b897d6a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-151e4f29-baa4-45dc-bf51-134624f82e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-3f2d5554-bced-4502-ac2c-11b84a43374d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-557891747-172.17.0.18-1595958072376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38820,DS-6dbb9312-f666-4658-96fb-33ecc3344255,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-9fcd4167-b413-45e8-9908-1233fcf54f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-56db4d8b-3c8c-4c56-a77f-f92c2355ff10,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-ab8af802-5538-4f69-99b4-265947480d54,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-9b35b0dc-a6f2-45fe-a26b-b7347bf82f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-7907f920-13c1-405b-b44e-da4b897d6a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-151e4f29-baa4-45dc-bf51-134624f82e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-3f2d5554-bced-4502-ac2c-11b84a43374d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79335148-172.17.0.18-1595958450488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33505,DS-ac92f394-2d7d-42e8-9c4d-d6f864e2ef37,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-895cfa15-921c-4f9f-bc34-5f1cc8c0de81,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-cbc71393-6885-4e60-bf25-fbb9fdafd2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-6d959301-5645-46b6-bb0e-80cdb6cbaf41,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-70a641f3-ec28-498c-bf55-90a84894c85e,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-ab398d15-adaf-45c5-9215-f7e3dda82e29,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-199b5a23-9877-4cac-9b50-953bfdc6e032,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-e791bf1a-9f89-44b9-8410-cb9206c424d0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79335148-172.17.0.18-1595958450488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33505,DS-ac92f394-2d7d-42e8-9c4d-d6f864e2ef37,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-895cfa15-921c-4f9f-bc34-5f1cc8c0de81,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-cbc71393-6885-4e60-bf25-fbb9fdafd2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-6d959301-5645-46b6-bb0e-80cdb6cbaf41,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-70a641f3-ec28-498c-bf55-90a84894c85e,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-ab398d15-adaf-45c5-9215-f7e3dda82e29,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-199b5a23-9877-4cac-9b50-953bfdc6e032,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-e791bf1a-9f89-44b9-8410-cb9206c424d0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461240597-172.17.0.18-1595958555047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41304,DS-950ea4f2-d5c3-4761-9790-7f307382c6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-1af964a2-ee8b-4f75-b903-92cf536e9adb,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-9a7606a3-2ae7-44e4-8ed8-7f06d69d8e65,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-9f0ccc9c-d388-4e7f-bcdc-839828a9d4db,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-7d27e338-8076-443e-8b49-3d7865626503,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-334c5109-4f81-4ff1-95b6-2f6eaf383730,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-3a44ff79-2f23-4cec-9657-90bb87aa1e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-c260a76c-3993-452e-a7ed-105b0f2e1dbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461240597-172.17.0.18-1595958555047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41304,DS-950ea4f2-d5c3-4761-9790-7f307382c6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-1af964a2-ee8b-4f75-b903-92cf536e9adb,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-9a7606a3-2ae7-44e4-8ed8-7f06d69d8e65,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-9f0ccc9c-d388-4e7f-bcdc-839828a9d4db,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-7d27e338-8076-443e-8b49-3d7865626503,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-334c5109-4f81-4ff1-95b6-2f6eaf383730,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-3a44ff79-2f23-4cec-9657-90bb87aa1e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-c260a76c-3993-452e-a7ed-105b0f2e1dbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-640052169-172.17.0.18-1595958731467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45936,DS-a98b736f-3657-47fb-a0fc-4c75cd8bf007,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-c875ef26-949a-493b-9bf1-54d1734aa6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-4f9ca1fd-d527-4fe9-ac20-db5b4b4e1311,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-a5e90043-1d23-4c53-880b-e55c09a99730,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-115c9eae-0c73-412a-9178-bf1ec3d2b644,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-0068de10-e9f2-43a9-a67d-fe54b4ba6317,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-6d0bd81c-c62d-49de-8bde-ca7cf5b09e49,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-1ef9b126-a935-4044-98e3-302e3299b6eb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-640052169-172.17.0.18-1595958731467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45936,DS-a98b736f-3657-47fb-a0fc-4c75cd8bf007,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-c875ef26-949a-493b-9bf1-54d1734aa6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-4f9ca1fd-d527-4fe9-ac20-db5b4b4e1311,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-a5e90043-1d23-4c53-880b-e55c09a99730,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-115c9eae-0c73-412a-9178-bf1ec3d2b644,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-0068de10-e9f2-43a9-a67d-fe54b4ba6317,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-6d0bd81c-c62d-49de-8bde-ca7cf5b09e49,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-1ef9b126-a935-4044-98e3-302e3299b6eb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5297
