reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567827823-172.17.0.6-1595515005440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41835,DS-fedb7802-eea1-4006-92cf-c5b0cb4dc3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-77eb19b1-6398-4c2f-97b4-7ba78cc6a16e,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-2ab0ac51-8417-4000-acb9-2717b1fa24d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-15781da2-6f48-484b-a256-6edc723d69f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-5efe7907-98bd-4ee1-ac16-79e7c5cb11a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-a5bf1400-a207-45e4-99f3-28e3ded6e7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-e278a24b-bc84-4230-8e15-1785393a3124,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-d9a3bd04-1037-4522-b659-44e83943d022,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567827823-172.17.0.6-1595515005440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41835,DS-fedb7802-eea1-4006-92cf-c5b0cb4dc3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-77eb19b1-6398-4c2f-97b4-7ba78cc6a16e,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-2ab0ac51-8417-4000-acb9-2717b1fa24d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-15781da2-6f48-484b-a256-6edc723d69f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-5efe7907-98bd-4ee1-ac16-79e7c5cb11a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-a5bf1400-a207-45e4-99f3-28e3ded6e7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-e278a24b-bc84-4230-8e15-1785393a3124,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-d9a3bd04-1037-4522-b659-44e83943d022,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1247506976-172.17.0.6-1595515822992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41222,DS-2be89ea0-cf90-488f-9a01-926321f13d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-dcf2c6cb-6af6-4ca0-8346-1e76afd1bc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-8fad13ce-5c5a-4f78-b17c-2e7e178957f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-67cc7437-f7f5-48bb-bca7-7edc979602e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-e02748b0-b214-4492-a424-db5d1f7300d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-b78858f2-e935-49f3-930f-95bf0194d6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-d90c3dfc-05ba-46a3-a09a-10f15572e447,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-4c0739fd-ea08-4e96-915c-53d186872da6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1247506976-172.17.0.6-1595515822992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41222,DS-2be89ea0-cf90-488f-9a01-926321f13d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-dcf2c6cb-6af6-4ca0-8346-1e76afd1bc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-8fad13ce-5c5a-4f78-b17c-2e7e178957f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-67cc7437-f7f5-48bb-bca7-7edc979602e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-e02748b0-b214-4492-a424-db5d1f7300d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-b78858f2-e935-49f3-930f-95bf0194d6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-d90c3dfc-05ba-46a3-a09a-10f15572e447,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-4c0739fd-ea08-4e96-915c-53d186872da6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717309992-172.17.0.6-1595516049142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34158,DS-df9eb70c-c2f5-4c58-81dc-f1925835706e,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-92ef36da-b54b-4890-a869-2ec5c3d3b081,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-b5706f92-35e5-4b4a-a288-e9c0cdaba9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-bc19c1eb-6f21-4bce-8c56-f0a5f067460a,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-11ad0ee9-c3a3-426d-862c-ed31d0ec1ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-6ae40bee-6c76-4ec8-adae-a06c96aa8e74,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-3545060f-1551-42e1-a11d-fd4ab5fa0d72,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-6c4856f6-8797-4288-a5cc-8fb6dca5c818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717309992-172.17.0.6-1595516049142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34158,DS-df9eb70c-c2f5-4c58-81dc-f1925835706e,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-92ef36da-b54b-4890-a869-2ec5c3d3b081,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-b5706f92-35e5-4b4a-a288-e9c0cdaba9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-bc19c1eb-6f21-4bce-8c56-f0a5f067460a,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-11ad0ee9-c3a3-426d-862c-ed31d0ec1ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-6ae40bee-6c76-4ec8-adae-a06c96aa8e74,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-3545060f-1551-42e1-a11d-fd4ab5fa0d72,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-6c4856f6-8797-4288-a5cc-8fb6dca5c818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115217743-172.17.0.6-1595516309928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36029,DS-59dc0b54-2c94-45fd-a853-09ce1437b35f,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-050cd945-1c03-4e2c-95cd-7ff367319f43,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-413ae22b-b8d9-44bb-9f67-9f9255ae3ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-8d8cbcea-2054-4b9b-8b13-674db322a7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-84021df5-3f25-4c83-a8ee-babaf0362ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-79836f80-2b3b-40c8-947a-fa246f8cc0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-b0598920-96ea-4d4b-a596-ecf50e68ab60,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-a1254c4e-fdc2-49eb-85df-1fd63517e310,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115217743-172.17.0.6-1595516309928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36029,DS-59dc0b54-2c94-45fd-a853-09ce1437b35f,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-050cd945-1c03-4e2c-95cd-7ff367319f43,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-413ae22b-b8d9-44bb-9f67-9f9255ae3ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-8d8cbcea-2054-4b9b-8b13-674db322a7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-84021df5-3f25-4c83-a8ee-babaf0362ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-79836f80-2b3b-40c8-947a-fa246f8cc0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-b0598920-96ea-4d4b-a596-ecf50e68ab60,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-a1254c4e-fdc2-49eb-85df-1fd63517e310,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2036627258-172.17.0.6-1595516465993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39603,DS-226a0d70-b4ce-4fc3-bd54-8ca40ef5ac85,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-ba6e2f0c-63e3-45cc-9499-0852f80dfa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-99d2023d-6fdc-49c4-83b8-2d4c98ed2c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-ece3194b-8406-4848-a435-1479a312e1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-c9c75f10-c795-4bcb-8cd9-b4fa59ec7bea,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-b9130817-fc8b-4090-a71b-86ea5d941d09,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-3071763e-54c6-4a9f-a326-f199c30f9904,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-64b80557-7826-448a-8a73-b75c7586422b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2036627258-172.17.0.6-1595516465993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39603,DS-226a0d70-b4ce-4fc3-bd54-8ca40ef5ac85,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-ba6e2f0c-63e3-45cc-9499-0852f80dfa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-99d2023d-6fdc-49c4-83b8-2d4c98ed2c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-ece3194b-8406-4848-a435-1479a312e1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-c9c75f10-c795-4bcb-8cd9-b4fa59ec7bea,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-b9130817-fc8b-4090-a71b-86ea5d941d09,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-3071763e-54c6-4a9f-a326-f199c30f9904,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-64b80557-7826-448a-8a73-b75c7586422b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1802230190-172.17.0.6-1595516827946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44872,DS-4ed98d4c-78e0-40e5-8fa7-79c586f9e353,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-e2186550-fff7-407d-88c3-1e7c1d93c584,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-78f585d4-b3a3-4851-a98b-227d5108fb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-228154f5-61fb-44f2-b681-0a26567ae955,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-5396bb7d-0695-4626-a462-ae15d6e3ec83,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-0efecf65-555b-4bea-b599-04377ada5e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-1bf92ff3-a7cf-40ca-8e52-f36737ab6dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-46d9755d-f347-4bd2-81a9-3f36184198b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1802230190-172.17.0.6-1595516827946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44872,DS-4ed98d4c-78e0-40e5-8fa7-79c586f9e353,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-e2186550-fff7-407d-88c3-1e7c1d93c584,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-78f585d4-b3a3-4851-a98b-227d5108fb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-228154f5-61fb-44f2-b681-0a26567ae955,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-5396bb7d-0695-4626-a462-ae15d6e3ec83,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-0efecf65-555b-4bea-b599-04377ada5e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-1bf92ff3-a7cf-40ca-8e52-f36737ab6dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-46d9755d-f347-4bd2-81a9-3f36184198b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092453334-172.17.0.6-1595516912883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36930,DS-44f57640-4ef8-435a-a584-bb03eaad4809,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-b562bdfd-4bf8-4192-9e13-6d4306f7a390,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-1b01a863-1962-411d-b224-f8a46a8bb7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-bad8778a-cc2f-4449-a41b-0420ba81a483,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-7e6f9a99-6b60-486b-8961-36423cd95b51,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-966da412-c3d5-4e4e-b154-b2c6d82b353d,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-5c976c1e-9062-49c1-aa43-2035e7c189d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-38bbdc11-a48c-4e9d-8e88-ad57a2e63023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092453334-172.17.0.6-1595516912883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36930,DS-44f57640-4ef8-435a-a584-bb03eaad4809,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-b562bdfd-4bf8-4192-9e13-6d4306f7a390,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-1b01a863-1962-411d-b224-f8a46a8bb7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-bad8778a-cc2f-4449-a41b-0420ba81a483,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-7e6f9a99-6b60-486b-8961-36423cd95b51,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-966da412-c3d5-4e4e-b154-b2c6d82b353d,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-5c976c1e-9062-49c1-aa43-2035e7c189d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-38bbdc11-a48c-4e9d-8e88-ad57a2e63023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227038628-172.17.0.6-1595517252378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38707,DS-080ad40f-91d8-4886-92e9-090ed37cea7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-0b4eb318-6966-4604-816e-80755ffdeb86,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-2deb4dd3-ab67-4dd6-9503-566bc2e3692b,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-4dfed364-8d14-4b91-9d31-ffd985fed3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-bd971fbf-a688-4f10-aba6-c2822d701612,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-bed7c364-ba72-4c12-8636-7b3ead127745,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-837053cb-1b7f-446f-8f4e-c4455904d3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-12ed1439-2c04-4790-b252-9a062027b9e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227038628-172.17.0.6-1595517252378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38707,DS-080ad40f-91d8-4886-92e9-090ed37cea7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-0b4eb318-6966-4604-816e-80755ffdeb86,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-2deb4dd3-ab67-4dd6-9503-566bc2e3692b,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-4dfed364-8d14-4b91-9d31-ffd985fed3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-bd971fbf-a688-4f10-aba6-c2822d701612,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-bed7c364-ba72-4c12-8636-7b3ead127745,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-837053cb-1b7f-446f-8f4e-c4455904d3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-12ed1439-2c04-4790-b252-9a062027b9e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704277623-172.17.0.6-1595517505938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37777,DS-44236926-3825-4368-8ed8-638a553459d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-77acf039-a963-4c3e-9b0e-db399e3ee54c,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-aad18c3e-db45-42b5-9ece-6bcb5489afff,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-26560e1f-2faa-441f-9780-c4c7a9fc52c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-816cb56a-19ed-4220-9ae2-c183be352706,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-35cfb025-3537-42e1-86a3-2f1c201d29c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-e9ffcf9b-519e-47fd-96f5-b0449dff0abd,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-cd6ae331-74e9-4544-a6eb-c5856ea19cb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704277623-172.17.0.6-1595517505938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37777,DS-44236926-3825-4368-8ed8-638a553459d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-77acf039-a963-4c3e-9b0e-db399e3ee54c,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-aad18c3e-db45-42b5-9ece-6bcb5489afff,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-26560e1f-2faa-441f-9780-c4c7a9fc52c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-816cb56a-19ed-4220-9ae2-c183be352706,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-35cfb025-3537-42e1-86a3-2f1c201d29c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-e9ffcf9b-519e-47fd-96f5-b0449dff0abd,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-cd6ae331-74e9-4544-a6eb-c5856ea19cb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-317670483-172.17.0.6-1595517693710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36834,DS-1bd6ea06-f714-4a1c-8d06-88c370cc9df0,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-20d4c574-6496-4b31-ba22-6afd42333f25,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-91e56117-84bc-459c-aaff-ac292cf2de14,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-45378120-040c-4656-8612-f9571383e086,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-e34229d5-ee76-4782-803c-2eef2745328d,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-ce62b083-2f85-47fa-bc9c-f0cdb2a627ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-fef1c4d4-12bc-49f4-85d3-5a11b2137f68,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-f3e763e2-4faa-429b-a8ce-c30cf698d30c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-317670483-172.17.0.6-1595517693710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36834,DS-1bd6ea06-f714-4a1c-8d06-88c370cc9df0,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-20d4c574-6496-4b31-ba22-6afd42333f25,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-91e56117-84bc-459c-aaff-ac292cf2de14,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-45378120-040c-4656-8612-f9571383e086,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-e34229d5-ee76-4782-803c-2eef2745328d,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-ce62b083-2f85-47fa-bc9c-f0cdb2a627ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-fef1c4d4-12bc-49f4-85d3-5a11b2137f68,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-f3e763e2-4faa-429b-a8ce-c30cf698d30c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801371149-172.17.0.6-1595517791647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39469,DS-aec9aa98-1f91-4725-b992-d561fc50bad8,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-68e41cf3-7d6e-4b64-89db-e0e59241f0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-3483aa3d-35a8-4347-aabd-e7d1cfa50612,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-448fef5e-831d-469c-aab9-baad20be4213,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-587f1bf2-b62c-4955-b4cc-19299b72f0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-d03d09be-6010-4f79-98d9-1120192497ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-7bfcdc02-554a-4c23-982c-21945e341561,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-89d0b5a9-4448-4f50-a27c-af070062cfa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801371149-172.17.0.6-1595517791647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39469,DS-aec9aa98-1f91-4725-b992-d561fc50bad8,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-68e41cf3-7d6e-4b64-89db-e0e59241f0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-3483aa3d-35a8-4347-aabd-e7d1cfa50612,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-448fef5e-831d-469c-aab9-baad20be4213,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-587f1bf2-b62c-4955-b4cc-19299b72f0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-d03d09be-6010-4f79-98d9-1120192497ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-7bfcdc02-554a-4c23-982c-21945e341561,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-89d0b5a9-4448-4f50-a27c-af070062cfa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1136152390-172.17.0.6-1595518563718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43966,DS-4547456e-5c57-4563-b8cb-48f3883a38e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-9fd89ee2-164e-4df4-9aa6-f731d2bf619e,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-07fc0380-d927-4840-bf1c-7b7152400128,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-3746e733-4cba-46d8-9efd-c5f21635b857,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-46975d54-36a4-4049-8c56-e400e70fb6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-c6e2ac40-ebc0-425d-ad80-5e41130f1803,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-cb33fa4f-9d6d-4186-b9bc-d34191199492,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-ecfd9c67-9d6b-4878-8657-c9a5f2b77f41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1136152390-172.17.0.6-1595518563718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43966,DS-4547456e-5c57-4563-b8cb-48f3883a38e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-9fd89ee2-164e-4df4-9aa6-f731d2bf619e,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-07fc0380-d927-4840-bf1c-7b7152400128,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-3746e733-4cba-46d8-9efd-c5f21635b857,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-46975d54-36a4-4049-8c56-e400e70fb6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-c6e2ac40-ebc0-425d-ad80-5e41130f1803,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-cb33fa4f-9d6d-4186-b9bc-d34191199492,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-ecfd9c67-9d6b-4878-8657-c9a5f2b77f41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875446481-172.17.0.6-1595519130755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36701,DS-6dfa6cc3-73f0-4bde-a63f-4a1328baa942,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-1f4c1fb1-aad7-4c24-9632-9340d25bf51f,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-34ab49c1-231b-4e65-9463-f9afc6175ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-3f43fdf6-76c2-48cc-b7fe-5dbba1c40db1,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-3c2310ff-6a0e-42da-81b8-d22b8889d3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-5c941cd9-f562-4bd7-89bf-97bab2f5a80f,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-ca2f71f5-f875-4cb1-ae2e-484d0e3afe36,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-d57d74ca-4825-4f63-8dd3-2fd7ec4d2385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875446481-172.17.0.6-1595519130755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36701,DS-6dfa6cc3-73f0-4bde-a63f-4a1328baa942,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-1f4c1fb1-aad7-4c24-9632-9340d25bf51f,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-34ab49c1-231b-4e65-9463-f9afc6175ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-3f43fdf6-76c2-48cc-b7fe-5dbba1c40db1,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-3c2310ff-6a0e-42da-81b8-d22b8889d3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-5c941cd9-f562-4bd7-89bf-97bab2f5a80f,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-ca2f71f5-f875-4cb1-ae2e-484d0e3afe36,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-d57d74ca-4825-4f63-8dd3-2fd7ec4d2385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1670167864-172.17.0.6-1595519175876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39745,DS-484a80eb-69e1-4421-940b-73f0167726a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-a2595e26-911c-4e0c-a625-6f14387149a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-701898e9-2e1b-400e-a6f5-07135bb24da8,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-4161a857-b578-476d-b319-cded6d216e43,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-4b37b1dd-68c0-4a83-a737-09f51b530438,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-80bba5bb-f865-4191-99c3-8235895f336f,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-9ddae52f-8938-4b7a-865b-0b3589ed1e60,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-26382f02-40d6-466b-93cd-1943b0df7d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1670167864-172.17.0.6-1595519175876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39745,DS-484a80eb-69e1-4421-940b-73f0167726a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-a2595e26-911c-4e0c-a625-6f14387149a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-701898e9-2e1b-400e-a6f5-07135bb24da8,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-4161a857-b578-476d-b319-cded6d216e43,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-4b37b1dd-68c0-4a83-a737-09f51b530438,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-80bba5bb-f865-4191-99c3-8235895f336f,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-9ddae52f-8938-4b7a-865b-0b3589ed1e60,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-26382f02-40d6-466b-93cd-1943b0df7d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051191281-172.17.0.6-1595519230998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36284,DS-b3c4a90a-5004-4510-bdec-8d70f63778f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-b82cfb95-78b7-41f8-bd09-fa1e35874089,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-645fa7a2-09af-49d1-8385-9aade6736647,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-dade189f-a13d-4caa-b819-998e6581e4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-d798cb72-72c9-43c5-9131-f7772ed65eef,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-88436755-634d-4c8e-b516-73d47675f943,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-29fd0bac-a555-46cc-bff2-09bb7369c5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-17da040e-8894-4beb-a22d-4c3ada74f663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051191281-172.17.0.6-1595519230998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36284,DS-b3c4a90a-5004-4510-bdec-8d70f63778f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-b82cfb95-78b7-41f8-bd09-fa1e35874089,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-645fa7a2-09af-49d1-8385-9aade6736647,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-dade189f-a13d-4caa-b819-998e6581e4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-d798cb72-72c9-43c5-9131-f7772ed65eef,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-88436755-634d-4c8e-b516-73d47675f943,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-29fd0bac-a555-46cc-bff2-09bb7369c5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-17da040e-8894-4beb-a22d-4c3ada74f663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1140993702-172.17.0.6-1595519797663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38218,DS-ce44d6f2-d15e-41ff-b779-38f071b07e86,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-9b2dab4a-39a8-47f0-bff7-ee1796f7f322,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-2424a8ba-c287-4a0e-95c6-44a8b53f1c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-6d75b163-3281-496b-a7af-f53038b8cc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-3685ae67-2a3f-415d-969d-3907d6c335c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-3fc738fc-a33b-4abd-8d33-9c5d5c7c6771,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-ff3d6a85-1878-4a46-a990-97521150f7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-55591af9-3205-48a7-bc86-275b59f56dbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1140993702-172.17.0.6-1595519797663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38218,DS-ce44d6f2-d15e-41ff-b779-38f071b07e86,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-9b2dab4a-39a8-47f0-bff7-ee1796f7f322,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-2424a8ba-c287-4a0e-95c6-44a8b53f1c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-6d75b163-3281-496b-a7af-f53038b8cc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-3685ae67-2a3f-415d-969d-3907d6c335c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-3fc738fc-a33b-4abd-8d33-9c5d5c7c6771,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-ff3d6a85-1878-4a46-a990-97521150f7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-55591af9-3205-48a7-bc86-275b59f56dbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242888780-172.17.0.6-1595519892990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43856,DS-6f61f192-e051-4f06-8176-de3dc2216f03,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-e13ff9fc-1dce-4825-ba83-2f71cf9b1013,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-1f20c0e4-8cff-4d28-ba15-f12574ecb6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-b244d12e-52ba-402f-b5bc-b307345c1362,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-b28be989-f25d-493e-a8ce-cdfc44e7cf39,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-3f40c8c0-d179-4cac-a03c-92684d487f81,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-41eecc5c-8950-4b08-9e7d-f33e5905730b,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-9a2350ca-4064-40cd-a7f9-d7fe8b21909d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242888780-172.17.0.6-1595519892990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43856,DS-6f61f192-e051-4f06-8176-de3dc2216f03,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-e13ff9fc-1dce-4825-ba83-2f71cf9b1013,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-1f20c0e4-8cff-4d28-ba15-f12574ecb6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-b244d12e-52ba-402f-b5bc-b307345c1362,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-b28be989-f25d-493e-a8ce-cdfc44e7cf39,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-3f40c8c0-d179-4cac-a03c-92684d487f81,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-41eecc5c-8950-4b08-9e7d-f33e5905730b,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-9a2350ca-4064-40cd-a7f9-d7fe8b21909d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-179557071-172.17.0.6-1595520097055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46189,DS-4d6f8280-54fd-417a-ad95-84a18402762c,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-dfcc9dfa-f91b-421a-9553-654bb8443e34,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-58178f41-be12-486c-b934-73a89a0bfeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-b3538f7d-16e4-410c-92a2-e27865d7d8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-36f54c3d-695c-40a3-945e-87b4e9a9b957,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-6e3a6366-c15a-4f0e-b8bd-a4b4fae24983,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-1bd8dcfe-b92b-4107-9a3e-1976b137a220,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-081cad48-814e-4cc8-86ee-96472a6b5ec3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-179557071-172.17.0.6-1595520097055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46189,DS-4d6f8280-54fd-417a-ad95-84a18402762c,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-dfcc9dfa-f91b-421a-9553-654bb8443e34,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-58178f41-be12-486c-b934-73a89a0bfeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-b3538f7d-16e4-410c-92a2-e27865d7d8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-36f54c3d-695c-40a3-945e-87b4e9a9b957,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-6e3a6366-c15a-4f0e-b8bd-a4b4fae24983,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-1bd8dcfe-b92b-4107-9a3e-1976b137a220,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-081cad48-814e-4cc8-86ee-96472a6b5ec3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-726269282-172.17.0.6-1595520610820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34676,DS-09485a20-c97a-4b95-bb63-b9dcdba0b943,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-b1d31a9c-be13-4b15-a117-85841b38f782,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-60489960-a4e3-4944-b531-6264f2c6f6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-35cef34a-314e-4d90-a100-bd0accf52a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-8abf2729-47a7-4a57-9b48-a9c4f1103b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-197ca274-d6f7-4f6d-9c10-6669dd06b782,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-58c64db5-70ed-49b1-b21e-61b6352757be,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-fd44d70f-86a0-4ab5-a3df-e5e56346fdca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-726269282-172.17.0.6-1595520610820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34676,DS-09485a20-c97a-4b95-bb63-b9dcdba0b943,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-b1d31a9c-be13-4b15-a117-85841b38f782,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-60489960-a4e3-4944-b531-6264f2c6f6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-35cef34a-314e-4d90-a100-bd0accf52a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-8abf2729-47a7-4a57-9b48-a9c4f1103b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-197ca274-d6f7-4f6d-9c10-6669dd06b782,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-58c64db5-70ed-49b1-b21e-61b6352757be,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-fd44d70f-86a0-4ab5-a3df-e5e56346fdca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-336486656-172.17.0.6-1595520976554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35783,DS-bef2ec56-b660-4b2f-8650-6b3590b5ec32,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-dd4d5766-9071-4761-8cb9-667f72a39e46,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-46e33592-a68b-47d6-8b32-5d31bc132aea,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-976c03c8-c3b7-4cd7-9b6a-530996414da3,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-c4e9fc1b-da2b-4e7e-90fb-23e68d904333,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-ba31f122-d83d-480f-8f40-227402ee0075,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-9d3db58e-7c74-4133-bcfb-69afbf836393,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-1a446603-7ece-4f01-81d4-7586ab667c31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-336486656-172.17.0.6-1595520976554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35783,DS-bef2ec56-b660-4b2f-8650-6b3590b5ec32,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-dd4d5766-9071-4761-8cb9-667f72a39e46,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-46e33592-a68b-47d6-8b32-5d31bc132aea,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-976c03c8-c3b7-4cd7-9b6a-530996414da3,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-c4e9fc1b-da2b-4e7e-90fb-23e68d904333,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-ba31f122-d83d-480f-8f40-227402ee0075,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-9d3db58e-7c74-4133-bcfb-69afbf836393,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-1a446603-7ece-4f01-81d4-7586ab667c31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6833
