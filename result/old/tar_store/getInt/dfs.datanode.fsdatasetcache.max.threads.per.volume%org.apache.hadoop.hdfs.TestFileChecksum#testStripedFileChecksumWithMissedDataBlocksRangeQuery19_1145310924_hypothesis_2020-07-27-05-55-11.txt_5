reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1989890504-172.17.0.17-1595829400341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39186,DS-d2e405b6-57c7-4fde-8781-8611dd2e6123,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-98588a5c-c7d3-4def-b9c8-4da3c62b3039,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-130249a0-6def-4678-8ec4-1e74751af795,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-4c691aee-ba49-4e26-86be-540567f67b74,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-03c15aa8-3d3e-4b9f-b848-2e7d99fcc9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-0760f8a0-5b61-4b49-9fb5-8cb51459c0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-bab3bc4d-3d5b-4450-87f5-4c2356eb3c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-0f6dd1a6-4f3a-42d9-a48b-edde587e81ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1989890504-172.17.0.17-1595829400341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39186,DS-d2e405b6-57c7-4fde-8781-8611dd2e6123,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-98588a5c-c7d3-4def-b9c8-4da3c62b3039,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-130249a0-6def-4678-8ec4-1e74751af795,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-4c691aee-ba49-4e26-86be-540567f67b74,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-03c15aa8-3d3e-4b9f-b848-2e7d99fcc9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-0760f8a0-5b61-4b49-9fb5-8cb51459c0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-bab3bc4d-3d5b-4450-87f5-4c2356eb3c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-0f6dd1a6-4f3a-42d9-a48b-edde587e81ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1988897478-172.17.0.17-1595829581614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38783,DS-34abbd29-147b-4d59-a427-a07f7158ba6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-55724dfd-e6a4-407c-bf1e-63583a1d94f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-91c38e54-fd4f-4419-a8c2-dc2152ec69c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-4aae8559-b19d-4568-94f8-9d5fe92dfc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-8666173e-4389-4d7e-84e2-c565d95b4a50,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-8e02f259-f66a-454f-ae7f-374a719d00fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-17176916-290e-4d24-ad70-de5c9d936a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-e095b196-15ab-4993-92d6-2f178d8e1038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1988897478-172.17.0.17-1595829581614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38783,DS-34abbd29-147b-4d59-a427-a07f7158ba6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-55724dfd-e6a4-407c-bf1e-63583a1d94f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-91c38e54-fd4f-4419-a8c2-dc2152ec69c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-4aae8559-b19d-4568-94f8-9d5fe92dfc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-8666173e-4389-4d7e-84e2-c565d95b4a50,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-8e02f259-f66a-454f-ae7f-374a719d00fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-17176916-290e-4d24-ad70-de5c9d936a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-e095b196-15ab-4993-92d6-2f178d8e1038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-563486393-172.17.0.17-1595829938073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35095,DS-ea5af172-9d92-4036-8743-2bcf14391800,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-58646c60-46d6-4505-aa97-930f68f87c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-dc331488-5975-4ec2-a9ee-6c5f4c50c38f,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-f8d22689-1996-4bcf-9d7d-f10636cf07a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-253b75ba-c719-43c2-8a4b-44f9e21d4b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-8e26e59d-eccc-4d66-b664-cc5891d17728,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-cdb02dc9-2e08-4b4c-a031-41ab4e606888,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-9a103728-6d70-4783-b5e6-ce223b105c72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-563486393-172.17.0.17-1595829938073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35095,DS-ea5af172-9d92-4036-8743-2bcf14391800,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-58646c60-46d6-4505-aa97-930f68f87c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-dc331488-5975-4ec2-a9ee-6c5f4c50c38f,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-f8d22689-1996-4bcf-9d7d-f10636cf07a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-253b75ba-c719-43c2-8a4b-44f9e21d4b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-8e26e59d-eccc-4d66-b664-cc5891d17728,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-cdb02dc9-2e08-4b4c-a031-41ab4e606888,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-9a103728-6d70-4783-b5e6-ce223b105c72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-334289479-172.17.0.17-1595830016375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42780,DS-dede2db6-d739-47b6-a56a-0403acac57be,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-24add2b4-c41d-4a33-b316-2eed68037b94,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-d7ba5439-1989-48d6-bb35-f39b0aee5b75,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-cca4518e-52ae-419b-a10f-235f48b545a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-c1509d08-9581-4314-85b3-ac5586cc9e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-863e2929-3df0-4653-a743-eeaeb2ef960c,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-b929bafb-83f4-43f8-a20c-7f5961a9c4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-47c1fd7b-4487-4557-b41e-61c1042299e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-334289479-172.17.0.17-1595830016375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42780,DS-dede2db6-d739-47b6-a56a-0403acac57be,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-24add2b4-c41d-4a33-b316-2eed68037b94,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-d7ba5439-1989-48d6-bb35-f39b0aee5b75,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-cca4518e-52ae-419b-a10f-235f48b545a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-c1509d08-9581-4314-85b3-ac5586cc9e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-863e2929-3df0-4653-a743-eeaeb2ef960c,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-b929bafb-83f4-43f8-a20c-7f5961a9c4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-47c1fd7b-4487-4557-b41e-61c1042299e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-632978213-172.17.0.17-1595830205051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40581,DS-9a727c8d-20e5-439a-9176-c0a84b82c6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-a526ca0d-e15d-4ed5-8f09-c0ab2036995d,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-5dfd3cea-7ed2-4497-85d8-005b93053c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-211bdac2-392f-419c-82fe-b8c685f1cdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-a5bb0e56-4631-4d1f-bb29-64c1dcb6775f,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-b15b9f48-dad3-406c-88f9-863569e4e9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-529f30aa-93df-4906-850c-7612f52ae51c,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-e1817e9c-dd23-4600-abc6-0d11cdedaa70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-632978213-172.17.0.17-1595830205051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40581,DS-9a727c8d-20e5-439a-9176-c0a84b82c6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-a526ca0d-e15d-4ed5-8f09-c0ab2036995d,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-5dfd3cea-7ed2-4497-85d8-005b93053c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-211bdac2-392f-419c-82fe-b8c685f1cdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-a5bb0e56-4631-4d1f-bb29-64c1dcb6775f,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-b15b9f48-dad3-406c-88f9-863569e4e9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-529f30aa-93df-4906-850c-7612f52ae51c,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-e1817e9c-dd23-4600-abc6-0d11cdedaa70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-828877785-172.17.0.17-1595830349680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44702,DS-eef6897a-3611-444b-9247-103141cadf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-7e087634-b3b7-43fd-8a77-2d29c9a1faf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-3f46451f-5df9-4777-b3d3-4df095abb6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-c4d2020d-1ba1-4275-a595-e31f79688efb,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-e363ee67-2464-4c8d-bdad-6be601fba1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34839,DS-fbe4e51f-315c-40e5-b086-a92a37797a24,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-7c50560c-65b0-4b50-8d76-8d3c83ddae0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-fec43e18-8058-40e1-b5af-4bcc1772dd34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-828877785-172.17.0.17-1595830349680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44702,DS-eef6897a-3611-444b-9247-103141cadf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-7e087634-b3b7-43fd-8a77-2d29c9a1faf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-3f46451f-5df9-4777-b3d3-4df095abb6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-c4d2020d-1ba1-4275-a595-e31f79688efb,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-e363ee67-2464-4c8d-bdad-6be601fba1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34839,DS-fbe4e51f-315c-40e5-b086-a92a37797a24,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-7c50560c-65b0-4b50-8d76-8d3c83ddae0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-fec43e18-8058-40e1-b5af-4bcc1772dd34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-911195782-172.17.0.17-1595830811316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33150,DS-96b27f34-1ba8-4593-9852-2c587ed39641,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-e9d5f9f8-e656-4f09-969d-e6a1f2dd02c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-62c9b7be-b1c7-40a4-97ab-35e767dc47fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-1e8db941-c86d-480f-bf94-bfa099853db8,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-0e7a6643-e2d3-4adf-8c33-8bda04262975,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-fe74fa3b-8adb-4293-8bec-ce1527228984,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-76bb1d8b-7819-441d-877d-da1a690608cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-161ed7e8-aa7d-4a0d-8b32-164786700b67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-911195782-172.17.0.17-1595830811316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33150,DS-96b27f34-1ba8-4593-9852-2c587ed39641,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-e9d5f9f8-e656-4f09-969d-e6a1f2dd02c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-62c9b7be-b1c7-40a4-97ab-35e767dc47fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-1e8db941-c86d-480f-bf94-bfa099853db8,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-0e7a6643-e2d3-4adf-8c33-8bda04262975,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-fe74fa3b-8adb-4293-8bec-ce1527228984,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-76bb1d8b-7819-441d-877d-da1a690608cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-161ed7e8-aa7d-4a0d-8b32-164786700b67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-509864595-172.17.0.17-1595830845914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34563,DS-d9dce6c1-32a2-4c9e-a7f3-f83acf141dda,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-72c073cc-ee4d-415a-a2aa-179d880927e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-2cf4ba3a-8d86-49cf-a5a1-2bbfc90cff5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-aa9e0f97-b119-4992-a625-61578ebbe981,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-c8044364-73f7-488f-a72b-df94f8203574,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-4d46bea1-6b60-4bc1-b707-24a75f3aacea,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-6224017f-998d-4095-8d6f-b1e99625d572,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-570c6f61-2106-44a8-af50-6447e8f9d507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-509864595-172.17.0.17-1595830845914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34563,DS-d9dce6c1-32a2-4c9e-a7f3-f83acf141dda,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-72c073cc-ee4d-415a-a2aa-179d880927e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-2cf4ba3a-8d86-49cf-a5a1-2bbfc90cff5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-aa9e0f97-b119-4992-a625-61578ebbe981,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-c8044364-73f7-488f-a72b-df94f8203574,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-4d46bea1-6b60-4bc1-b707-24a75f3aacea,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-6224017f-998d-4095-8d6f-b1e99625d572,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-570c6f61-2106-44a8-af50-6447e8f9d507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703253344-172.17.0.17-1595831661504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34961,DS-cd786021-49df-4f1b-b924-403054a7461e,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-666012c1-7b9a-498b-a853-84d0f25e8245,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-3f0e4f19-3540-4978-997a-b03d9f50acaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-d264c249-8c95-49ff-a826-4405fb4b07b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-545d7177-fcc6-49a3-b21d-143f9703050f,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-a35d2042-e2b3-406a-bb43-5f0c55c8cb83,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-6579ab79-55f9-44e0-898d-758a7d2ec2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-25be6b23-a3b2-42ce-82a0-0434f993694c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703253344-172.17.0.17-1595831661504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34961,DS-cd786021-49df-4f1b-b924-403054a7461e,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-666012c1-7b9a-498b-a853-84d0f25e8245,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-3f0e4f19-3540-4978-997a-b03d9f50acaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-d264c249-8c95-49ff-a826-4405fb4b07b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-545d7177-fcc6-49a3-b21d-143f9703050f,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-a35d2042-e2b3-406a-bb43-5f0c55c8cb83,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-6579ab79-55f9-44e0-898d-758a7d2ec2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-25be6b23-a3b2-42ce-82a0-0434f993694c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1486329894-172.17.0.17-1595831831227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45094,DS-047a8da5-b28b-44d9-ba1e-4aa0a9beaef3,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-665983ea-097e-4aad-a63c-adb796024576,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-8e0d995c-1890-4506-8b49-33f945935adf,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-f288af22-9ec5-42bd-8962-9b6ac2c3f788,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-3f8273b4-d7f3-4976-9640-86f0032fd7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-fb021c60-fea9-4cb0-9135-f92c05c380d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-8a49b716-64f4-4b9f-b598-fc604fc44639,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-ca28f541-c010-425f-a9e7-11bfc569b707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1486329894-172.17.0.17-1595831831227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45094,DS-047a8da5-b28b-44d9-ba1e-4aa0a9beaef3,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-665983ea-097e-4aad-a63c-adb796024576,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-8e0d995c-1890-4506-8b49-33f945935adf,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-f288af22-9ec5-42bd-8962-9b6ac2c3f788,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-3f8273b4-d7f3-4976-9640-86f0032fd7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-fb021c60-fea9-4cb0-9135-f92c05c380d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-8a49b716-64f4-4b9f-b598-fc604fc44639,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-ca28f541-c010-425f-a9e7-11bfc569b707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-496471775-172.17.0.17-1595831931681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46415,DS-9816fa60-39f2-460c-b4c5-74a6ed714ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-fed8a1d2-f3ad-41eb-8c83-8f55b51c0c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-1ba6954b-ddbe-4008-bb49-d4c1b7599cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-2378e7b6-b314-45a7-b7ca-1efe1b100fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-369c9496-6632-4609-ac2f-303c433d822e,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-c528e8cf-5cca-41d5-9744-fc400fa8a518,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-15ab6279-92d2-40d1-87f5-38e745ca59c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-bd892ef2-767f-4eaf-877b-f101ba54791e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-496471775-172.17.0.17-1595831931681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46415,DS-9816fa60-39f2-460c-b4c5-74a6ed714ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-fed8a1d2-f3ad-41eb-8c83-8f55b51c0c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-1ba6954b-ddbe-4008-bb49-d4c1b7599cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-2378e7b6-b314-45a7-b7ca-1efe1b100fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-369c9496-6632-4609-ac2f-303c433d822e,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-c528e8cf-5cca-41d5-9744-fc400fa8a518,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-15ab6279-92d2-40d1-87f5-38e745ca59c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-bd892ef2-767f-4eaf-877b-f101ba54791e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1091450664-172.17.0.17-1595832076187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35371,DS-d8f67d7c-e3bd-4a0c-87f6-9d42d7c2ad44,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-565f77f7-7e67-4840-9f8d-1a448a68cd88,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-0a2d9cec-fae1-4ebc-9e73-a3eeb7ae2a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-6370a3d0-d035-43d8-a58a-70659713cb52,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-a1fac0be-0930-4fcd-a43a-0fb2d4a37bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-8d89666b-2b43-49b3-a6be-6350586fea6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-627036ef-93c7-4e0d-a737-5a8b88c8f138,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-7a7d6448-16bb-4de0-913e-e02b84f1d2da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1091450664-172.17.0.17-1595832076187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35371,DS-d8f67d7c-e3bd-4a0c-87f6-9d42d7c2ad44,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-565f77f7-7e67-4840-9f8d-1a448a68cd88,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-0a2d9cec-fae1-4ebc-9e73-a3eeb7ae2a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-6370a3d0-d035-43d8-a58a-70659713cb52,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-a1fac0be-0930-4fcd-a43a-0fb2d4a37bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-8d89666b-2b43-49b3-a6be-6350586fea6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-627036ef-93c7-4e0d-a737-5a8b88c8f138,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-7a7d6448-16bb-4de0-913e-e02b84f1d2da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132479303-172.17.0.17-1595832208003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40968,DS-f696b328-7898-4a5b-a2ec-fa81b555c668,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-855d6137-4c46-454d-8444-97e09befd804,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-4e8f0b47-16ca-4271-8a77-be426e3d2db2,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-29f61f04-12f2-4068-aca1-0f318aa107c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-71abff65-61a5-44a6-9088-25763cfbda38,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-afdf1091-7c26-4c57-8f04-c022194bba5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-43a5176e-346d-48b5-ba55-65bf8fec4602,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-627f08d5-1205-467c-84f2-048ed8096338,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132479303-172.17.0.17-1595832208003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40968,DS-f696b328-7898-4a5b-a2ec-fa81b555c668,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-855d6137-4c46-454d-8444-97e09befd804,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-4e8f0b47-16ca-4271-8a77-be426e3d2db2,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-29f61f04-12f2-4068-aca1-0f318aa107c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-71abff65-61a5-44a6-9088-25763cfbda38,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-afdf1091-7c26-4c57-8f04-c022194bba5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-43a5176e-346d-48b5-ba55-65bf8fec4602,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-627f08d5-1205-467c-84f2-048ed8096338,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-446234554-172.17.0.17-1595832385883:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42639,DS-8090b097-6943-4b95-85cf-37248e084b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-3b53e317-5248-4572-bc1a-276dabcdaf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-eb221462-3627-4d16-8843-54d5be6da24c,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-1177a6cc-e2e3-4dce-af6b-80e4b97eb24d,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-08f3a865-af7c-4b62-be27-0f9d378e5ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-b30bb07a-e629-4db7-8bf4-805f448824b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-27011dbf-0810-45eb-a983-aa91ddcf036b,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-323f79a4-d911-411d-a9da-c6b29fac6a8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-446234554-172.17.0.17-1595832385883:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42639,DS-8090b097-6943-4b95-85cf-37248e084b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-3b53e317-5248-4572-bc1a-276dabcdaf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-eb221462-3627-4d16-8843-54d5be6da24c,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-1177a6cc-e2e3-4dce-af6b-80e4b97eb24d,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-08f3a865-af7c-4b62-be27-0f9d378e5ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-b30bb07a-e629-4db7-8bf4-805f448824b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-27011dbf-0810-45eb-a983-aa91ddcf036b,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-323f79a4-d911-411d-a9da-c6b29fac6a8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835187168-172.17.0.17-1595833138520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43673,DS-3d0d6be4-4008-409e-8e0a-6c317795a8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-c484b37c-c2c7-4d76-8b3b-c65decbcc0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-74d6c1b7-8764-4103-9043-52461c7905bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-894f1bd0-2915-4e0e-9d92-56ebaa0b7f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-db071eb5-d8fe-49e7-96bd-85ec6ccd883d,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-108c748d-387d-49b4-831e-21bb150f7f55,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-612886c7-1165-4081-a2ce-57baea1c26e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-d3cd910f-d4e9-4d4d-8699-4fbc5b409d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835187168-172.17.0.17-1595833138520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43673,DS-3d0d6be4-4008-409e-8e0a-6c317795a8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-c484b37c-c2c7-4d76-8b3b-c65decbcc0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-74d6c1b7-8764-4103-9043-52461c7905bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-894f1bd0-2915-4e0e-9d92-56ebaa0b7f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-db071eb5-d8fe-49e7-96bd-85ec6ccd883d,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-108c748d-387d-49b4-831e-21bb150f7f55,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-612886c7-1165-4081-a2ce-57baea1c26e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-d3cd910f-d4e9-4d4d-8699-4fbc5b409d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1117278471-172.17.0.17-1595833987326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34384,DS-20434d2f-949b-46c9-9b39-6c6ac99417cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-d87dc07c-a9dd-4174-9fdc-cb33ff251880,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-f8ba2e16-c975-4cdb-be7e-5ba2e9b35d89,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-1dbebce5-7d02-4109-a478-6dbd1e0b6362,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-ae00f587-1993-42c9-bdf9-9e395788452d,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-550f22b6-0ab3-4492-8900-940455ceb873,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-7032e293-0d9e-4dcc-9fe1-46f8b3d67291,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-0730b48c-4a96-43d2-96aa-f7ce4fe18d67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1117278471-172.17.0.17-1595833987326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34384,DS-20434d2f-949b-46c9-9b39-6c6ac99417cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-d87dc07c-a9dd-4174-9fdc-cb33ff251880,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-f8ba2e16-c975-4cdb-be7e-5ba2e9b35d89,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-1dbebce5-7d02-4109-a478-6dbd1e0b6362,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-ae00f587-1993-42c9-bdf9-9e395788452d,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-550f22b6-0ab3-4492-8900-940455ceb873,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-7032e293-0d9e-4dcc-9fe1-46f8b3d67291,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-0730b48c-4a96-43d2-96aa-f7ce4fe18d67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5255
