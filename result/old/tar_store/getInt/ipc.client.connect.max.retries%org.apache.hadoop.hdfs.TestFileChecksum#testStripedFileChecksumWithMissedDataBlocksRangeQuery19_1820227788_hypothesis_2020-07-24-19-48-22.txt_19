reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272662959-172.17.0.13-1595620678501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35016,DS-f3d60480-ac20-41fa-8a5d-e35be5dbbaa3,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-6f77296c-c476-4347-8168-7ddae20f24a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-119d7da2-be7e-4166-9f56-2d2239daec83,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-ff6c7305-e73f-48b9-a183-074eab0fdb19,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-dcbc54f9-16ec-4b90-825e-552c9e53813c,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-f8e22749-c2fa-4935-b6d6-f991fb161b91,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-0a430d82-c185-4433-954a-48f8495ae8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-1b1dd1d4-2377-43dc-8922-1170b9c53e1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272662959-172.17.0.13-1595620678501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35016,DS-f3d60480-ac20-41fa-8a5d-e35be5dbbaa3,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-6f77296c-c476-4347-8168-7ddae20f24a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-119d7da2-be7e-4166-9f56-2d2239daec83,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-ff6c7305-e73f-48b9-a183-074eab0fdb19,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-dcbc54f9-16ec-4b90-825e-552c9e53813c,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-f8e22749-c2fa-4935-b6d6-f991fb161b91,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-0a430d82-c185-4433-954a-48f8495ae8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-1b1dd1d4-2377-43dc-8922-1170b9c53e1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1435692466-172.17.0.13-1595621243515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42375,DS-b0c4e0c8-4dac-4e6e-b60a-fa8a2159b248,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-1ef147a3-ab92-46d6-ab26-4a80a0b5803c,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-f6a1fe8a-3f88-483a-87ea-23e9a8bdb7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-6d4174e0-544f-460d-8872-d37640fb5b66,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-2422ebf3-3a9f-4957-af79-236219d72179,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-62aff8f5-ef6d-479f-85e0-da944d7090d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-5dd81d39-d01b-48c7-8485-3645e824cb63,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-8866a37a-3eda-4518-8ecc-bc7bdfcf2b5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1435692466-172.17.0.13-1595621243515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42375,DS-b0c4e0c8-4dac-4e6e-b60a-fa8a2159b248,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-1ef147a3-ab92-46d6-ab26-4a80a0b5803c,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-f6a1fe8a-3f88-483a-87ea-23e9a8bdb7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-6d4174e0-544f-460d-8872-d37640fb5b66,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-2422ebf3-3a9f-4957-af79-236219d72179,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-62aff8f5-ef6d-479f-85e0-da944d7090d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-5dd81d39-d01b-48c7-8485-3645e824cb63,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-8866a37a-3eda-4518-8ecc-bc7bdfcf2b5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1448691906-172.17.0.13-1595621541048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41733,DS-3f267f37-4379-4a36-9f07-87457497b525,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-c1850af4-650b-437a-8c67-ef57af818362,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-f094fcd2-d4f5-45ed-ae7b-787600bbd6be,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-b8844c1f-b165-41e5-a2ff-80ca370cdcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-90162f24-2fa1-4ed1-8f82-ee08a7ecaaea,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-c2fd50f5-574d-45cd-8cfb-0cc84051a19c,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-a433ae1a-b498-449d-baed-4d20e4ca2ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-c74aa27e-919b-4112-91b7-d389013dfb6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1448691906-172.17.0.13-1595621541048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41733,DS-3f267f37-4379-4a36-9f07-87457497b525,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-c1850af4-650b-437a-8c67-ef57af818362,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-f094fcd2-d4f5-45ed-ae7b-787600bbd6be,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-b8844c1f-b165-41e5-a2ff-80ca370cdcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-90162f24-2fa1-4ed1-8f82-ee08a7ecaaea,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-c2fd50f5-574d-45cd-8cfb-0cc84051a19c,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-a433ae1a-b498-449d-baed-4d20e4ca2ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-c74aa27e-919b-4112-91b7-d389013dfb6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1490953237-172.17.0.13-1595622543135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45544,DS-fe81d973-7f79-493a-bd71-166e26ecc11f,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-e032212f-bf67-4995-b37c-1c802014986a,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-48f46cea-f530-42ab-812a-ab3c7cfc2e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-9af13a23-cbaa-4a27-8c35-f4c7009b8c69,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-fff9acc3-ef2f-4252-b52d-16499433eb66,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-7e7c7f05-8d4d-4c8d-b1a2-7a3d17238859,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-9e35099d-85ee-4458-9344-09e1cbcc57e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-89288c10-2c95-467f-934f-cf69ce19c216,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1490953237-172.17.0.13-1595622543135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45544,DS-fe81d973-7f79-493a-bd71-166e26ecc11f,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-e032212f-bf67-4995-b37c-1c802014986a,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-48f46cea-f530-42ab-812a-ab3c7cfc2e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-9af13a23-cbaa-4a27-8c35-f4c7009b8c69,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-fff9acc3-ef2f-4252-b52d-16499433eb66,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-7e7c7f05-8d4d-4c8d-b1a2-7a3d17238859,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-9e35099d-85ee-4458-9344-09e1cbcc57e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-89288c10-2c95-467f-934f-cf69ce19c216,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-723388521-172.17.0.13-1595622651332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42363,DS-d663db7f-2eb6-41a3-aac9-6b4553a2a707,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-e50753ba-0b5b-4315-85e9-b29ca49d3bee,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-42550f60-ca56-42de-98fe-62130aee097c,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-71f91076-870f-40a9-89f0-9d2edb77c874,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-10397264-53e4-485f-ac0f-2e2b9dcb921c,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-087ec970-8668-4c6c-b288-5b0b8b49ab7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-e75826b7-0fce-4a59-9fd7-388c2228d9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-055825ac-e06f-4cfb-baae-901b9d8f58d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-723388521-172.17.0.13-1595622651332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42363,DS-d663db7f-2eb6-41a3-aac9-6b4553a2a707,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-e50753ba-0b5b-4315-85e9-b29ca49d3bee,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-42550f60-ca56-42de-98fe-62130aee097c,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-71f91076-870f-40a9-89f0-9d2edb77c874,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-10397264-53e4-485f-ac0f-2e2b9dcb921c,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-087ec970-8668-4c6c-b288-5b0b8b49ab7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-e75826b7-0fce-4a59-9fd7-388c2228d9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-055825ac-e06f-4cfb-baae-901b9d8f58d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-266456266-172.17.0.13-1595622939163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40011,DS-1a6ac7f4-fa40-4c43-88ea-0766fcf7492f,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-298b7dc7-a553-4fa1-847c-029541a27e09,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-0d09480a-1b8e-4ec5-96bc-27caf3e20bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-f666ab21-713b-4bc9-895b-7c94f337f166,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-1e459c39-2f62-42df-ae8e-83969ba1c1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-2858c993-eeac-46ac-8558-739a4fb1591b,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-9a3a81c1-df0d-43a4-b6b5-8feab4ad825f,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-794c8433-1b83-4773-acc3-e94bb0e4670b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-266456266-172.17.0.13-1595622939163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40011,DS-1a6ac7f4-fa40-4c43-88ea-0766fcf7492f,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-298b7dc7-a553-4fa1-847c-029541a27e09,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-0d09480a-1b8e-4ec5-96bc-27caf3e20bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-f666ab21-713b-4bc9-895b-7c94f337f166,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-1e459c39-2f62-42df-ae8e-83969ba1c1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-2858c993-eeac-46ac-8558-739a4fb1591b,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-9a3a81c1-df0d-43a4-b6b5-8feab4ad825f,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-794c8433-1b83-4773-acc3-e94bb0e4670b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-998351572-172.17.0.13-1595623072139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34931,DS-40774f01-ca0d-4ee1-8824-51dfc1342577,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-8326a760-935a-49f0-a42d-42c12b3e4087,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-b1ffe0ee-038e-48d8-bdae-a814fc421cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-debdd262-2e6b-449a-b457-ccac2b711218,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-b763b7ee-e35f-44e7-80e4-3ed400b49e66,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-a4c0b3ed-01a6-4c46-ae67-6a5ee494dd25,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-7f8033a8-f3d7-48cf-a702-ee34b220233e,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-628105ee-f8b4-472f-a803-1830ad343ae9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-998351572-172.17.0.13-1595623072139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34931,DS-40774f01-ca0d-4ee1-8824-51dfc1342577,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-8326a760-935a-49f0-a42d-42c12b3e4087,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-b1ffe0ee-038e-48d8-bdae-a814fc421cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-debdd262-2e6b-449a-b457-ccac2b711218,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-b763b7ee-e35f-44e7-80e4-3ed400b49e66,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-a4c0b3ed-01a6-4c46-ae67-6a5ee494dd25,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-7f8033a8-f3d7-48cf-a702-ee34b220233e,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-628105ee-f8b4-472f-a803-1830ad343ae9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1348964986-172.17.0.13-1595623519831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35677,DS-6bba082b-89f9-46b9-ab50-b4b1208ae4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-06a88199-a78f-4ed9-93c6-cbbfbf1edc53,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-facb1a74-1935-4ac5-9379-f24d0a8f401c,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-2d9779d1-7c62-462f-9d9d-03030f60039b,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-431e924c-30f8-4cab-bec4-0965c22c17af,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-63b8b625-ce0c-4e8d-b1cf-f11b2b836124,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-490b7ed0-5fb4-4981-a252-7e6e3a4d756a,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-e4f0ccee-9ab9-4cdd-9b7e-107df4bc69f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1348964986-172.17.0.13-1595623519831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35677,DS-6bba082b-89f9-46b9-ab50-b4b1208ae4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-06a88199-a78f-4ed9-93c6-cbbfbf1edc53,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-facb1a74-1935-4ac5-9379-f24d0a8f401c,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-2d9779d1-7c62-462f-9d9d-03030f60039b,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-431e924c-30f8-4cab-bec4-0965c22c17af,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-63b8b625-ce0c-4e8d-b1cf-f11b2b836124,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-490b7ed0-5fb4-4981-a252-7e6e3a4d756a,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-e4f0ccee-9ab9-4cdd-9b7e-107df4bc69f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646643820-172.17.0.13-1595623658250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45010,DS-fca44ac0-3573-4a4b-b620-c2c73affd2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-f9b9e8fd-fddf-4abc-bc51-e8b6b128d2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-a1865e74-51e3-4ecd-9caa-af7719acf345,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-b09ae3ae-a00b-4b87-91e2-0ed46b7057a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-4d4bf7f9-1fca-4a0c-80a5-a2ff3d6a2593,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-f1c6aed4-506f-4024-8b30-576cf5f6827c,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-31408c31-9af3-4fe9-aeda-a1857389d5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-d62f50ad-545e-453a-98ea-ab2f692868f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646643820-172.17.0.13-1595623658250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45010,DS-fca44ac0-3573-4a4b-b620-c2c73affd2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-f9b9e8fd-fddf-4abc-bc51-e8b6b128d2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-a1865e74-51e3-4ecd-9caa-af7719acf345,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-b09ae3ae-a00b-4b87-91e2-0ed46b7057a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-4d4bf7f9-1fca-4a0c-80a5-a2ff3d6a2593,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-f1c6aed4-506f-4024-8b30-576cf5f6827c,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-31408c31-9af3-4fe9-aeda-a1857389d5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-d62f50ad-545e-453a-98ea-ab2f692868f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-173151185-172.17.0.13-1595625182253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34633,DS-53b45831-367c-4eac-9229-9c2b9950e995,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-9811cd9d-5d99-465e-9e72-767b40d462f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-1b99591f-b259-403f-ad7a-b9ed879211eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-b684c585-5721-4326-ace0-d5538432388a,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-1566fe8c-dddf-49a9-98f7-da6739c9faf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-705cd2f1-8f21-436f-97de-2fab43238419,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-5e1333c7-a32e-49e6-b182-b92b9c142830,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-0d8e40eb-a266-4ecb-9c4a-07b8803fa650,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-173151185-172.17.0.13-1595625182253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34633,DS-53b45831-367c-4eac-9229-9c2b9950e995,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-9811cd9d-5d99-465e-9e72-767b40d462f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-1b99591f-b259-403f-ad7a-b9ed879211eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-b684c585-5721-4326-ace0-d5538432388a,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-1566fe8c-dddf-49a9-98f7-da6739c9faf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-705cd2f1-8f21-436f-97de-2fab43238419,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-5e1333c7-a32e-49e6-b182-b92b9c142830,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-0d8e40eb-a266-4ecb-9c4a-07b8803fa650,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-17763582-172.17.0.13-1595625881220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45082,DS-c2530812-105f-4a27-a918-67ab76900bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-3c39ae53-83e0-4d7e-844c-4395f2f8181b,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-bb2c163e-53b3-42c2-bb11-1922c8a40347,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-c23f24ce-a056-43a5-985f-5c3e913694de,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-eb679b6c-7512-4cd8-902a-b0ec3143f4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-64649a6a-6742-476e-bdfe-8aa3b70e89f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-0cb1c062-f04e-4846-b59f-9bd7210fcc91,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-f835ac4c-5ba3-4d62-a03a-6a1f24fa27a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-17763582-172.17.0.13-1595625881220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45082,DS-c2530812-105f-4a27-a918-67ab76900bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-3c39ae53-83e0-4d7e-844c-4395f2f8181b,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-bb2c163e-53b3-42c2-bb11-1922c8a40347,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-c23f24ce-a056-43a5-985f-5c3e913694de,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-eb679b6c-7512-4cd8-902a-b0ec3143f4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-64649a6a-6742-476e-bdfe-8aa3b70e89f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-0cb1c062-f04e-4846-b59f-9bd7210fcc91,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-f835ac4c-5ba3-4d62-a03a-6a1f24fa27a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-911744252-172.17.0.13-1595626161427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45012,DS-5a1cd0df-f94d-4a56-8636-eeb06b1187ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-31a64697-fee6-4284-a319-32d64a631c20,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-5424402f-2ced-4e1e-aa92-d708497a5bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-1286869b-a753-4ab8-ad40-4211f3d80383,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-f585b4d2-6e2d-49fa-879e-47a61081eedb,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-0e6088e6-245a-4512-97c2-34e3c9b99c06,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-c18bead7-1f6d-4334-b236-be393ae13952,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-089d4972-7712-4e90-99b0-015739428dd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-911744252-172.17.0.13-1595626161427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45012,DS-5a1cd0df-f94d-4a56-8636-eeb06b1187ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-31a64697-fee6-4284-a319-32d64a631c20,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-5424402f-2ced-4e1e-aa92-d708497a5bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-1286869b-a753-4ab8-ad40-4211f3d80383,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-f585b4d2-6e2d-49fa-879e-47a61081eedb,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-0e6088e6-245a-4512-97c2-34e3c9b99c06,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-c18bead7-1f6d-4334-b236-be393ae13952,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-089d4972-7712-4e90-99b0-015739428dd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1476078764-172.17.0.13-1595626207825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33333,DS-1d176d01-1a06-4ed9-9c6f-b28bb984c862,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-16ddf688-373a-41bc-a9b8-a4750622155f,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-5a565b80-9c66-4fe7-8ed0-efc3c43db11d,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-e726b7ab-5a4e-46eb-bc0b-2fd8c524cd55,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-93c34812-179d-4acc-ae68-60d0333ad1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-ed2872a8-bb0e-4d1d-8ede-b1afb0d4c167,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-c44bedcc-b1d2-4116-adbb-e11515d10704,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-f40ba418-7627-45ee-a8ee-5bc9b3c5018f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1476078764-172.17.0.13-1595626207825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33333,DS-1d176d01-1a06-4ed9-9c6f-b28bb984c862,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-16ddf688-373a-41bc-a9b8-a4750622155f,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-5a565b80-9c66-4fe7-8ed0-efc3c43db11d,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-e726b7ab-5a4e-46eb-bc0b-2fd8c524cd55,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-93c34812-179d-4acc-ae68-60d0333ad1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-ed2872a8-bb0e-4d1d-8ede-b1afb0d4c167,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-c44bedcc-b1d2-4116-adbb-e11515d10704,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-f40ba418-7627-45ee-a8ee-5bc9b3c5018f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1831730238-172.17.0.13-1595626253568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43246,DS-2d74b857-af85-4af2-8238-d1b65eb47846,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-8d1bf0db-b3e6-44a8-a1e0-b7e360eac827,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-3b5ba0bf-fabf-49f5-bb26-c740f8577e12,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-26101ab7-e8fd-48cc-98c6-27e4647c8424,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-2e3462a3-de12-44f2-9b0a-2eadaa9568e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-7c86037e-d239-4e62-ba90-3455812be7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-6c40cf90-0771-49bf-9730-ac820d1559bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-25516209-d3bc-4e5c-9bee-99ca6567307f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1831730238-172.17.0.13-1595626253568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43246,DS-2d74b857-af85-4af2-8238-d1b65eb47846,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-8d1bf0db-b3e6-44a8-a1e0-b7e360eac827,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-3b5ba0bf-fabf-49f5-bb26-c740f8577e12,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-26101ab7-e8fd-48cc-98c6-27e4647c8424,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-2e3462a3-de12-44f2-9b0a-2eadaa9568e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-7c86037e-d239-4e62-ba90-3455812be7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-6c40cf90-0771-49bf-9730-ac820d1559bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-25516209-d3bc-4e5c-9bee-99ca6567307f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-143795046-172.17.0.13-1595626329463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35063,DS-297247c9-c0a6-4c42-8e56-010f22789f89,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-c8f2a06f-b9b7-48fc-b73b-44294041c9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-336e1630-50f2-448e-b018-2ff9f2032203,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-e1ede58b-16de-462f-bbb7-2d4a466d9250,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-a571201c-5dad-42a3-a17f-7a1619046201,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-81390bca-0e83-4cae-908d-81f5b597c1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-56db19cc-d09e-440d-afb6-08c51a6095d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-84aab405-aaae-47be-9743-83b75769b35c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-143795046-172.17.0.13-1595626329463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35063,DS-297247c9-c0a6-4c42-8e56-010f22789f89,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-c8f2a06f-b9b7-48fc-b73b-44294041c9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-336e1630-50f2-448e-b018-2ff9f2032203,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-e1ede58b-16de-462f-bbb7-2d4a466d9250,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-a571201c-5dad-42a3-a17f-7a1619046201,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-81390bca-0e83-4cae-908d-81f5b597c1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-56db19cc-d09e-440d-afb6-08c51a6095d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-84aab405-aaae-47be-9743-83b75769b35c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1037498283-172.17.0.13-1595626997191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43207,DS-d61f591d-d037-4282-9223-61241e3b969c,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-c7dc7a64-e382-4c3a-ac3f-ed287b87deb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-8f512842-e41d-4ca4-b5f2-97950500017a,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-a5716ea9-b2d3-4d3f-8a76-664fa3ee8896,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-96f72790-f9b2-454e-ba0e-80a366dd4937,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-c0f134e0-0a86-4e33-a634-f0b0b616fc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-71fab39a-d877-4490-8680-a19049d80d53,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-b69f458a-dc20-4c6c-97a5-6857f0cd368a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1037498283-172.17.0.13-1595626997191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43207,DS-d61f591d-d037-4282-9223-61241e3b969c,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-c7dc7a64-e382-4c3a-ac3f-ed287b87deb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-8f512842-e41d-4ca4-b5f2-97950500017a,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-a5716ea9-b2d3-4d3f-8a76-664fa3ee8896,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-96f72790-f9b2-454e-ba0e-80a366dd4937,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-c0f134e0-0a86-4e33-a634-f0b0b616fc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-71fab39a-d877-4490-8680-a19049d80d53,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-b69f458a-dc20-4c6c-97a5-6857f0cd368a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6971
