reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943992056-172.17.0.9-1595978960704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39570,DS-91745df3-334d-4e04-8bfe-a69e260a55d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-17a8ba86-f851-49c2-a16b-c3dab0f38421,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-831cb53c-bbd3-44ca-8a4e-83cc5f871ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-f42b50bb-52e6-4d22-b5c6-80fc9ee27e69,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-f66139db-f027-4a4a-a05d-0792dbdb2785,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-76ecc98b-549b-48ee-b621-07d5d61f596d,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-e18b731f-1acf-4e45-b277-a0e51f79df01,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-2928fc93-fe0f-48d4-916e-098b22943bb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943992056-172.17.0.9-1595978960704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39570,DS-91745df3-334d-4e04-8bfe-a69e260a55d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-17a8ba86-f851-49c2-a16b-c3dab0f38421,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-831cb53c-bbd3-44ca-8a4e-83cc5f871ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-f42b50bb-52e6-4d22-b5c6-80fc9ee27e69,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-f66139db-f027-4a4a-a05d-0792dbdb2785,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-76ecc98b-549b-48ee-b621-07d5d61f596d,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-e18b731f-1acf-4e45-b277-a0e51f79df01,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-2928fc93-fe0f-48d4-916e-098b22943bb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79233111-172.17.0.9-1595979457531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39663,DS-11eddc5c-120a-4d50-97ec-1510454163e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-a9b04864-2a07-440e-b92e-142d63e2d186,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-0ec643c4-d1d6-49e3-a923-664e212070a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-56ed66d6-6392-430f-b8e0-0a39fd5850d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-861f23c6-6e7c-44ec-8f0a-acef3cf8b401,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-8ead4f38-d055-4c63-972d-66cb6757ab36,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-90057820-140c-4d66-a827-75fc5dbc17dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-7c62b371-84bd-4dfc-874b-e801920cbd00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79233111-172.17.0.9-1595979457531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39663,DS-11eddc5c-120a-4d50-97ec-1510454163e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-a9b04864-2a07-440e-b92e-142d63e2d186,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-0ec643c4-d1d6-49e3-a923-664e212070a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-56ed66d6-6392-430f-b8e0-0a39fd5850d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-861f23c6-6e7c-44ec-8f0a-acef3cf8b401,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-8ead4f38-d055-4c63-972d-66cb6757ab36,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-90057820-140c-4d66-a827-75fc5dbc17dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-7c62b371-84bd-4dfc-874b-e801920cbd00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797689939-172.17.0.9-1595979494851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35198,DS-badfce34-8e02-4c98-be5b-9bb8ab40020e,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-e4bf7bba-61fc-4ca1-969c-2107d2d02cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-2a360084-1248-4bf5-81e0-e648b72bc914,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-4f4c0fd6-c7e1-4be9-8381-9ab0eaf49945,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-3f2849b9-c351-4611-98d1-6a9beb238a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-8776c389-5757-4b87-9720-99cfc8451ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-39a8e7e7-bdf2-447e-af04-9014e805b2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-fb4c9f5b-c05c-4125-96a0-36d26845293d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797689939-172.17.0.9-1595979494851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35198,DS-badfce34-8e02-4c98-be5b-9bb8ab40020e,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-e4bf7bba-61fc-4ca1-969c-2107d2d02cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-2a360084-1248-4bf5-81e0-e648b72bc914,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-4f4c0fd6-c7e1-4be9-8381-9ab0eaf49945,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-3f2849b9-c351-4611-98d1-6a9beb238a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-8776c389-5757-4b87-9720-99cfc8451ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-39a8e7e7-bdf2-447e-af04-9014e805b2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-fb4c9f5b-c05c-4125-96a0-36d26845293d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683691625-172.17.0.9-1595979712288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32774,DS-176cfb9a-3c81-4c48-96d9-d65b02256e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-7b11a435-39cb-4c94-94e4-7dc68e922b77,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-7820b806-2005-48a4-8d26-600cad888259,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-9dcddd92-9727-435a-ae60-e74af71b85e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-3d0b5b5c-f519-45cc-97cb-5b49b4860766,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-55d5581e-adb6-4018-b098-8f49dfc2851c,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-cc81318f-be43-405e-968e-1eafa3fb4151,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-7ce7cf40-6ba2-4cd9-bbab-57918f0dcfa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683691625-172.17.0.9-1595979712288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32774,DS-176cfb9a-3c81-4c48-96d9-d65b02256e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-7b11a435-39cb-4c94-94e4-7dc68e922b77,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-7820b806-2005-48a4-8d26-600cad888259,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-9dcddd92-9727-435a-ae60-e74af71b85e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-3d0b5b5c-f519-45cc-97cb-5b49b4860766,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-55d5581e-adb6-4018-b098-8f49dfc2851c,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-cc81318f-be43-405e-968e-1eafa3fb4151,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-7ce7cf40-6ba2-4cd9-bbab-57918f0dcfa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76895912-172.17.0.9-1595979757246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34011,DS-3c395c2c-9988-46d4-bb1d-b66ee3c3d5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-2ac68ee1-ca69-4acd-80c7-c6bdf8e6fedc,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-0ee5448e-39a1-4dc0-87e9-086daf4b2dda,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-9184c88e-2667-4ca1-8a99-fa6856ffef63,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-d6d58df0-f001-410e-a528-9afc897424bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-e3c4a231-3d8d-46b4-b497-d0e0f61eb1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-0ffd156d-75a4-43d0-8f29-7fd655313a48,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-92528e82-1896-4f84-ab55-84fbe50353d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76895912-172.17.0.9-1595979757246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34011,DS-3c395c2c-9988-46d4-bb1d-b66ee3c3d5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-2ac68ee1-ca69-4acd-80c7-c6bdf8e6fedc,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-0ee5448e-39a1-4dc0-87e9-086daf4b2dda,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-9184c88e-2667-4ca1-8a99-fa6856ffef63,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-d6d58df0-f001-410e-a528-9afc897424bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-e3c4a231-3d8d-46b4-b497-d0e0f61eb1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-0ffd156d-75a4-43d0-8f29-7fd655313a48,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-92528e82-1896-4f84-ab55-84fbe50353d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914557373-172.17.0.9-1595980085547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35111,DS-9e680c53-2a4c-41f8-8f7d-3daef48929fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-2470dcb0-d7c9-4974-8cb7-fa34332b3be6,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-378fc25f-1c37-457a-9d8e-9ed04f24af1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-8770c37a-adb2-45c1-be3c-31912923aa36,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-4ab67691-2e2d-4e05-99d2-50ac6b46faa0,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-101584c1-4f48-4b57-b82e-34c13d520234,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-eb091b4e-d5ed-4d42-a442-734ce317a24a,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-22bc6b05-ab56-4d29-b455-217affb13179,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914557373-172.17.0.9-1595980085547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35111,DS-9e680c53-2a4c-41f8-8f7d-3daef48929fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-2470dcb0-d7c9-4974-8cb7-fa34332b3be6,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-378fc25f-1c37-457a-9d8e-9ed04f24af1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-8770c37a-adb2-45c1-be3c-31912923aa36,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-4ab67691-2e2d-4e05-99d2-50ac6b46faa0,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-101584c1-4f48-4b57-b82e-34c13d520234,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-eb091b4e-d5ed-4d42-a442-734ce317a24a,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-22bc6b05-ab56-4d29-b455-217affb13179,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995666924-172.17.0.9-1595980224165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40167,DS-a08aefc2-a1c8-4893-8b86-12a3b8c9c0af,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-9140242d-1792-45b3-b533-223ea539b43d,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-c901f83c-3f4e-4e33-bf48-4d6274ab1f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-1442630c-fb75-4238-99f8-82b1d607c05d,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-d7a92a21-d395-41de-8ff7-31b791d662a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-5914926c-b1b4-419a-97b4-3edbb09fa779,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-1c42dd56-6083-4a71-be62-17e90fecd733,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-ce16e042-fc50-4de2-ac4b-8918c8f62bd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995666924-172.17.0.9-1595980224165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40167,DS-a08aefc2-a1c8-4893-8b86-12a3b8c9c0af,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-9140242d-1792-45b3-b533-223ea539b43d,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-c901f83c-3f4e-4e33-bf48-4d6274ab1f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-1442630c-fb75-4238-99f8-82b1d607c05d,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-d7a92a21-d395-41de-8ff7-31b791d662a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-5914926c-b1b4-419a-97b4-3edbb09fa779,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-1c42dd56-6083-4a71-be62-17e90fecd733,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-ce16e042-fc50-4de2-ac4b-8918c8f62bd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-431952856-172.17.0.9-1595980267505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37350,DS-9f6286ac-6383-40f8-9aab-7890ad0ed32e,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-ea3ea4a6-e430-4809-98b8-af4c4f51925c,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-d45ffaf1-af02-488f-9712-9c868b687cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-623b184d-3238-4652-85ab-c38ea9fc6a14,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-610aa04f-696b-43f0-92dd-69e8f4ecc472,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-f848cc13-276c-4659-b2f2-53ce290205b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-5e8c2b70-5f44-4317-95a6-0972e89c46d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-6f90f44e-8b4f-40d0-848a-b1a03454652a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-431952856-172.17.0.9-1595980267505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37350,DS-9f6286ac-6383-40f8-9aab-7890ad0ed32e,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-ea3ea4a6-e430-4809-98b8-af4c4f51925c,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-d45ffaf1-af02-488f-9712-9c868b687cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-623b184d-3238-4652-85ab-c38ea9fc6a14,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-610aa04f-696b-43f0-92dd-69e8f4ecc472,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-f848cc13-276c-4659-b2f2-53ce290205b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-5e8c2b70-5f44-4317-95a6-0972e89c46d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-6f90f44e-8b4f-40d0-848a-b1a03454652a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107277136-172.17.0.9-1595980830574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39260,DS-1c68b2ff-4fcf-4e26-8ac0-7f976b4e4ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-2fac0198-caf6-4400-8eca-6d3c54a984e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-6fa45468-649a-4d39-b0cf-7ed7fdd61228,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-e2f829b6-78b2-4ba9-b49a-f9b451fc6be5,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-9d337b58-34f1-4b4e-b533-9e9ec108613f,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-acf83145-68bf-47dd-9776-42890ef27eee,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-7352fec9-2f7a-4423-88ca-9adcd8506963,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-359a0ee1-dca3-4274-9e87-bd0197ba03e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107277136-172.17.0.9-1595980830574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39260,DS-1c68b2ff-4fcf-4e26-8ac0-7f976b4e4ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-2fac0198-caf6-4400-8eca-6d3c54a984e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-6fa45468-649a-4d39-b0cf-7ed7fdd61228,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-e2f829b6-78b2-4ba9-b49a-f9b451fc6be5,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-9d337b58-34f1-4b4e-b533-9e9ec108613f,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-acf83145-68bf-47dd-9776-42890ef27eee,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-7352fec9-2f7a-4423-88ca-9adcd8506963,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-359a0ee1-dca3-4274-9e87-bd0197ba03e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1809510458-172.17.0.9-1595981393927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36757,DS-ad46768d-b7f0-45d0-929b-5bd1f46c7e05,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-3eced85c-5d41-4191-8404-174fe01b7d78,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-13ae0227-487f-471a-853f-89700e47642c,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-fb8c7bfd-227b-42be-93f6-89ec2dd36098,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-928f9b51-73d4-46bc-998b-19354d8ef8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-f3388f22-0966-4a3d-9fc9-9c0a74c6e11d,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-7ea32afe-dde3-4f82-9488-10ef000d115a,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-21031653-74a9-402b-b36f-1870b57d0deb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1809510458-172.17.0.9-1595981393927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36757,DS-ad46768d-b7f0-45d0-929b-5bd1f46c7e05,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-3eced85c-5d41-4191-8404-174fe01b7d78,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-13ae0227-487f-471a-853f-89700e47642c,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-fb8c7bfd-227b-42be-93f6-89ec2dd36098,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-928f9b51-73d4-46bc-998b-19354d8ef8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-f3388f22-0966-4a3d-9fc9-9c0a74c6e11d,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-7ea32afe-dde3-4f82-9488-10ef000d115a,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-21031653-74a9-402b-b36f-1870b57d0deb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839930713-172.17.0.9-1595981618789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38020,DS-67c8ae5b-16ec-4df6-ba5c-50f43169a0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-70afc64f-f7e0-4b56-a579-5d4196062768,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-34f871c6-c3aa-4ffa-a933-28bd0b4a2aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-66488585-8603-42a7-adcd-4e8cad37af10,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-1f3eb5a4-0d41-45fd-b060-f3c6ce1824d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-3e718fc7-e8cc-4cd8-a56f-9b0f36162de6,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-61062aed-fb78-4ad4-9fc1-4ed25cb242e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-b40241e2-b16c-46d3-9bcf-6a3f837ca837,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839930713-172.17.0.9-1595981618789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38020,DS-67c8ae5b-16ec-4df6-ba5c-50f43169a0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-70afc64f-f7e0-4b56-a579-5d4196062768,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-34f871c6-c3aa-4ffa-a933-28bd0b4a2aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-66488585-8603-42a7-adcd-4e8cad37af10,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-1f3eb5a4-0d41-45fd-b060-f3c6ce1824d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-3e718fc7-e8cc-4cd8-a56f-9b0f36162de6,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-61062aed-fb78-4ad4-9fc1-4ed25cb242e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-b40241e2-b16c-46d3-9bcf-6a3f837ca837,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1878142860-172.17.0.9-1595982693004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40069,DS-e09c7ada-25f2-4c28-90fd-36fa023a57fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-c154b4f0-eb57-4eb9-b6c4-4b2a35fc2553,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-cdf6965d-d551-4efe-befc-cf38baa85c63,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-953cb02c-0df9-4a9e-b6ac-6d7e7ff42df0,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-a009f864-ec33-4b8c-ae4b-0451b64a7457,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-9cab3d3e-852c-42fc-b500-d10670d3c4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-d1895105-7954-453e-8399-55b22a52d3da,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-4acab691-186f-487e-a2f5-bbe086808105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1878142860-172.17.0.9-1595982693004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40069,DS-e09c7ada-25f2-4c28-90fd-36fa023a57fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-c154b4f0-eb57-4eb9-b6c4-4b2a35fc2553,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-cdf6965d-d551-4efe-befc-cf38baa85c63,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-953cb02c-0df9-4a9e-b6ac-6d7e7ff42df0,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-a009f864-ec33-4b8c-ae4b-0451b64a7457,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-9cab3d3e-852c-42fc-b500-d10670d3c4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-d1895105-7954-453e-8399-55b22a52d3da,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-4acab691-186f-487e-a2f5-bbe086808105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-264705980-172.17.0.9-1595984259666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35717,DS-f2189656-61d9-418d-91d3-524e0d76f53b,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-dd28d9ad-9f34-47df-9728-b930f01a4e00,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-e5af1ca9-f65c-4e5b-8df0-44d20bd7069d,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-d991b102-12bf-451c-b4d1-1e4bef5304ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-fe347949-548f-434d-b7f5-82e38b7bd44a,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-1c4c3c24-4df7-42c5-93ba-a36831f1a05e,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-8a801919-58ba-4da5-b29d-be20c19353e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-23c680a8-a642-45a9-b77a-edb19e34dc33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-264705980-172.17.0.9-1595984259666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35717,DS-f2189656-61d9-418d-91d3-524e0d76f53b,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-dd28d9ad-9f34-47df-9728-b930f01a4e00,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-e5af1ca9-f65c-4e5b-8df0-44d20bd7069d,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-d991b102-12bf-451c-b4d1-1e4bef5304ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-fe347949-548f-434d-b7f5-82e38b7bd44a,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-1c4c3c24-4df7-42c5-93ba-a36831f1a05e,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-8a801919-58ba-4da5-b29d-be20c19353e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-23c680a8-a642-45a9-b77a-edb19e34dc33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638572710-172.17.0.9-1595984688141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42256,DS-9a9e202a-603d-46c7-a25a-fe3775fdee16,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-634b398b-3bda-4013-b241-0f1f601559ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-87ce895b-bf54-4371-b46f-782f50a8c388,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-91f66efe-882e-4ec2-a1e2-e6dc231d0687,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-0fa7de47-a46b-465e-b12c-df84d5eb47bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-e7b626a6-05e0-4934-8889-63ecb94cc58b,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-dda05837-40d0-40ff-aad4-9e779b558c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-804d40e5-ae2c-4b9d-b33a-85535f006147,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638572710-172.17.0.9-1595984688141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42256,DS-9a9e202a-603d-46c7-a25a-fe3775fdee16,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-634b398b-3bda-4013-b241-0f1f601559ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-87ce895b-bf54-4371-b46f-782f50a8c388,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-91f66efe-882e-4ec2-a1e2-e6dc231d0687,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-0fa7de47-a46b-465e-b12c-df84d5eb47bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-e7b626a6-05e0-4934-8889-63ecb94cc58b,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-dda05837-40d0-40ff-aad4-9e779b558c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-804d40e5-ae2c-4b9d-b33a-85535f006147,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509309890-172.17.0.9-1595985121427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41359,DS-4ef0e2e0-b4ec-4f6d-ab2d-b4eddc719709,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-9785322b-0466-46bb-b49a-50d66d99f152,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-1045c9f5-5506-4714-8b7a-f6b4602422a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-3915cbd3-1cc7-4b94-8b5f-e91dac1cb8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-2d1612e8-5039-400a-a6d9-8630fef80ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-085a4c0f-a917-4a3d-b891-77a3693521c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-bb5dd803-230b-490c-8ecc-8c41f391791f,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-1e0f19c2-8738-49cf-86f8-3bd519724e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509309890-172.17.0.9-1595985121427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41359,DS-4ef0e2e0-b4ec-4f6d-ab2d-b4eddc719709,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-9785322b-0466-46bb-b49a-50d66d99f152,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-1045c9f5-5506-4714-8b7a-f6b4602422a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-3915cbd3-1cc7-4b94-8b5f-e91dac1cb8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-2d1612e8-5039-400a-a6d9-8630fef80ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-085a4c0f-a917-4a3d-b891-77a3693521c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-bb5dd803-230b-490c-8ecc-8c41f391791f,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-1e0f19c2-8738-49cf-86f8-3bd519724e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6523
