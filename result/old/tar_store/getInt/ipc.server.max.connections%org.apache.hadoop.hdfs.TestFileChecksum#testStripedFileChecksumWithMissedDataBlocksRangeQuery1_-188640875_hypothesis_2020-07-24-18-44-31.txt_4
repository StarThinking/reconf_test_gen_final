reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977687200-172.17.0.18-1595616512839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33887,DS-17553ddc-7e50-4841-ae59-b73a23e1e052,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-bffc9ee7-3de7-4f8d-acbd-abcb5d40cbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-9a7fad97-5077-486d-bb03-b4ed19dcb5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-c5a6fd54-02c0-41c4-9250-426b4e950de5,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-44215ac0-b5fa-4319-98f6-daa4fb14b67a,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-ec778853-63f7-4ed8-8c26-f57e50397ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-338c144a-455b-49dd-8c5f-a90a72051877,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-aac5b63e-e833-4ca9-8c50-a38b1fda808b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977687200-172.17.0.18-1595616512839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33887,DS-17553ddc-7e50-4841-ae59-b73a23e1e052,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-bffc9ee7-3de7-4f8d-acbd-abcb5d40cbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-9a7fad97-5077-486d-bb03-b4ed19dcb5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-c5a6fd54-02c0-41c4-9250-426b4e950de5,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-44215ac0-b5fa-4319-98f6-daa4fb14b67a,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-ec778853-63f7-4ed8-8c26-f57e50397ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-338c144a-455b-49dd-8c5f-a90a72051877,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-aac5b63e-e833-4ca9-8c50-a38b1fda808b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-810422340-172.17.0.18-1595616735633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44613,DS-1399f6da-003e-42e6-b18e-f778e04029f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-f34a2b9f-b9da-4921-af53-33ea41226c09,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-7c0f843f-0c8c-47b3-95cd-b7e8e1a7525d,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-5974c3aa-590e-44ae-b599-6d5a19911d59,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-bf821b2a-1f39-4b58-89de-c1e4e997f565,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-b4f5ddc0-c1aa-409e-8f52-f1c75b485e57,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-b1b0c64b-efba-46d2-98ff-c3ce8ade6c07,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-8372a8d2-9c99-4c98-861d-37d7630b0b94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-810422340-172.17.0.18-1595616735633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44613,DS-1399f6da-003e-42e6-b18e-f778e04029f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-f34a2b9f-b9da-4921-af53-33ea41226c09,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-7c0f843f-0c8c-47b3-95cd-b7e8e1a7525d,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-5974c3aa-590e-44ae-b599-6d5a19911d59,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-bf821b2a-1f39-4b58-89de-c1e4e997f565,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-b4f5ddc0-c1aa-409e-8f52-f1c75b485e57,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-b1b0c64b-efba-46d2-98ff-c3ce8ade6c07,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-8372a8d2-9c99-4c98-861d-37d7630b0b94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986904889-172.17.0.18-1595616769548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43105,DS-68ba74ce-c9f3-4436-bc5e-f5ebaa3647ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-f801bbeb-1265-4172-8ecd-ea04ad0b4a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-9099bdb9-49d8-4b3b-9e30-743c0e4373d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-99b256df-6cfc-4850-9974-456f88cb0f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-3965ede0-28b4-4176-b240-704b7ef6a578,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-a04bd560-1af6-414d-af03-1b50feeccde6,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-85361285-078c-479c-86bd-8f00918fa265,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-fcdcff5a-7bd0-4427-b9cd-69511cbfc43d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986904889-172.17.0.18-1595616769548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43105,DS-68ba74ce-c9f3-4436-bc5e-f5ebaa3647ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-f801bbeb-1265-4172-8ecd-ea04ad0b4a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-9099bdb9-49d8-4b3b-9e30-743c0e4373d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-99b256df-6cfc-4850-9974-456f88cb0f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-3965ede0-28b4-4176-b240-704b7ef6a578,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-a04bd560-1af6-414d-af03-1b50feeccde6,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-85361285-078c-479c-86bd-8f00918fa265,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-fcdcff5a-7bd0-4427-b9cd-69511cbfc43d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1213118779-172.17.0.18-1595616861759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36911,DS-85a5a4bc-5dc8-4939-8054-7ad9ff154ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-2514a10a-d950-4321-a5d4-38e3f20b8e45,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-7e187149-18b1-4966-a208-837cba961656,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-83d65345-3739-46d5-9741-9792fdd0c859,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-f7ee6299-d6a5-490a-adc9-390c5d4dcdde,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-09f70ded-cfea-41de-bc11-b3c011d234f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-29e66eed-2c9c-4ee6-9d48-b5443540d74a,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-489e1339-f81b-43b2-b6de-0b8250d11fc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1213118779-172.17.0.18-1595616861759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36911,DS-85a5a4bc-5dc8-4939-8054-7ad9ff154ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-2514a10a-d950-4321-a5d4-38e3f20b8e45,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-7e187149-18b1-4966-a208-837cba961656,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-83d65345-3739-46d5-9741-9792fdd0c859,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-f7ee6299-d6a5-490a-adc9-390c5d4dcdde,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-09f70ded-cfea-41de-bc11-b3c011d234f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-29e66eed-2c9c-4ee6-9d48-b5443540d74a,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-489e1339-f81b-43b2-b6de-0b8250d11fc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104181240-172.17.0.18-1595617263039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34543,DS-09d6bf4a-ace7-40e0-a6e5-06450b3a822e,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-e1a0cf4e-3305-4f37-837d-aff646e88198,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-069919ab-973a-40dd-9741-6a8eb9174111,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-421c8906-f9a4-48fe-8318-5b0cfa0129de,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-4b599c94-f3c2-4d29-9e0b-a2670328de0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-318dd579-9f42-4ed5-858c-790052260647,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-80440f06-f109-473c-962c-84e8add033a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-e9cf4fd7-3da3-4e41-89a0-e8ee7ea620aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104181240-172.17.0.18-1595617263039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34543,DS-09d6bf4a-ace7-40e0-a6e5-06450b3a822e,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-e1a0cf4e-3305-4f37-837d-aff646e88198,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-069919ab-973a-40dd-9741-6a8eb9174111,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-421c8906-f9a4-48fe-8318-5b0cfa0129de,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-4b599c94-f3c2-4d29-9e0b-a2670328de0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-318dd579-9f42-4ed5-858c-790052260647,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-80440f06-f109-473c-962c-84e8add033a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-e9cf4fd7-3da3-4e41-89a0-e8ee7ea620aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320273973-172.17.0.18-1595617390194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42286,DS-187d860d-ba5d-4276-a795-fcb2738d99b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-ef1aa865-9d2d-49fe-85cd-82fd34924e47,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-aac3878c-67a5-475d-b310-3b31e0b6d191,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-86cc9ec8-fcf0-42ae-9563-72cde47aa2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-b2f1e15f-5c4c-4a51-a03d-560e1b9910f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-dce10439-af7b-4c93-983d-7b7172ff1207,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-6b116baa-216b-4106-99fb-44c4cae44974,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-31af3e8a-4231-4225-b914-502dd7b05aaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320273973-172.17.0.18-1595617390194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42286,DS-187d860d-ba5d-4276-a795-fcb2738d99b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-ef1aa865-9d2d-49fe-85cd-82fd34924e47,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-aac3878c-67a5-475d-b310-3b31e0b6d191,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-86cc9ec8-fcf0-42ae-9563-72cde47aa2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-b2f1e15f-5c4c-4a51-a03d-560e1b9910f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-dce10439-af7b-4c93-983d-7b7172ff1207,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-6b116baa-216b-4106-99fb-44c4cae44974,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-31af3e8a-4231-4225-b914-502dd7b05aaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129928834-172.17.0.18-1595617562165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44022,DS-29685c10-150e-47b7-b4b4-eb6571f7ec76,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-38cc649e-0572-49b9-ac11-cfd905f85e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-e7b72437-e023-452d-9495-f358de274859,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-6b6fa8d1-45f5-4ca4-83f9-3e4cc67db33c,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-05e140f9-9669-433a-8936-b9589411cbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-b09420dd-347d-4abd-b270-267876f1bd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-4f1cab5b-7394-4aff-99fe-34c2d42e44be,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-872a81ee-b362-4746-9280-63184132bb04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129928834-172.17.0.18-1595617562165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44022,DS-29685c10-150e-47b7-b4b4-eb6571f7ec76,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-38cc649e-0572-49b9-ac11-cfd905f85e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-e7b72437-e023-452d-9495-f358de274859,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-6b6fa8d1-45f5-4ca4-83f9-3e4cc67db33c,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-05e140f9-9669-433a-8936-b9589411cbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-b09420dd-347d-4abd-b270-267876f1bd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-4f1cab5b-7394-4aff-99fe-34c2d42e44be,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-872a81ee-b362-4746-9280-63184132bb04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354589822-172.17.0.18-1595617613267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44195,DS-9399bbe9-5c40-4eb1-a832-17c0fb91a577,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-8fb63aad-4c49-4a25-9d6b-2e5172082e34,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-54174817-deb6-4c39-ba6c-e59d21461553,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-1ccf9178-8a10-40ab-a540-296a902d9729,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-05fa1151-6973-4c94-acc9-4bc6682036b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-6b6446fb-9b55-4e3a-a49b-cf5b7a53a949,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-5bb4321f-4460-4884-9f33-be7b7351bd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-2cb0760a-d514-4c0f-9b53-927714aa3308,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354589822-172.17.0.18-1595617613267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44195,DS-9399bbe9-5c40-4eb1-a832-17c0fb91a577,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-8fb63aad-4c49-4a25-9d6b-2e5172082e34,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-54174817-deb6-4c39-ba6c-e59d21461553,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-1ccf9178-8a10-40ab-a540-296a902d9729,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-05fa1151-6973-4c94-acc9-4bc6682036b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-6b6446fb-9b55-4e3a-a49b-cf5b7a53a949,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-5bb4321f-4460-4884-9f33-be7b7351bd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-2cb0760a-d514-4c0f-9b53-927714aa3308,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1556327347-172.17.0.18-1595617660875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44940,DS-c7b3c9ae-7146-4ed3-befc-b18c3a12f015,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-166251b8-cffc-4a23-908d-aa7f6683a081,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-3c716e36-0cab-405c-97df-b1cf1d67990c,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-25c2a2d7-c5ee-410a-b32d-591938724633,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-c6d93c1c-667b-4751-b03c-227a980f786b,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-9b773ea2-ed0a-4421-b1b5-d4a27ced552b,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-84e63bf0-f117-4aa6-be30-11c4745226e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-bc315a7f-c455-4c8e-a4e9-b5dfffda3bbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1556327347-172.17.0.18-1595617660875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44940,DS-c7b3c9ae-7146-4ed3-befc-b18c3a12f015,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-166251b8-cffc-4a23-908d-aa7f6683a081,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-3c716e36-0cab-405c-97df-b1cf1d67990c,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-25c2a2d7-c5ee-410a-b32d-591938724633,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-c6d93c1c-667b-4751-b03c-227a980f786b,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-9b773ea2-ed0a-4421-b1b5-d4a27ced552b,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-84e63bf0-f117-4aa6-be30-11c4745226e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-bc315a7f-c455-4c8e-a4e9-b5dfffda3bbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1261789158-172.17.0.18-1595617789608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33923,DS-095ccb36-0f56-4efa-9bfc-d66d65a02ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-c90881c6-fbc9-4e9c-b20b-74a9fe84a1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-ded6421f-223d-41e0-9c75-7c9725e015e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-894edaa8-f7c3-4117-b1e5-1247ed408cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-b7269274-cb0b-4ec0-adef-1c48541079e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-31538b35-fe39-4a13-85f3-7b99bd5a3b50,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-8fed749c-9c4f-4964-bee9-17ba89d6dc77,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-dc472e75-ae84-408a-82e0-714649d70917,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1261789158-172.17.0.18-1595617789608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33923,DS-095ccb36-0f56-4efa-9bfc-d66d65a02ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-c90881c6-fbc9-4e9c-b20b-74a9fe84a1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-ded6421f-223d-41e0-9c75-7c9725e015e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-894edaa8-f7c3-4117-b1e5-1247ed408cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-b7269274-cb0b-4ec0-adef-1c48541079e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-31538b35-fe39-4a13-85f3-7b99bd5a3b50,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-8fed749c-9c4f-4964-bee9-17ba89d6dc77,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-dc472e75-ae84-408a-82e0-714649d70917,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593865696-172.17.0.18-1595619188861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38026,DS-6b0cb892-6a01-4ff5-be2e-0c1e4035a1da,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-c87b2407-c5ca-4d4b-82a1-18ad3133d6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-a222f8ac-0cf0-4b3c-b88b-66e986632376,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-b06f7e9d-0470-443b-b351-db7b932065ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-c95557e8-f759-49ff-8c1c-2fa3eca62e59,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-8fedb5bf-084d-4995-9618-8ff62dd37e51,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-ae87d13f-d949-4437-9c03-f9d2f33e011d,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-8b663d6b-5c86-49b1-b80f-77fbeb2dc68f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593865696-172.17.0.18-1595619188861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38026,DS-6b0cb892-6a01-4ff5-be2e-0c1e4035a1da,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-c87b2407-c5ca-4d4b-82a1-18ad3133d6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-a222f8ac-0cf0-4b3c-b88b-66e986632376,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-b06f7e9d-0470-443b-b351-db7b932065ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-c95557e8-f759-49ff-8c1c-2fa3eca62e59,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-8fedb5bf-084d-4995-9618-8ff62dd37e51,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-ae87d13f-d949-4437-9c03-f9d2f33e011d,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-8b663d6b-5c86-49b1-b80f-77fbeb2dc68f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-621455334-172.17.0.18-1595619407325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37398,DS-8b4ec5b2-c7dc-4c10-88df-83d04589efc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-dbcc387f-900a-4eb7-a3ce-f8b8508601d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-20f8ce95-b0b7-447a-980b-4304b7906426,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-7a4c05d4-3d5a-4d52-b6df-ccbbf9820c36,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-49c43fe3-d3dc-4b39-a566-ae1a1ceb8e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-ddbd25dc-8328-449a-bbb2-fe894ac07ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-bc25ef16-420a-4a09-b925-9d9066a0e37b,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-3ed49983-18bb-4b2b-85cd-569b2e422a75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-621455334-172.17.0.18-1595619407325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37398,DS-8b4ec5b2-c7dc-4c10-88df-83d04589efc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-dbcc387f-900a-4eb7-a3ce-f8b8508601d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-20f8ce95-b0b7-447a-980b-4304b7906426,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-7a4c05d4-3d5a-4d52-b6df-ccbbf9820c36,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-49c43fe3-d3dc-4b39-a566-ae1a1ceb8e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-ddbd25dc-8328-449a-bbb2-fe894ac07ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-bc25ef16-420a-4a09-b925-9d9066a0e37b,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-3ed49983-18bb-4b2b-85cd-569b2e422a75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-118386755-172.17.0.18-1595619488966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39539,DS-f3b9dbb4-0b49-403d-8abc-135069bb6a21,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-68f35319-601f-4e7c-9b6d-ce34fbc49e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-2bb4aa42-591f-4fec-8f3a-6e129c71f372,DISK], DatanodeInfoWithStorage[127.0.0.1:43319,DS-80fc484b-9c89-4204-a9d3-6d643164f0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-9c5e86ae-4923-494d-9b22-9ca77fa6c5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-a69b1069-c99c-44af-9b1a-4a4602ec8913,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-77668dd1-27cd-43dc-b35b-85f26541c364,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-2fdd7c59-4c23-40aa-add1-e310fd102d0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-118386755-172.17.0.18-1595619488966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39539,DS-f3b9dbb4-0b49-403d-8abc-135069bb6a21,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-68f35319-601f-4e7c-9b6d-ce34fbc49e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-2bb4aa42-591f-4fec-8f3a-6e129c71f372,DISK], DatanodeInfoWithStorage[127.0.0.1:43319,DS-80fc484b-9c89-4204-a9d3-6d643164f0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-9c5e86ae-4923-494d-9b22-9ca77fa6c5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-a69b1069-c99c-44af-9b1a-4a4602ec8913,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-77668dd1-27cd-43dc-b35b-85f26541c364,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-2fdd7c59-4c23-40aa-add1-e310fd102d0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1670061640-172.17.0.18-1595619962570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39790,DS-3b4a9faa-836e-4918-9093-d5c973f120bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-e5c8cd19-a61c-4e23-b8b9-92cfb571b872,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-56c009c3-eb3f-43a2-8910-3e4aac61a99c,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-bf27f74e-8cf2-4647-b089-ce9d76abb4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-443b21f4-4b5a-4f71-9701-687d09f81b13,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-12db3b02-d015-40f4-99c7-c45ac1faea77,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-afa95677-2d22-4c3f-b7f7-5ea57810cf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-37b0e896-627a-4881-b2b0-8ec5eae7be31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1670061640-172.17.0.18-1595619962570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39790,DS-3b4a9faa-836e-4918-9093-d5c973f120bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-e5c8cd19-a61c-4e23-b8b9-92cfb571b872,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-56c009c3-eb3f-43a2-8910-3e4aac61a99c,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-bf27f74e-8cf2-4647-b089-ce9d76abb4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-443b21f4-4b5a-4f71-9701-687d09f81b13,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-12db3b02-d015-40f4-99c7-c45ac1faea77,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-afa95677-2d22-4c3f-b7f7-5ea57810cf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-37b0e896-627a-4881-b2b0-8ec5eae7be31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-830334960-172.17.0.18-1595620351945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46538,DS-dfd95fe8-b5ee-4393-bb0b-2d67d6d60c91,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-2bb86ad0-ed22-46cb-a37e-987fee1decc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-549fba5e-d36b-4e7c-8fc8-113157a9b49b,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-795dfb57-bb3b-4a48-9014-192afb58005d,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-bb5eae82-2cc2-41d9-aae7-37dcff4a0520,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-4c7a40cf-8a58-43e6-8198-aa357e5ca9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-bf0b336a-e491-43be-89bf-56a619d942d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-cb1c2606-400d-40f2-8b23-dd4978360017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-830334960-172.17.0.18-1595620351945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46538,DS-dfd95fe8-b5ee-4393-bb0b-2d67d6d60c91,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-2bb86ad0-ed22-46cb-a37e-987fee1decc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-549fba5e-d36b-4e7c-8fc8-113157a9b49b,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-795dfb57-bb3b-4a48-9014-192afb58005d,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-bb5eae82-2cc2-41d9-aae7-37dcff4a0520,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-4c7a40cf-8a58-43e6-8198-aa357e5ca9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-bf0b336a-e491-43be-89bf-56a619d942d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-cb1c2606-400d-40f2-8b23-dd4978360017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-248567545-172.17.0.18-1595620390559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41754,DS-74ef076d-9e6a-47a3-b8ee-5a9cafbfac76,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-65e07f3a-dfec-4099-b214-a15e08161699,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-f78b1089-2ed5-4e90-a321-eb2216625f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-4981f191-58e2-41ad-abef-26f8bd222d52,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-be5dfefa-d9d6-4f14-b10c-0861a3821f26,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-9668dda3-7249-464e-833a-84be10229712,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-a900779c-e252-4aa3-9667-87c5f8889db6,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-57e03452-eb31-424a-8945-3c6f6beb8b71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-248567545-172.17.0.18-1595620390559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41754,DS-74ef076d-9e6a-47a3-b8ee-5a9cafbfac76,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-65e07f3a-dfec-4099-b214-a15e08161699,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-f78b1089-2ed5-4e90-a321-eb2216625f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-4981f191-58e2-41ad-abef-26f8bd222d52,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-be5dfefa-d9d6-4f14-b10c-0861a3821f26,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-9668dda3-7249-464e-833a-84be10229712,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-a900779c-e252-4aa3-9667-87c5f8889db6,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-57e03452-eb31-424a-8945-3c6f6beb8b71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767374618-172.17.0.18-1595620477148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43317,DS-39f650be-2727-4b27-bab4-3f0cd61fafd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-88e268f9-ba63-4592-8874-39eb6faf53fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-a9d4899f-f4c9-4ef5-8584-b684d4b3093f,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-9eb57dc1-659f-4c2e-a3d4-2ab9afd6417a,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-e4a5f725-22d1-4e1a-a0c3-ecb6ba255309,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-ec142ed0-b968-4949-9236-dd39772cbfba,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-de76eb25-bd37-46c0-9c7c-647e6e75d81b,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-14c3d383-a838-4ace-8733-426c0382ab50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767374618-172.17.0.18-1595620477148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43317,DS-39f650be-2727-4b27-bab4-3f0cd61fafd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-88e268f9-ba63-4592-8874-39eb6faf53fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-a9d4899f-f4c9-4ef5-8584-b684d4b3093f,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-9eb57dc1-659f-4c2e-a3d4-2ab9afd6417a,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-e4a5f725-22d1-4e1a-a0c3-ecb6ba255309,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-ec142ed0-b968-4949-9236-dd39772cbfba,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-de76eb25-bd37-46c0-9c7c-647e6e75d81b,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-14c3d383-a838-4ace-8733-426c0382ab50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-582889531-172.17.0.18-1595620680034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44584,DS-d0b56ac5-bfbe-4346-b1fe-4aa3b30c7a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-5318b229-97d9-4271-8102-c9c9c7fa190f,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-1e25d229-baef-43f9-a3f8-d1776edd2283,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-b9c6f49e-7bbb-4916-b88c-79c44f2e1f03,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-c6c10ecd-fffa-4843-af0d-03b6de715a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-19670c26-e065-4978-adcc-452d54b58bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-0e12eedb-28aa-402e-8aac-93f14c958436,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-c357377d-7a84-48cd-87a5-8cee0ff63ecf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-582889531-172.17.0.18-1595620680034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44584,DS-d0b56ac5-bfbe-4346-b1fe-4aa3b30c7a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-5318b229-97d9-4271-8102-c9c9c7fa190f,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-1e25d229-baef-43f9-a3f8-d1776edd2283,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-b9c6f49e-7bbb-4916-b88c-79c44f2e1f03,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-c6c10ecd-fffa-4843-af0d-03b6de715a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-19670c26-e065-4978-adcc-452d54b58bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-0e12eedb-28aa-402e-8aac-93f14c958436,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-c357377d-7a84-48cd-87a5-8cee0ff63ecf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-964569842-172.17.0.18-1595621256572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35333,DS-9d49636a-df42-4577-92a9-025e25c7bace,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-7d0697d4-8de9-4f32-93c0-eb66f298f797,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-c3f630d5-dc71-4a8a-99f2-6d066ad3274a,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-f06e07af-3faa-44d2-9bde-35b360b6bcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-37042913-195f-4784-a911-b5951f3dd6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-a33a3231-d626-4284-a28a-22c60658e1da,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-aeb27b78-238a-4eeb-bdd5-15fa33d28f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-d21e22c5-f945-4b87-954f-fed2e2838f95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-964569842-172.17.0.18-1595621256572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35333,DS-9d49636a-df42-4577-92a9-025e25c7bace,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-7d0697d4-8de9-4f32-93c0-eb66f298f797,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-c3f630d5-dc71-4a8a-99f2-6d066ad3274a,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-f06e07af-3faa-44d2-9bde-35b360b6bcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-37042913-195f-4784-a911-b5951f3dd6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-a33a3231-d626-4284-a28a-22c60658e1da,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-aeb27b78-238a-4eeb-bdd5-15fa33d28f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-d21e22c5-f945-4b87-954f-fed2e2838f95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595291197-172.17.0.18-1595621986006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35024,DS-1d33de99-8f59-4c4c-9947-2d46d13d187a,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-d580423d-c4f5-4d7b-bb73-059e0d7ef8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-983c4afa-129d-43b3-a561-5fd4b92dddfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-6772fee2-65cf-4ff0-bfec-71d0cc55a99d,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-5c77615e-9eaf-4d9a-bd46-94547e786b32,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-3471ac85-01ff-467e-b4cc-122f400deee7,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-bcbb424d-e9fe-4a42-9979-3263163640fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-98fff062-7e5c-4d2b-be13-25e42908b08f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595291197-172.17.0.18-1595621986006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35024,DS-1d33de99-8f59-4c4c-9947-2d46d13d187a,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-d580423d-c4f5-4d7b-bb73-059e0d7ef8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-983c4afa-129d-43b3-a561-5fd4b92dddfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-6772fee2-65cf-4ff0-bfec-71d0cc55a99d,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-5c77615e-9eaf-4d9a-bd46-94547e786b32,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-3471ac85-01ff-467e-b4cc-122f400deee7,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-bcbb424d-e9fe-4a42-9979-3263163640fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-98fff062-7e5c-4d2b-be13-25e42908b08f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709630563-172.17.0.18-1595622268710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43664,DS-46ab4776-b2bc-4654-939a-3c86079adce1,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-84225e80-ed49-4ec3-b1c2-25b0b5c7417e,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-5bf250e6-d757-4b61-870c-26131034d8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-2ed08d7e-8d18-497e-b1aa-d07de9022b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-fb5aff0c-68f4-4841-bdb0-9f8645fc80e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-271d1d8a-5937-48ba-8dbe-d439866d1c97,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-874086a0-67de-4470-a798-6efb89e81392,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-1a32154b-cab2-4e0a-88de-6a390b58e2dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709630563-172.17.0.18-1595622268710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43664,DS-46ab4776-b2bc-4654-939a-3c86079adce1,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-84225e80-ed49-4ec3-b1c2-25b0b5c7417e,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-5bf250e6-d757-4b61-870c-26131034d8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-2ed08d7e-8d18-497e-b1aa-d07de9022b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-fb5aff0c-68f4-4841-bdb0-9f8645fc80e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-271d1d8a-5937-48ba-8dbe-d439866d1c97,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-874086a0-67de-4470-a798-6efb89e81392,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-1a32154b-cab2-4e0a-88de-6a390b58e2dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35063773-172.17.0.18-1595622416542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37939,DS-009a965f-aec4-4ea3-99b3-622926309ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-8c663819-8561-47a7-9c27-23ae68a3651c,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-0fc7336b-25d2-4348-b3a0-4fe92bd8f1de,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-68b9f06b-6d67-4cb0-8a5c-15f8c6255d06,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-5e7a926b-f37d-4caf-9cf6-504f4e9b7447,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-9c772ff0-cfb9-4c6c-a6f6-04e9f836ec88,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-ca99477b-15d3-41df-b93c-3f2d6f7317d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-a3f40ba8-af31-4a35-a9f1-eb5138f1c48b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35063773-172.17.0.18-1595622416542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37939,DS-009a965f-aec4-4ea3-99b3-622926309ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-8c663819-8561-47a7-9c27-23ae68a3651c,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-0fc7336b-25d2-4348-b3a0-4fe92bd8f1de,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-68b9f06b-6d67-4cb0-8a5c-15f8c6255d06,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-5e7a926b-f37d-4caf-9cf6-504f4e9b7447,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-9c772ff0-cfb9-4c6c-a6f6-04e9f836ec88,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-ca99477b-15d3-41df-b93c-3f2d6f7317d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-a3f40ba8-af31-4a35-a9f1-eb5138f1c48b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2764370-172.17.0.18-1595622456872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41134,DS-d2318433-9b9a-49e8-b99d-2414807c52e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-2c1da20f-ac8b-467d-8f70-bf0d2aa55903,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-93451b46-36c5-4e0e-b26d-146794ba7de7,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-a5224bfc-060e-43e8-8903-f6de0fc6f7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-c15f8e5c-32c2-4b30-97d0-3cf92427e6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-ad0637b1-7f7c-4253-87f8-266fa72f0df0,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-68baa9f0-7d7b-4959-942b-6afb1ac1d582,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-c20521ca-f3f5-49ba-9e71-8700d722ed56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2764370-172.17.0.18-1595622456872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41134,DS-d2318433-9b9a-49e8-b99d-2414807c52e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-2c1da20f-ac8b-467d-8f70-bf0d2aa55903,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-93451b46-36c5-4e0e-b26d-146794ba7de7,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-a5224bfc-060e-43e8-8903-f6de0fc6f7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-c15f8e5c-32c2-4b30-97d0-3cf92427e6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-ad0637b1-7f7c-4253-87f8-266fa72f0df0,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-68baa9f0-7d7b-4959-942b-6afb1ac1d582,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-c20521ca-f3f5-49ba-9e71-8700d722ed56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6542
