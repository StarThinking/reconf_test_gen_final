reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-752593484-172.17.0.15-1595900908674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38852,DS-6de71b09-4c37-465e-8865-b124dff2ecb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-5ab9653c-0fdc-4e93-8d79-87ab3f79f17f,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-42c4e00a-1885-42ca-8e0f-77963912ed87,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-515caa36-6deb-4590-8bb7-96dd1e3dd33e,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-90a7efc2-ddb2-456c-94ba-577a1235a343,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-cdecb194-595a-449f-ba17-83dc2663b48d,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-a35f6cda-e911-45f3-afa6-296c49546d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-e4f0033e-98b7-4ae6-88c7-725fcc9ab634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-752593484-172.17.0.15-1595900908674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38852,DS-6de71b09-4c37-465e-8865-b124dff2ecb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-5ab9653c-0fdc-4e93-8d79-87ab3f79f17f,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-42c4e00a-1885-42ca-8e0f-77963912ed87,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-515caa36-6deb-4590-8bb7-96dd1e3dd33e,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-90a7efc2-ddb2-456c-94ba-577a1235a343,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-cdecb194-595a-449f-ba17-83dc2663b48d,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-a35f6cda-e911-45f3-afa6-296c49546d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-e4f0033e-98b7-4ae6-88c7-725fcc9ab634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2030269095-172.17.0.15-1595901059750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39218,DS-7c907d1a-45c9-47db-9220-4536556d21c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-0351d39b-ab27-4c3c-9445-6f4da516f1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-7149a966-b948-4f63-a51a-8d17e3982703,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-3404ea21-a656-45ca-8073-fc152ef460cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-5b9ed246-4a2b-464d-8dc8-880ceca56776,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-b7ce3e6b-dc12-498f-83ef-806a2390b9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-21862e47-8961-4e8e-9a72-6e9fd1813faa,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-f8d3796a-3023-45b9-9a1f-e297cf7bfddf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2030269095-172.17.0.15-1595901059750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39218,DS-7c907d1a-45c9-47db-9220-4536556d21c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-0351d39b-ab27-4c3c-9445-6f4da516f1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-7149a966-b948-4f63-a51a-8d17e3982703,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-3404ea21-a656-45ca-8073-fc152ef460cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-5b9ed246-4a2b-464d-8dc8-880ceca56776,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-b7ce3e6b-dc12-498f-83ef-806a2390b9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-21862e47-8961-4e8e-9a72-6e9fd1813faa,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-f8d3796a-3023-45b9-9a1f-e297cf7bfddf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126281229-172.17.0.15-1595902657162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37248,DS-70ab84ff-af21-418b-8045-011bcba9f5da,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-3f21a74b-8299-4855-9344-25cdb106046f,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-bde94466-995f-47f4-8459-07e9f6c4222a,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-6fc13b03-5cad-4a23-930d-293a23336993,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-c9296f90-f09b-45d3-b1ce-a6f10588301c,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-57e90ebd-8640-4515-bf83-4a68a6d6c572,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-46987e96-dde8-4f73-86ff-fd4348861028,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-0d6c8882-b9cd-4f3f-8873-ba7120240a26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126281229-172.17.0.15-1595902657162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37248,DS-70ab84ff-af21-418b-8045-011bcba9f5da,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-3f21a74b-8299-4855-9344-25cdb106046f,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-bde94466-995f-47f4-8459-07e9f6c4222a,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-6fc13b03-5cad-4a23-930d-293a23336993,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-c9296f90-f09b-45d3-b1ce-a6f10588301c,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-57e90ebd-8640-4515-bf83-4a68a6d6c572,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-46987e96-dde8-4f73-86ff-fd4348861028,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-0d6c8882-b9cd-4f3f-8873-ba7120240a26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376142208-172.17.0.15-1595902771430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34736,DS-0a1588fe-aa29-4dc4-88a3-16bb1966472f,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-e1422903-1f4a-40cd-9983-767a13d32992,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-cb53819d-024e-4207-b37b-7a2894fd6d63,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-cdaf1235-f2b9-4dc6-bfe8-06dd525eb28c,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-45af36da-5a82-4a7f-b896-837ff0e89967,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-d4572255-9c1b-411f-b604-4653b7998cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-6b33528b-10bc-45ea-81ba-1a7ff1c3443e,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-f940daa8-1927-4c5f-b3ee-a305bcb5b9be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376142208-172.17.0.15-1595902771430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34736,DS-0a1588fe-aa29-4dc4-88a3-16bb1966472f,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-e1422903-1f4a-40cd-9983-767a13d32992,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-cb53819d-024e-4207-b37b-7a2894fd6d63,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-cdaf1235-f2b9-4dc6-bfe8-06dd525eb28c,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-45af36da-5a82-4a7f-b896-837ff0e89967,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-d4572255-9c1b-411f-b604-4653b7998cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-6b33528b-10bc-45ea-81ba-1a7ff1c3443e,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-f940daa8-1927-4c5f-b3ee-a305bcb5b9be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1807879800-172.17.0.15-1595903179475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36983,DS-71d4c39a-0382-44b4-9ecd-1b00599dc0db,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-5a91b2da-fe8d-4ccd-aaea-cf16879dfcf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-4ce78b42-ff50-4c6b-921d-8d051ddca79b,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-d3072ca7-c282-4d3c-974a-c9a9665eb0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-647c92a5-456c-4b1c-b901-edfa2cef77f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-f5165791-12c1-404e-b6f0-941b8ce1631b,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-e29730fd-134b-4d6a-84d8-dbe4cfbd7fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-e8e1cd72-3d92-4e0a-a1fb-15f607781903,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1807879800-172.17.0.15-1595903179475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36983,DS-71d4c39a-0382-44b4-9ecd-1b00599dc0db,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-5a91b2da-fe8d-4ccd-aaea-cf16879dfcf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-4ce78b42-ff50-4c6b-921d-8d051ddca79b,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-d3072ca7-c282-4d3c-974a-c9a9665eb0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-647c92a5-456c-4b1c-b901-edfa2cef77f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-f5165791-12c1-404e-b6f0-941b8ce1631b,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-e29730fd-134b-4d6a-84d8-dbe4cfbd7fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-e8e1cd72-3d92-4e0a-a1fb-15f607781903,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461316720-172.17.0.15-1595903291588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43929,DS-3bb02e20-a048-448b-9963-3e00cabae5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-4c1f9b6d-4d32-44ff-be90-407a3e3bca8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-6d4adfbf-0f59-4585-979a-5bd24f690284,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-c7086a40-78fe-4aeb-945d-18c45f03a467,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-e85acf8e-2dde-489e-9b9c-57477a837c41,DISK], DatanodeInfoWithStorage[127.0.0.1:33086,DS-c7e9fbc3-5975-4f52-aade-4dd030c62713,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-9295b572-e13a-4d05-b31c-347ccd1d95db,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-4950f0ef-1833-4404-950b-96fca761747a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461316720-172.17.0.15-1595903291588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43929,DS-3bb02e20-a048-448b-9963-3e00cabae5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-4c1f9b6d-4d32-44ff-be90-407a3e3bca8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-6d4adfbf-0f59-4585-979a-5bd24f690284,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-c7086a40-78fe-4aeb-945d-18c45f03a467,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-e85acf8e-2dde-489e-9b9c-57477a837c41,DISK], DatanodeInfoWithStorage[127.0.0.1:33086,DS-c7e9fbc3-5975-4f52-aade-4dd030c62713,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-9295b572-e13a-4d05-b31c-347ccd1d95db,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-4950f0ef-1833-4404-950b-96fca761747a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803556127-172.17.0.15-1595903435589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46074,DS-e6d4417a-7ca2-4509-8312-6b76f429707b,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-d9299276-e51b-4b04-b072-eeb4fb6a15d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-54ae403a-9c13-4fc1-a431-15354b98d4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-115f22fc-ebc4-4b8a-8984-46c741e87558,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-25fa11ba-e5f5-45b1-a494-d0364db0e6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-e43f9ad1-70ca-4259-9d97-2d854bf5b9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-9a593957-a214-4f71-9984-9292a4359b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-a2ae5569-156c-48fa-ad75-6bea6decd2a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803556127-172.17.0.15-1595903435589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46074,DS-e6d4417a-7ca2-4509-8312-6b76f429707b,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-d9299276-e51b-4b04-b072-eeb4fb6a15d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-54ae403a-9c13-4fc1-a431-15354b98d4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-115f22fc-ebc4-4b8a-8984-46c741e87558,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-25fa11ba-e5f5-45b1-a494-d0364db0e6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-e43f9ad1-70ca-4259-9d97-2d854bf5b9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-9a593957-a214-4f71-9984-9292a4359b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-a2ae5569-156c-48fa-ad75-6bea6decd2a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243462-172.17.0.15-1595903470792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42984,DS-8aeb938e-6be6-464f-9e5e-9b647e6ad895,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-d996e9ef-9a24-48fa-bec2-36b9639437ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-d800874c-16ee-45d7-92fd-f89d8676284d,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-efbd4d6f-0ca7-4326-9cdb-2661bd621ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-8e6ebf9a-0ccd-4d0d-8d98-579fa4781077,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-490536c5-c2da-4293-b98d-f155a9908c68,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-3b853100-9b2b-497e-8eeb-171c55afecb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-2b6bfca6-c0df-4749-b64d-0d36fb120356,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243462-172.17.0.15-1595903470792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42984,DS-8aeb938e-6be6-464f-9e5e-9b647e6ad895,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-d996e9ef-9a24-48fa-bec2-36b9639437ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-d800874c-16ee-45d7-92fd-f89d8676284d,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-efbd4d6f-0ca7-4326-9cdb-2661bd621ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-8e6ebf9a-0ccd-4d0d-8d98-579fa4781077,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-490536c5-c2da-4293-b98d-f155a9908c68,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-3b853100-9b2b-497e-8eeb-171c55afecb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-2b6bfca6-c0df-4749-b64d-0d36fb120356,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851561385-172.17.0.15-1595903541107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40678,DS-589579ca-e639-4d23-929c-9e9d8fe2538b,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-b91ffd2b-7d0a-4b89-8602-f1df3d451a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-cbfc6db7-9a6f-47d8-901e-939b2f2b8bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-b8b6172b-3c5e-4e61-a470-f9ec09beebf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-a8a5604a-1bab-4421-93e0-052235c16e80,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-c77dd450-f0f3-429b-8ed5-dab9b7e0c614,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-bb321335-f188-4ac6-b3f4-51c6ab6ed76b,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-4e7f5d38-9b20-43a1-8080-afc097401ab4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851561385-172.17.0.15-1595903541107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40678,DS-589579ca-e639-4d23-929c-9e9d8fe2538b,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-b91ffd2b-7d0a-4b89-8602-f1df3d451a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-cbfc6db7-9a6f-47d8-901e-939b2f2b8bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-b8b6172b-3c5e-4e61-a470-f9ec09beebf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-a8a5604a-1bab-4421-93e0-052235c16e80,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-c77dd450-f0f3-429b-8ed5-dab9b7e0c614,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-bb321335-f188-4ac6-b3f4-51c6ab6ed76b,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-4e7f5d38-9b20-43a1-8080-afc097401ab4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092489560-172.17.0.15-1595903762339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46745,DS-426ca817-862b-44a5-a9a3-c7b93beaa291,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-3415e348-dc7c-45fe-8d2b-91a37a319a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-14e8a610-84b5-490e-afae-3b4f7565c857,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-62ea2653-1887-497d-a51d-ab34319a04f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-e9450cca-d031-4689-ba20-8481ed111978,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-2255ce24-dc8e-42a1-bb2e-7e5134c3c2be,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-06882c2f-16ec-43cb-a7e2-ad6ffca57376,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-a0f8eb40-f557-4ab2-851f-5704baf2d188,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092489560-172.17.0.15-1595903762339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46745,DS-426ca817-862b-44a5-a9a3-c7b93beaa291,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-3415e348-dc7c-45fe-8d2b-91a37a319a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-14e8a610-84b5-490e-afae-3b4f7565c857,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-62ea2653-1887-497d-a51d-ab34319a04f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-e9450cca-d031-4689-ba20-8481ed111978,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-2255ce24-dc8e-42a1-bb2e-7e5134c3c2be,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-06882c2f-16ec-43cb-a7e2-ad6ffca57376,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-a0f8eb40-f557-4ab2-851f-5704baf2d188,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631097516-172.17.0.15-1595904204390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36174,DS-2fb203e1-6deb-40ac-a58b-9706a20e4d84,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-cd7104f6-4728-41f1-9f1e-95f75236da4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-29728ffa-f2de-4d6f-beec-d902f7bcee75,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-fb879040-ba95-4b1a-b4f7-702062e2e0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-29a9cd50-6445-4f20-bfd3-a2f7c6555757,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-a65e2ffa-9989-48b0-8b98-9fbbd2f25f59,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-2772cce6-8d75-4549-88a7-198d9471dcce,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-718930d8-9db9-4c1a-83fc-9747a372e353,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631097516-172.17.0.15-1595904204390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36174,DS-2fb203e1-6deb-40ac-a58b-9706a20e4d84,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-cd7104f6-4728-41f1-9f1e-95f75236da4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-29728ffa-f2de-4d6f-beec-d902f7bcee75,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-fb879040-ba95-4b1a-b4f7-702062e2e0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-29a9cd50-6445-4f20-bfd3-a2f7c6555757,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-a65e2ffa-9989-48b0-8b98-9fbbd2f25f59,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-2772cce6-8d75-4549-88a7-198d9471dcce,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-718930d8-9db9-4c1a-83fc-9747a372e353,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492605055-172.17.0.15-1595905302130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44858,DS-e224a39b-c88e-4397-929b-79e3fd1a77c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-b65a8f24-8434-4655-a5e4-1f8cd1c02466,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-e6b55731-d919-4d8c-8bff-e127d3cabcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-47e84507-d1a1-461d-bfb2-86d7911d5415,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-ddd75bb8-ed84-4cfb-93eb-46df749dd223,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-fd8218c2-b679-4f45-9903-635bff00fcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-89232856-62c1-47b0-977a-3ccbda14da4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-056aa547-17c6-4cd9-a33d-3a2a52b781df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492605055-172.17.0.15-1595905302130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44858,DS-e224a39b-c88e-4397-929b-79e3fd1a77c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-b65a8f24-8434-4655-a5e4-1f8cd1c02466,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-e6b55731-d919-4d8c-8bff-e127d3cabcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-47e84507-d1a1-461d-bfb2-86d7911d5415,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-ddd75bb8-ed84-4cfb-93eb-46df749dd223,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-fd8218c2-b679-4f45-9903-635bff00fcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-89232856-62c1-47b0-977a-3ccbda14da4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-056aa547-17c6-4cd9-a33d-3a2a52b781df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086021084-172.17.0.15-1595905366046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40940,DS-f6743531-15b2-4baa-9944-38833f68d48e,DISK], DatanodeInfoWithStorage[127.0.0.1:45280,DS-1857e184-4cd1-4378-9440-36d7d5f605fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-f9b96ed5-6e2f-492b-8410-55cca0cd7a47,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-8c661f81-904a-44c0-b9c6-31182246adc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-0db92196-652f-47d3-bbbe-8487c88b3930,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-0782b2a7-58e2-436d-aca9-ddaa1199c1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-8806fdc9-a9d3-4e85-bbba-725404fc5cef,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-f5e9eebe-052d-45c3-92c8-ed9a9a4ec619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086021084-172.17.0.15-1595905366046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40940,DS-f6743531-15b2-4baa-9944-38833f68d48e,DISK], DatanodeInfoWithStorage[127.0.0.1:45280,DS-1857e184-4cd1-4378-9440-36d7d5f605fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-f9b96ed5-6e2f-492b-8410-55cca0cd7a47,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-8c661f81-904a-44c0-b9c6-31182246adc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-0db92196-652f-47d3-bbbe-8487c88b3930,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-0782b2a7-58e2-436d-aca9-ddaa1199c1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-8806fdc9-a9d3-4e85-bbba-725404fc5cef,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-f5e9eebe-052d-45c3-92c8-ed9a9a4ec619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1821467249-172.17.0.15-1595905433507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40348,DS-d531df98-5865-4fdb-9091-4f2f5a9ee33c,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-63a372f2-a8b0-45d4-8fd9-0d40eaede571,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-31afc697-629f-4d3e-b036-89e35a3299ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-8f2316dd-ae9c-4ad1-b66f-240ac72ff5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-0c78fde6-41bc-4deb-9ade-309a770647f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-22ee01d4-c5cc-4142-a09e-b8507aef68ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-e51d504f-e99b-40a8-ada2-f1f63f4f99a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-062cbc69-7ba9-43d6-af84-698989158d6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1821467249-172.17.0.15-1595905433507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40348,DS-d531df98-5865-4fdb-9091-4f2f5a9ee33c,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-63a372f2-a8b0-45d4-8fd9-0d40eaede571,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-31afc697-629f-4d3e-b036-89e35a3299ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-8f2316dd-ae9c-4ad1-b66f-240ac72ff5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-0c78fde6-41bc-4deb-9ade-309a770647f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-22ee01d4-c5cc-4142-a09e-b8507aef68ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-e51d504f-e99b-40a8-ada2-f1f63f4f99a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-062cbc69-7ba9-43d6-af84-698989158d6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221628170-172.17.0.15-1595905776940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36509,DS-00c11479-fca8-4529-b156-dcb588aebf23,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-4610eaf5-c9e2-48e5-a75f-374a7eb15a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-2a840be8-5806-46ed-bb7f-a24b867533bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-ee8e1998-c53a-4d63-b1f1-4608b24b4331,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-abca892a-4323-42f8-b5ec-063862703432,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-e6722092-7075-4247-9ea0-07759fb5f151,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-a10d6ca2-2082-4ea7-8aeb-98855f7c39f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-df49929f-cfd3-4224-a1fb-cd799c53024f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221628170-172.17.0.15-1595905776940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36509,DS-00c11479-fca8-4529-b156-dcb588aebf23,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-4610eaf5-c9e2-48e5-a75f-374a7eb15a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-2a840be8-5806-46ed-bb7f-a24b867533bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-ee8e1998-c53a-4d63-b1f1-4608b24b4331,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-abca892a-4323-42f8-b5ec-063862703432,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-e6722092-7075-4247-9ea0-07759fb5f151,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-a10d6ca2-2082-4ea7-8aeb-98855f7c39f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-df49929f-cfd3-4224-a1fb-cd799c53024f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-813662467-172.17.0.15-1595905995798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43250,DS-4f92dca9-3b2a-46db-b97c-f8e4ab096fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-0f22eadb-d9cb-4576-bb7b-cedd85824720,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-bcc70c3c-2dff-48d0-98eb-a6e768db9522,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-08d63641-e9ce-47f5-b0b0-4f09417e3744,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-97f434b2-c770-4643-a0b8-87a2b24dab4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-3fd385ac-8829-4eb5-a1b9-76e9e67394cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-4d33d56d-3537-4c4b-b29f-4e4ab1765d66,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-ab2385e0-19e5-4071-9866-3184512c31bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-813662467-172.17.0.15-1595905995798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43250,DS-4f92dca9-3b2a-46db-b97c-f8e4ab096fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-0f22eadb-d9cb-4576-bb7b-cedd85824720,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-bcc70c3c-2dff-48d0-98eb-a6e768db9522,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-08d63641-e9ce-47f5-b0b0-4f09417e3744,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-97f434b2-c770-4643-a0b8-87a2b24dab4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-3fd385ac-8829-4eb5-a1b9-76e9e67394cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-4d33d56d-3537-4c4b-b29f-4e4ab1765d66,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-ab2385e0-19e5-4071-9866-3184512c31bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061592887-172.17.0.15-1595906240050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34457,DS-2fca976e-a07f-479e-8f8b-69cc33daf24c,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-e9a11fa3-915b-4b87-9f22-8c89ac6c1763,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-b9117eac-e41b-4c39-959b-213f2337db1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-1c242fd5-6402-41f3-85bc-45cb0a2921ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-796254f8-ef9b-4541-b68b-2a010bb158b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-a1b08ff1-fe05-46bc-9df5-82318fcf9598,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-e13c351d-0da9-4e74-8844-d8d088043d05,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-8ca53613-915b-4ccd-9cc7-dd555daf8b25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061592887-172.17.0.15-1595906240050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34457,DS-2fca976e-a07f-479e-8f8b-69cc33daf24c,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-e9a11fa3-915b-4b87-9f22-8c89ac6c1763,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-b9117eac-e41b-4c39-959b-213f2337db1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-1c242fd5-6402-41f3-85bc-45cb0a2921ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-796254f8-ef9b-4541-b68b-2a010bb158b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-a1b08ff1-fe05-46bc-9df5-82318fcf9598,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-e13c351d-0da9-4e74-8844-d8d088043d05,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-8ca53613-915b-4ccd-9cc7-dd555daf8b25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5443
