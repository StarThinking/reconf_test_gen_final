reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1641886573-172.17.0.4-1595929315799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43689,DS-805af18b-60f1-4dd8-ba32-e218d0b65b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-9caed9d5-0490-4243-9b45-8993f3f8f680,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-bfdd7ca1-9ac6-4ffa-bdba-f078ac7bf650,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-6ad67420-a6ab-415b-909c-2c4001093627,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-95d96a2e-3e43-46b8-93a6-7a6924fb5159,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-0ef5b495-8e3f-4297-b4e5-6b7be5aac684,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-387d171b-1f8e-4f78-b865-8ada8f7faab2,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-6abe3048-1dfa-4578-9d33-62275926887c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1641886573-172.17.0.4-1595929315799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43689,DS-805af18b-60f1-4dd8-ba32-e218d0b65b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-9caed9d5-0490-4243-9b45-8993f3f8f680,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-bfdd7ca1-9ac6-4ffa-bdba-f078ac7bf650,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-6ad67420-a6ab-415b-909c-2c4001093627,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-95d96a2e-3e43-46b8-93a6-7a6924fb5159,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-0ef5b495-8e3f-4297-b4e5-6b7be5aac684,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-387d171b-1f8e-4f78-b865-8ada8f7faab2,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-6abe3048-1dfa-4578-9d33-62275926887c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1705379363-172.17.0.4-1595929381349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33013,DS-c4ca0131-4861-477e-b092-62e72c682a36,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-d586d648-2c91-4711-94ed-34af25f75894,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-2e47ca46-ae3b-4015-a8c0-cd6bcd821015,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-3e5b15e4-07ad-4ffa-a97b-1d5a63fcf726,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-319261ed-aea1-405c-ab0a-b64c307caac5,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-d7376af7-5e4f-455e-962e-59388d963996,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-a9608228-6bc8-4d8e-9318-08fbb1c2f086,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-14bae792-3e0f-429e-aa58-d28393fc24d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1705379363-172.17.0.4-1595929381349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33013,DS-c4ca0131-4861-477e-b092-62e72c682a36,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-d586d648-2c91-4711-94ed-34af25f75894,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-2e47ca46-ae3b-4015-a8c0-cd6bcd821015,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-3e5b15e4-07ad-4ffa-a97b-1d5a63fcf726,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-319261ed-aea1-405c-ab0a-b64c307caac5,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-d7376af7-5e4f-455e-962e-59388d963996,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-a9608228-6bc8-4d8e-9318-08fbb1c2f086,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-14bae792-3e0f-429e-aa58-d28393fc24d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1373943733-172.17.0.4-1595929887505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42231,DS-b4bd7617-eea0-481e-94ec-01e90547694c,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-b52cd13e-2263-42f0-9d5c-58ee5d629035,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-9023a827-b851-47f7-9e86-5d7f4be08efb,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-014a5b34-7278-485f-8b2d-619bc4678c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-dc61cae6-c075-48c9-9f2d-03338f59ba25,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-159013ca-7bd4-4553-a8df-22625da3cb35,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-bf923054-bf97-4761-bc1b-6bcca5556d87,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-29486bc7-f48d-496d-b3c0-ba1bab7c566d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1373943733-172.17.0.4-1595929887505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42231,DS-b4bd7617-eea0-481e-94ec-01e90547694c,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-b52cd13e-2263-42f0-9d5c-58ee5d629035,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-9023a827-b851-47f7-9e86-5d7f4be08efb,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-014a5b34-7278-485f-8b2d-619bc4678c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-dc61cae6-c075-48c9-9f2d-03338f59ba25,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-159013ca-7bd4-4553-a8df-22625da3cb35,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-bf923054-bf97-4761-bc1b-6bcca5556d87,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-29486bc7-f48d-496d-b3c0-ba1bab7c566d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-152233249-172.17.0.4-1595929958092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41303,DS-8a0bcd2e-bef7-48a9-a63a-095e1d399f49,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-7f185f97-3851-4418-b6cd-910d19bdbda1,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-596f1a4b-e342-40c4-b585-0dfed9f1d475,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-10d214bb-e606-4f3f-9845-3da4747cf969,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-eff69b6d-1aaf-4a52-bd51-7c97299df7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-561bd317-2698-4ae0-865c-2819c679e005,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-3aa4bc70-93e8-41ea-aa4c-75c26f61c8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-898a6b94-80d4-4c49-9aac-c669c76600ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-152233249-172.17.0.4-1595929958092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41303,DS-8a0bcd2e-bef7-48a9-a63a-095e1d399f49,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-7f185f97-3851-4418-b6cd-910d19bdbda1,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-596f1a4b-e342-40c4-b585-0dfed9f1d475,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-10d214bb-e606-4f3f-9845-3da4747cf969,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-eff69b6d-1aaf-4a52-bd51-7c97299df7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-561bd317-2698-4ae0-865c-2819c679e005,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-3aa4bc70-93e8-41ea-aa4c-75c26f61c8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-898a6b94-80d4-4c49-9aac-c669c76600ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-345184062-172.17.0.4-1595930025964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37669,DS-9daaf254-0793-4fd2-8a2f-223996309efb,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-636dd56d-9f54-4468-a42f-c98765c0b9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-f15d4824-4c19-4e17-bffd-53714544196b,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-c582c6d1-3a3d-4115-b5d1-a1c287c79961,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-7ac8f9f2-f7a5-4de5-b815-9397aef5c778,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-6a2663bf-fc3d-45f1-8e21-a10d17a546f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-22938dcc-a00f-440b-9c97-897681e82f79,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-0a3cabd4-4e18-43a7-9ef1-1ac35647dbb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-345184062-172.17.0.4-1595930025964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37669,DS-9daaf254-0793-4fd2-8a2f-223996309efb,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-636dd56d-9f54-4468-a42f-c98765c0b9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-f15d4824-4c19-4e17-bffd-53714544196b,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-c582c6d1-3a3d-4115-b5d1-a1c287c79961,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-7ac8f9f2-f7a5-4de5-b815-9397aef5c778,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-6a2663bf-fc3d-45f1-8e21-a10d17a546f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-22938dcc-a00f-440b-9c97-897681e82f79,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-0a3cabd4-4e18-43a7-9ef1-1ac35647dbb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1835139285-172.17.0.4-1595930357601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35034,DS-57c7d557-5d1d-4129-9244-675188717639,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-597f561b-f37a-473d-a7a6-bb94247a3a26,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-7a0654a6-8337-4128-a963-2cfd2f4608f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-9164a113-4129-47eb-9743-5379b93cbfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-31214015-40d4-4620-a3ee-e5bd326c4323,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-0452362b-2b72-4481-96e1-64e8f6a8486f,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-9990fb03-bfe5-4d7e-b347-6d7855982234,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-591569fc-91a1-4941-a383-ff20dcf4f450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1835139285-172.17.0.4-1595930357601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35034,DS-57c7d557-5d1d-4129-9244-675188717639,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-597f561b-f37a-473d-a7a6-bb94247a3a26,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-7a0654a6-8337-4128-a963-2cfd2f4608f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-9164a113-4129-47eb-9743-5379b93cbfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-31214015-40d4-4620-a3ee-e5bd326c4323,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-0452362b-2b72-4481-96e1-64e8f6a8486f,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-9990fb03-bfe5-4d7e-b347-6d7855982234,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-591569fc-91a1-4941-a383-ff20dcf4f450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-418535145-172.17.0.4-1595930771598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41347,DS-59f619b4-5720-4b27-a09b-f007ae35418d,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-1b10e21b-4308-420b-8340-46bad33abd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-97c14e7f-8397-45e8-b719-42b06cbeca54,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-65bc058f-9f73-459d-92af-d6df55f3edea,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-db6f4cd7-48a9-4db1-9dc7-90b5a0bddfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-ddbe5aa8-72e5-4638-bdff-345cae2580d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-ce88eb01-c587-499f-8716-3932540a38ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-f82425fb-ed9c-4d69-8ec6-3f671e3692d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-418535145-172.17.0.4-1595930771598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41347,DS-59f619b4-5720-4b27-a09b-f007ae35418d,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-1b10e21b-4308-420b-8340-46bad33abd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-97c14e7f-8397-45e8-b719-42b06cbeca54,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-65bc058f-9f73-459d-92af-d6df55f3edea,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-db6f4cd7-48a9-4db1-9dc7-90b5a0bddfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-ddbe5aa8-72e5-4638-bdff-345cae2580d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-ce88eb01-c587-499f-8716-3932540a38ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-f82425fb-ed9c-4d69-8ec6-3f671e3692d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1777143405-172.17.0.4-1595931509692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43587,DS-028dd544-a254-4b55-b0c1-d35e6954569d,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-cfede854-372d-4378-b248-83a216e90a55,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-9bca0c74-4a88-49fb-b858-26a45c4eaf26,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-58528c9b-00b2-43f8-8ae8-cb0ddec9df4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-84042acd-e428-46bf-84c7-8c335be843eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-b6273c79-fec9-4440-85ab-73c5c0cbad4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-b093ec14-caf3-4770-b467-a3936a0bcea7,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-7f814f02-d534-4701-b4a6-ed2213764f0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1777143405-172.17.0.4-1595931509692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43587,DS-028dd544-a254-4b55-b0c1-d35e6954569d,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-cfede854-372d-4378-b248-83a216e90a55,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-9bca0c74-4a88-49fb-b858-26a45c4eaf26,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-58528c9b-00b2-43f8-8ae8-cb0ddec9df4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-84042acd-e428-46bf-84c7-8c335be843eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-b6273c79-fec9-4440-85ab-73c5c0cbad4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-b093ec14-caf3-4770-b467-a3936a0bcea7,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-7f814f02-d534-4701-b4a6-ed2213764f0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-814087360-172.17.0.4-1595932252660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42578,DS-49fb17a4-454d-4386-8934-c65f437fe489,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-76d2656c-8c96-4cf5-82c6-0cb933d4b7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-74082371-74a3-4a45-a814-b10e3054e3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-3682840a-37f6-436e-9f05-5947231dad2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-51d1fc3f-3329-402f-aaba-16698ad554ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-afc9a6ce-aaea-4a58-a518-f9ebfd774153,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-bfb50419-9e56-49b3-bfc6-af2fb923c8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-c726b81f-ea22-4c68-aa10-67501d295f79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-814087360-172.17.0.4-1595932252660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42578,DS-49fb17a4-454d-4386-8934-c65f437fe489,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-76d2656c-8c96-4cf5-82c6-0cb933d4b7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-74082371-74a3-4a45-a814-b10e3054e3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-3682840a-37f6-436e-9f05-5947231dad2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-51d1fc3f-3329-402f-aaba-16698ad554ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-afc9a6ce-aaea-4a58-a518-f9ebfd774153,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-bfb50419-9e56-49b3-bfc6-af2fb923c8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-c726b81f-ea22-4c68-aa10-67501d295f79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-868764360-172.17.0.4-1595932668943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40602,DS-962d3ecc-ec4f-46c3-bba3-b1f118c8cd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-b1d63174-81ec-4efc-a361-e209b621a6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-72f269dc-13b5-44fe-8017-cd11c764787e,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-50444061-04a1-48a0-8c4e-a96b4bbc2e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-ea1fe5ae-f2da-4c12-8cac-ce6566a6bb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-337fe8d5-97c2-4ddc-a2df-3ffcbecc8233,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-580acc7f-96c5-4f54-823b-462d18ed07fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-c6309894-1fd9-496b-96ed-abb8370eb474,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-868764360-172.17.0.4-1595932668943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40602,DS-962d3ecc-ec4f-46c3-bba3-b1f118c8cd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-b1d63174-81ec-4efc-a361-e209b621a6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-72f269dc-13b5-44fe-8017-cd11c764787e,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-50444061-04a1-48a0-8c4e-a96b4bbc2e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-ea1fe5ae-f2da-4c12-8cac-ce6566a6bb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-337fe8d5-97c2-4ddc-a2df-3ffcbecc8233,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-580acc7f-96c5-4f54-823b-462d18ed07fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-c6309894-1fd9-496b-96ed-abb8370eb474,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118713832-172.17.0.4-1595932811405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44539,DS-5e83152a-a549-4018-aa24-592ea6e6a410,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-66df5419-b837-427a-9de4-a5ce833a6818,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-55299d94-f1c8-4883-9d7b-17a60fa48575,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-a8f7acbc-3ba0-4262-a33b-218cbe1f1849,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-2d03648c-46d6-4aff-937e-6d1c57850bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-72f21b09-5056-4cbe-a40f-f21e332cf2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-37d385c7-3c4a-45a5-a44f-a8551f627dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-89788200-67c5-4942-bc54-91ed782d1a92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118713832-172.17.0.4-1595932811405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44539,DS-5e83152a-a549-4018-aa24-592ea6e6a410,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-66df5419-b837-427a-9de4-a5ce833a6818,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-55299d94-f1c8-4883-9d7b-17a60fa48575,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-a8f7acbc-3ba0-4262-a33b-218cbe1f1849,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-2d03648c-46d6-4aff-937e-6d1c57850bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-72f21b09-5056-4cbe-a40f-f21e332cf2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-37d385c7-3c4a-45a5-a44f-a8551f627dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-89788200-67c5-4942-bc54-91ed782d1a92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2001020538-172.17.0.4-1595932841387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44634,DS-a5e4e763-1bd1-46b1-98bd-5c9d2aedc122,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-d17abeb6-a3fb-478f-9d8b-6f50bfe2d1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-42c0dab1-4719-4c53-9167-fc47121e76cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-78af0071-b05b-4f4c-b044-17a274b922e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-138d5c55-ef19-4af2-a1ee-67e9af981d14,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-cd57c4d4-3a3c-429a-86e4-12f114663d67,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-1bc14acd-b902-45dd-b3cd-70242d75bab9,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-44d25c3f-23bc-4b3c-aa30-9b6f2153927e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2001020538-172.17.0.4-1595932841387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44634,DS-a5e4e763-1bd1-46b1-98bd-5c9d2aedc122,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-d17abeb6-a3fb-478f-9d8b-6f50bfe2d1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-42c0dab1-4719-4c53-9167-fc47121e76cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-78af0071-b05b-4f4c-b044-17a274b922e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-138d5c55-ef19-4af2-a1ee-67e9af981d14,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-cd57c4d4-3a3c-429a-86e4-12f114663d67,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-1bc14acd-b902-45dd-b3cd-70242d75bab9,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-44d25c3f-23bc-4b3c-aa30-9b6f2153927e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1977225930-172.17.0.4-1595932909509:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41118,DS-72f2ce9e-0496-4308-8bfc-14bcc057ef44,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-39a8cffd-22d0-4837-be78-e7f1b4cb4a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-45bc5f06-09fa-4b64-82df-51115ef28b04,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-fcea6f20-a4a8-48fb-baa4-81b9761832da,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-87586fb4-193f-4d6f-8dfb-e8851195cbea,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-77e8d4df-e875-4cb2-8f09-e74bec1b2860,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-775049a3-4a65-43f1-9700-01349d57431f,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-6fa220d5-2b1a-45ae-ad27-04a394dbea8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1977225930-172.17.0.4-1595932909509:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41118,DS-72f2ce9e-0496-4308-8bfc-14bcc057ef44,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-39a8cffd-22d0-4837-be78-e7f1b4cb4a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-45bc5f06-09fa-4b64-82df-51115ef28b04,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-fcea6f20-a4a8-48fb-baa4-81b9761832da,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-87586fb4-193f-4d6f-8dfb-e8851195cbea,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-77e8d4df-e875-4cb2-8f09-e74bec1b2860,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-775049a3-4a65-43f1-9700-01349d57431f,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-6fa220d5-2b1a-45ae-ad27-04a394dbea8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-93865579-172.17.0.4-1595933261713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42234,DS-a5a69aa1-e140-473b-ad83-d9df8aad4440,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-ce745079-fe88-402b-831f-c0dc7a54f534,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-61680a6e-be3a-4e53-884f-69c0477ac387,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-3b133681-2f0b-465d-a2c6-6905caf6ef35,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-1a437171-2373-4e19-bc6c-7d5c9660e070,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-7a05cdcd-8733-438b-a042-4b55d0793445,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-00838257-34ed-47eb-97b9-9848e533b009,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-668d116c-0d53-4144-8d14-a98c0cb2d46a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-93865579-172.17.0.4-1595933261713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42234,DS-a5a69aa1-e140-473b-ad83-d9df8aad4440,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-ce745079-fe88-402b-831f-c0dc7a54f534,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-61680a6e-be3a-4e53-884f-69c0477ac387,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-3b133681-2f0b-465d-a2c6-6905caf6ef35,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-1a437171-2373-4e19-bc6c-7d5c9660e070,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-7a05cdcd-8733-438b-a042-4b55d0793445,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-00838257-34ed-47eb-97b9-9848e533b009,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-668d116c-0d53-4144-8d14-a98c0cb2d46a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-22751832-172.17.0.4-1595933296212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37157,DS-e94bae3f-c657-4b31-87b0-5ad9f32ff2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-f90a6925-7755-4020-b493-03a6cdcdfa4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-c22e240f-586b-4f6c-9c65-e7c1daa0d47a,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-909799d2-8ef5-4935-b411-506464751fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-c68f6c00-d558-44bf-9857-09b78fe4e786,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-1c34dd4f-5866-4777-821a-6fd72598eb13,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-60988546-24ec-4e6a-b665-ac86cde8f568,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-25bba5eb-9478-4a7c-b590-dcb29b8382d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-22751832-172.17.0.4-1595933296212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37157,DS-e94bae3f-c657-4b31-87b0-5ad9f32ff2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-f90a6925-7755-4020-b493-03a6cdcdfa4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-c22e240f-586b-4f6c-9c65-e7c1daa0d47a,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-909799d2-8ef5-4935-b411-506464751fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-c68f6c00-d558-44bf-9857-09b78fe4e786,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-1c34dd4f-5866-4777-821a-6fd72598eb13,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-60988546-24ec-4e6a-b665-ac86cde8f568,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-25bba5eb-9478-4a7c-b590-dcb29b8382d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829725775-172.17.0.4-1595933988896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43797,DS-cef60509-d257-4b45-b3a7-ee0e29ee575a,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-b6e1b322-8c31-4296-b02e-2861ab481129,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-6fa41bd8-ab62-4f1b-b6ab-6e9dbe9a6320,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-0dffc6f0-808a-41e2-b0fe-bcd0b675c8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-a1364083-6f56-4b86-af71-6bbfc3fb4287,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-96527971-4c17-4bee-9ea7-8fa7bdf1a204,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-a8a3ff4c-cbee-479d-ae04-756fb9ac0dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-bc2bb4d1-e99b-4caf-a260-e2c243d5ccb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829725775-172.17.0.4-1595933988896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43797,DS-cef60509-d257-4b45-b3a7-ee0e29ee575a,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-b6e1b322-8c31-4296-b02e-2861ab481129,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-6fa41bd8-ab62-4f1b-b6ab-6e9dbe9a6320,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-0dffc6f0-808a-41e2-b0fe-bcd0b675c8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-a1364083-6f56-4b86-af71-6bbfc3fb4287,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-96527971-4c17-4bee-9ea7-8fa7bdf1a204,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-a8a3ff4c-cbee-479d-ae04-756fb9ac0dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-bc2bb4d1-e99b-4caf-a260-e2c243d5ccb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-111729675-172.17.0.4-1595934031427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34230,DS-2cda88e9-ac0b-4b2d-af4f-38c01727e58c,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-46420919-3531-406e-a93d-bccee0bce6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-d304355c-7f37-429a-b26d-bbcaf8feb0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-59e4e358-d016-47c2-a937-906c3b5d29a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-674b740a-208e-41d8-9659-81e182d3a316,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-c2d7f0f3-f738-4b56-b6c3-6a96b9bb9d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-4ec9497a-d2c7-46d7-b206-7e89a48793b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-8ada7091-1582-4b76-8e4c-26fe82c0e83d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-111729675-172.17.0.4-1595934031427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34230,DS-2cda88e9-ac0b-4b2d-af4f-38c01727e58c,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-46420919-3531-406e-a93d-bccee0bce6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-d304355c-7f37-429a-b26d-bbcaf8feb0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-59e4e358-d016-47c2-a937-906c3b5d29a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-674b740a-208e-41d8-9659-81e182d3a316,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-c2d7f0f3-f738-4b56-b6c3-6a96b9bb9d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-4ec9497a-d2c7-46d7-b206-7e89a48793b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-8ada7091-1582-4b76-8e4c-26fe82c0e83d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5176
