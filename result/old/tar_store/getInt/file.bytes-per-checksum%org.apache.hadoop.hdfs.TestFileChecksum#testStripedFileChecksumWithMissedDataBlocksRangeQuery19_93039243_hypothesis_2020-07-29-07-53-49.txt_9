reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116109187-172.17.0.19-1596009241751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34150,DS-07bee855-5431-495d-b04d-908bf37a88d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-2fe619bc-acdd-4b6a-a635-f06e4d6d793c,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-e9580f04-81a6-429f-ad9d-e1bf5f32ff0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-69bbbf6e-708d-4e78-806b-7231e62ac02c,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-deab5d33-aa42-4e57-a15a-3d4d8a7198c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-f433b288-4ae2-47dd-afc3-06b3875442c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-6c34bc91-1fbc-4be6-86a6-b1e4a3c93ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-601fa3ab-685e-4487-b6de-51af801d3492,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116109187-172.17.0.19-1596009241751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34150,DS-07bee855-5431-495d-b04d-908bf37a88d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-2fe619bc-acdd-4b6a-a635-f06e4d6d793c,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-e9580f04-81a6-429f-ad9d-e1bf5f32ff0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-69bbbf6e-708d-4e78-806b-7231e62ac02c,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-deab5d33-aa42-4e57-a15a-3d4d8a7198c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-f433b288-4ae2-47dd-afc3-06b3875442c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-6c34bc91-1fbc-4be6-86a6-b1e4a3c93ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-601fa3ab-685e-4487-b6de-51af801d3492,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-995646742-172.17.0.19-1596009429025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39192,DS-8f244836-a382-4f24-96fd-9312113e1b53,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-28cba8f6-7f8d-459c-bf07-4b6d9d8ea7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-470f8e91-b438-4faa-b862-1fef0c1979cf,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-25f821c9-2f4b-4b6d-b399-1c37b27b6142,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-87755cf9-7af6-4c66-ac3c-4cf3efdc939b,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-56071515-4d11-4cf5-8c9f-06ce9be4b758,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-1fd4d788-7d12-4968-8bec-a55a10eae343,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-df6e7827-2529-4fbd-bda3-de3bfdaace46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-995646742-172.17.0.19-1596009429025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39192,DS-8f244836-a382-4f24-96fd-9312113e1b53,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-28cba8f6-7f8d-459c-bf07-4b6d9d8ea7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-470f8e91-b438-4faa-b862-1fef0c1979cf,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-25f821c9-2f4b-4b6d-b399-1c37b27b6142,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-87755cf9-7af6-4c66-ac3c-4cf3efdc939b,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-56071515-4d11-4cf5-8c9f-06ce9be4b758,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-1fd4d788-7d12-4968-8bec-a55a10eae343,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-df6e7827-2529-4fbd-bda3-de3bfdaace46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1463639467-172.17.0.19-1596009738755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43529,DS-f872c72e-1e3f-4f3a-8909-9e0f08d67d63,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-da1ba3d6-947f-48a4-824b-c54a2e6bc81e,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-fec2ebcf-0dd8-43d0-aec9-abe598fe34f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-a987daaf-188b-40f5-9cd7-b23796fca402,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-e158a908-8be6-40a8-8539-1c6327d286ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-20383c99-a94e-47b3-afd3-72083c17c87c,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-34645c05-6cd8-405f-8ee4-7d3a6f0172b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-5e924d7e-5319-47ee-ac38-d89d77fb4557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1463639467-172.17.0.19-1596009738755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43529,DS-f872c72e-1e3f-4f3a-8909-9e0f08d67d63,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-da1ba3d6-947f-48a4-824b-c54a2e6bc81e,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-fec2ebcf-0dd8-43d0-aec9-abe598fe34f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-a987daaf-188b-40f5-9cd7-b23796fca402,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-e158a908-8be6-40a8-8539-1c6327d286ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-20383c99-a94e-47b3-afd3-72083c17c87c,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-34645c05-6cd8-405f-8ee4-7d3a6f0172b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-5e924d7e-5319-47ee-ac38-d89d77fb4557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-614393111-172.17.0.19-1596009944817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43634,DS-e2add42c-b47e-49a3-98fc-e108cb3688f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-cef3d32c-c70c-45e7-b44f-78ec83bdd4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-4ff7a960-5248-4327-960c-ee9bf59949ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-ed142ea5-98b2-4ce5-a9c2-d44da97ebde4,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-c5816dcd-4c72-4517-ae99-c6b49ee03004,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-1b876f1e-d1c9-4390-a04b-cf12073a6f64,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-7e5b033f-ee15-4570-882f-6f225b9cb42b,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-f749aa85-3f36-480b-8373-44fd2f0838f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-614393111-172.17.0.19-1596009944817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43634,DS-e2add42c-b47e-49a3-98fc-e108cb3688f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-cef3d32c-c70c-45e7-b44f-78ec83bdd4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-4ff7a960-5248-4327-960c-ee9bf59949ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-ed142ea5-98b2-4ce5-a9c2-d44da97ebde4,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-c5816dcd-4c72-4517-ae99-c6b49ee03004,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-1b876f1e-d1c9-4390-a04b-cf12073a6f64,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-7e5b033f-ee15-4570-882f-6f225b9cb42b,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-f749aa85-3f36-480b-8373-44fd2f0838f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-392380589-172.17.0.19-1596010280594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44962,DS-3d889a79-364a-449e-99ef-87e7066f4c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-a809df39-c4c9-4210-8637-fe191073a2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-3d3f1897-efdf-4fdb-bc75-25b70277f062,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-232bbf79-d91f-4418-a64e-465f826ab413,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-90c39a28-8765-40ed-b2db-04613c96d14e,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-e4335593-553a-435b-8eea-d6916b2900e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-27cd7f32-8e59-432f-892c-93ff141bab46,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-046dd2c6-80ea-49f9-bc23-c6a0e975918b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-392380589-172.17.0.19-1596010280594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44962,DS-3d889a79-364a-449e-99ef-87e7066f4c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-a809df39-c4c9-4210-8637-fe191073a2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-3d3f1897-efdf-4fdb-bc75-25b70277f062,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-232bbf79-d91f-4418-a64e-465f826ab413,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-90c39a28-8765-40ed-b2db-04613c96d14e,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-e4335593-553a-435b-8eea-d6916b2900e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-27cd7f32-8e59-432f-892c-93ff141bab46,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-046dd2c6-80ea-49f9-bc23-c6a0e975918b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1833542423-172.17.0.19-1596010429172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41521,DS-4a01e94c-0e9c-4ca0-9419-3af99d53365a,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-1c28c7a1-959c-4d31-928e-6f35e2c8a3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-3e0da012-0d29-4a6e-acd2-7a144a6ce3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-1a7f1771-a898-4940-9c40-38afd7814b96,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-ceb25f86-361b-48fd-9737-a0d7d2cc9d21,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-dff05b21-6e70-4bf2-a54a-8961c24e90dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-09f15670-3569-4dd4-9766-a83780489e64,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-1992f302-1e06-4342-9f67-c9d0282c6393,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1833542423-172.17.0.19-1596010429172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41521,DS-4a01e94c-0e9c-4ca0-9419-3af99d53365a,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-1c28c7a1-959c-4d31-928e-6f35e2c8a3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-3e0da012-0d29-4a6e-acd2-7a144a6ce3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-1a7f1771-a898-4940-9c40-38afd7814b96,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-ceb25f86-361b-48fd-9737-a0d7d2cc9d21,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-dff05b21-6e70-4bf2-a54a-8961c24e90dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-09f15670-3569-4dd4-9766-a83780489e64,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-1992f302-1e06-4342-9f67-c9d0282c6393,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-679766066-172.17.0.19-1596010560478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38040,DS-fc184d45-e235-4922-874e-be2ac7d958aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-b57624f1-5b31-4ef7-b690-f7cf4b64aaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-8c2b05bb-2b66-43d3-942f-bed8c258337e,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-b1bb8440-a714-4ff8-9255-6d1cf68ae1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-8dad46fc-fe78-4bc5-ba84-37d26474f825,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-827835d4-5c5c-4547-af58-a17e3ae07f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-4625b900-1f50-49ae-82b2-e058e53a84d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-c860639c-6c26-4c52-a3b3-1fcf2e5c93f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-679766066-172.17.0.19-1596010560478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38040,DS-fc184d45-e235-4922-874e-be2ac7d958aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-b57624f1-5b31-4ef7-b690-f7cf4b64aaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-8c2b05bb-2b66-43d3-942f-bed8c258337e,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-b1bb8440-a714-4ff8-9255-6d1cf68ae1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-8dad46fc-fe78-4bc5-ba84-37d26474f825,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-827835d4-5c5c-4547-af58-a17e3ae07f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-4625b900-1f50-49ae-82b2-e058e53a84d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-c860639c-6c26-4c52-a3b3-1fcf2e5c93f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-712340648-172.17.0.19-1596010884524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39347,DS-5b4a8895-968d-4516-b755-0a47315444a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-0b915d94-083a-4763-97a9-e7b530bc522d,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-0fff36ce-cc59-45ab-a289-eeda1ad9b229,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-573fa9e1-81fc-4a25-843c-6efb70fec0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-bac79324-11f6-41d6-954c-d1fa5ee251df,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-1dd75a76-2b38-4cc9-839d-cbf2ea20abc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-03002b09-aafc-4972-a0ce-5f71e12d8b05,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-574a1145-ae26-45a1-9d4e-849f106603f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-712340648-172.17.0.19-1596010884524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39347,DS-5b4a8895-968d-4516-b755-0a47315444a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-0b915d94-083a-4763-97a9-e7b530bc522d,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-0fff36ce-cc59-45ab-a289-eeda1ad9b229,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-573fa9e1-81fc-4a25-843c-6efb70fec0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-bac79324-11f6-41d6-954c-d1fa5ee251df,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-1dd75a76-2b38-4cc9-839d-cbf2ea20abc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-03002b09-aafc-4972-a0ce-5f71e12d8b05,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-574a1145-ae26-45a1-9d4e-849f106603f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1665602684-172.17.0.19-1596011168644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45820,DS-35470f96-c249-4d2a-a1b6-d1cc1908a503,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-8038428c-faca-4edf-bbe7-3d08fc5512c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-50ca9e86-9395-43a2-b67d-39a169e1d655,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-d27ee1d9-73ae-4bc0-bb1b-31098f3bc26f,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-ee0ce9ec-fda7-4172-8031-6551e8374774,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-169e9998-31ce-457f-9cdc-6c0cde369f84,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-3e7b0451-75b5-4447-a33b-ddbff3bf4dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-64f3ba64-7f5b-43eb-b5d8-bcace17e0395,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1665602684-172.17.0.19-1596011168644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45820,DS-35470f96-c249-4d2a-a1b6-d1cc1908a503,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-8038428c-faca-4edf-bbe7-3d08fc5512c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-50ca9e86-9395-43a2-b67d-39a169e1d655,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-d27ee1d9-73ae-4bc0-bb1b-31098f3bc26f,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-ee0ce9ec-fda7-4172-8031-6551e8374774,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-169e9998-31ce-457f-9cdc-6c0cde369f84,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-3e7b0451-75b5-4447-a33b-ddbff3bf4dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-64f3ba64-7f5b-43eb-b5d8-bcace17e0395,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1941603803-172.17.0.19-1596011682433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42195,DS-9734e71b-25c1-475a-8da3-7582cebdb2db,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-9e17a88c-b87c-4701-b053-4af2291e602e,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-02794933-9e35-403e-82b3-07c8041c6331,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-429948db-05a6-4074-b8e9-2866d8394e82,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-21ca93e2-0ecd-40bc-b39c-7186c3461fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-aa3c7fbb-a247-4571-9e28-db74bb4444bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-abea089e-3c6d-4bd0-8669-8d6a2697216d,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-586d5d21-3087-4d4b-876e-2471377f7016,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1941603803-172.17.0.19-1596011682433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42195,DS-9734e71b-25c1-475a-8da3-7582cebdb2db,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-9e17a88c-b87c-4701-b053-4af2291e602e,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-02794933-9e35-403e-82b3-07c8041c6331,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-429948db-05a6-4074-b8e9-2866d8394e82,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-21ca93e2-0ecd-40bc-b39c-7186c3461fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-aa3c7fbb-a247-4571-9e28-db74bb4444bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-abea089e-3c6d-4bd0-8669-8d6a2697216d,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-586d5d21-3087-4d4b-876e-2471377f7016,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1615197525-172.17.0.19-1596012005420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42370,DS-638397b2-dd32-4fad-ab00-09c68b37e369,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-c67d35a8-a0e5-4de3-a0ad-28e31a87d848,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-821c0e3a-acaf-45b0-a902-e0685393130d,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-32f991a1-3384-4db7-bf72-d690a33ab1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-df2f93b9-1815-4589-9f83-96cbe31f683b,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-60fb4068-ce2a-4f49-921c-93f7a54dc3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-0f656544-48e0-4d5d-9e6f-a45a44dc696e,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-33fe2425-c252-4c5d-bbb1-c66bfbb792b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1615197525-172.17.0.19-1596012005420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42370,DS-638397b2-dd32-4fad-ab00-09c68b37e369,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-c67d35a8-a0e5-4de3-a0ad-28e31a87d848,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-821c0e3a-acaf-45b0-a902-e0685393130d,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-32f991a1-3384-4db7-bf72-d690a33ab1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-df2f93b9-1815-4589-9f83-96cbe31f683b,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-60fb4068-ce2a-4f49-921c-93f7a54dc3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-0f656544-48e0-4d5d-9e6f-a45a44dc696e,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-33fe2425-c252-4c5d-bbb1-c66bfbb792b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285898714-172.17.0.19-1596012076889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35524,DS-1147924c-884d-451a-ac96-32f73aeae7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-a4d07f9f-8856-4e92-abed-7743bef1009b,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-42335974-bb7a-497e-a8e7-982dd737bad8,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-c498ee35-a44a-4cc5-9eda-0946813468ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-73c1bd2d-27c1-4292-8f4a-970ca03e2c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-6e3bcea7-f5cd-49f4-81c2-64608d169d45,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-27e695ca-8caf-4164-86ea-36c378b08515,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-e6e8d177-df38-48e7-8340-82fbeeee86fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285898714-172.17.0.19-1596012076889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35524,DS-1147924c-884d-451a-ac96-32f73aeae7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-a4d07f9f-8856-4e92-abed-7743bef1009b,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-42335974-bb7a-497e-a8e7-982dd737bad8,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-c498ee35-a44a-4cc5-9eda-0946813468ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-73c1bd2d-27c1-4292-8f4a-970ca03e2c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-6e3bcea7-f5cd-49f4-81c2-64608d169d45,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-27e695ca-8caf-4164-86ea-36c378b08515,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-e6e8d177-df38-48e7-8340-82fbeeee86fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-138939400-172.17.0.19-1596012119160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37206,DS-0b6f3fcc-56f7-443b-9afd-cfc148c578e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-6867280a-ba33-48e2-885c-783fc2d87c70,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-cd962d1a-9058-4e2d-aa19-a45df9472a62,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-34f15645-3cbf-433b-8919-0601e02ce61b,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-20f67a10-35fd-4bc5-8524-5ad66e850541,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-b0e7f612-9425-4c31-82c4-8c15fddf8484,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-4112875c-532b-448f-a848-516fb255a981,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-c8cc71ad-f1eb-49ab-847e-73eca54b1fec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-138939400-172.17.0.19-1596012119160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37206,DS-0b6f3fcc-56f7-443b-9afd-cfc148c578e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-6867280a-ba33-48e2-885c-783fc2d87c70,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-cd962d1a-9058-4e2d-aa19-a45df9472a62,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-34f15645-3cbf-433b-8919-0601e02ce61b,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-20f67a10-35fd-4bc5-8524-5ad66e850541,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-b0e7f612-9425-4c31-82c4-8c15fddf8484,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-4112875c-532b-448f-a848-516fb255a981,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-c8cc71ad-f1eb-49ab-847e-73eca54b1fec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1421579325-172.17.0.19-1596012155331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33969,DS-727c77ca-b4b7-4188-8b64-c5eefd28574b,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-7be5130f-6647-447e-b5cb-ea6ff897689d,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-1959d83a-47e3-4cb0-99a6-f8ab6122cf29,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-67c765b3-1d5b-4f4e-b988-fa44cf0b4628,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-30347966-0340-44f0-b232-e50ab31bff53,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-dc2850e5-87cb-4f80-a0a2-c60a1c49510e,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-1426b801-f958-4171-91e2-d34e31a597fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-dce13b6b-7f4e-45db-870b-de900d6d0869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1421579325-172.17.0.19-1596012155331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33969,DS-727c77ca-b4b7-4188-8b64-c5eefd28574b,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-7be5130f-6647-447e-b5cb-ea6ff897689d,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-1959d83a-47e3-4cb0-99a6-f8ab6122cf29,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-67c765b3-1d5b-4f4e-b988-fa44cf0b4628,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-30347966-0340-44f0-b232-e50ab31bff53,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-dc2850e5-87cb-4f80-a0a2-c60a1c49510e,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-1426b801-f958-4171-91e2-d34e31a597fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-dce13b6b-7f4e-45db-870b-de900d6d0869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1087248065-172.17.0.19-1596013018453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37805,DS-ffe38970-f501-448f-9c6a-f51a61332cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-7d7e8a43-f380-4019-8174-d86d806e0ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-971700dd-7e38-4bd0-bb8a-a13f80b883d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-23175e26-7b43-42d7-bf25-a2f6697468d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-6bbce789-2961-48ab-ab02-374d6d550829,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-8c2278b9-e2bb-4657-8d68-d2aae956aad0,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-c8fe7cb7-43ad-4315-8330-00bb5d7a0d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-a56443aa-9e44-438c-bbe9-a6c3af1a4028,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1087248065-172.17.0.19-1596013018453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37805,DS-ffe38970-f501-448f-9c6a-f51a61332cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-7d7e8a43-f380-4019-8174-d86d806e0ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-971700dd-7e38-4bd0-bb8a-a13f80b883d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-23175e26-7b43-42d7-bf25-a2f6697468d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-6bbce789-2961-48ab-ab02-374d6d550829,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-8c2278b9-e2bb-4657-8d68-d2aae956aad0,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-c8fe7cb7-43ad-4315-8330-00bb5d7a0d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-a56443aa-9e44-438c-bbe9-a6c3af1a4028,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-461024080-172.17.0.19-1596013439812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40370,DS-866ed5be-1ffd-45a7-8400-f8225917f212,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-a5bf847f-4e9a-44bd-8647-d6fea536000e,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-8d68674b-6da8-4503-a06a-5c58363b7509,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-f45c702d-2387-4ed7-906e-2fc6c3837618,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-797d7258-ee67-4e3b-9e05-b1f09b8d9a33,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-73798f0a-e55f-47d7-953b-43c9f3e3cb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-9937a2e7-d10d-4146-bbd8-5b208011dc80,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-efdbde99-34b7-4124-a992-02d5741385b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-461024080-172.17.0.19-1596013439812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40370,DS-866ed5be-1ffd-45a7-8400-f8225917f212,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-a5bf847f-4e9a-44bd-8647-d6fea536000e,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-8d68674b-6da8-4503-a06a-5c58363b7509,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-f45c702d-2387-4ed7-906e-2fc6c3837618,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-797d7258-ee67-4e3b-9e05-b1f09b8d9a33,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-73798f0a-e55f-47d7-953b-43c9f3e3cb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-9937a2e7-d10d-4146-bbd8-5b208011dc80,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-efdbde99-34b7-4124-a992-02d5741385b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1469707013-172.17.0.19-1596013571202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35752,DS-2d79e651-a75e-42db-8b1f-6493a50dfb14,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-f85e7202-e7b9-4374-a088-8df61ed1c574,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-0c319c90-94b7-49c6-bbe8-8cba6f0af54f,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-d9d523d7-3c70-4547-b8af-924848f868d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-499f3b64-da18-4df1-9ef4-14aa13580a20,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-30da12ef-912f-4f2c-b3d9-d140142dfad3,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-52972645-fefe-4a7a-a448-6f0ee283c6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-65d238a6-3e58-4902-8a0a-c120c8b1078a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1469707013-172.17.0.19-1596013571202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35752,DS-2d79e651-a75e-42db-8b1f-6493a50dfb14,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-f85e7202-e7b9-4374-a088-8df61ed1c574,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-0c319c90-94b7-49c6-bbe8-8cba6f0af54f,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-d9d523d7-3c70-4547-b8af-924848f868d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-499f3b64-da18-4df1-9ef4-14aa13580a20,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-30da12ef-912f-4f2c-b3d9-d140142dfad3,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-52972645-fefe-4a7a-a448-6f0ee283c6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-65d238a6-3e58-4902-8a0a-c120c8b1078a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1166240616-172.17.0.19-1596013769205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38139,DS-6b616235-b37f-41c0-97c8-ca43a7bbaef5,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-6bfd5f74-0411-4d27-bcb0-35fe98b2e0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-c424c7f7-f553-4e60-a923-a03a9769088f,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-c1fd94b8-bcdd-4369-bb43-1b3adbe91fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-9e422e2a-10db-4fa4-9ff4-db429edd032c,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-1b66883d-6e39-4156-bfb7-6ec12ce2e346,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-6a07e7c7-d948-4e9e-ba74-6cdc4a39c024,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-a21b75a2-2378-4558-92e8-fb5bf48de31f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1166240616-172.17.0.19-1596013769205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38139,DS-6b616235-b37f-41c0-97c8-ca43a7bbaef5,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-6bfd5f74-0411-4d27-bcb0-35fe98b2e0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-c424c7f7-f553-4e60-a923-a03a9769088f,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-c1fd94b8-bcdd-4369-bb43-1b3adbe91fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-9e422e2a-10db-4fa4-9ff4-db429edd032c,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-1b66883d-6e39-4156-bfb7-6ec12ce2e346,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-6a07e7c7-d948-4e9e-ba74-6cdc4a39c024,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-a21b75a2-2378-4558-92e8-fb5bf48de31f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1142943003-172.17.0.19-1596013897976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43300,DS-2901d926-a430-4179-a9bf-98485614689a,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-320a9735-f6ce-42f8-9fe8-bab4eb03375d,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-e7a9c64f-a79c-43db-be30-f74dd6fdf33b,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-a5cd29e0-6197-408a-a197-9b14044b8145,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-6895184b-85cb-4c8e-8452-7fb85875e782,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-057f434b-97af-46c4-bd7a-f1d5894e07c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-89556f98-cd06-42a8-aadc-6087b259a41c,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-cc6f68fe-3be8-4ad7-baa5-7fdf75092fd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1142943003-172.17.0.19-1596013897976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43300,DS-2901d926-a430-4179-a9bf-98485614689a,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-320a9735-f6ce-42f8-9fe8-bab4eb03375d,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-e7a9c64f-a79c-43db-be30-f74dd6fdf33b,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-a5cd29e0-6197-408a-a197-9b14044b8145,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-6895184b-85cb-4c8e-8452-7fb85875e782,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-057f434b-97af-46c4-bd7a-f1d5894e07c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-89556f98-cd06-42a8-aadc-6087b259a41c,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-cc6f68fe-3be8-4ad7-baa5-7fdf75092fd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-548438978-172.17.0.19-1596013934303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38633,DS-8fc50ad2-207d-43bf-bf53-2b56e0926770,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-ed10f17e-f3b9-4844-828b-d990426f24f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-1109a787-74e5-417f-9178-5974891680e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-b847385b-584d-4258-8269-a69346a0a98e,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-dc22f320-e987-4f24-bfa6-85bfb76c8ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-c449a328-a864-4f98-ab04-2e23156133e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-4045cf67-a6b3-46d4-9995-4f7dd56ff007,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-11d0ef52-389e-4eb3-9ebe-82ac3e71f570,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-548438978-172.17.0.19-1596013934303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38633,DS-8fc50ad2-207d-43bf-bf53-2b56e0926770,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-ed10f17e-f3b9-4844-828b-d990426f24f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-1109a787-74e5-417f-9178-5974891680e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-b847385b-584d-4258-8269-a69346a0a98e,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-dc22f320-e987-4f24-bfa6-85bfb76c8ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-c449a328-a864-4f98-ab04-2e23156133e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-4045cf67-a6b3-46d4-9995-4f7dd56ff007,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-11d0ef52-389e-4eb3-9ebe-82ac3e71f570,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-376455834-172.17.0.19-1596014058739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45304,DS-a6f706fa-8067-43a3-a092-54200fc3916c,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-33fbd1ba-3a79-4994-bb2e-4a2e7ac2b9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-e3cc2790-7f84-43c0-9df3-0266b6b77df4,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-9c74ab23-3100-47b4-b811-a9d7199997a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-5e99a5ec-95d7-4a30-802d-162943bc5acf,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-92b9e63f-c364-43f2-9a8c-ddc690e52409,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-f414584f-4843-4108-9938-6c53fd94aea1,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-7f3c14ad-ba90-433f-b347-981203c8c1ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-376455834-172.17.0.19-1596014058739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45304,DS-a6f706fa-8067-43a3-a092-54200fc3916c,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-33fbd1ba-3a79-4994-bb2e-4a2e7ac2b9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-e3cc2790-7f84-43c0-9df3-0266b6b77df4,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-9c74ab23-3100-47b4-b811-a9d7199997a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-5e99a5ec-95d7-4a30-802d-162943bc5acf,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-92b9e63f-c364-43f2-9a8c-ddc690e52409,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-f414584f-4843-4108-9938-6c53fd94aea1,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-7f3c14ad-ba90-433f-b347-981203c8c1ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5750
