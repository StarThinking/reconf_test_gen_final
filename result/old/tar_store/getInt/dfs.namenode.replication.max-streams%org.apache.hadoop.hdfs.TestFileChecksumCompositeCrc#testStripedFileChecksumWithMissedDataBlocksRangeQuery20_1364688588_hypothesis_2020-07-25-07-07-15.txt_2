reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-733536284-172.17.0.19-1595661534056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39702,DS-6f2c00ca-29c2-4571-835b-1272b4a147cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-569046dc-6408-4900-b8aa-3de98a842b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-dd532dea-a452-46e3-bad8-0a6526ac3a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-d599c2cb-822e-4f22-8ba8-cd3ad6d1847f,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-749059dc-78ff-4c54-8eba-b01dfb04c6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-6fc8fd9a-4ce5-4b9c-b2d8-5ed64dd967cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-3630b99d-80f3-44b7-a6b7-c0f95c32f12a,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-30e5a4e3-128b-4641-bd91-efca8f5dd8e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-733536284-172.17.0.19-1595661534056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39702,DS-6f2c00ca-29c2-4571-835b-1272b4a147cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-569046dc-6408-4900-b8aa-3de98a842b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-dd532dea-a452-46e3-bad8-0a6526ac3a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-d599c2cb-822e-4f22-8ba8-cd3ad6d1847f,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-749059dc-78ff-4c54-8eba-b01dfb04c6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-6fc8fd9a-4ce5-4b9c-b2d8-5ed64dd967cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-3630b99d-80f3-44b7-a6b7-c0f95c32f12a,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-30e5a4e3-128b-4641-bd91-efca8f5dd8e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1053429165-172.17.0.19-1595661636000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36624,DS-85b027d8-bab9-408f-a216-1fb8be1ae622,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-cd49fe22-5378-43a6-aece-82df7b3986b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-e1b4e1aa-416c-459d-869e-f706778cc415,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-eebddfbc-d1f4-4e3e-9feb-6450296e114b,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-077ed372-327f-4a00-8207-f1260192a886,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-a0e09167-1525-4214-a5ac-dd17020cb7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-b8e556ea-ec6a-4ed8-8571-3178a3298b82,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-298a8f41-370c-437b-a0c9-c945863ab57c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1053429165-172.17.0.19-1595661636000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36624,DS-85b027d8-bab9-408f-a216-1fb8be1ae622,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-cd49fe22-5378-43a6-aece-82df7b3986b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-e1b4e1aa-416c-459d-869e-f706778cc415,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-eebddfbc-d1f4-4e3e-9feb-6450296e114b,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-077ed372-327f-4a00-8207-f1260192a886,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-a0e09167-1525-4214-a5ac-dd17020cb7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-b8e556ea-ec6a-4ed8-8571-3178a3298b82,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-298a8f41-370c-437b-a0c9-c945863ab57c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1354869776-172.17.0.19-1595661758147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37670,DS-4b2d3e9d-c21e-4dea-87f1-e4d31ab58a76,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-e018a4bf-a469-4cbc-92eb-823bb37acad4,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-b9938cb6-8fa3-4369-96d6-d9615893abde,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-a1a03a43-f85d-4278-8b07-4fd9304725b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-56a89219-e6ee-4c8f-ab30-7be6f41006d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-0e7b0dad-e3ab-446c-b352-a334171437a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-515aa966-644b-429d-9db4-cb2047622d54,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-aaabd6f9-85d3-4411-80b4-ba7f7905eb00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1354869776-172.17.0.19-1595661758147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37670,DS-4b2d3e9d-c21e-4dea-87f1-e4d31ab58a76,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-e018a4bf-a469-4cbc-92eb-823bb37acad4,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-b9938cb6-8fa3-4369-96d6-d9615893abde,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-a1a03a43-f85d-4278-8b07-4fd9304725b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-56a89219-e6ee-4c8f-ab30-7be6f41006d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-0e7b0dad-e3ab-446c-b352-a334171437a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-515aa966-644b-429d-9db4-cb2047622d54,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-aaabd6f9-85d3-4411-80b4-ba7f7905eb00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1328983467-172.17.0.19-1595662274033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46243,DS-8d24aec2-3087-476c-b47a-9bd8d2eed6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-2e831879-6d8f-438f-9836-7dbe140a74b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-622d177e-0543-4a0a-a459-7db6eff83465,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-52aee550-a34a-4a8e-9dfd-f47dcaa63251,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-c069a41f-43f1-4016-a5e2-cab835931cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-e4ecaa38-dd65-4d5d-94c4-82a7decbd367,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-ad2519fd-63d2-40d9-817b-23172b4d57ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-935a83d0-297d-4137-9cba-73cc0fa537eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1328983467-172.17.0.19-1595662274033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46243,DS-8d24aec2-3087-476c-b47a-9bd8d2eed6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-2e831879-6d8f-438f-9836-7dbe140a74b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-622d177e-0543-4a0a-a459-7db6eff83465,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-52aee550-a34a-4a8e-9dfd-f47dcaa63251,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-c069a41f-43f1-4016-a5e2-cab835931cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-e4ecaa38-dd65-4d5d-94c4-82a7decbd367,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-ad2519fd-63d2-40d9-817b-23172b4d57ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-935a83d0-297d-4137-9cba-73cc0fa537eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1574973366-172.17.0.19-1595662984351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43938,DS-4b5a6eba-08d6-4fb0-bdf0-b3aa717b7795,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-57de7113-ba3a-43be-8aee-aa2ae50dc7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-1c7f96fb-064c-4f38-945c-1230ff6488a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-a997c444-7957-42f9-90ff-edd5ad8ab330,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-85cdead6-65d9-4089-b7c3-f530a0cab0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-7d0f27fa-e4b6-4baf-833f-a1671b1c04b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-1d534600-1f0c-44fe-8fe9-b0a23483e940,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-ac1f4b3a-9a9e-4442-90b8-a2644b2db989,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1574973366-172.17.0.19-1595662984351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43938,DS-4b5a6eba-08d6-4fb0-bdf0-b3aa717b7795,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-57de7113-ba3a-43be-8aee-aa2ae50dc7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-1c7f96fb-064c-4f38-945c-1230ff6488a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-a997c444-7957-42f9-90ff-edd5ad8ab330,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-85cdead6-65d9-4089-b7c3-f530a0cab0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-7d0f27fa-e4b6-4baf-833f-a1671b1c04b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-1d534600-1f0c-44fe-8fe9-b0a23483e940,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-ac1f4b3a-9a9e-4442-90b8-a2644b2db989,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1214584711-172.17.0.19-1595663331535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46293,DS-e65380ab-0def-4022-a9ac-c2af7c0c370f,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-4fbefab7-a942-4cd8-8167-dd751a1cc0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-95d20561-b302-40f7-a464-d1e6f6d81e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-700c4869-153e-4631-a3ae-6d14b92002d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-298ab5f4-b3ea-42ad-9dca-8c5a2afdd201,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-21398723-e8bd-4ef5-b3aa-1ae9e82720ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44243,DS-dd322292-ab06-41cf-827d-1898d3662246,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-a35ec05b-3562-438c-b8e4-02e293a2bc5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1214584711-172.17.0.19-1595663331535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46293,DS-e65380ab-0def-4022-a9ac-c2af7c0c370f,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-4fbefab7-a942-4cd8-8167-dd751a1cc0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-95d20561-b302-40f7-a464-d1e6f6d81e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-700c4869-153e-4631-a3ae-6d14b92002d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-298ab5f4-b3ea-42ad-9dca-8c5a2afdd201,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-21398723-e8bd-4ef5-b3aa-1ae9e82720ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44243,DS-dd322292-ab06-41cf-827d-1898d3662246,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-a35ec05b-3562-438c-b8e4-02e293a2bc5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-651346909-172.17.0.19-1595663429418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39911,DS-1146a0ea-7368-476f-9f12-757b891157eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-86500768-33b3-4115-aa66-956b918de7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-5f4d786d-0ae9-4cf4-af56-5d72ea52ea14,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-4504aa6f-aff6-4a23-98b3-f8c959d47257,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-3700d53c-2a9f-4c24-ab60-59ff16f6dbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-c9dbb270-83ba-4f3a-9c81-cb540a25d9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-31c9abd7-8ef0-4911-b87c-5453f2534f62,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-45b71ef2-1493-482e-8c69-32205f3601f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-651346909-172.17.0.19-1595663429418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39911,DS-1146a0ea-7368-476f-9f12-757b891157eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-86500768-33b3-4115-aa66-956b918de7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-5f4d786d-0ae9-4cf4-af56-5d72ea52ea14,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-4504aa6f-aff6-4a23-98b3-f8c959d47257,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-3700d53c-2a9f-4c24-ab60-59ff16f6dbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-c9dbb270-83ba-4f3a-9c81-cb540a25d9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-31c9abd7-8ef0-4911-b87c-5453f2534f62,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-45b71ef2-1493-482e-8c69-32205f3601f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1631316699-172.17.0.19-1595664142405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43904,DS-8d7a714e-61ca-4dec-a78c-c31b382eb49e,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-0d421db2-08be-4b55-85b2-f9c9ffce3913,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-064b0d14-285c-48b9-a571-21389343106c,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-39d755a4-f0f7-4461-bd5a-9abda5f9c529,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-1f7c362a-5f7b-45e1-92a7-c3de5733912f,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-50e0f6d4-58ea-494d-99f0-d7ec163dadf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-9bc0160f-764e-4daa-b9cc-bf4b84f4b4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-5841dc91-b557-4f56-b00d-c7778358bab8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1631316699-172.17.0.19-1595664142405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43904,DS-8d7a714e-61ca-4dec-a78c-c31b382eb49e,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-0d421db2-08be-4b55-85b2-f9c9ffce3913,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-064b0d14-285c-48b9-a571-21389343106c,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-39d755a4-f0f7-4461-bd5a-9abda5f9c529,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-1f7c362a-5f7b-45e1-92a7-c3de5733912f,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-50e0f6d4-58ea-494d-99f0-d7ec163dadf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-9bc0160f-764e-4daa-b9cc-bf4b84f4b4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-5841dc91-b557-4f56-b00d-c7778358bab8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-449191388-172.17.0.19-1595664324240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35612,DS-896d3ee2-f53b-4081-9e5a-b82984e1a16c,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-58972759-e74c-4669-b799-bc85b5829a61,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-c122b568-b181-4235-ae56-5c3d75b554a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-902b356a-eff9-4c3a-8f78-f87fb0d93ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-2d494395-535a-493f-a642-3dc6b784219e,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-8dc9c60a-f11d-4d47-94e8-cf552be7665f,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-ff7bbc7f-e915-4a69-bffe-f25ddd259531,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-f507ac69-1ccf-49da-94c2-998f98c19a60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-449191388-172.17.0.19-1595664324240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35612,DS-896d3ee2-f53b-4081-9e5a-b82984e1a16c,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-58972759-e74c-4669-b799-bc85b5829a61,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-c122b568-b181-4235-ae56-5c3d75b554a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-902b356a-eff9-4c3a-8f78-f87fb0d93ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-2d494395-535a-493f-a642-3dc6b784219e,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-8dc9c60a-f11d-4d47-94e8-cf552be7665f,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-ff7bbc7f-e915-4a69-bffe-f25ddd259531,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-f507ac69-1ccf-49da-94c2-998f98c19a60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1510012907-172.17.0.19-1595665636918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35162,DS-801bdf5d-7fd7-437a-8422-846925093610,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-8abddd0d-6121-4ecd-adeb-b2bdd8d50924,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-d710ba33-a39d-46c6-9b9e-b1da9f82b67e,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-e8b44d42-c4e9-4060-b8ec-b6b992026864,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-69756c98-e0f5-4fc1-9e6b-dc6fac15276c,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-b69f5dc8-859c-426b-afc0-d1d556052491,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-8b245f78-0e14-4ece-aa77-9456330e7673,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-d108fee9-fa8c-4e33-8a41-11da009c64bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1510012907-172.17.0.19-1595665636918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35162,DS-801bdf5d-7fd7-437a-8422-846925093610,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-8abddd0d-6121-4ecd-adeb-b2bdd8d50924,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-d710ba33-a39d-46c6-9b9e-b1da9f82b67e,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-e8b44d42-c4e9-4060-b8ec-b6b992026864,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-69756c98-e0f5-4fc1-9e6b-dc6fac15276c,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-b69f5dc8-859c-426b-afc0-d1d556052491,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-8b245f78-0e14-4ece-aa77-9456330e7673,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-d108fee9-fa8c-4e33-8a41-11da009c64bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199621206-172.17.0.19-1595665835731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38966,DS-93f0ddb5-e2c1-4750-b527-c704a1dc1924,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-7fcd48d5-eba2-47e8-8297-62541d6d232f,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-77c13537-d27f-4362-9c4c-aec495c92fda,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-6d6fbd1f-56bb-4b34-a6e1-1ed2e0e6e597,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-c4b9774b-8676-446c-a5ac-fac35e1212e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-f3a7c35d-221e-4f4e-9f71-205e6b9706ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-b812d826-cb98-4020-acd0-6896b8dcf520,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-26446942-6b7f-4a87-a2bb-c41b398bc04c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199621206-172.17.0.19-1595665835731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38966,DS-93f0ddb5-e2c1-4750-b527-c704a1dc1924,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-7fcd48d5-eba2-47e8-8297-62541d6d232f,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-77c13537-d27f-4362-9c4c-aec495c92fda,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-6d6fbd1f-56bb-4b34-a6e1-1ed2e0e6e597,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-c4b9774b-8676-446c-a5ac-fac35e1212e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-f3a7c35d-221e-4f4e-9f71-205e6b9706ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-b812d826-cb98-4020-acd0-6896b8dcf520,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-26446942-6b7f-4a87-a2bb-c41b398bc04c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1044004766-172.17.0.19-1595666012097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41529,DS-abd15a18-c5cd-4463-babe-e62ffae28ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-ba53dcea-ad7e-4c65-9226-3bde3378752e,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-00e3f34d-f0b5-469e-b92a-921fe930229b,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-9736dac4-ed93-48e9-958f-32fb09aad5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-e869983e-595f-4e12-8d20-ed2b397f52c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-17dd8863-e64f-4425-8733-e23487140cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-cb1c21e7-c251-456c-ac82-578aacfeb84a,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-afa0ba86-c88d-4907-8fae-90906d567f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1044004766-172.17.0.19-1595666012097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41529,DS-abd15a18-c5cd-4463-babe-e62ffae28ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-ba53dcea-ad7e-4c65-9226-3bde3378752e,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-00e3f34d-f0b5-469e-b92a-921fe930229b,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-9736dac4-ed93-48e9-958f-32fb09aad5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-e869983e-595f-4e12-8d20-ed2b397f52c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-17dd8863-e64f-4425-8733-e23487140cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-cb1c21e7-c251-456c-ac82-578aacfeb84a,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-afa0ba86-c88d-4907-8fae-90906d567f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-792560472-172.17.0.19-1595666063054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40134,DS-78f1601a-16b7-498e-aa30-279e8b7dff65,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-93849b12-413a-4309-83d6-3eb910feec2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-acae5bc0-6e68-490a-9f59-8c0cb1939308,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-4a8743fa-919a-4584-aad0-70436ff34665,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-836b28d1-99fe-4028-ab1b-37c02a79e911,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-30352b88-7340-4ee8-83f8-1b92db8bfc42,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-77a163c9-c722-4708-a506-0ae9b13e3976,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-573b3ef1-a899-453e-8b42-2e6383e4a6b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-792560472-172.17.0.19-1595666063054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40134,DS-78f1601a-16b7-498e-aa30-279e8b7dff65,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-93849b12-413a-4309-83d6-3eb910feec2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-acae5bc0-6e68-490a-9f59-8c0cb1939308,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-4a8743fa-919a-4584-aad0-70436ff34665,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-836b28d1-99fe-4028-ab1b-37c02a79e911,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-30352b88-7340-4ee8-83f8-1b92db8bfc42,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-77a163c9-c722-4708-a506-0ae9b13e3976,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-573b3ef1-a899-453e-8b42-2e6383e4a6b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1551564279-172.17.0.19-1595667110988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34071,DS-e97f2f56-d16f-4efa-9e58-009a1280fb39,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-e5a3252a-e7c4-404d-a02f-9c773d22a4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-e09cc1de-334c-480f-b1ad-518e1ce72b05,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-e53ebfa3-ea85-4f9e-bf5f-640d5b594d59,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-d90b0504-2f72-41cd-b0bd-56a0f632b3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-2e9225e2-16e1-47fe-9708-c0bba0a525eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-67da0d81-f58e-4afe-ace9-cb26292788ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-d2869615-d0bb-4643-a003-18cf799a7518,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1551564279-172.17.0.19-1595667110988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34071,DS-e97f2f56-d16f-4efa-9e58-009a1280fb39,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-e5a3252a-e7c4-404d-a02f-9c773d22a4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-e09cc1de-334c-480f-b1ad-518e1ce72b05,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-e53ebfa3-ea85-4f9e-bf5f-640d5b594d59,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-d90b0504-2f72-41cd-b0bd-56a0f632b3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-2e9225e2-16e1-47fe-9708-c0bba0a525eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-67da0d81-f58e-4afe-ace9-cb26292788ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-d2869615-d0bb-4643-a003-18cf799a7518,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1324133413-172.17.0.19-1595667294209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43686,DS-bf6bb768-b5bf-4a6c-9e9d-f5c5d70b51fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-58a26ac1-72cd-428b-8448-9230e2ab4113,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-9942c952-62f2-4d27-8860-50c552ec9eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-12ae9f55-bf6c-43a4-bd92-af4ab6e9fe54,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-2861c176-626d-48a6-a1bc-95f59c46eb70,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-7feecb02-b9a6-430a-a056-17e448b3bc38,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-e0e6858c-b28a-4c88-9b92-82b1ce468980,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-7c797fb8-15e9-41dd-8824-76d3ceb1cd73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1324133413-172.17.0.19-1595667294209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43686,DS-bf6bb768-b5bf-4a6c-9e9d-f5c5d70b51fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-58a26ac1-72cd-428b-8448-9230e2ab4113,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-9942c952-62f2-4d27-8860-50c552ec9eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-12ae9f55-bf6c-43a4-bd92-af4ab6e9fe54,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-2861c176-626d-48a6-a1bc-95f59c46eb70,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-7feecb02-b9a6-430a-a056-17e448b3bc38,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-e0e6858c-b28a-4c88-9b92-82b1ce468980,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-7c797fb8-15e9-41dd-8824-76d3ceb1cd73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171713718-172.17.0.19-1595667431705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41569,DS-dfc32228-830e-4b37-8014-c52a1827a46f,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-38bdc998-44fc-45f8-84c0-2f462789858c,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-d541de0c-41f9-42f6-b326-43e81aa6ca9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-78622795-9d3b-483d-8330-785d4f5adc12,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-c9e11ba8-0a10-470f-9d62-0a907812bbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-595ffba7-8852-418b-9f3b-98cfd1013c73,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-d5310b09-b40f-4a83-94fe-defce7cb6c57,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-7b48ff3e-df80-4844-859c-59ee895b358c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171713718-172.17.0.19-1595667431705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41569,DS-dfc32228-830e-4b37-8014-c52a1827a46f,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-38bdc998-44fc-45f8-84c0-2f462789858c,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-d541de0c-41f9-42f6-b326-43e81aa6ca9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-78622795-9d3b-483d-8330-785d4f5adc12,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-c9e11ba8-0a10-470f-9d62-0a907812bbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-595ffba7-8852-418b-9f3b-98cfd1013c73,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-d5310b09-b40f-4a83-94fe-defce7cb6c57,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-7b48ff3e-df80-4844-859c-59ee895b358c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6808
