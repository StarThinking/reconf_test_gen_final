reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533511566-172.17.0.7-1595842708374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41925,DS-a42256d0-2457-4087-a595-625db73c3e82,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-2ac3a0b2-13ba-4e19-9a89-7d251a998b58,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-57eb76c7-c92b-45d9-890f-c523850363f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36156,DS-4c8787ef-9f9c-4e57-82f4-64bf5ea29e42,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-e8cac393-9d90-43dd-8cce-6743d7a75c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-ababc7b1-a1da-4f52-8d53-cd6bc341054d,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-69b0e029-5592-4cf7-9184-efdf989ef0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46100,DS-1d625c5b-6c9d-4175-9a5d-1e20be8e5aad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533511566-172.17.0.7-1595842708374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41925,DS-a42256d0-2457-4087-a595-625db73c3e82,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-2ac3a0b2-13ba-4e19-9a89-7d251a998b58,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-57eb76c7-c92b-45d9-890f-c523850363f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36156,DS-4c8787ef-9f9c-4e57-82f4-64bf5ea29e42,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-e8cac393-9d90-43dd-8cce-6743d7a75c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-ababc7b1-a1da-4f52-8d53-cd6bc341054d,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-69b0e029-5592-4cf7-9184-efdf989ef0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46100,DS-1d625c5b-6c9d-4175-9a5d-1e20be8e5aad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-328691532-172.17.0.7-1595843299192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42001,DS-45107d32-c054-4b58-929d-6fe20d557fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-e07d0ac7-2b58-4c68-b9e6-66bb94e47351,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-e544a28a-39a0-4f4e-812a-0a3edd7a622b,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-b730b472-d969-41be-9bdc-5f8adcf4c172,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-71478e4b-921b-48de-9735-2564916f4a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-12906b66-c98b-460e-953c-11a97f304e93,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-f6b2711a-df4d-4b50-a66d-2cd07c6703d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-57bc9a45-c876-4489-8f64-757df000ab88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-328691532-172.17.0.7-1595843299192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42001,DS-45107d32-c054-4b58-929d-6fe20d557fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-e07d0ac7-2b58-4c68-b9e6-66bb94e47351,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-e544a28a-39a0-4f4e-812a-0a3edd7a622b,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-b730b472-d969-41be-9bdc-5f8adcf4c172,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-71478e4b-921b-48de-9735-2564916f4a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-12906b66-c98b-460e-953c-11a97f304e93,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-f6b2711a-df4d-4b50-a66d-2cd07c6703d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-57bc9a45-c876-4489-8f64-757df000ab88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-164317417-172.17.0.7-1595844288883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33339,DS-778c588c-d168-44a0-addf-7bb7803ff9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-f8234822-0948-431a-8229-3d618f428d47,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-fa67c400-0a4c-47af-8182-2a054d6bc07a,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-84fba4b4-9990-41d1-9652-bb32b05bd4df,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-25a6f2e1-26cb-45f7-9000-15d2ac02176b,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-9f2c1e18-be00-457f-9a63-7fb2fa56ec0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-94c125b4-6bb8-4c35-87a5-1af199cf5919,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-b37c267a-b595-4e59-8218-c13ec28a5a8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-164317417-172.17.0.7-1595844288883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33339,DS-778c588c-d168-44a0-addf-7bb7803ff9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-f8234822-0948-431a-8229-3d618f428d47,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-fa67c400-0a4c-47af-8182-2a054d6bc07a,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-84fba4b4-9990-41d1-9652-bb32b05bd4df,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-25a6f2e1-26cb-45f7-9000-15d2ac02176b,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-9f2c1e18-be00-457f-9a63-7fb2fa56ec0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-94c125b4-6bb8-4c35-87a5-1af199cf5919,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-b37c267a-b595-4e59-8218-c13ec28a5a8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131776744-172.17.0.7-1595844934860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45733,DS-3cf743d3-ab6e-488a-8f96-0bdf2a4a4dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-a69ed159-1aa0-4b9c-8d99-2c584f6f4b33,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-d8727043-1e4e-4ca0-8983-84b8c9377d70,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-3ec62625-8128-4ce7-82cb-e98f3ac9537d,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-b5be2bab-22f6-4abe-8922-8cf41dd2e320,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-ebe009d1-8c19-4fc3-8400-2bb4deffb64b,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-03570ffa-ed9b-43b5-ba3b-c4046e138e54,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-06cc6138-7131-4dd4-bb82-32ea7dd316e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131776744-172.17.0.7-1595844934860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45733,DS-3cf743d3-ab6e-488a-8f96-0bdf2a4a4dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-a69ed159-1aa0-4b9c-8d99-2c584f6f4b33,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-d8727043-1e4e-4ca0-8983-84b8c9377d70,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-3ec62625-8128-4ce7-82cb-e98f3ac9537d,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-b5be2bab-22f6-4abe-8922-8cf41dd2e320,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-ebe009d1-8c19-4fc3-8400-2bb4deffb64b,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-03570ffa-ed9b-43b5-ba3b-c4046e138e54,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-06cc6138-7131-4dd4-bb82-32ea7dd316e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1724590433-172.17.0.7-1595845361419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42589,DS-722a54c2-c16a-478a-92b6-5659f6159d09,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-f4c38e94-8400-4101-962e-cecc7740119c,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-d6bbe1cb-bace-4d2c-82cf-a6baabc411df,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-91ddd9fd-91fb-454b-96f3-ffffefed713f,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-d9526860-4d3e-4831-8798-98156491ecd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-036f4b1f-dbdd-4c97-8ae2-ad9797dc2d10,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-38927826-84b7-4d75-b870-b66d1195a041,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-20777fc9-c91c-4a9c-896d-c1c76438fc52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1724590433-172.17.0.7-1595845361419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42589,DS-722a54c2-c16a-478a-92b6-5659f6159d09,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-f4c38e94-8400-4101-962e-cecc7740119c,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-d6bbe1cb-bace-4d2c-82cf-a6baabc411df,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-91ddd9fd-91fb-454b-96f3-ffffefed713f,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-d9526860-4d3e-4831-8798-98156491ecd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-036f4b1f-dbdd-4c97-8ae2-ad9797dc2d10,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-38927826-84b7-4d75-b870-b66d1195a041,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-20777fc9-c91c-4a9c-896d-c1c76438fc52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982467711-172.17.0.7-1595845434095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37916,DS-286db785-144e-490e-ba02-3cdc2fd5331e,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-ec37c9b6-7b50-4d70-bd86-863c861eb521,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-f74d1715-45b4-41a6-9fee-c7170f0fe6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-fe5c0d96-f1e4-49ee-97d6-2f8684caeab0,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-5c1f6542-ce65-496a-b7db-df08fdb31e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-08ea1743-13ab-4f22-8c02-7b8636d49e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-46afe070-3816-4f9d-b8d0-1c55b83ca518,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-93abd7a8-00d6-45d4-b10c-69f251de12d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982467711-172.17.0.7-1595845434095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37916,DS-286db785-144e-490e-ba02-3cdc2fd5331e,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-ec37c9b6-7b50-4d70-bd86-863c861eb521,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-f74d1715-45b4-41a6-9fee-c7170f0fe6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-fe5c0d96-f1e4-49ee-97d6-2f8684caeab0,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-5c1f6542-ce65-496a-b7db-df08fdb31e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-08ea1743-13ab-4f22-8c02-7b8636d49e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-46afe070-3816-4f9d-b8d0-1c55b83ca518,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-93abd7a8-00d6-45d4-b10c-69f251de12d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469529783-172.17.0.7-1595845473088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44871,DS-2f235090-36f8-4f4e-97a5-fd7dc9d250ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-007b6cf0-3c01-4e68-8818-9bbdca3585e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-4ef5ce79-945e-4494-af5a-71b74f0e7a91,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-6b261975-d695-490d-8628-2d22e667a007,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-91fc1b89-1f8d-44bf-950d-275114452985,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-dc9caec2-1f52-4823-bf15-bb8b9a4f21fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-1431860f-6abb-4b0f-9ce2-1dab2f8ffaae,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-b53b39b0-9a33-48b2-817f-59485409d443,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469529783-172.17.0.7-1595845473088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44871,DS-2f235090-36f8-4f4e-97a5-fd7dc9d250ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-007b6cf0-3c01-4e68-8818-9bbdca3585e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-4ef5ce79-945e-4494-af5a-71b74f0e7a91,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-6b261975-d695-490d-8628-2d22e667a007,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-91fc1b89-1f8d-44bf-950d-275114452985,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-dc9caec2-1f52-4823-bf15-bb8b9a4f21fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-1431860f-6abb-4b0f-9ce2-1dab2f8ffaae,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-b53b39b0-9a33-48b2-817f-59485409d443,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111081224-172.17.0.7-1595846365330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37886,DS-3592d787-4790-49bb-a315-c3d86f098e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-fa2ed3d6-8f1c-4c97-b89f-a0d4f074ee0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-b31a2fc4-3528-4380-9842-1383ff41baa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-0e6f5cce-d002-42be-a1de-ae63a5529265,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-1dc8d880-71d3-4b43-8e80-cf4dfc317441,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-f89bd617-6d19-4b5a-8220-6d3c15d82325,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-d4b4c73a-eb92-4381-b0c5-c6135f6b5cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-89c79393-38d2-426b-b96e-60ee856c965d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111081224-172.17.0.7-1595846365330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37886,DS-3592d787-4790-49bb-a315-c3d86f098e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-fa2ed3d6-8f1c-4c97-b89f-a0d4f074ee0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-b31a2fc4-3528-4380-9842-1383ff41baa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-0e6f5cce-d002-42be-a1de-ae63a5529265,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-1dc8d880-71d3-4b43-8e80-cf4dfc317441,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-f89bd617-6d19-4b5a-8220-6d3c15d82325,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-d4b4c73a-eb92-4381-b0c5-c6135f6b5cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-89c79393-38d2-426b-b96e-60ee856c965d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1350192724-172.17.0.7-1595846441629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34124,DS-0cdb40e1-a031-43ca-b660-afdb7b002251,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-403b3373-9f0d-4bb9-beae-d295c3887f71,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-5bf16a21-96a6-44c0-90a4-a0c1e0c461aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-bf26ac70-45a2-497d-8e34-8c7deb4d39dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-7c212119-1c86-44ba-9791-c16027fea3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-93a2f1b8-7acb-455f-a7ff-9866ced61ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-811543fa-c35e-4578-9a2b-7b73d488b46c,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-a064472f-b035-46e6-9ab8-e17677b4a1e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1350192724-172.17.0.7-1595846441629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34124,DS-0cdb40e1-a031-43ca-b660-afdb7b002251,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-403b3373-9f0d-4bb9-beae-d295c3887f71,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-5bf16a21-96a6-44c0-90a4-a0c1e0c461aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-bf26ac70-45a2-497d-8e34-8c7deb4d39dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-7c212119-1c86-44ba-9791-c16027fea3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-93a2f1b8-7acb-455f-a7ff-9866ced61ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-811543fa-c35e-4578-9a2b-7b73d488b46c,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-a064472f-b035-46e6-9ab8-e17677b4a1e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1273522911-172.17.0.7-1595846478471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35033,DS-e9962dc3-817c-4c95-a456-6bf752f84483,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-c4e64b97-ec2f-4749-8fdf-0a00b617aeec,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-a6912d56-1976-4737-bf71-5421dc01e8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-c1668aab-efb4-4b1c-9f6d-2d27eedc1c44,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-1fc6fd77-44d8-4bd8-8568-252671a81134,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-d7324788-9653-48f4-b413-c910356969de,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-831daa7f-79b3-4283-a1fb-346bfa2d56e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-2d024f8b-2d98-4d20-a7ad-3bd9a390327f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1273522911-172.17.0.7-1595846478471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35033,DS-e9962dc3-817c-4c95-a456-6bf752f84483,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-c4e64b97-ec2f-4749-8fdf-0a00b617aeec,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-a6912d56-1976-4737-bf71-5421dc01e8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-c1668aab-efb4-4b1c-9f6d-2d27eedc1c44,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-1fc6fd77-44d8-4bd8-8568-252671a81134,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-d7324788-9653-48f4-b413-c910356969de,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-831daa7f-79b3-4283-a1fb-346bfa2d56e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-2d024f8b-2d98-4d20-a7ad-3bd9a390327f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-465038799-172.17.0.7-1595846765652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43919,DS-9ca67427-a70b-4480-9412-917715df5451,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-7c39c7e5-bb28-4ee9-987d-7285dd21d446,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-3455156c-3217-47ab-88c4-7439929cec43,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-670a0226-bb23-4ecc-9722-d28690665ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-fc55b348-8e26-453d-86bb-89679672c712,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-728094ed-809f-474a-a901-2cfcf58fc9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-8145da77-24eb-47a7-ac7b-9e92aefff89d,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-4a0467cb-9aa0-447c-ac08-ee1de4cb090e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-465038799-172.17.0.7-1595846765652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43919,DS-9ca67427-a70b-4480-9412-917715df5451,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-7c39c7e5-bb28-4ee9-987d-7285dd21d446,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-3455156c-3217-47ab-88c4-7439929cec43,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-670a0226-bb23-4ecc-9722-d28690665ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-fc55b348-8e26-453d-86bb-89679672c712,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-728094ed-809f-474a-a901-2cfcf58fc9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-8145da77-24eb-47a7-ac7b-9e92aefff89d,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-4a0467cb-9aa0-447c-ac08-ee1de4cb090e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2076853739-172.17.0.7-1595846904815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46857,DS-7baa777f-7ad4-4b03-b9b0-252b9cb0f009,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-8e57c7da-682e-423d-adac-8db29f282fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-e9d12a11-f09c-472a-93cc-4bcefb9a0796,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-63047080-8e60-428d-b18a-94a847f20f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-ac8336df-81a8-4f8e-9b04-e244fbd2137b,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-5a33b076-234d-470a-842f-fd0b9d0711e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-763ddb78-55c1-4f28-87bc-5699c3293983,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-d206ca0a-86df-48cb-b3f6-290ea66bdeb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2076853739-172.17.0.7-1595846904815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46857,DS-7baa777f-7ad4-4b03-b9b0-252b9cb0f009,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-8e57c7da-682e-423d-adac-8db29f282fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-e9d12a11-f09c-472a-93cc-4bcefb9a0796,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-63047080-8e60-428d-b18a-94a847f20f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-ac8336df-81a8-4f8e-9b04-e244fbd2137b,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-5a33b076-234d-470a-842f-fd0b9d0711e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-763ddb78-55c1-4f28-87bc-5699c3293983,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-d206ca0a-86df-48cb-b3f6-290ea66bdeb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1473380867-172.17.0.7-1595847009324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41097,DS-8ac5b603-6d2a-4003-b619-77d1fd2277dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-90a3bbb4-e706-40d7-96c0-447819c59297,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-cba2f5a7-d760-419c-b188-e214aa081086,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-4c660630-5c72-4082-a5cc-9178e209f120,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-11677df5-0a2f-47ed-ab7e-02efab26c6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-8413707f-c22d-4b73-a545-7c7208a1a379,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-10ca46b4-42d0-45ab-a756-a92f9c8e2b99,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-03aa55f8-844c-4d28-a148-f4f19d3831dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1473380867-172.17.0.7-1595847009324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41097,DS-8ac5b603-6d2a-4003-b619-77d1fd2277dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-90a3bbb4-e706-40d7-96c0-447819c59297,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-cba2f5a7-d760-419c-b188-e214aa081086,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-4c660630-5c72-4082-a5cc-9178e209f120,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-11677df5-0a2f-47ed-ab7e-02efab26c6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-8413707f-c22d-4b73-a545-7c7208a1a379,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-10ca46b4-42d0-45ab-a756-a92f9c8e2b99,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-03aa55f8-844c-4d28-a148-f4f19d3831dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134179540-172.17.0.7-1595847125598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36551,DS-0fb34e5d-f651-4bda-8d4b-12a4cd9c0347,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-59216dbc-886f-49c4-a63d-57542cbe7b38,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-db452258-3aa5-4461-b5af-38790c325230,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-28e147fa-5ca5-4f52-a4ad-71009a4f132d,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-0f5aece4-e349-4142-a2e9-a385d9c71624,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-da5e0c30-252c-4052-a008-46c5f2961c77,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-a2b8528c-0bd6-489e-a62e-919cfd898630,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-c38f6d51-75cb-404b-b919-74d3b7050e26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134179540-172.17.0.7-1595847125598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36551,DS-0fb34e5d-f651-4bda-8d4b-12a4cd9c0347,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-59216dbc-886f-49c4-a63d-57542cbe7b38,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-db452258-3aa5-4461-b5af-38790c325230,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-28e147fa-5ca5-4f52-a4ad-71009a4f132d,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-0f5aece4-e349-4142-a2e9-a385d9c71624,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-da5e0c30-252c-4052-a008-46c5f2961c77,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-a2b8528c-0bd6-489e-a62e-919cfd898630,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-c38f6d51-75cb-404b-b919-74d3b7050e26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5467
