reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862162636-172.17.0.21-1595497971005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42649,DS-ef87b7ec-6881-4390-93c5-b872a464a950,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-8fc3e0c8-9bc3-4228-bc71-3b7772c68ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-c283c627-1ead-4632-bc7d-6ed5833d5ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-ed568e0c-6f97-4c81-8a7a-ce59f438145c,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-bd2ed2fc-2323-4144-bd9e-89eaa26290bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-85890a60-8704-42d1-8cf8-95c67933d7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-77890311-7f23-44a0-a7d0-d99f1efcb9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-f6fec410-f381-474b-99e3-df29e115dbac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862162636-172.17.0.21-1595497971005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42649,DS-ef87b7ec-6881-4390-93c5-b872a464a950,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-8fc3e0c8-9bc3-4228-bc71-3b7772c68ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-c283c627-1ead-4632-bc7d-6ed5833d5ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-ed568e0c-6f97-4c81-8a7a-ce59f438145c,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-bd2ed2fc-2323-4144-bd9e-89eaa26290bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-85890a60-8704-42d1-8cf8-95c67933d7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-77890311-7f23-44a0-a7d0-d99f1efcb9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-f6fec410-f381-474b-99e3-df29e115dbac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85664964-172.17.0.21-1595498413661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45845,DS-4e6d9d95-b584-43fc-bc87-4f459fa6d017,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-7bb281ef-10ff-4571-826a-67dab0249780,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-917b0c69-577d-4369-a70e-8bf5c3c4ef64,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-3ad4a40b-113b-4127-ae14-adb5ed45eba3,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-21dc2bff-ccbd-42b9-a3d2-a0527993d435,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-87631138-5819-403d-8df3-6ad5396ab7da,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-e53057cb-e3de-4f75-9cca-81cd98baccf2,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-dec45c40-304e-4ee0-9c6f-ac59a024c9a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85664964-172.17.0.21-1595498413661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45845,DS-4e6d9d95-b584-43fc-bc87-4f459fa6d017,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-7bb281ef-10ff-4571-826a-67dab0249780,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-917b0c69-577d-4369-a70e-8bf5c3c4ef64,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-3ad4a40b-113b-4127-ae14-adb5ed45eba3,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-21dc2bff-ccbd-42b9-a3d2-a0527993d435,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-87631138-5819-403d-8df3-6ad5396ab7da,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-e53057cb-e3de-4f75-9cca-81cd98baccf2,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-dec45c40-304e-4ee0-9c6f-ac59a024c9a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1656788942-172.17.0.21-1595499129103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43787,DS-3694f07f-9709-4357-852c-20564a9f4802,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-ff585e94-dc97-41e2-aef0-1a464328d26a,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-bc449e26-1bce-45d0-be90-110f1adc4340,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-0e21599c-42d7-4287-b66b-8fe012e137a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-7dc3ca88-2bca-479e-b5a6-9fc72bbd6049,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-9300fedb-cfc9-4a0c-bdc0-1ed86396b692,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-8bb3b1e5-a373-4cec-91dc-3d46cb910981,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-25630f8b-e8e5-46b0-adae-d4c8e6c9e4ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1656788942-172.17.0.21-1595499129103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43787,DS-3694f07f-9709-4357-852c-20564a9f4802,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-ff585e94-dc97-41e2-aef0-1a464328d26a,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-bc449e26-1bce-45d0-be90-110f1adc4340,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-0e21599c-42d7-4287-b66b-8fe012e137a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-7dc3ca88-2bca-479e-b5a6-9fc72bbd6049,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-9300fedb-cfc9-4a0c-bdc0-1ed86396b692,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-8bb3b1e5-a373-4cec-91dc-3d46cb910981,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-25630f8b-e8e5-46b0-adae-d4c8e6c9e4ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879643500-172.17.0.21-1595499740970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41878,DS-df953e54-d0e6-4747-8ab8-787b17b72524,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-1084b8ae-60c5-45a0-aa65-e60f2df62a08,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-308b7d6a-93e1-4dda-bdbc-0aa3735c8201,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-cc48e571-4dac-48c4-9ec4-608780dac3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-737b8a8d-fc40-43a6-8e5e-63c129f45068,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-ba7559a2-2f77-4bc3-9636-92052c06fe98,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-9de28c7a-1367-4c44-a258-a1587800dbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-5a7bc723-6034-4cee-a31f-cfad34b2b74e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879643500-172.17.0.21-1595499740970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41878,DS-df953e54-d0e6-4747-8ab8-787b17b72524,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-1084b8ae-60c5-45a0-aa65-e60f2df62a08,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-308b7d6a-93e1-4dda-bdbc-0aa3735c8201,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-cc48e571-4dac-48c4-9ec4-608780dac3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-737b8a8d-fc40-43a6-8e5e-63c129f45068,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-ba7559a2-2f77-4bc3-9636-92052c06fe98,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-9de28c7a-1367-4c44-a258-a1587800dbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-5a7bc723-6034-4cee-a31f-cfad34b2b74e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461558752-172.17.0.21-1595500122580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36918,DS-139a6c25-46cc-4ad4-96a6-4ca12e1e974f,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-e90cc181-e16e-484f-ae9b-88f945859322,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-79ed2ca4-9d5c-44ad-827c-cbe2d08b4126,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-5a6d437a-8828-4e80-9fc2-d5b01a8e440b,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-cbd6c726-9bbb-462d-9bd3-e215b2df975d,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-fcdca77f-fc4c-4a8f-b4d9-f8307342cacf,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-366d71ad-bf38-469b-b37c-663c54ee0b88,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-52c73354-321a-4033-bf36-8fe5eb1af840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461558752-172.17.0.21-1595500122580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36918,DS-139a6c25-46cc-4ad4-96a6-4ca12e1e974f,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-e90cc181-e16e-484f-ae9b-88f945859322,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-79ed2ca4-9d5c-44ad-827c-cbe2d08b4126,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-5a6d437a-8828-4e80-9fc2-d5b01a8e440b,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-cbd6c726-9bbb-462d-9bd3-e215b2df975d,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-fcdca77f-fc4c-4a8f-b4d9-f8307342cacf,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-366d71ad-bf38-469b-b37c-663c54ee0b88,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-52c73354-321a-4033-bf36-8fe5eb1af840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-985553325-172.17.0.21-1595500164095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40538,DS-37d4f4e0-655c-44d6-8fd9-0c283d4f2de7,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-d986890d-6c65-494f-a21a-103c1dcd62d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-967ee848-6883-42db-ad92-66d0f66183e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-6deb3dec-3541-449a-921e-d5b66f8b202b,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-5388fe78-abcd-440e-ba4f-d73064ec66cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-93233a38-1e15-41d4-a94e-d0d20069ee0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-18edd62a-dd09-4c61-96bc-aa977dd1d088,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-6515910c-6853-43cb-b36f-4f0141f7cf71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-985553325-172.17.0.21-1595500164095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40538,DS-37d4f4e0-655c-44d6-8fd9-0c283d4f2de7,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-d986890d-6c65-494f-a21a-103c1dcd62d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-967ee848-6883-42db-ad92-66d0f66183e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-6deb3dec-3541-449a-921e-d5b66f8b202b,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-5388fe78-abcd-440e-ba4f-d73064ec66cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-93233a38-1e15-41d4-a94e-d0d20069ee0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-18edd62a-dd09-4c61-96bc-aa977dd1d088,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-6515910c-6853-43cb-b36f-4f0141f7cf71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92029516-172.17.0.21-1595500729588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45793,DS-a4e575eb-3885-46ff-8d38-815310c59155,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-1d2511e2-3f53-42e7-adee-592f3d2e5f42,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-4e5be95a-5817-4ccd-812f-ca273d37e96c,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-ec4ab660-d45b-40ba-be16-cf1b5b2f0403,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-8c0bb2fe-8e48-4e5e-b15f-732e2ad66363,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-246827f9-585c-41c3-ba34-ac6b2220647e,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-7a140a93-b067-415d-aa6b-00095d117132,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-e3944df6-ea8c-4ca3-9535-f696f3f91504,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92029516-172.17.0.21-1595500729588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45793,DS-a4e575eb-3885-46ff-8d38-815310c59155,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-1d2511e2-3f53-42e7-adee-592f3d2e5f42,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-4e5be95a-5817-4ccd-812f-ca273d37e96c,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-ec4ab660-d45b-40ba-be16-cf1b5b2f0403,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-8c0bb2fe-8e48-4e5e-b15f-732e2ad66363,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-246827f9-585c-41c3-ba34-ac6b2220647e,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-7a140a93-b067-415d-aa6b-00095d117132,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-e3944df6-ea8c-4ca3-9535-f696f3f91504,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673533791-172.17.0.21-1595501155375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42961,DS-841c1e15-580e-4e88-bc57-0c1a54999a45,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-5697d9a6-7b20-4c16-8e81-8cbd9d71dff4,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-be17e618-21d6-495f-836f-a9d738ebf4da,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-db93be90-0a5d-4a76-ac58-9f75b4b7395f,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-908a38c0-006a-4ff7-a1ec-820d81542541,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-0c3f9152-30db-4bfe-ae2e-19b6587f72de,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-f87ec0b0-4a54-41ba-b991-5eaf0aaffe36,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-313f3b42-1e7f-4f11-8990-dcdfa254d3ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673533791-172.17.0.21-1595501155375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42961,DS-841c1e15-580e-4e88-bc57-0c1a54999a45,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-5697d9a6-7b20-4c16-8e81-8cbd9d71dff4,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-be17e618-21d6-495f-836f-a9d738ebf4da,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-db93be90-0a5d-4a76-ac58-9f75b4b7395f,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-908a38c0-006a-4ff7-a1ec-820d81542541,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-0c3f9152-30db-4bfe-ae2e-19b6587f72de,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-f87ec0b0-4a54-41ba-b991-5eaf0aaffe36,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-313f3b42-1e7f-4f11-8990-dcdfa254d3ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-19104540-172.17.0.21-1595502004825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40433,DS-cb17e87e-6750-4fa8-b479-424f7fb82d38,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-9e9b4747-09bb-4d51-bcce-3790f55dedbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-585d00e8-05ac-410d-b829-aa1eca69679b,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-4efbf499-7416-4d84-8981-5dfc1b7271cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-12fe3e38-ca98-493d-87ec-130a398ac447,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-aa7fccba-8961-4c07-b149-ad0e03c417ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-da31244f-acc2-4220-84a2-d6cfe47e591a,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-83ac5943-65dd-47d8-bd1a-f63ba891b67c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-19104540-172.17.0.21-1595502004825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40433,DS-cb17e87e-6750-4fa8-b479-424f7fb82d38,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-9e9b4747-09bb-4d51-bcce-3790f55dedbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-585d00e8-05ac-410d-b829-aa1eca69679b,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-4efbf499-7416-4d84-8981-5dfc1b7271cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-12fe3e38-ca98-493d-87ec-130a398ac447,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-aa7fccba-8961-4c07-b149-ad0e03c417ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-da31244f-acc2-4220-84a2-d6cfe47e591a,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-83ac5943-65dd-47d8-bd1a-f63ba891b67c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757288054-172.17.0.21-1595502277345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45138,DS-650eacfc-e163-436f-a7cb-250dfec25b65,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-f01ea58f-da46-450c-aac6-fe266a3738a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-febffd48-3ccf-4c30-9d96-6edd4fa2beb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-d0e83e68-a883-481b-8f04-fbc5c5753e25,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-7b151c64-02a9-4184-ba2a-9258b2d03416,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-a3b01981-38da-441e-a441-abb30586a706,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-42fae8f3-31a9-471f-bd52-fd83ec862b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-c8048be8-368d-4050-b308-47a0764302f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757288054-172.17.0.21-1595502277345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45138,DS-650eacfc-e163-436f-a7cb-250dfec25b65,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-f01ea58f-da46-450c-aac6-fe266a3738a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-febffd48-3ccf-4c30-9d96-6edd4fa2beb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-d0e83e68-a883-481b-8f04-fbc5c5753e25,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-7b151c64-02a9-4184-ba2a-9258b2d03416,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-a3b01981-38da-441e-a441-abb30586a706,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-42fae8f3-31a9-471f-bd52-fd83ec862b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-c8048be8-368d-4050-b308-47a0764302f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673167894-172.17.0.21-1595502455505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34991,DS-5c1ae5d2-65d3-49b9-9e8d-29dfd73c22c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-0222dcb7-a982-43af-8993-f433d01cb918,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-eae94810-8855-4015-b955-b1af9d1d6a20,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-2f9cd986-2f6f-4a1d-8b11-8e07013a76ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-c3fcfda6-bcbd-4568-a781-c09e1aaa4324,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-54e840cb-8152-4e8d-b2b0-75f8a3a02f52,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-3951d141-eaed-452b-96b7-ab6d9fded921,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-47934064-a37e-4a6c-8282-da528ea8db03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673167894-172.17.0.21-1595502455505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34991,DS-5c1ae5d2-65d3-49b9-9e8d-29dfd73c22c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-0222dcb7-a982-43af-8993-f433d01cb918,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-eae94810-8855-4015-b955-b1af9d1d6a20,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-2f9cd986-2f6f-4a1d-8b11-8e07013a76ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-c3fcfda6-bcbd-4568-a781-c09e1aaa4324,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-54e840cb-8152-4e8d-b2b0-75f8a3a02f52,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-3951d141-eaed-452b-96b7-ab6d9fded921,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-47934064-a37e-4a6c-8282-da528ea8db03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587666542-172.17.0.21-1595502593647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41146,DS-2b7403aa-fbad-4701-aad5-925ed7c2e77c,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-ebb4ae86-7409-4f29-b0df-dd12825180a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-36aa0235-39c9-4026-833c-ff7659137126,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-f308ce3d-db02-4a33-aaa2-72632c6a0358,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-6914775d-2b86-42ff-8720-5a008e3aae83,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-e671615b-e6ec-4adb-95f0-6490c01d8174,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-a74fc2a8-ddb8-4481-9ee2-7747d38aad4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-230bfe33-397c-4d57-a3b4-2f7476fef3bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587666542-172.17.0.21-1595502593647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41146,DS-2b7403aa-fbad-4701-aad5-925ed7c2e77c,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-ebb4ae86-7409-4f29-b0df-dd12825180a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-36aa0235-39c9-4026-833c-ff7659137126,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-f308ce3d-db02-4a33-aaa2-72632c6a0358,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-6914775d-2b86-42ff-8720-5a008e3aae83,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-e671615b-e6ec-4adb-95f0-6490c01d8174,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-a74fc2a8-ddb8-4481-9ee2-7747d38aad4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-230bfe33-397c-4d57-a3b4-2f7476fef3bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048009573-172.17.0.21-1595502682566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35289,DS-bef51377-6f6e-4668-9550-b349d3c41f71,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-6ff03c89-82cc-4a1e-bfe7-7234b4176f88,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-b5e7675f-e1a4-4712-8497-d5cd64e834ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-049744b8-7c1c-43b0-8982-0ebfe85ad2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-c86ca98f-8d8c-44eb-8720-55a929834c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-67bf4c49-9342-4524-94d6-51563110b983,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-b930b60a-636f-42f6-bb6d-c0530fdf5a10,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-dac73c8b-5fde-4390-9d07-bc6f93c33169,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048009573-172.17.0.21-1595502682566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35289,DS-bef51377-6f6e-4668-9550-b349d3c41f71,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-6ff03c89-82cc-4a1e-bfe7-7234b4176f88,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-b5e7675f-e1a4-4712-8497-d5cd64e834ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-049744b8-7c1c-43b0-8982-0ebfe85ad2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-c86ca98f-8d8c-44eb-8720-55a929834c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-67bf4c49-9342-4524-94d6-51563110b983,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-b930b60a-636f-42f6-bb6d-c0530fdf5a10,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-dac73c8b-5fde-4390-9d07-bc6f93c33169,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973895434-172.17.0.21-1595503236758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36098,DS-32806a80-e97e-4a04-beca-fcbe6b8d44a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-10d4d46c-f8cd-4fec-82d1-4d0784215fef,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-4b292693-8585-40a1-bb5f-a49319b192e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-e2671573-2b8f-45c2-843a-aabb4efd6702,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-a39fe1f3-75b7-4b2c-b83a-f6b86daa4b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-97909f17-e423-48a3-9282-988fa1630b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-62800270-571c-4bfa-8952-2d9a49057565,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-0630bc36-2464-486e-a44e-3c97bac2b648,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973895434-172.17.0.21-1595503236758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36098,DS-32806a80-e97e-4a04-beca-fcbe6b8d44a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-10d4d46c-f8cd-4fec-82d1-4d0784215fef,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-4b292693-8585-40a1-bb5f-a49319b192e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-e2671573-2b8f-45c2-843a-aabb4efd6702,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-a39fe1f3-75b7-4b2c-b83a-f6b86daa4b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-97909f17-e423-48a3-9282-988fa1630b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-62800270-571c-4bfa-8952-2d9a49057565,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-0630bc36-2464-486e-a44e-3c97bac2b648,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-613173857-172.17.0.21-1595503382604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45877,DS-c6a3a39f-f74e-4bdb-a42a-191194db3a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-8a538284-9f44-49dc-9c58-fe90730b77c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-f7583b5f-bc36-4eea-878e-eb2ac7ab3f00,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-6710fa40-866b-49ee-994b-97f9a8e28cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-c657aaa7-21c2-4f1b-8214-45ccdce1d4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-53ef7cde-4c89-46c5-bb71-f6c0170ee003,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-55051e1f-400f-4ade-8768-cf0b5014e8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-34e4aba6-c84d-44f2-b88e-2d71850d64d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-613173857-172.17.0.21-1595503382604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45877,DS-c6a3a39f-f74e-4bdb-a42a-191194db3a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-8a538284-9f44-49dc-9c58-fe90730b77c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-f7583b5f-bc36-4eea-878e-eb2ac7ab3f00,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-6710fa40-866b-49ee-994b-97f9a8e28cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-c657aaa7-21c2-4f1b-8214-45ccdce1d4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-53ef7cde-4c89-46c5-bb71-f6c0170ee003,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-55051e1f-400f-4ade-8768-cf0b5014e8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-34e4aba6-c84d-44f2-b88e-2d71850d64d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1907724094-172.17.0.21-1595504648379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42376,DS-36af0405-288d-47e6-9ab9-ea3928470322,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-32df2879-8346-481c-adae-c35de9448315,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-2e911150-4df7-47aa-a6b0-09ef3f360b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-a01ff620-7646-4659-8283-486f89f52728,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-4a01f136-ba27-49f8-bb20-aa0e7882e7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-82486a98-2082-405b-8937-c4e3cc34aa22,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-132cbeaf-9af9-4a6f-9c39-80f34d0cbfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-3afe64ab-5b01-4e41-84f1-43b0caf8686f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1907724094-172.17.0.21-1595504648379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42376,DS-36af0405-288d-47e6-9ab9-ea3928470322,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-32df2879-8346-481c-adae-c35de9448315,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-2e911150-4df7-47aa-a6b0-09ef3f360b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-a01ff620-7646-4659-8283-486f89f52728,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-4a01f136-ba27-49f8-bb20-aa0e7882e7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-82486a98-2082-405b-8937-c4e3cc34aa22,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-132cbeaf-9af9-4a6f-9c39-80f34d0cbfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-3afe64ab-5b01-4e41-84f1-43b0caf8686f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561523859-172.17.0.21-1595504780328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46508,DS-2ed94a2f-60e0-4b5e-9253-3e176e5493b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-4ce908b5-e118-44c7-8433-a3ce6e20129d,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-66519882-9209-4f57-8552-595878b26a10,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-4764950e-80e8-434d-ab24-af55131fadb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-bcc156b7-560f-4442-91b4-43b1415c9640,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-69ac8e01-cd31-4886-b5b8-7e9b485bc542,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-459a580f-1816-4f47-90d6-304db7ff07c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-ea810e5f-25f4-4783-8d1a-1fb4cd9eb588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561523859-172.17.0.21-1595504780328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46508,DS-2ed94a2f-60e0-4b5e-9253-3e176e5493b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-4ce908b5-e118-44c7-8433-a3ce6e20129d,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-66519882-9209-4f57-8552-595878b26a10,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-4764950e-80e8-434d-ab24-af55131fadb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-bcc156b7-560f-4442-91b4-43b1415c9640,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-69ac8e01-cd31-4886-b5b8-7e9b485bc542,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-459a580f-1816-4f47-90d6-304db7ff07c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-ea810e5f-25f4-4783-8d1a-1fb4cd9eb588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 7126
