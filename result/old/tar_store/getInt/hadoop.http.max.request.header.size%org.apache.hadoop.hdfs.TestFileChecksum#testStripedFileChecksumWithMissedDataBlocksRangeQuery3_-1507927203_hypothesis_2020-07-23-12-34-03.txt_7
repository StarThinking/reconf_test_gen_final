reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1930764982-172.17.0.7-1595507692319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39912,DS-46836ac8-7675-44a5-a5d4-a65664657119,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-d37e23f6-1b82-4ac2-8f6f-460272f6add6,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-83865bfa-2361-4409-8080-fe8092ec5aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-3bab5b40-700d-409c-aed5-76356980a180,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-d3ebd71e-ae73-404b-8cc8-49e48fbdd51a,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-ea785a38-0a7e-4c66-9629-5701cfdad80d,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-ff362f27-0982-46e0-8caa-11ba1b408ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-1ff5d743-e620-465b-acea-2293c8d7fb94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1930764982-172.17.0.7-1595507692319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39912,DS-46836ac8-7675-44a5-a5d4-a65664657119,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-d37e23f6-1b82-4ac2-8f6f-460272f6add6,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-83865bfa-2361-4409-8080-fe8092ec5aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-3bab5b40-700d-409c-aed5-76356980a180,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-d3ebd71e-ae73-404b-8cc8-49e48fbdd51a,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-ea785a38-0a7e-4c66-9629-5701cfdad80d,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-ff362f27-0982-46e0-8caa-11ba1b408ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-1ff5d743-e620-465b-acea-2293c8d7fb94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1513335236-172.17.0.7-1595507942718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36137,DS-4c346535-8876-4163-b77b-4eb6c19b3972,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-310c2aae-2b61-4a8f-be40-616bb9b9a020,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-ca7035ec-830d-4488-a6cc-8102cfa09400,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-82d43d2c-5532-4efa-b2a3-38bcec3c5417,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-b5de46cc-bbc7-4870-b1a1-0b10e8af691f,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-676031da-5644-49b2-b276-7144ba2d69f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-1447b96c-4e1d-40bc-bcdd-dc33dd796c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-694e9f38-91cf-4143-882d-67354d3da57a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1513335236-172.17.0.7-1595507942718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36137,DS-4c346535-8876-4163-b77b-4eb6c19b3972,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-310c2aae-2b61-4a8f-be40-616bb9b9a020,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-ca7035ec-830d-4488-a6cc-8102cfa09400,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-82d43d2c-5532-4efa-b2a3-38bcec3c5417,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-b5de46cc-bbc7-4870-b1a1-0b10e8af691f,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-676031da-5644-49b2-b276-7144ba2d69f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-1447b96c-4e1d-40bc-bcdd-dc33dd796c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-694e9f38-91cf-4143-882d-67354d3da57a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231482656-172.17.0.7-1595508190530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39273,DS-9624f91f-8b22-4810-9634-8e8651cf1369,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-c725f64a-40a5-42a0-ac35-993610dfe9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-b52b042b-ef04-48af-b578-fadf6c45b5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-9dab98ca-da2c-45b2-a547-befe37f869fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-3e095bf0-edb0-4abf-89fe-3e9fda9864ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-afee0c09-5c77-4063-8286-a6567f1d05c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-faff9dde-c6ec-4840-a81e-091613bc0863,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-9bc15b1e-302f-4429-81a1-83694e5a1586,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231482656-172.17.0.7-1595508190530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39273,DS-9624f91f-8b22-4810-9634-8e8651cf1369,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-c725f64a-40a5-42a0-ac35-993610dfe9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-b52b042b-ef04-48af-b578-fadf6c45b5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-9dab98ca-da2c-45b2-a547-befe37f869fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-3e095bf0-edb0-4abf-89fe-3e9fda9864ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-afee0c09-5c77-4063-8286-a6567f1d05c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-faff9dde-c6ec-4840-a81e-091613bc0863,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-9bc15b1e-302f-4429-81a1-83694e5a1586,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568461820-172.17.0.7-1595509072142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34587,DS-a1046994-8783-4434-9584-f593dfc8b6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-a8a9208b-d053-4974-b7e9-8dfc8074af46,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-85a372f8-484c-410e-b754-40d9dbfaf309,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-165a7b59-7aa3-4885-8644-38780b560a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-85c3334a-14f9-4a4f-b0b9-788a692029a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-b27a886e-368a-4cbf-b79f-46301345e980,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-118d8de7-988a-4c7c-8cb7-f5ea20fa0c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-6334964e-4d48-4ea0-982d-ba88940eb9df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568461820-172.17.0.7-1595509072142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34587,DS-a1046994-8783-4434-9584-f593dfc8b6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-a8a9208b-d053-4974-b7e9-8dfc8074af46,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-85a372f8-484c-410e-b754-40d9dbfaf309,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-165a7b59-7aa3-4885-8644-38780b560a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-85c3334a-14f9-4a4f-b0b9-788a692029a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-b27a886e-368a-4cbf-b79f-46301345e980,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-118d8de7-988a-4c7c-8cb7-f5ea20fa0c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-6334964e-4d48-4ea0-982d-ba88940eb9df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277724513-172.17.0.7-1595509260192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42777,DS-8b369db3-de17-40ac-afd0-a17828b28665,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-95a6053d-7422-4e34-b488-49576920e821,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-bd2fec38-072d-4375-bdd5-59b846903d50,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-cd8f478f-4183-4701-a86d-f64293e8e990,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-126544df-6b1e-4919-96c1-d6447733d5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-fc986b66-fd54-48ec-a05b-94ddf2d7af80,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-45e36d55-e54b-47ad-ab5f-4a694734eaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-b7866e4c-1d28-4063-9dda-f663d5d5e839,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277724513-172.17.0.7-1595509260192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42777,DS-8b369db3-de17-40ac-afd0-a17828b28665,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-95a6053d-7422-4e34-b488-49576920e821,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-bd2fec38-072d-4375-bdd5-59b846903d50,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-cd8f478f-4183-4701-a86d-f64293e8e990,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-126544df-6b1e-4919-96c1-d6447733d5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-fc986b66-fd54-48ec-a05b-94ddf2d7af80,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-45e36d55-e54b-47ad-ab5f-4a694734eaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-b7866e4c-1d28-4063-9dda-f663d5d5e839,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351034458-172.17.0.7-1595509298521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45917,DS-d54749a9-466b-43fc-8eec-0fae326184e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-7e4b6f3c-8648-4de2-bcd0-641a8232458a,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-88773f08-a55d-41db-af10-fedaac79e684,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-7f41e6fc-0ba6-47ec-b328-82d6ce543803,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-2fc31c48-cb4f-4ff8-9743-8e33dd810f47,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-ff547eef-eee1-4eb7-bdb1-39f894ceff6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-a4c7b1c2-a221-4192-8bbb-62db40098c96,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-14f0d813-ba97-4e13-9203-6aef94a4fef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351034458-172.17.0.7-1595509298521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45917,DS-d54749a9-466b-43fc-8eec-0fae326184e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-7e4b6f3c-8648-4de2-bcd0-641a8232458a,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-88773f08-a55d-41db-af10-fedaac79e684,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-7f41e6fc-0ba6-47ec-b328-82d6ce543803,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-2fc31c48-cb4f-4ff8-9743-8e33dd810f47,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-ff547eef-eee1-4eb7-bdb1-39f894ceff6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-a4c7b1c2-a221-4192-8bbb-62db40098c96,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-14f0d813-ba97-4e13-9203-6aef94a4fef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-254609259-172.17.0.7-1595509586613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35285,DS-f08859e7-30c7-46b3-8098-bb6a42a4e96a,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-277751d7-9656-424e-a771-58c1b3f0c7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-ac548cdf-8ea3-4130-919d-95acaaa21bef,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-b1e2696f-b495-4e40-a026-41159954cd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-4800dd60-8834-47af-bd4b-10b654728bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-481c24e7-d39a-4da3-972c-ea4ecfe10b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-db813de4-4298-4f56-8d90-edb0215daaad,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-0aed65dd-a30f-4595-abb9-37ea135cb8a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-254609259-172.17.0.7-1595509586613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35285,DS-f08859e7-30c7-46b3-8098-bb6a42a4e96a,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-277751d7-9656-424e-a771-58c1b3f0c7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-ac548cdf-8ea3-4130-919d-95acaaa21bef,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-b1e2696f-b495-4e40-a026-41159954cd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-4800dd60-8834-47af-bd4b-10b654728bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-481c24e7-d39a-4da3-972c-ea4ecfe10b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-db813de4-4298-4f56-8d90-edb0215daaad,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-0aed65dd-a30f-4595-abb9-37ea135cb8a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443001166-172.17.0.7-1595510010796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36218,DS-5b5aeada-f875-4e7b-8d5a-bad9d215b55a,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-58b1ef85-09b1-4af0-a239-5e942e9e07dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-498f7cee-ac3d-4655-9954-5afa089cef04,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-5232026f-a4e4-4751-93e5-94b632a1aa85,DISK], DatanodeInfoWithStorage[127.0.0.1:36345,DS-b63c7d80-8d83-4d1d-b737-b9038e3177f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-5b5ab63a-e82d-4c2c-835a-6f1233bece53,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-12f8c811-9ccb-4973-b214-beb2657db79f,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-df4e7dea-013e-4756-a0df-ad9c45fc8167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443001166-172.17.0.7-1595510010796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36218,DS-5b5aeada-f875-4e7b-8d5a-bad9d215b55a,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-58b1ef85-09b1-4af0-a239-5e942e9e07dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-498f7cee-ac3d-4655-9954-5afa089cef04,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-5232026f-a4e4-4751-93e5-94b632a1aa85,DISK], DatanodeInfoWithStorage[127.0.0.1:36345,DS-b63c7d80-8d83-4d1d-b737-b9038e3177f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-5b5ab63a-e82d-4c2c-835a-6f1233bece53,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-12f8c811-9ccb-4973-b214-beb2657db79f,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-df4e7dea-013e-4756-a0df-ad9c45fc8167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1550015962-172.17.0.7-1595510172138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45760,DS-76725efb-5e3c-498b-94da-d35f5dc4e1af,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-a432d2f1-0646-46c4-8ecd-6761453e2423,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-d73cacc8-a25f-498d-8dcb-046f9b8902a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-9acf52cb-9f52-4883-8b1e-a84b1108d6af,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-39411efe-3fb4-4906-a9d0-b389fda9d624,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-377388bb-ad38-4261-95ba-d660b96e933a,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-02196dfe-4ee6-465b-b66e-fd0b43dda9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-e0c3cd2b-a872-4788-bd00-3d724f5e529d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1550015962-172.17.0.7-1595510172138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45760,DS-76725efb-5e3c-498b-94da-d35f5dc4e1af,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-a432d2f1-0646-46c4-8ecd-6761453e2423,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-d73cacc8-a25f-498d-8dcb-046f9b8902a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-9acf52cb-9f52-4883-8b1e-a84b1108d6af,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-39411efe-3fb4-4906-a9d0-b389fda9d624,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-377388bb-ad38-4261-95ba-d660b96e933a,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-02196dfe-4ee6-465b-b66e-fd0b43dda9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-e0c3cd2b-a872-4788-bd00-3d724f5e529d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102777958-172.17.0.7-1595510566242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38483,DS-3b159621-b6e0-4e4c-a798-7247e0afe9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-2d5892b8-78f6-4ffa-8be0-c2449606c6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-98134791-e5dc-495e-8072-2e20e944d2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-6e802d86-cad3-4281-a692-a2b6e5170994,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-d1c876e5-1e55-4ce9-80e0-35413abe4ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-b74cc09b-1d68-4645-b789-18dbe116cc81,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-e8dcb6c6-1f52-4964-82f3-03c05184be65,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-95348532-f0b4-4bbc-9639-7a70fef8cf7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102777958-172.17.0.7-1595510566242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38483,DS-3b159621-b6e0-4e4c-a798-7247e0afe9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-2d5892b8-78f6-4ffa-8be0-c2449606c6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-98134791-e5dc-495e-8072-2e20e944d2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-6e802d86-cad3-4281-a692-a2b6e5170994,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-d1c876e5-1e55-4ce9-80e0-35413abe4ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-b74cc09b-1d68-4645-b789-18dbe116cc81,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-e8dcb6c6-1f52-4964-82f3-03c05184be65,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-95348532-f0b4-4bbc-9639-7a70fef8cf7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1326680028-172.17.0.7-1595511174499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36022,DS-b2201351-596f-468f-b4d2-97a148b64171,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-8c463702-a6b0-44fa-bf75-79a75c64992c,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-b01beec6-8b4a-48b3-9299-afbce07cc912,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-a4b37b63-6e3b-4bf3-8b5a-a76dfd61e0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-5a9505fa-73f2-4521-83f6-5b835081ae69,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-333b4f8e-3dca-4efd-ae34-ec11e4cf0128,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-52b9c2bc-afc5-4f27-9efc-c80c53af090f,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-57c87d7b-53d9-47e3-8f75-c9743ee48327,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1326680028-172.17.0.7-1595511174499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36022,DS-b2201351-596f-468f-b4d2-97a148b64171,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-8c463702-a6b0-44fa-bf75-79a75c64992c,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-b01beec6-8b4a-48b3-9299-afbce07cc912,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-a4b37b63-6e3b-4bf3-8b5a-a76dfd61e0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-5a9505fa-73f2-4521-83f6-5b835081ae69,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-333b4f8e-3dca-4efd-ae34-ec11e4cf0128,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-52b9c2bc-afc5-4f27-9efc-c80c53af090f,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-57c87d7b-53d9-47e3-8f75-c9743ee48327,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624049619-172.17.0.7-1595511659955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46347,DS-776f33c7-2cde-4ff9-b025-fe2782c86f58,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-eb42c9e0-13bf-40ca-85ad-a7660c92a0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-15cb2a9a-d330-410c-8842-cbe95dffcb95,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-4ba0983a-7b66-4379-8af7-d39f7713356c,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-8e7d0a74-0f1b-4b2a-b0aa-6ab49b3eb993,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-b5ae9817-86b9-4eb0-b761-7bc82a334186,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-0922addf-b6d3-4811-8ff1-23a40d5df2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-e032f726-c527-4d26-b862-d8edf74d6bb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624049619-172.17.0.7-1595511659955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46347,DS-776f33c7-2cde-4ff9-b025-fe2782c86f58,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-eb42c9e0-13bf-40ca-85ad-a7660c92a0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-15cb2a9a-d330-410c-8842-cbe95dffcb95,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-4ba0983a-7b66-4379-8af7-d39f7713356c,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-8e7d0a74-0f1b-4b2a-b0aa-6ab49b3eb993,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-b5ae9817-86b9-4eb0-b761-7bc82a334186,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-0922addf-b6d3-4811-8ff1-23a40d5df2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-e032f726-c527-4d26-b862-d8edf74d6bb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1951884396-172.17.0.7-1595511695250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43685,DS-cee7cfda-586d-41f8-badd-dc62a5662666,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-6ff3fb97-33e2-4f93-b543-f0bf77c305ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-2ffbc6ae-b3d5-447a-8c3b-8559853f7454,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-1429748f-ea66-4e7d-8071-c3f0b07fa350,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-d1b8c674-6666-4cea-bce7-39b5f4df0e58,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-8e449c59-dc4d-4df1-b8ea-8c3d1c315641,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-d692cc3d-6cc9-43a0-b4e4-5a6d99529149,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-f1170d72-e032-4434-b977-551e87770682,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1951884396-172.17.0.7-1595511695250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43685,DS-cee7cfda-586d-41f8-badd-dc62a5662666,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-6ff3fb97-33e2-4f93-b543-f0bf77c305ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-2ffbc6ae-b3d5-447a-8c3b-8559853f7454,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-1429748f-ea66-4e7d-8071-c3f0b07fa350,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-d1b8c674-6666-4cea-bce7-39b5f4df0e58,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-8e449c59-dc4d-4df1-b8ea-8c3d1c315641,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-d692cc3d-6cc9-43a0-b4e4-5a6d99529149,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-f1170d72-e032-4434-b977-551e87770682,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1762177146-172.17.0.7-1595511731269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37434,DS-89536322-39c7-4294-bd68-6c9e87b600dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-d7e6b126-1bcd-4eca-ae3c-bf4527de39bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-cd1ace9c-5bc8-4e90-9b46-0c2d99071383,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-7dbc3949-5f9f-4d33-84ee-95ae01111bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-2915ba4d-250b-4798-ad34-5e89a075188f,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-b0c447aa-7771-4cbe-b42f-03ed6f05a72e,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-97043d87-6a54-4e52-906d-2d57c578a9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-b377fec3-ce85-4821-8b44-922fa474b874,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1762177146-172.17.0.7-1595511731269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37434,DS-89536322-39c7-4294-bd68-6c9e87b600dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-d7e6b126-1bcd-4eca-ae3c-bf4527de39bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-cd1ace9c-5bc8-4e90-9b46-0c2d99071383,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-7dbc3949-5f9f-4d33-84ee-95ae01111bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-2915ba4d-250b-4798-ad34-5e89a075188f,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-b0c447aa-7771-4cbe-b42f-03ed6f05a72e,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-97043d87-6a54-4e52-906d-2d57c578a9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-b377fec3-ce85-4821-8b44-922fa474b874,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611806294-172.17.0.7-1595511912369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45919,DS-1d8e1ee3-1e87-46a9-837d-6261058dc546,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-649ad23f-1b13-4415-a16a-e1e0e50f72e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-300d71fa-8236-4adb-9e02-3830176c9515,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-caa04a36-50bc-4eff-9221-35c802acc05b,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-6eaeb6e0-9f88-4f40-bb60-9feb32ff3262,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-9359c1ce-f2d7-4a18-ba06-52f5a357988a,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-03508849-b430-49f5-b522-5a228097458f,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-fe637c73-de94-4b50-8fe9-aea04a6eeb1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611806294-172.17.0.7-1595511912369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45919,DS-1d8e1ee3-1e87-46a9-837d-6261058dc546,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-649ad23f-1b13-4415-a16a-e1e0e50f72e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-300d71fa-8236-4adb-9e02-3830176c9515,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-caa04a36-50bc-4eff-9221-35c802acc05b,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-6eaeb6e0-9f88-4f40-bb60-9feb32ff3262,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-9359c1ce-f2d7-4a18-ba06-52f5a357988a,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-03508849-b430-49f5-b522-5a228097458f,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-fe637c73-de94-4b50-8fe9-aea04a6eeb1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1313507618-172.17.0.7-1595512107335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37358,DS-44c31faf-6a91-494b-9fe5-69bb39690708,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-0d1e3e24-b98d-4471-81aa-bbe8d01dabb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-5baaf84a-b772-4b50-b5f9-c68fd53f445b,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-565a07d6-30fe-49d9-9f24-d141b87f8a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-212fea7b-1235-45ab-a6c9-01779e8ba84d,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-e6a4c7d3-0f95-4ba4-8b1d-d0a9181c21fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-f7dafa98-021a-40db-8566-d9f111e3352f,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-27e33dd7-c635-44fb-8899-010964e1d4a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1313507618-172.17.0.7-1595512107335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37358,DS-44c31faf-6a91-494b-9fe5-69bb39690708,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-0d1e3e24-b98d-4471-81aa-bbe8d01dabb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-5baaf84a-b772-4b50-b5f9-c68fd53f445b,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-565a07d6-30fe-49d9-9f24-d141b87f8a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-212fea7b-1235-45ab-a6c9-01779e8ba84d,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-e6a4c7d3-0f95-4ba4-8b1d-d0a9181c21fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-f7dafa98-021a-40db-8566-d9f111e3352f,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-27e33dd7-c635-44fb-8899-010964e1d4a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-769061862-172.17.0.7-1595512146146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37606,DS-941c92d6-a1f0-4ca1-9be9-6b8f3afb64a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-cb864fe1-d2e8-41ea-b210-2b6332259391,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-b9ab6f29-216e-4527-9438-d14755ede122,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-907e1a5f-a22a-4751-b88e-2bde5df1f557,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-503b5592-33aa-4777-8223-2df4baac6ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-f503eb47-0d2d-4dc0-8e83-7bb062cb1071,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-47e952ac-9316-4ee5-be89-47e59a714997,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-6350f908-f35e-497b-91d4-83da0d9d90ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-769061862-172.17.0.7-1595512146146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37606,DS-941c92d6-a1f0-4ca1-9be9-6b8f3afb64a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-cb864fe1-d2e8-41ea-b210-2b6332259391,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-b9ab6f29-216e-4527-9438-d14755ede122,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-907e1a5f-a22a-4751-b88e-2bde5df1f557,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-503b5592-33aa-4777-8223-2df4baac6ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-f503eb47-0d2d-4dc0-8e83-7bb062cb1071,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-47e952ac-9316-4ee5-be89-47e59a714997,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-6350f908-f35e-497b-91d4-83da0d9d90ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1073392671-172.17.0.7-1595512850839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40878,DS-512115f7-2fd8-411b-985f-7d2467c73e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-4b183289-489a-40f4-9cb5-fd8d9708a232,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-ea2879bc-baa5-41b6-ae43-6880176dc0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-5c450d45-354d-41ea-b6b4-5919763617e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-e875f1ca-a3cb-4210-a229-9604502455d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-6ac9b0c5-60ad-46e9-bb4a-8d81c99b5360,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-62fd85ea-91f6-4cef-84aa-50b49befb3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-b20668a9-dce2-4841-91ae-0de4f5ecdfef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1073392671-172.17.0.7-1595512850839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40878,DS-512115f7-2fd8-411b-985f-7d2467c73e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-4b183289-489a-40f4-9cb5-fd8d9708a232,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-ea2879bc-baa5-41b6-ae43-6880176dc0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-5c450d45-354d-41ea-b6b4-5919763617e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-e875f1ca-a3cb-4210-a229-9604502455d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-6ac9b0c5-60ad-46e9-bb4a-8d81c99b5360,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-62fd85ea-91f6-4cef-84aa-50b49befb3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-b20668a9-dce2-4841-91ae-0de4f5ecdfef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5340
