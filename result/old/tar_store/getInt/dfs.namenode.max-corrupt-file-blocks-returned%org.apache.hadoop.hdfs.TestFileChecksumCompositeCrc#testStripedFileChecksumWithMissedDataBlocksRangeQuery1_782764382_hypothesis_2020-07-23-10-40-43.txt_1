reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051160454-172.17.0.13-1595501964129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35268,DS-6d21296a-4f8b-4d97-a5f7-caf763c5f169,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-de443f97-0abe-42dc-94d3-221676a666a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-21bd4a40-39b6-49d4-8ad7-17be3aedf5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-82850abe-5e85-4fa0-9281-c8d9bf5cd562,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-038e6556-74d4-4ef6-8421-8e75da2f1b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-0e6b6292-9ed2-43d3-8a49-102fd1c95e37,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-e4d493ce-2d43-42e9-bd20-3bf8909c3480,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-7e14fe5d-8dc6-4a74-bb3d-a971e078726e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051160454-172.17.0.13-1595501964129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35268,DS-6d21296a-4f8b-4d97-a5f7-caf763c5f169,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-de443f97-0abe-42dc-94d3-221676a666a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-21bd4a40-39b6-49d4-8ad7-17be3aedf5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-82850abe-5e85-4fa0-9281-c8d9bf5cd562,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-038e6556-74d4-4ef6-8421-8e75da2f1b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-0e6b6292-9ed2-43d3-8a49-102fd1c95e37,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-e4d493ce-2d43-42e9-bd20-3bf8909c3480,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-7e14fe5d-8dc6-4a74-bb3d-a971e078726e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809899049-172.17.0.13-1595502003228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33951,DS-f4dda54a-4319-40b1-bf3e-08677b91856c,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-6d10fd27-ad04-4434-9ad5-463f69561f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-0a8893a7-17c2-456c-a73a-a2164a4ab4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-c467861d-2ba4-4654-8a74-0ad6cef304bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-1f4cc97a-f126-4c72-b32e-beb2d194016e,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-6f82af4b-36e5-473b-bcda-048ab99ab026,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-36201065-31a7-43eb-a8e3-9e32fde26f69,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-9166991f-1b9a-4c20-9133-5dd107f307d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809899049-172.17.0.13-1595502003228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33951,DS-f4dda54a-4319-40b1-bf3e-08677b91856c,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-6d10fd27-ad04-4434-9ad5-463f69561f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-0a8893a7-17c2-456c-a73a-a2164a4ab4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-c467861d-2ba4-4654-8a74-0ad6cef304bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-1f4cc97a-f126-4c72-b32e-beb2d194016e,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-6f82af4b-36e5-473b-bcda-048ab99ab026,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-36201065-31a7-43eb-a8e3-9e32fde26f69,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-9166991f-1b9a-4c20-9133-5dd107f307d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1873208545-172.17.0.13-1595502309344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43653,DS-ab9a3dbc-d149-407e-a7d5-3fd3470d50a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-1135e802-4723-4a92-b943-3b4aec718583,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-e0cb2e8f-d9a3-49fd-af3d-924e6aba1fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-fa28d455-7a74-4f75-a256-4f8f920e2c61,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-a328562c-9fac-4683-8c5b-d1163f840632,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-0c55ddae-3a7d-4ab6-92e6-19d15abb4adb,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-d49ef062-5fbb-4e6e-acd7-f5b1b863d51a,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-82a03c82-3335-4643-b3b5-0dbbfcd4fa44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1873208545-172.17.0.13-1595502309344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43653,DS-ab9a3dbc-d149-407e-a7d5-3fd3470d50a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-1135e802-4723-4a92-b943-3b4aec718583,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-e0cb2e8f-d9a3-49fd-af3d-924e6aba1fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-fa28d455-7a74-4f75-a256-4f8f920e2c61,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-a328562c-9fac-4683-8c5b-d1163f840632,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-0c55ddae-3a7d-4ab6-92e6-19d15abb4adb,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-d49ef062-5fbb-4e6e-acd7-f5b1b863d51a,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-82a03c82-3335-4643-b3b5-0dbbfcd4fa44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517378201-172.17.0.13-1595502411148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38373,DS-3f8977f3-20cd-4c4a-8b3f-eb23d3b9b3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-a322c721-92ed-4db8-bb59-4827bacd8e47,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-96004b85-2d64-4ec6-8ec4-66f53d282cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-8b5a9837-8e4c-4093-b241-d6169b8e6987,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-794ad4af-0b42-475f-9d02-2aabe96f32c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-b9f768f5-08ac-480e-be24-bb49cb4b20b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-5a87cd23-a2a6-4c41-b986-7c9937d46ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-8a9c061f-6b11-4beb-8ff2-787da3113383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517378201-172.17.0.13-1595502411148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38373,DS-3f8977f3-20cd-4c4a-8b3f-eb23d3b9b3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-a322c721-92ed-4db8-bb59-4827bacd8e47,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-96004b85-2d64-4ec6-8ec4-66f53d282cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-8b5a9837-8e4c-4093-b241-d6169b8e6987,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-794ad4af-0b42-475f-9d02-2aabe96f32c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-b9f768f5-08ac-480e-be24-bb49cb4b20b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-5a87cd23-a2a6-4c41-b986-7c9937d46ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-8a9c061f-6b11-4beb-8ff2-787da3113383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-314932612-172.17.0.13-1595502757583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39475,DS-34d60219-3338-4014-a9b0-64ecc8f07108,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-f0300fcc-53b1-4189-9bf1-b2dec0a2be0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-2d784ffc-06ee-4995-be0a-99016e7843fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-81987779-4fbd-4564-b369-bae67986b64b,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-4dc32e13-b43b-459e-814d-8cac8f3acf93,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-91a36adb-26e3-4d57-b4de-5498c6b88816,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-54134021-eb47-4219-854d-540a1a8448ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-74ae6b60-0b78-450e-a47e-4119b589915a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-314932612-172.17.0.13-1595502757583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39475,DS-34d60219-3338-4014-a9b0-64ecc8f07108,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-f0300fcc-53b1-4189-9bf1-b2dec0a2be0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-2d784ffc-06ee-4995-be0a-99016e7843fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-81987779-4fbd-4564-b369-bae67986b64b,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-4dc32e13-b43b-459e-814d-8cac8f3acf93,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-91a36adb-26e3-4d57-b4de-5498c6b88816,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-54134021-eb47-4219-854d-540a1a8448ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-74ae6b60-0b78-450e-a47e-4119b589915a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-314787328-172.17.0.13-1595503553932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44320,DS-41add9e6-aecf-49a4-91c7-09d429e996e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-185ec53f-03c9-45e0-9b3f-3e7470ffa767,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-969c1367-168f-4b9b-9db9-cada4eda8899,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-266ebd0c-0382-409f-a7dc-49db05d8d273,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-9a44df7c-6684-40b5-8814-af395955ac4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-48124f08-59ac-4eb0-8ab3-9ddb59394f44,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-ad60fd44-26a5-429a-a558-d38c7d1b5e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-d6a76b8a-aadd-49ac-9f03-63aa6e571ff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-314787328-172.17.0.13-1595503553932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44320,DS-41add9e6-aecf-49a4-91c7-09d429e996e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-185ec53f-03c9-45e0-9b3f-3e7470ffa767,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-969c1367-168f-4b9b-9db9-cada4eda8899,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-266ebd0c-0382-409f-a7dc-49db05d8d273,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-9a44df7c-6684-40b5-8814-af395955ac4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-48124f08-59ac-4eb0-8ab3-9ddb59394f44,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-ad60fd44-26a5-429a-a558-d38c7d1b5e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-d6a76b8a-aadd-49ac-9f03-63aa6e571ff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933032068-172.17.0.13-1595503669148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33423,DS-d9c547b1-e33c-4530-9e65-ec9eeb4e1775,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-90e41727-bced-44f1-8739-c98a9be746ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-6104f9aa-402e-4a38-acba-5295bfe50720,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-d09e11f6-cd88-4cde-bdfa-aed9bebdb37f,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-c76aeee8-ef0a-4481-bce0-d43aa451a778,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-c1524e96-5ec8-4b2c-aa32-f0a8869d1999,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-4e1d8d64-c1c3-4330-aa0f-664f65f06217,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-bcb1239d-4752-42bf-9ddf-d4cf1a8e7cb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933032068-172.17.0.13-1595503669148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33423,DS-d9c547b1-e33c-4530-9e65-ec9eeb4e1775,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-90e41727-bced-44f1-8739-c98a9be746ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-6104f9aa-402e-4a38-acba-5295bfe50720,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-d09e11f6-cd88-4cde-bdfa-aed9bebdb37f,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-c76aeee8-ef0a-4481-bce0-d43aa451a778,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-c1524e96-5ec8-4b2c-aa32-f0a8869d1999,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-4e1d8d64-c1c3-4330-aa0f-664f65f06217,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-bcb1239d-4752-42bf-9ddf-d4cf1a8e7cb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409994706-172.17.0.13-1595503825514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39299,DS-ae16430a-9655-485e-b981-3d988b5dd7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-a63e78c6-761e-44ea-bfb1-cfb440d5aa0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-5f4d4b62-b766-4b52-90bd-e94fc24253bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-e8092459-d3e4-44af-8a55-54ef202d6cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-8372518e-3f77-4340-b971-ff391de52322,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-1338e13b-b0dc-4ab0-9e44-2c73c1a5e775,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-42fe3775-394b-40d1-85cd-fed5192f6ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-b9dddc4c-80f3-492d-8534-6016e8f98247,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409994706-172.17.0.13-1595503825514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39299,DS-ae16430a-9655-485e-b981-3d988b5dd7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-a63e78c6-761e-44ea-bfb1-cfb440d5aa0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-5f4d4b62-b766-4b52-90bd-e94fc24253bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-e8092459-d3e4-44af-8a55-54ef202d6cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-8372518e-3f77-4340-b971-ff391de52322,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-1338e13b-b0dc-4ab0-9e44-2c73c1a5e775,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-42fe3775-394b-40d1-85cd-fed5192f6ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-b9dddc4c-80f3-492d-8534-6016e8f98247,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1043025017-172.17.0.13-1595504179395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35087,DS-0c94adc3-7fb0-46af-b476-0376a019e84e,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-009624b8-2a17-449e-9f08-2f958e1f6d78,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-d210c0bc-e328-4683-818d-3bdd187e2f58,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-639a4edb-619f-43be-8db3-186dde8b5ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-f7567582-8908-44e1-87cc-5b54cd0c65d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-5432f75d-3622-436a-9af8-c1a2a9c1ebf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-12190418-3eb4-44fe-b6b9-55442a4072fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-ab4f06f3-9fe9-4b35-8ebb-e7d842aee7c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1043025017-172.17.0.13-1595504179395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35087,DS-0c94adc3-7fb0-46af-b476-0376a019e84e,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-009624b8-2a17-449e-9f08-2f958e1f6d78,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-d210c0bc-e328-4683-818d-3bdd187e2f58,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-639a4edb-619f-43be-8db3-186dde8b5ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-f7567582-8908-44e1-87cc-5b54cd0c65d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-5432f75d-3622-436a-9af8-c1a2a9c1ebf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-12190418-3eb4-44fe-b6b9-55442a4072fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-ab4f06f3-9fe9-4b35-8ebb-e7d842aee7c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-572454804-172.17.0.13-1595504221958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41229,DS-ef606f2f-0b53-41e2-a31c-3584d5c7f50f,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-ba8c3475-9782-458b-a872-11fd11f79444,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-0e738195-14f2-4626-8f6b-5090754f36ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-972b07e0-31d7-4ec0-91fe-6e8e7d3d979e,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-e7f294e8-b809-428f-aff0-9e7b97d8d523,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-edf30b8b-54c3-4f8a-9dbd-1432c8cfb783,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-220775a0-3d4e-4f95-99bb-3ab15cc68397,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-788c1ccd-8714-4f93-a3a2-46531bdd90ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-572454804-172.17.0.13-1595504221958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41229,DS-ef606f2f-0b53-41e2-a31c-3584d5c7f50f,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-ba8c3475-9782-458b-a872-11fd11f79444,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-0e738195-14f2-4626-8f6b-5090754f36ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-972b07e0-31d7-4ec0-91fe-6e8e7d3d979e,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-e7f294e8-b809-428f-aff0-9e7b97d8d523,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-edf30b8b-54c3-4f8a-9dbd-1432c8cfb783,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-220775a0-3d4e-4f95-99bb-3ab15cc68397,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-788c1ccd-8714-4f93-a3a2-46531bdd90ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-68873332-172.17.0.13-1595504264432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43584,DS-74bfaf7a-9fee-4691-820c-d0d2cef38a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-8d95cffa-590b-4efe-b3e8-f439e1807907,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-9e2f4936-0474-45a4-97e9-5e6610f60655,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-bb303ea7-7074-47dd-9572-26fae7eb0c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-f00fb9c5-5594-4ba9-8160-1d55200b6cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-f6274d8f-4e2e-4790-8e2e-331c972b5b70,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-5fba4d87-1ab3-4613-8c70-e60485b6a099,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-e83d5b7b-b502-45b1-957c-a15227b1712e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-68873332-172.17.0.13-1595504264432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43584,DS-74bfaf7a-9fee-4691-820c-d0d2cef38a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-8d95cffa-590b-4efe-b3e8-f439e1807907,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-9e2f4936-0474-45a4-97e9-5e6610f60655,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-bb303ea7-7074-47dd-9572-26fae7eb0c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-f00fb9c5-5594-4ba9-8160-1d55200b6cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-f6274d8f-4e2e-4790-8e2e-331c972b5b70,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-5fba4d87-1ab3-4613-8c70-e60485b6a099,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-e83d5b7b-b502-45b1-957c-a15227b1712e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429947400-172.17.0.13-1595505214780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38201,DS-5d91f3f9-ba0f-4511-ad09-bb435a14593d,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-b287d6f4-4534-47ae-a736-95081f59515a,DISK], DatanodeInfoWithStorage[127.0.0.1:39958,DS-50673590-a05f-486c-9996-868907648596,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-5d788a48-3801-412a-8240-d56c6357c249,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-0d38c3f5-6421-47b9-9dac-c57bfd854be9,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-bf11fab9-a571-491e-8b5a-a5722a84229d,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-9bf786bb-5e63-4de9-a397-f0b4e96e7c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-6a000b4a-532d-4b67-8506-e6b41f52f1f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429947400-172.17.0.13-1595505214780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38201,DS-5d91f3f9-ba0f-4511-ad09-bb435a14593d,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-b287d6f4-4534-47ae-a736-95081f59515a,DISK], DatanodeInfoWithStorage[127.0.0.1:39958,DS-50673590-a05f-486c-9996-868907648596,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-5d788a48-3801-412a-8240-d56c6357c249,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-0d38c3f5-6421-47b9-9dac-c57bfd854be9,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-bf11fab9-a571-491e-8b5a-a5722a84229d,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-9bf786bb-5e63-4de9-a397-f0b4e96e7c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-6a000b4a-532d-4b67-8506-e6b41f52f1f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-260994609-172.17.0.13-1595505248024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44934,DS-b255fc95-5db8-4849-a004-d369494d846d,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-4764aaeb-4a39-4176-92c7-cec71bb36ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-41179a31-c80c-4d43-ad36-179491b36824,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-a0de82a2-3f24-463a-9af0-86d48d45de20,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-ef9c13cb-c24e-45d1-8e8b-52ca1f9333ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-8543ca5b-8238-44c2-adad-f308dade1d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-5225e62d-5ecf-4725-b5c7-0ea77fe48564,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-f3dde81d-bfc9-4285-8388-ac806443a7d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-260994609-172.17.0.13-1595505248024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44934,DS-b255fc95-5db8-4849-a004-d369494d846d,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-4764aaeb-4a39-4176-92c7-cec71bb36ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-41179a31-c80c-4d43-ad36-179491b36824,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-a0de82a2-3f24-463a-9af0-86d48d45de20,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-ef9c13cb-c24e-45d1-8e8b-52ca1f9333ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-8543ca5b-8238-44c2-adad-f308dade1d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-5225e62d-5ecf-4725-b5c7-0ea77fe48564,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-f3dde81d-bfc9-4285-8388-ac806443a7d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418627023-172.17.0.13-1595505280283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43888,DS-f5d99449-18ec-406e-b200-fe880257d9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-f0e9f3a4-a46d-4bd7-bdb0-2e7a5b6c9320,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-a62c0ddf-f4f8-47d7-b354-d600628eabf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-ddcdad2e-c7d9-489d-9a3e-cbe5642734c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-cbd77db2-25c1-4e5b-ba9a-7eb690c4c5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-15ec23be-b9bb-4c35-a44c-9db3cfde7961,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-64bed6d1-008a-4380-af28-83034c696878,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-7eecd557-750e-49f4-8966-fd236624c1a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418627023-172.17.0.13-1595505280283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43888,DS-f5d99449-18ec-406e-b200-fe880257d9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-f0e9f3a4-a46d-4bd7-bdb0-2e7a5b6c9320,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-a62c0ddf-f4f8-47d7-b354-d600628eabf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-ddcdad2e-c7d9-489d-9a3e-cbe5642734c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-cbd77db2-25c1-4e5b-ba9a-7eb690c4c5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-15ec23be-b9bb-4c35-a44c-9db3cfde7961,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-64bed6d1-008a-4380-af28-83034c696878,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-7eecd557-750e-49f4-8966-fd236624c1a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1135521909-172.17.0.13-1595505480017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38809,DS-ca01b9a7-2cf1-4533-b7ce-8cc2121546bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-ce78a7a7-8b4a-4725-bc12-bfc7a867276c,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-178899bd-4f92-4e04-a934-5de5ca0e64da,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-888e15e6-2979-4eac-8079-e4f1223470bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-3cbe8048-7e5e-4b2d-9acb-ef03b2f866da,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-c2831711-14d6-400b-b010-d3f045814491,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-9a8b6339-0386-4f3d-b781-de55f75d82d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-4e7cb3f1-4e43-4d2c-8729-d504a5c5224a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1135521909-172.17.0.13-1595505480017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38809,DS-ca01b9a7-2cf1-4533-b7ce-8cc2121546bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-ce78a7a7-8b4a-4725-bc12-bfc7a867276c,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-178899bd-4f92-4e04-a934-5de5ca0e64da,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-888e15e6-2979-4eac-8079-e4f1223470bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-3cbe8048-7e5e-4b2d-9acb-ef03b2f866da,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-c2831711-14d6-400b-b010-d3f045814491,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-9a8b6339-0386-4f3d-b781-de55f75d82d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-4e7cb3f1-4e43-4d2c-8729-d504a5c5224a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673176424-172.17.0.13-1595505994541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37649,DS-0fd65cb4-ff75-48fb-a940-9c28be1275b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-99ff83ff-57d1-4761-8480-20485563f562,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-8ee9b3ff-c3fd-45c2-978d-bd89616150bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-f79d0bb0-76a1-484a-ba94-3b05a6cf9ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-2a8e6334-b372-44a6-8e01-8046e3fd62cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-ad8a2c86-4378-486f-b830-9cd1831a5751,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-0cd8b093-ce1f-4588-b523-bd08fbf21dec,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-bda43ca2-9899-41b8-b681-50540987ffc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673176424-172.17.0.13-1595505994541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37649,DS-0fd65cb4-ff75-48fb-a940-9c28be1275b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-99ff83ff-57d1-4761-8480-20485563f562,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-8ee9b3ff-c3fd-45c2-978d-bd89616150bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-f79d0bb0-76a1-484a-ba94-3b05a6cf9ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-2a8e6334-b372-44a6-8e01-8046e3fd62cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-ad8a2c86-4378-486f-b830-9cd1831a5751,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-0cd8b093-ce1f-4588-b523-bd08fbf21dec,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-bda43ca2-9899-41b8-b681-50540987ffc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384278292-172.17.0.13-1595506146290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38490,DS-0417fe23-d8af-42a5-bc93-4bef7f12c462,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-2382358b-b94a-4183-9cf4-d2cb7a191d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-a7803ca6-954d-45af-a84a-68637bbc7f18,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-288dc0a3-2668-4717-80e2-716e922d1415,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-53860daf-1282-4bfb-b52e-2fef74cef2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-f59f1a69-7fe6-48fa-bfd4-bfc1d18b6160,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-eb4261d4-ad5e-425f-aa70-620975d8d1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-c3dd8679-a1ba-490e-8a1b-d9c0ed36f465,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384278292-172.17.0.13-1595506146290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38490,DS-0417fe23-d8af-42a5-bc93-4bef7f12c462,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-2382358b-b94a-4183-9cf4-d2cb7a191d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-a7803ca6-954d-45af-a84a-68637bbc7f18,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-288dc0a3-2668-4717-80e2-716e922d1415,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-53860daf-1282-4bfb-b52e-2fef74cef2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-f59f1a69-7fe6-48fa-bfd4-bfc1d18b6160,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-eb4261d4-ad5e-425f-aa70-620975d8d1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-c3dd8679-a1ba-490e-8a1b-d9c0ed36f465,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5533
