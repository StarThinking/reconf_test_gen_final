reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-978176516-172.17.0.5-1596021233530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42505,DS-fbb83140-55f7-4005-b2a7-83d7853d0690,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-b9769c78-5ee2-4005-bb3e-68a6a698a876,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-62c60e3e-1a26-4bbb-8f97-04240191fde4,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-cfeb2b97-d6b4-484d-9c04-fffea9a34d72,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-d2e9d845-0e3c-4613-b9ab-46a1030118d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-ab4b7695-ddff-4f8f-aaec-7aad193914d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-59173710-e313-4b66-b66f-9c024bba2e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-288f21b6-2385-4726-ab63-9cdc8bd62186,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-978176516-172.17.0.5-1596021233530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42505,DS-fbb83140-55f7-4005-b2a7-83d7853d0690,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-b9769c78-5ee2-4005-bb3e-68a6a698a876,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-62c60e3e-1a26-4bbb-8f97-04240191fde4,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-cfeb2b97-d6b4-484d-9c04-fffea9a34d72,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-d2e9d845-0e3c-4613-b9ab-46a1030118d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-ab4b7695-ddff-4f8f-aaec-7aad193914d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-59173710-e313-4b66-b66f-9c024bba2e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-288f21b6-2385-4726-ab63-9cdc8bd62186,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-831400038-172.17.0.5-1596021390422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39362,DS-91c2523a-bc51-462f-8a6f-978956fd589e,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-e0636403-6045-4e12-8d7b-6fb72a820054,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-d805ec32-bfaa-4648-8cb1-bade764e80c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-65f94085-2dd4-46ab-9611-5632768ba213,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-4e349840-ff73-4939-92a4-f95ce4af6d43,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-745732d6-c4f3-4caa-bf77-8cf0cbff5cad,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-553974f7-fc15-49af-8584-5fcff768039a,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-3f83bcc3-b1a2-479f-9b92-6a07ef445a38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-831400038-172.17.0.5-1596021390422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39362,DS-91c2523a-bc51-462f-8a6f-978956fd589e,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-e0636403-6045-4e12-8d7b-6fb72a820054,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-d805ec32-bfaa-4648-8cb1-bade764e80c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-65f94085-2dd4-46ab-9611-5632768ba213,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-4e349840-ff73-4939-92a4-f95ce4af6d43,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-745732d6-c4f3-4caa-bf77-8cf0cbff5cad,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-553974f7-fc15-49af-8584-5fcff768039a,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-3f83bcc3-b1a2-479f-9b92-6a07ef445a38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835428947-172.17.0.5-1596021706079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38696,DS-2fbdac19-20b0-4f19-80b6-03a471bbf0da,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-52a4d3c7-b40b-4187-9283-82aa961167b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-c9890e2b-fe05-44f1-929a-3b06f19bd307,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-a3b997e9-6ebc-4057-80a5-0fabdb6f30fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-c0f0a208-5d49-4533-b3fe-8bfb5a16c635,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-fbac187e-354a-4dae-9a09-720c61da3c96,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-d41cf066-0501-4bf4-be04-12853c4eb667,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-9e7a5057-32b9-4e5a-a8fa-2b7ee393890a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835428947-172.17.0.5-1596021706079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38696,DS-2fbdac19-20b0-4f19-80b6-03a471bbf0da,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-52a4d3c7-b40b-4187-9283-82aa961167b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-c9890e2b-fe05-44f1-929a-3b06f19bd307,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-a3b997e9-6ebc-4057-80a5-0fabdb6f30fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-c0f0a208-5d49-4533-b3fe-8bfb5a16c635,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-fbac187e-354a-4dae-9a09-720c61da3c96,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-d41cf066-0501-4bf4-be04-12853c4eb667,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-9e7a5057-32b9-4e5a-a8fa-2b7ee393890a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1435919848-172.17.0.5-1596021884415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42781,DS-f7399745-ee37-4d8a-acb5-293babf6a662,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-63b89c8c-064f-451e-9d31-bce8168d7e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-bcc02637-17bd-4896-925a-8029216eedab,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-1df3204c-1791-4439-bb55-b10c4898000b,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-fe2d477e-cd77-4dc8-84f4-94fb17d21ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-920ee902-862a-4af8-b425-3cc2e6c8cca6,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-e4f54c1a-8b54-413a-b12a-157de0af192f,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-95d5d119-14f2-45ed-a1d4-a40d4528ddf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1435919848-172.17.0.5-1596021884415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42781,DS-f7399745-ee37-4d8a-acb5-293babf6a662,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-63b89c8c-064f-451e-9d31-bce8168d7e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-bcc02637-17bd-4896-925a-8029216eedab,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-1df3204c-1791-4439-bb55-b10c4898000b,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-fe2d477e-cd77-4dc8-84f4-94fb17d21ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-920ee902-862a-4af8-b425-3cc2e6c8cca6,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-e4f54c1a-8b54-413a-b12a-157de0af192f,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-95d5d119-14f2-45ed-a1d4-a40d4528ddf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1631043226-172.17.0.5-1596021927438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36387,DS-7bed106c-2118-49f0-a675-2292926be29b,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-f8c62e1d-6603-48e1-ae58-bd72badc6843,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-75066076-abc4-43ad-9853-4574a55465e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-8c424bd9-ae0b-4309-add3-3e2c15c749e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-c8044db3-f8e8-4545-8e45-cbe84eec0b19,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-e145ac8e-383b-4a66-a8ef-bc84a4186ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-7d35425a-3de1-4f07-b3dd-7e87a7de4502,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-b8279b00-873f-4986-bb02-a9bb9322b593,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1631043226-172.17.0.5-1596021927438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36387,DS-7bed106c-2118-49f0-a675-2292926be29b,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-f8c62e1d-6603-48e1-ae58-bd72badc6843,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-75066076-abc4-43ad-9853-4574a55465e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-8c424bd9-ae0b-4309-add3-3e2c15c749e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-c8044db3-f8e8-4545-8e45-cbe84eec0b19,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-e145ac8e-383b-4a66-a8ef-bc84a4186ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-7d35425a-3de1-4f07-b3dd-7e87a7de4502,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-b8279b00-873f-4986-bb02-a9bb9322b593,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-851027764-172.17.0.5-1596022181688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45382,DS-bca4c7f8-faf5-45ed-af62-acacb08393df,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-d3a1c0e8-da9c-40be-84a2-b2c7f9f979b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-4a2c755c-a6ec-4d74-a2b1-300f8f6359bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-e74552a9-0c69-4611-b8ac-2b576ac12bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-ed71b704-0d5a-4fce-a2cf-baeaf67cf922,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-2c0ee7f9-7a2d-4da9-b8d4-32fd3dd1c6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-c9e36e6a-6beb-4147-9636-4caff8835be3,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-9be95d2e-75d2-4210-a65c-50258554152c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-851027764-172.17.0.5-1596022181688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45382,DS-bca4c7f8-faf5-45ed-af62-acacb08393df,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-d3a1c0e8-da9c-40be-84a2-b2c7f9f979b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-4a2c755c-a6ec-4d74-a2b1-300f8f6359bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-e74552a9-0c69-4611-b8ac-2b576ac12bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-ed71b704-0d5a-4fce-a2cf-baeaf67cf922,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-2c0ee7f9-7a2d-4da9-b8d4-32fd3dd1c6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-c9e36e6a-6beb-4147-9636-4caff8835be3,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-9be95d2e-75d2-4210-a65c-50258554152c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1611194346-172.17.0.5-1596022738867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46173,DS-7c851e8c-8d89-48d4-9226-6f4fd4953e39,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-a7a99f11-b0eb-456e-aa4f-ae9b7615eea8,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-2745ba61-3f7a-4681-9630-cd83c1ec6e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-2deec64e-d988-4542-a1bb-7d7c09b4d3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-a2bded71-5378-4d6a-a7d3-4ed9869f19fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-2dfc4614-cae7-4d23-aa59-60c014ed395e,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-0c2577d5-a8c1-4126-b76d-0ece83836a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-f9e5ce41-eb28-4479-b7aa-8e0ada6a6632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1611194346-172.17.0.5-1596022738867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46173,DS-7c851e8c-8d89-48d4-9226-6f4fd4953e39,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-a7a99f11-b0eb-456e-aa4f-ae9b7615eea8,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-2745ba61-3f7a-4681-9630-cd83c1ec6e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-2deec64e-d988-4542-a1bb-7d7c09b4d3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-a2bded71-5378-4d6a-a7d3-4ed9869f19fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-2dfc4614-cae7-4d23-aa59-60c014ed395e,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-0c2577d5-a8c1-4126-b76d-0ece83836a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-f9e5ce41-eb28-4479-b7aa-8e0ada6a6632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-95446870-172.17.0.5-1596023132856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37887,DS-c9202f44-6cb5-4ccf-a994-7d971a11ba31,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-4e02aa3b-62b9-46d5-a297-d8106137c7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-fabce49f-8b7b-40f7-8c13-a030f696a173,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-3e6a9db6-a5b5-4067-b8d3-3fe7419d7904,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-4bcc5ff9-e18a-4c06-a06f-ddea3014c2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-4f04df19-cbfe-47e8-bc93-ed1270f61bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-f496fc62-84d3-4f1c-ae5e-583d8829e6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-7a5c73e8-b473-46fb-ae13-558fe7238e0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-95446870-172.17.0.5-1596023132856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37887,DS-c9202f44-6cb5-4ccf-a994-7d971a11ba31,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-4e02aa3b-62b9-46d5-a297-d8106137c7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-fabce49f-8b7b-40f7-8c13-a030f696a173,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-3e6a9db6-a5b5-4067-b8d3-3fe7419d7904,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-4bcc5ff9-e18a-4c06-a06f-ddea3014c2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-4f04df19-cbfe-47e8-bc93-ed1270f61bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-f496fc62-84d3-4f1c-ae5e-583d8829e6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-7a5c73e8-b473-46fb-ae13-558fe7238e0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1970998513-172.17.0.5-1596023171929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35678,DS-91811f8e-706f-47ff-83c0-2b5f1ec3fbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-bdae1873-74d2-4297-beaf-7d264c77c280,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-4c82a155-2393-4150-8b5c-86cdc5e8a6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-5bd2c7e5-c767-4ffb-902d-3b1237d19abe,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-68f1f27f-28b4-4429-aff4-373e662a4e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-ca4da1c3-a673-433c-a82f-5fbc8af57a75,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-ae680366-8f52-4d6f-9a63-e20bf362bb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-98da5efc-6d89-41ff-99a2-5265a777d9f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1970998513-172.17.0.5-1596023171929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35678,DS-91811f8e-706f-47ff-83c0-2b5f1ec3fbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-bdae1873-74d2-4297-beaf-7d264c77c280,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-4c82a155-2393-4150-8b5c-86cdc5e8a6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-5bd2c7e5-c767-4ffb-902d-3b1237d19abe,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-68f1f27f-28b4-4429-aff4-373e662a4e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-ca4da1c3-a673-433c-a82f-5fbc8af57a75,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-ae680366-8f52-4d6f-9a63-e20bf362bb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-98da5efc-6d89-41ff-99a2-5265a777d9f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1660103638-172.17.0.5-1596023272446:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42795,DS-21a1c817-0c7a-4114-8761-bc18af077e53,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-083d9597-b416-4a38-bb9f-3b5a825ef6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-04e72866-d982-4d8a-96de-a771438a1f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-8d4be2dd-d707-488f-aa39-555cb38568ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-90fdacdb-8a98-4b8a-9e46-3bbaabff8881,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-a156f0ee-cdd3-4168-bf90-726193003e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-2ed059a5-833b-4e44-95e6-a04c8623ce69,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-6eb67b98-9d20-44cc-8182-66aa13edd7ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1660103638-172.17.0.5-1596023272446:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42795,DS-21a1c817-0c7a-4114-8761-bc18af077e53,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-083d9597-b416-4a38-bb9f-3b5a825ef6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-04e72866-d982-4d8a-96de-a771438a1f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-8d4be2dd-d707-488f-aa39-555cb38568ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-90fdacdb-8a98-4b8a-9e46-3bbaabff8881,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-a156f0ee-cdd3-4168-bf90-726193003e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-2ed059a5-833b-4e44-95e6-a04c8623ce69,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-6eb67b98-9d20-44cc-8182-66aa13edd7ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-96239345-172.17.0.5-1596023699931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35922,DS-148da8d3-481a-498d-9662-968197a9e0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-802eabb6-d3a2-45b2-8e13-4b38493357dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-1b795bc8-dd6b-4ff0-8f37-5d1448d28f80,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-10b7a7a2-1b3e-49b1-959d-99c063684709,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-f7792bd1-f791-4cb3-afc1-b4dc3593f367,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-3e60df84-0eab-48d6-a5f6-c21ef2cffc77,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-d47e09a7-dce3-4f74-8a65-920c88364d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-7e697333-423f-4a34-ae9f-2bfd1edc23d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-96239345-172.17.0.5-1596023699931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35922,DS-148da8d3-481a-498d-9662-968197a9e0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-802eabb6-d3a2-45b2-8e13-4b38493357dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-1b795bc8-dd6b-4ff0-8f37-5d1448d28f80,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-10b7a7a2-1b3e-49b1-959d-99c063684709,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-f7792bd1-f791-4cb3-afc1-b4dc3593f367,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-3e60df84-0eab-48d6-a5f6-c21ef2cffc77,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-d47e09a7-dce3-4f74-8a65-920c88364d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-7e697333-423f-4a34-ae9f-2bfd1edc23d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-76198870-172.17.0.5-1596024020618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45948,DS-73d93783-e814-40fb-b9a2-445c676cfe8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-13c3edb6-6f4f-4470-84c3-2390758ad629,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-40685e4a-ada2-48c4-b686-d056f205fb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-e224fff7-ddb0-409c-9853-bbd6b65cc142,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-ba3823ee-287c-4c9a-925a-a1bb444ced40,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-f467ef70-84e4-4185-a691-2e6da54baf30,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-03103819-8d01-462d-a02c-6ee11224df33,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-88cffc72-d4e3-43f8-88f2-01fd95dde6dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-76198870-172.17.0.5-1596024020618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45948,DS-73d93783-e814-40fb-b9a2-445c676cfe8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-13c3edb6-6f4f-4470-84c3-2390758ad629,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-40685e4a-ada2-48c4-b686-d056f205fb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-e224fff7-ddb0-409c-9853-bbd6b65cc142,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-ba3823ee-287c-4c9a-925a-a1bb444ced40,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-f467ef70-84e4-4185-a691-2e6da54baf30,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-03103819-8d01-462d-a02c-6ee11224df33,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-88cffc72-d4e3-43f8-88f2-01fd95dde6dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-567725537-172.17.0.5-1596024482426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42756,DS-bdf05b3a-e414-48d0-8dc6-0d557f26135a,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-f4e0eb17-ce2a-4b70-aedf-62f78bef0c25,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-a192b988-8617-4367-84a7-e338c79b299f,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-91601ea3-6fb7-4539-a528-8b5b01db576c,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-f5ab7647-734c-4cc3-922b-5d96e9a134f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-c808a628-45c0-4d1d-ae71-15fc0e57c971,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-d07063c0-706a-45d5-940b-5b62db12ddce,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-01fb9025-8569-4234-bee9-09a086806b5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-567725537-172.17.0.5-1596024482426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42756,DS-bdf05b3a-e414-48d0-8dc6-0d557f26135a,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-f4e0eb17-ce2a-4b70-aedf-62f78bef0c25,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-a192b988-8617-4367-84a7-e338c79b299f,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-91601ea3-6fb7-4539-a528-8b5b01db576c,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-f5ab7647-734c-4cc3-922b-5d96e9a134f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-c808a628-45c0-4d1d-ae71-15fc0e57c971,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-d07063c0-706a-45d5-940b-5b62db12ddce,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-01fb9025-8569-4234-bee9-09a086806b5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2046448733-172.17.0.5-1596024620706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33415,DS-ce57a4d5-fa0b-468c-889c-abdfd896ce06,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-d04c116b-ca1b-42e2-88ee-4af0f51d423b,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-15183d79-6a23-447b-a34a-a43bb901f90d,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-76ca779e-dd5a-4d85-9949-9432f74d01d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-a37dda07-9c4b-4b8d-b65d-e14eb89e4288,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-4eac4299-3be5-4fbe-ba89-7cfc6bc51eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-c1c95be3-6906-46ed-a813-50c4ba064ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-f0a6666b-caae-4b11-99d6-3592886fac30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2046448733-172.17.0.5-1596024620706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33415,DS-ce57a4d5-fa0b-468c-889c-abdfd896ce06,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-d04c116b-ca1b-42e2-88ee-4af0f51d423b,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-15183d79-6a23-447b-a34a-a43bb901f90d,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-76ca779e-dd5a-4d85-9949-9432f74d01d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-a37dda07-9c4b-4b8d-b65d-e14eb89e4288,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-4eac4299-3be5-4fbe-ba89-7cfc6bc51eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-c1c95be3-6906-46ed-a813-50c4ba064ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-f0a6666b-caae-4b11-99d6-3592886fac30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1019422368-172.17.0.5-1596024656280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42085,DS-2657a372-a834-41b5-9159-3b91d579dbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-a6eef9ec-ba75-43cd-a46e-b70bf552f571,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-1b2cfffc-9add-4ff6-9745-365080efa2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-bddd8408-ff3d-4ef7-9673-e0ac1f2af18a,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-56aea5b9-ca85-4c19-b4f9-c0a5dd5a4644,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-c4d1f0bf-2dae-421e-b80a-78ada908113b,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-aa46d9f5-58a8-4458-bdc0-4cfb40cc8509,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-0ce8c8d8-a5b5-4563-a25f-2bff5f95cdff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1019422368-172.17.0.5-1596024656280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42085,DS-2657a372-a834-41b5-9159-3b91d579dbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-a6eef9ec-ba75-43cd-a46e-b70bf552f571,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-1b2cfffc-9add-4ff6-9745-365080efa2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-bddd8408-ff3d-4ef7-9673-e0ac1f2af18a,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-56aea5b9-ca85-4c19-b4f9-c0a5dd5a4644,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-c4d1f0bf-2dae-421e-b80a-78ada908113b,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-aa46d9f5-58a8-4458-bdc0-4cfb40cc8509,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-0ce8c8d8-a5b5-4563-a25f-2bff5f95cdff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1665617817-172.17.0.5-1596025328589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36190,DS-58f22b49-589f-496c-801f-89c20c3ec687,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-616fc074-813a-424c-b980-e09bd44aeded,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-8fdd176d-2214-4400-80cb-0f9af4f40d94,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-0095b96c-d6cf-45bc-b592-d17145754659,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-4e5847ea-8c07-46a1-8cec-4f336aa3c11b,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-7ef06902-7762-4a25-a6fb-15cd44b98aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-1a19997a-0808-4919-9f5b-41023b31e673,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-e1a630f4-a54c-4109-b05e-ef371876a8ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1665617817-172.17.0.5-1596025328589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36190,DS-58f22b49-589f-496c-801f-89c20c3ec687,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-616fc074-813a-424c-b980-e09bd44aeded,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-8fdd176d-2214-4400-80cb-0f9af4f40d94,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-0095b96c-d6cf-45bc-b592-d17145754659,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-4e5847ea-8c07-46a1-8cec-4f336aa3c11b,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-7ef06902-7762-4a25-a6fb-15cd44b98aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-1a19997a-0808-4919-9f5b-41023b31e673,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-e1a630f4-a54c-4109-b05e-ef371876a8ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1373107130-172.17.0.5-1596025605762:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37407,DS-a6a5b0be-b534-4f61-a01c-b64b10f48f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-62cd837a-b4c6-4a2d-8632-ab424b0dec67,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-90201d39-1727-4a6c-9c3c-1d432e466bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-4980cb00-31b8-4832-9742-6e695b939ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-7a2bb49d-4060-4ce3-9676-e0f04c7354c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-73f12562-be88-4b0a-91bb-670d9f108cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-f250a3ae-c448-44e6-8898-54a1d5837d85,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-8bbe0403-2e0d-4dd7-bbff-cabf7af46d7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1373107130-172.17.0.5-1596025605762:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37407,DS-a6a5b0be-b534-4f61-a01c-b64b10f48f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-62cd837a-b4c6-4a2d-8632-ab424b0dec67,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-90201d39-1727-4a6c-9c3c-1d432e466bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-4980cb00-31b8-4832-9742-6e695b939ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-7a2bb49d-4060-4ce3-9676-e0f04c7354c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-73f12562-be88-4b0a-91bb-670d9f108cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-f250a3ae-c448-44e6-8898-54a1d5837d85,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-8bbe0403-2e0d-4dd7-bbff-cabf7af46d7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-741875571-172.17.0.5-1596025705508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33498,DS-e9256ad4-e625-4cbc-9acb-d82b65a936e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-cc97821d-5f57-4e42-a09b-42629204da3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-d2822248-2952-4e1a-a609-f16ac2147a67,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-c337ecb8-e08c-49f4-9432-a0d98b481c56,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-f0b571ac-45aa-436b-9393-9521f2e34d69,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-00282b78-2b13-475e-baae-5357639d76b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-2bcdfa23-7788-4e4b-b5d2-321dd88abf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-4961cb51-49e5-4787-a597-7ebf3d541794,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-741875571-172.17.0.5-1596025705508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33498,DS-e9256ad4-e625-4cbc-9acb-d82b65a936e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-cc97821d-5f57-4e42-a09b-42629204da3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-d2822248-2952-4e1a-a609-f16ac2147a67,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-c337ecb8-e08c-49f4-9432-a0d98b481c56,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-f0b571ac-45aa-436b-9393-9521f2e34d69,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-00282b78-2b13-475e-baae-5357639d76b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-2bcdfa23-7788-4e4b-b5d2-321dd88abf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-4961cb51-49e5-4787-a597-7ebf3d541794,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-138563710-172.17.0.5-1596026027510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34959,DS-9699aa58-2e9a-4cf4-b4d2-195b5fd639e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-5d3079b6-1498-4088-8e59-ecc9f027b1af,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-37de85f0-ca83-4c3b-91d2-2f2e3453a18e,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-b5c4d1a5-068c-4a4b-8cb6-5922d02b7be4,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-dff44544-4e9e-4831-bf00-ee5787034078,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-9f7e169e-b599-424a-a0e5-b7ef766c0459,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-92ae95bb-fc2b-4a93-8831-907d59454629,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-904d4c43-a9b2-4bc8-8560-5602cf6a4cdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-138563710-172.17.0.5-1596026027510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34959,DS-9699aa58-2e9a-4cf4-b4d2-195b5fd639e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-5d3079b6-1498-4088-8e59-ecc9f027b1af,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-37de85f0-ca83-4c3b-91d2-2f2e3453a18e,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-b5c4d1a5-068c-4a4b-8cb6-5922d02b7be4,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-dff44544-4e9e-4831-bf00-ee5787034078,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-9f7e169e-b599-424a-a0e5-b7ef766c0459,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-92ae95bb-fc2b-4a93-8831-907d59454629,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-904d4c43-a9b2-4bc8-8560-5602cf6a4cdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1612327281-172.17.0.5-1596026059639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46086,DS-1128a0e5-c0ff-41a1-9548-f5831acac194,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-10d40664-34db-408a-88b5-f9a4823e0e15,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-34ecb448-672d-441c-be6a-3143fe49577f,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-fa47fd97-782f-441c-a917-bf3c25b81827,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-fa230abc-6083-4077-aacd-a52715774201,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-b22e087d-e239-4d6f-ba14-ef30c35f50ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-81ec1821-8ca8-4a63-af1d-59ead0b9da0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-9d1147a7-08ab-47fa-8978-46c6a1d8c52a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1612327281-172.17.0.5-1596026059639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46086,DS-1128a0e5-c0ff-41a1-9548-f5831acac194,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-10d40664-34db-408a-88b5-f9a4823e0e15,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-34ecb448-672d-441c-be6a-3143fe49577f,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-fa47fd97-782f-441c-a917-bf3c25b81827,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-fa230abc-6083-4077-aacd-a52715774201,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-b22e087d-e239-4d6f-ba14-ef30c35f50ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-81ec1821-8ca8-4a63-af1d-59ead0b9da0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-9d1147a7-08ab-47fa-8978-46c6a1d8c52a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680455291-172.17.0.5-1596026187527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44251,DS-7c7fe4ca-f50e-4009-883c-4d6085b5b6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-a8501a9d-881e-4ee0-90aa-fdf16e933c29,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-2f4a2e5e-90d7-4f80-8908-1a91d024b421,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-dbca20db-b862-4a18-a496-56e896859bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-6599089b-a531-44df-a7ec-53d0b1643fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-150891f8-7006-4a48-af79-ec9fcdd4a0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-a9688aca-3d2b-43cd-b8fe-d01502f86c08,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-05964695-4978-4391-8716-2e8c2c4424f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680455291-172.17.0.5-1596026187527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44251,DS-7c7fe4ca-f50e-4009-883c-4d6085b5b6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-a8501a9d-881e-4ee0-90aa-fdf16e933c29,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-2f4a2e5e-90d7-4f80-8908-1a91d024b421,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-dbca20db-b862-4a18-a496-56e896859bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-6599089b-a531-44df-a7ec-53d0b1643fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-150891f8-7006-4a48-af79-ec9fcdd4a0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-a9688aca-3d2b-43cd-b8fe-d01502f86c08,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-05964695-4978-4391-8716-2e8c2c4424f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5222
