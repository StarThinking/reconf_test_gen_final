reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137343633-172.17.0.4-1595583542849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42290,DS-a8c7e77d-c098-4d75-8c48-609c35b6ae01,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-82915238-1b36-43d6-be79-a73de01153c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-8b337bc5-e289-4234-bb73-0653b311de6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-e96cf981-bd41-4b98-8570-45e7303fcfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-06d81097-543a-454d-8f4a-85428d3025a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-b2bafb8d-1ec8-4885-a725-3037712fff94,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-ac1beeb3-bfe0-43b7-9979-b29a2cd0f3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-fcb7ad8f-9100-4f10-b057-7e198d4c5abf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137343633-172.17.0.4-1595583542849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42290,DS-a8c7e77d-c098-4d75-8c48-609c35b6ae01,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-82915238-1b36-43d6-be79-a73de01153c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-8b337bc5-e289-4234-bb73-0653b311de6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-e96cf981-bd41-4b98-8570-45e7303fcfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-06d81097-543a-454d-8f4a-85428d3025a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-b2bafb8d-1ec8-4885-a725-3037712fff94,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-ac1beeb3-bfe0-43b7-9979-b29a2cd0f3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-fcb7ad8f-9100-4f10-b057-7e198d4c5abf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630883269-172.17.0.4-1595583653633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35606,DS-0223c030-da66-464b-aaa7-884612a337d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-fc13ea57-13a1-4832-97e5-a3640be7913c,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-952718d2-cee9-4514-939b-381d43d848b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-6238b103-4b00-4e61-bcf5-36e31f35ac39,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-c44ae3ae-727b-472e-a4a3-18cea19cd5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-588dd3de-2340-4f0f-97d4-00b40bf85ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-f6c7d56e-e6c1-46bd-b626-3d85bcdb624f,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-98f36ae9-afb7-4d71-8565-25fe3036ebcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630883269-172.17.0.4-1595583653633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35606,DS-0223c030-da66-464b-aaa7-884612a337d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-fc13ea57-13a1-4832-97e5-a3640be7913c,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-952718d2-cee9-4514-939b-381d43d848b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-6238b103-4b00-4e61-bcf5-36e31f35ac39,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-c44ae3ae-727b-472e-a4a3-18cea19cd5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-588dd3de-2340-4f0f-97d4-00b40bf85ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-f6c7d56e-e6c1-46bd-b626-3d85bcdb624f,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-98f36ae9-afb7-4d71-8565-25fe3036ebcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-304768589-172.17.0.4-1595583720000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44148,DS-ec4d9074-a527-442a-ba8a-0add396631e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-2bc83da0-c085-4041-94e9-5e1202e1523c,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-91210ead-9ac6-4562-8de0-08c99f600130,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-3c234599-ea48-4c89-8295-c9abc54928c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-1ee04d64-88c9-4342-9ae8-0b10c7c25ace,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-7e6e8e14-3bab-47e3-bdfc-2d6eaaa3a74d,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-2fc19237-4d6f-4b8b-a9c5-1d45210c97c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-0efdccb1-1108-4973-bdd1-9d8e5cc16bcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-304768589-172.17.0.4-1595583720000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44148,DS-ec4d9074-a527-442a-ba8a-0add396631e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-2bc83da0-c085-4041-94e9-5e1202e1523c,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-91210ead-9ac6-4562-8de0-08c99f600130,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-3c234599-ea48-4c89-8295-c9abc54928c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-1ee04d64-88c9-4342-9ae8-0b10c7c25ace,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-7e6e8e14-3bab-47e3-bdfc-2d6eaaa3a74d,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-2fc19237-4d6f-4b8b-a9c5-1d45210c97c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-0efdccb1-1108-4973-bdd1-9d8e5cc16bcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-16794863-172.17.0.4-1595583987378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37944,DS-1e67eea1-f302-4e69-a99b-26ad27314206,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-44eef2ec-f2e0-4811-ae03-78ef6abd96d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-c7e06f03-afde-4f30-a8f8-bf11a2646661,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-929e8ed1-a52d-4d60-b985-6889a42e85cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-109161b5-9a32-4d2f-a239-5eb880c5214c,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-dd8851fa-11d6-41cd-a2e2-281e30a871f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-26246726-c996-4395-b9c8-c42c9a913d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-c3a73c39-0aeb-42d8-b24c-da6dd4c302c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-16794863-172.17.0.4-1595583987378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37944,DS-1e67eea1-f302-4e69-a99b-26ad27314206,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-44eef2ec-f2e0-4811-ae03-78ef6abd96d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-c7e06f03-afde-4f30-a8f8-bf11a2646661,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-929e8ed1-a52d-4d60-b985-6889a42e85cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-109161b5-9a32-4d2f-a239-5eb880c5214c,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-dd8851fa-11d6-41cd-a2e2-281e30a871f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-26246726-c996-4395-b9c8-c42c9a913d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-c3a73c39-0aeb-42d8-b24c-da6dd4c302c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486291606-172.17.0.4-1595584417014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40749,DS-911cf09b-1507-4aab-b6fb-62e646637433,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-adcaca27-8ef7-4882-8e5f-f88bebc3b301,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-4fb100ae-eb74-468a-b85b-3c1ba72a6e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-56b52e63-0533-46f7-8931-09492ed29fae,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-de1521d8-e165-415a-8abb-f8cc194f0095,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-b4cc0a07-9f0e-47c9-bd76-95efe2f3256d,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-1cc2a1d3-ea91-4184-b20d-ab3f63a09d17,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-eb3a1c4c-9077-4f6d-a559-b2780b403acb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486291606-172.17.0.4-1595584417014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40749,DS-911cf09b-1507-4aab-b6fb-62e646637433,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-adcaca27-8ef7-4882-8e5f-f88bebc3b301,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-4fb100ae-eb74-468a-b85b-3c1ba72a6e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-56b52e63-0533-46f7-8931-09492ed29fae,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-de1521d8-e165-415a-8abb-f8cc194f0095,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-b4cc0a07-9f0e-47c9-bd76-95efe2f3256d,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-1cc2a1d3-ea91-4184-b20d-ab3f63a09d17,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-eb3a1c4c-9077-4f6d-a559-b2780b403acb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245038506-172.17.0.4-1595585481564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41633,DS-059a216e-e304-4a71-a400-4f4fd2df0f71,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-c3b2f1a0-803d-4506-b357-93da362be053,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-2bd665ac-99d8-43c7-9ce8-9c5ff53b7937,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-87a30da9-4585-4871-9e2c-e97fe3c58301,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-e5efdb37-cf62-43a7-8a13-62911c440457,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-9b682648-f7c4-49cb-b2e9-21c68dd47895,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-91443f56-3ab2-4e3e-836b-57e81541ea2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-a4eb542a-bf92-47b9-ac1c-40b8e6104d23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245038506-172.17.0.4-1595585481564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41633,DS-059a216e-e304-4a71-a400-4f4fd2df0f71,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-c3b2f1a0-803d-4506-b357-93da362be053,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-2bd665ac-99d8-43c7-9ce8-9c5ff53b7937,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-87a30da9-4585-4871-9e2c-e97fe3c58301,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-e5efdb37-cf62-43a7-8a13-62911c440457,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-9b682648-f7c4-49cb-b2e9-21c68dd47895,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-91443f56-3ab2-4e3e-836b-57e81541ea2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-a4eb542a-bf92-47b9-ac1c-40b8e6104d23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440716829-172.17.0.4-1595585517097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40015,DS-3656476e-ae28-4474-b4ad-e47ab0aa0e93,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-275e7e9b-94e1-401b-b174-f2be6bd5c3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-0f0044a7-061e-4c25-9779-a221ee193b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-d41ad49e-21e2-4afe-a7ea-853effcb8128,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-f02a838a-2a09-4c65-b21e-db9589467acf,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-165f77c1-3daa-45ac-ae39-b44a930d5462,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-1dc48285-4b54-41f4-bcb3-ccff6e8d942d,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-5e8e9bb4-6f09-4e44-a53d-b8568dda99de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440716829-172.17.0.4-1595585517097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40015,DS-3656476e-ae28-4474-b4ad-e47ab0aa0e93,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-275e7e9b-94e1-401b-b174-f2be6bd5c3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-0f0044a7-061e-4c25-9779-a221ee193b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-d41ad49e-21e2-4afe-a7ea-853effcb8128,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-f02a838a-2a09-4c65-b21e-db9589467acf,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-165f77c1-3daa-45ac-ae39-b44a930d5462,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-1dc48285-4b54-41f4-bcb3-ccff6e8d942d,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-5e8e9bb4-6f09-4e44-a53d-b8568dda99de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-914631489-172.17.0.4-1595585629857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38445,DS-e1f73308-9ade-433c-b0a6-1abe4dfbdde2,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-005a9d51-84dc-41e9-b030-b02bf0cac976,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-e9ee8f4a-c8c8-4bf5-9a79-88d1f89bef43,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-1a0678d0-9373-40a0-8b3e-58e29b58c90a,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-c0e38516-b75d-45c4-b043-a558c6e8c00c,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-0c76cbe9-b769-411b-8906-691f75b009e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-68ab335c-0b1b-4bf8-b906-fc0b6660e6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-a76745ae-6d11-426e-8ea6-a0adc8214c12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-914631489-172.17.0.4-1595585629857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38445,DS-e1f73308-9ade-433c-b0a6-1abe4dfbdde2,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-005a9d51-84dc-41e9-b030-b02bf0cac976,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-e9ee8f4a-c8c8-4bf5-9a79-88d1f89bef43,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-1a0678d0-9373-40a0-8b3e-58e29b58c90a,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-c0e38516-b75d-45c4-b043-a558c6e8c00c,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-0c76cbe9-b769-411b-8906-691f75b009e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-68ab335c-0b1b-4bf8-b906-fc0b6660e6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-a76745ae-6d11-426e-8ea6-a0adc8214c12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1027500829-172.17.0.4-1595585664716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36389,DS-155686bc-c282-4468-9865-58a3dcc56272,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-e82991e6-4288-4ce8-8175-35bc6c818704,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-84647757-60a1-421b-87e1-530b361045a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-b793eceb-3948-4ffb-9d24-749b95d22e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-8f8584ed-7d98-43e3-974a-8ba3be8a0426,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-49f12314-441a-4640-801b-6bbb4cd025be,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-9664512a-9138-4045-bc5b-742c485729be,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-0299ad13-224d-4b29-b394-dc5c783d4ec4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1027500829-172.17.0.4-1595585664716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36389,DS-155686bc-c282-4468-9865-58a3dcc56272,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-e82991e6-4288-4ce8-8175-35bc6c818704,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-84647757-60a1-421b-87e1-530b361045a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-b793eceb-3948-4ffb-9d24-749b95d22e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-8f8584ed-7d98-43e3-974a-8ba3be8a0426,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-49f12314-441a-4640-801b-6bbb4cd025be,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-9664512a-9138-4045-bc5b-742c485729be,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-0299ad13-224d-4b29-b394-dc5c783d4ec4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2016006671-172.17.0.4-1595585991679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44896,DS-2aa361e2-3832-44be-8a00-2f54b735a63d,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-d8edfd04-d563-41e0-b767-04e16bd7864e,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-cde1ddcf-e623-4b36-98ec-2ca36ed32845,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-3067fdc0-abb2-41e0-94a6-87bdab13fa5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-0fea9d80-2cd4-4add-8508-6c1994dcee85,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-468aec35-9cba-4c1a-8ec8-82c1c205139b,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-2283b277-8027-4b5e-8e6d-875e072fe39e,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-4518b2c8-babf-4db7-9d54-22836ea78612,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2016006671-172.17.0.4-1595585991679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44896,DS-2aa361e2-3832-44be-8a00-2f54b735a63d,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-d8edfd04-d563-41e0-b767-04e16bd7864e,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-cde1ddcf-e623-4b36-98ec-2ca36ed32845,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-3067fdc0-abb2-41e0-94a6-87bdab13fa5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-0fea9d80-2cd4-4add-8508-6c1994dcee85,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-468aec35-9cba-4c1a-8ec8-82c1c205139b,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-2283b277-8027-4b5e-8e6d-875e072fe39e,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-4518b2c8-babf-4db7-9d54-22836ea78612,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-512102337-172.17.0.4-1595586301328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45296,DS-57bd22ad-0b11-430a-ace3-c70e2ab63661,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-13564324-c4ab-47e1-97c8-57849871e073,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-4f84d801-03c8-4b30-9055-42948cb027b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-d7b3b68b-1ba6-438e-92fa-397ca870ab3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-8992faaa-5c60-4727-93f4-24d4cb16f110,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-97eb6d14-a456-4405-a921-fcd5f1a6492b,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-6a6bec7a-de15-40e8-85a2-1e3dc623441c,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-321c7470-eb81-4dd6-8281-12a982cd2f01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-512102337-172.17.0.4-1595586301328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45296,DS-57bd22ad-0b11-430a-ace3-c70e2ab63661,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-13564324-c4ab-47e1-97c8-57849871e073,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-4f84d801-03c8-4b30-9055-42948cb027b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-d7b3b68b-1ba6-438e-92fa-397ca870ab3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-8992faaa-5c60-4727-93f4-24d4cb16f110,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-97eb6d14-a456-4405-a921-fcd5f1a6492b,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-6a6bec7a-de15-40e8-85a2-1e3dc623441c,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-321c7470-eb81-4dd6-8281-12a982cd2f01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1182080517-172.17.0.4-1595586737155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44442,DS-c51de133-9d97-4397-989d-f74370d752b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-2163f141-2484-468e-b5cc-8bd99674c076,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-880bf57f-9f2f-4e69-b5f3-08582274b02a,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-54d60bd5-c91f-42c0-806a-1bd82147f2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-98ce2ae2-d463-44f5-add1-436bf258fdf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-e0ab0a5f-6cd1-4f35-a5f0-5b768661c66d,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-fe0780e2-9398-4627-a921-cae7719abdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-40243780-0b52-47e3-bd8f-639c9a5df5e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1182080517-172.17.0.4-1595586737155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44442,DS-c51de133-9d97-4397-989d-f74370d752b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-2163f141-2484-468e-b5cc-8bd99674c076,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-880bf57f-9f2f-4e69-b5f3-08582274b02a,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-54d60bd5-c91f-42c0-806a-1bd82147f2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-98ce2ae2-d463-44f5-add1-436bf258fdf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-e0ab0a5f-6cd1-4f35-a5f0-5b768661c66d,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-fe0780e2-9398-4627-a921-cae7719abdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-40243780-0b52-47e3-bd8f-639c9a5df5e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057843944-172.17.0.4-1595587573226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44567,DS-b3658b75-9d1e-4a2f-a6d5-1724c4a9334b,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-06169cce-346c-4569-afa9-a62a89184b30,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-ba928e91-a114-4430-b452-102bc7c15cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-b0687264-353d-40a2-8f3d-ea02ed375c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-eae0cf1b-fde2-4d10-821a-5429d4ce9570,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-67bef853-e82d-4bdb-8f77-2aad568bdff3,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-b8d3789b-7ce9-45bc-a315-fa6d572dcf0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-1ff66d28-9761-42ae-9496-9265a0399f95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057843944-172.17.0.4-1595587573226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44567,DS-b3658b75-9d1e-4a2f-a6d5-1724c4a9334b,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-06169cce-346c-4569-afa9-a62a89184b30,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-ba928e91-a114-4430-b452-102bc7c15cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-b0687264-353d-40a2-8f3d-ea02ed375c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-eae0cf1b-fde2-4d10-821a-5429d4ce9570,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-67bef853-e82d-4bdb-8f77-2aad568bdff3,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-b8d3789b-7ce9-45bc-a315-fa6d572dcf0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-1ff66d28-9761-42ae-9496-9265a0399f95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1179273593-172.17.0.4-1595588233636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45956,DS-34832184-5f99-4d15-b67c-2f60b0b09ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-ee92c384-28cc-4fc8-85fa-c3c4bff0e749,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-d178f31f-0977-4b1b-851e-dfcae1fc2efa,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-772f8092-b37b-44e5-8b57-9f27e757c51b,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-fe75bd4a-dac2-410c-ae72-9c8813ba43fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-9c07c507-3b9b-4c92-bdcd-6d2eb3147830,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-c66f6e90-68e7-4c15-8d02-b9cee207c348,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-0b4a1d6b-0c23-43e1-ae1b-e2a48f86bde4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1179273593-172.17.0.4-1595588233636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45956,DS-34832184-5f99-4d15-b67c-2f60b0b09ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-ee92c384-28cc-4fc8-85fa-c3c4bff0e749,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-d178f31f-0977-4b1b-851e-dfcae1fc2efa,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-772f8092-b37b-44e5-8b57-9f27e757c51b,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-fe75bd4a-dac2-410c-ae72-9c8813ba43fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-9c07c507-3b9b-4c92-bdcd-6d2eb3147830,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-c66f6e90-68e7-4c15-8d02-b9cee207c348,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-0b4a1d6b-0c23-43e1-ae1b-e2a48f86bde4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-162858907-172.17.0.4-1595588333370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38095,DS-5d4c9bf8-8e4a-4e96-9df3-7a19968881b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-01d606ad-a5f7-4f67-a041-59cd98d02e00,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-0e1dc591-f54b-4c40-a75c-ca68b51927c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-254d466d-537e-4fb3-9313-68567fa09585,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-98c0c504-35d2-4a56-a415-be6970dbaa8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-9ac00dd9-85f0-40bb-a761-b48f80aedd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-06e2a2f6-9012-403f-8681-9fc5af917710,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-6418207f-95ba-4b60-9a51-579bb5293ad2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-162858907-172.17.0.4-1595588333370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38095,DS-5d4c9bf8-8e4a-4e96-9df3-7a19968881b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-01d606ad-a5f7-4f67-a041-59cd98d02e00,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-0e1dc591-f54b-4c40-a75c-ca68b51927c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-254d466d-537e-4fb3-9313-68567fa09585,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-98c0c504-35d2-4a56-a415-be6970dbaa8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-9ac00dd9-85f0-40bb-a761-b48f80aedd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-06e2a2f6-9012-403f-8681-9fc5af917710,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-6418207f-95ba-4b60-9a51-579bb5293ad2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5342
