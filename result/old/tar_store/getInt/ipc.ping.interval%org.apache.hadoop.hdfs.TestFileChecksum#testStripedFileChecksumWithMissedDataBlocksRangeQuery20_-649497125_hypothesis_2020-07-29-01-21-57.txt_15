reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-795199356-172.17.0.4-1595986651187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40047,DS-01da0b04-ee13-4627-b851-53f08ef8f186,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-e425a1ef-98b5-4a7b-89e3-54eed07c9a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-6dae09a1-aa0c-4dc5-9eca-702b7a88575b,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-8700c08e-2b51-4053-acca-0a68c3ce04f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-a219ed56-1f6e-433e-9984-2084be8631d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-0af559c0-5af3-4c3a-9c8d-5707d20cd29d,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-550495a2-8e64-47f3-81d2-9bd2bc9272d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-9c8ce64b-295b-4b16-b718-602ffa38faf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-795199356-172.17.0.4-1595986651187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40047,DS-01da0b04-ee13-4627-b851-53f08ef8f186,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-e425a1ef-98b5-4a7b-89e3-54eed07c9a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-6dae09a1-aa0c-4dc5-9eca-702b7a88575b,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-8700c08e-2b51-4053-acca-0a68c3ce04f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-a219ed56-1f6e-433e-9984-2084be8631d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-0af559c0-5af3-4c3a-9c8d-5707d20cd29d,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-550495a2-8e64-47f3-81d2-9bd2bc9272d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-9c8ce64b-295b-4b16-b718-602ffa38faf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-28745672-172.17.0.4-1595987971604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37109,DS-958f99b6-b5b3-46aa-8e8d-0fd07b3fabbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-960426bf-f5c1-4731-a3eb-e18444f23560,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-73b5de16-8276-4058-bcb9-ea9b39c7c67f,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-9d88c1ae-5fbf-4b9e-9ced-f1dbe8efb98e,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-4d08340f-003e-42e1-88bd-b9c7b71b6844,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-c193c90d-5021-4671-a9b6-34f85bad6335,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-c52741f2-b7e7-4457-b1cc-32d232e91d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-21041401-b516-4038-86b2-7868960387fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-28745672-172.17.0.4-1595987971604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37109,DS-958f99b6-b5b3-46aa-8e8d-0fd07b3fabbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-960426bf-f5c1-4731-a3eb-e18444f23560,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-73b5de16-8276-4058-bcb9-ea9b39c7c67f,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-9d88c1ae-5fbf-4b9e-9ced-f1dbe8efb98e,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-4d08340f-003e-42e1-88bd-b9c7b71b6844,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-c193c90d-5021-4671-a9b6-34f85bad6335,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-c52741f2-b7e7-4457-b1cc-32d232e91d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-21041401-b516-4038-86b2-7868960387fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1871745179-172.17.0.4-1595988054292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33555,DS-40997bf1-e9e9-4709-876b-cc1741b61892,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-2359974b-a865-484d-b68c-74a4fb377ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-98c2bace-5aa5-4748-96b2-15c81a62e316,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-68e4626d-157b-4430-a5c4-02c01883a182,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-0970539c-fcee-4c40-be4e-baa86216c3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-34835ad0-6f71-47ec-93d7-ad1937ba66bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-66fd7a45-d014-4f03-b89d-a6f33da185dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-2dd2eaf1-d105-4b84-abf4-9b9d758df281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1871745179-172.17.0.4-1595988054292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33555,DS-40997bf1-e9e9-4709-876b-cc1741b61892,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-2359974b-a865-484d-b68c-74a4fb377ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-98c2bace-5aa5-4748-96b2-15c81a62e316,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-68e4626d-157b-4430-a5c4-02c01883a182,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-0970539c-fcee-4c40-be4e-baa86216c3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-34835ad0-6f71-47ec-93d7-ad1937ba66bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-66fd7a45-d014-4f03-b89d-a6f33da185dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-2dd2eaf1-d105-4b84-abf4-9b9d758df281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-505295035-172.17.0.4-1595988387022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45549,DS-4b4a6adb-bedf-494f-9376-4a4d124e7e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-53df278e-0e9a-4f3f-922d-4dae3a2f3e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-035b5a5a-3ac6-4372-8f0c-88e602a43338,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-26e09f2b-8430-4981-92f1-a691970049cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-9f211ea0-61b5-4d96-8c49-76ade85e16ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-51609dc8-0b35-4f15-ae02-fb92cf8cfe09,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-0db7ca8e-4787-49af-ad60-32b08b4c6a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-8942e1d3-d552-4519-b796-5ac500931abc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-505295035-172.17.0.4-1595988387022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45549,DS-4b4a6adb-bedf-494f-9376-4a4d124e7e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-53df278e-0e9a-4f3f-922d-4dae3a2f3e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-035b5a5a-3ac6-4372-8f0c-88e602a43338,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-26e09f2b-8430-4981-92f1-a691970049cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-9f211ea0-61b5-4d96-8c49-76ade85e16ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-51609dc8-0b35-4f15-ae02-fb92cf8cfe09,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-0db7ca8e-4787-49af-ad60-32b08b4c6a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-8942e1d3-d552-4519-b796-5ac500931abc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-869194282-172.17.0.4-1595988614588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46775,DS-77ec7ead-bd12-4448-a165-db953091a2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-877a2edf-948a-4f17-9771-a1441bfeee88,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-f0383322-8213-4419-8efe-20f80085bdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-aeedc447-bb03-4925-9384-39d6f883dbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-1a78a601-24c2-48ab-9a4d-261cb74dcaea,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-ed47013f-efa3-4ca5-ad73-9e379b7c46b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-7c76293e-1bc5-488e-92b3-24291a47802b,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-6ebae8b1-46d8-4c79-866d-9e40009b64b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-869194282-172.17.0.4-1595988614588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46775,DS-77ec7ead-bd12-4448-a165-db953091a2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-877a2edf-948a-4f17-9771-a1441bfeee88,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-f0383322-8213-4419-8efe-20f80085bdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-aeedc447-bb03-4925-9384-39d6f883dbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-1a78a601-24c2-48ab-9a4d-261cb74dcaea,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-ed47013f-efa3-4ca5-ad73-9e379b7c46b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-7c76293e-1bc5-488e-92b3-24291a47802b,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-6ebae8b1-46d8-4c79-866d-9e40009b64b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1871033311-172.17.0.4-1595988655733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38538,DS-43ec82dd-b131-4459-955d-4bcd25e3694b,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-19c8a423-79ce-41e5-847a-f55c27f9e76f,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-69472bb6-d5af-4a15-aab4-2eff8b92233c,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-c233b6e2-4e69-44ae-9225-2ffd246d7f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-d6a10474-41ac-489d-baf1-eac167620aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-abae99f7-58ea-4af1-a00c-06ad12d34be3,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-195a2409-059d-4bad-8c79-a8668166241d,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-765bdcca-90f7-4161-a425-242a895cef17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1871033311-172.17.0.4-1595988655733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38538,DS-43ec82dd-b131-4459-955d-4bcd25e3694b,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-19c8a423-79ce-41e5-847a-f55c27f9e76f,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-69472bb6-d5af-4a15-aab4-2eff8b92233c,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-c233b6e2-4e69-44ae-9225-2ffd246d7f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-d6a10474-41ac-489d-baf1-eac167620aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-abae99f7-58ea-4af1-a00c-06ad12d34be3,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-195a2409-059d-4bad-8c79-a8668166241d,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-765bdcca-90f7-4161-a425-242a895cef17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-795794605-172.17.0.4-1595989112520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38043,DS-701cf365-dfb9-48b8-998e-caf8868fdca0,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-5239e412-5ae0-4bbe-8473-c181dc5620bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-e3d33039-9a7d-4fa2-b218-a1d118c1a0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-6619b8b3-4e2e-4897-a2f2-7785efb46574,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-299e4256-11db-48f5-b6c7-1bf95ea6d8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-2715fbbc-830e-428f-9be6-d84ddd9c89ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-ff449834-203d-4acc-b33a-3cefb141840f,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-256c6dc9-6d63-4cea-9f79-c9fae7259778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-795794605-172.17.0.4-1595989112520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38043,DS-701cf365-dfb9-48b8-998e-caf8868fdca0,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-5239e412-5ae0-4bbe-8473-c181dc5620bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-e3d33039-9a7d-4fa2-b218-a1d118c1a0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-6619b8b3-4e2e-4897-a2f2-7785efb46574,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-299e4256-11db-48f5-b6c7-1bf95ea6d8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-2715fbbc-830e-428f-9be6-d84ddd9c89ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-ff449834-203d-4acc-b33a-3cefb141840f,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-256c6dc9-6d63-4cea-9f79-c9fae7259778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1828444621-172.17.0.4-1595989547979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37559,DS-02f64601-b901-4f7b-a891-b7e6cba6cd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-240fd0bc-6f16-4572-af2e-01101adfe6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-1b65aab1-a499-47c5-830b-4958b518edec,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-9146e836-2254-4f38-93b1-83b4f43a4433,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-c32b06bf-0736-4f57-a6cc-43a72efa2548,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-fc61f5bf-41a0-462a-af25-27a018e6bab0,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-f92c143b-887b-425f-a596-1d5914db6a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-17afe1ad-3f54-4f1a-b9ba-0f0ef1d5ddc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1828444621-172.17.0.4-1595989547979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37559,DS-02f64601-b901-4f7b-a891-b7e6cba6cd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-240fd0bc-6f16-4572-af2e-01101adfe6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-1b65aab1-a499-47c5-830b-4958b518edec,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-9146e836-2254-4f38-93b1-83b4f43a4433,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-c32b06bf-0736-4f57-a6cc-43a72efa2548,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-fc61f5bf-41a0-462a-af25-27a018e6bab0,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-f92c143b-887b-425f-a596-1d5914db6a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-17afe1ad-3f54-4f1a-b9ba-0f0ef1d5ddc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1249249173-172.17.0.4-1595990145366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38116,DS-07b9b820-fc7d-431f-bded-3d069bddea26,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-d8bc9a01-683c-4d7d-a41b-5c0e9058c5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-202e67ae-06bf-4aac-83d0-0c630a55ea55,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-b1feb344-7a59-4ef9-b15c-91ad807a5e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-57e4d6b3-99ef-4362-a8b1-15639153d8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-8a1aeab4-f5f3-4af4-beaa-3478ab9262ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-b41eb94a-f1bf-4d27-b0ce-2ffa42627917,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-f0caa385-7593-4260-819a-681b321a2b38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1249249173-172.17.0.4-1595990145366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38116,DS-07b9b820-fc7d-431f-bded-3d069bddea26,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-d8bc9a01-683c-4d7d-a41b-5c0e9058c5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-202e67ae-06bf-4aac-83d0-0c630a55ea55,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-b1feb344-7a59-4ef9-b15c-91ad807a5e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-57e4d6b3-99ef-4362-a8b1-15639153d8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-8a1aeab4-f5f3-4af4-beaa-3478ab9262ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-b41eb94a-f1bf-4d27-b0ce-2ffa42627917,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-f0caa385-7593-4260-819a-681b321a2b38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1320743865-172.17.0.4-1595990487129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34082,DS-883e7d1d-7c0f-49e5-8593-15eef06b45a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-81398724-082a-4fb4-bf4d-0435da3aec44,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-a69a7fbb-9cf6-422e-8f75-b571255eaf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-11f706eb-4642-4454-90d1-08534436b937,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-c232b8ef-3323-4c5b-b8c9-e5923c8c83f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-c0780b6a-8399-4a7a-b96d-902621d6545e,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-52f891dd-296b-47f5-ab1f-f224a62fee14,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-c53ee485-e798-430d-a7fc-c0738e63e4c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1320743865-172.17.0.4-1595990487129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34082,DS-883e7d1d-7c0f-49e5-8593-15eef06b45a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-81398724-082a-4fb4-bf4d-0435da3aec44,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-a69a7fbb-9cf6-422e-8f75-b571255eaf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-11f706eb-4642-4454-90d1-08534436b937,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-c232b8ef-3323-4c5b-b8c9-e5923c8c83f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-c0780b6a-8399-4a7a-b96d-902621d6545e,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-52f891dd-296b-47f5-ab1f-f224a62fee14,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-c53ee485-e798-430d-a7fc-c0738e63e4c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1843707562-172.17.0.4-1595991199658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39654,DS-e80488a5-c2ab-42b0-ac31-b0c1c844ec68,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-3ddb2f49-ec16-46ad-a992-68d826bcae06,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-afca67d5-b22b-40ff-9756-50b4ebcb71e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-9ad04e8e-f6c1-4509-bcb0-d2dfd30051d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-3b9a18ad-cc5c-4bca-b98c-bca1a2ea0df2,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-4953b997-291b-4b1d-a124-8a3c57dc87a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-afcd4dc1-a3ca-48d8-a4e7-c52790e0b9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-7a77ba2e-0527-4ead-a1fc-836ccdb496dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1843707562-172.17.0.4-1595991199658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39654,DS-e80488a5-c2ab-42b0-ac31-b0c1c844ec68,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-3ddb2f49-ec16-46ad-a992-68d826bcae06,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-afca67d5-b22b-40ff-9756-50b4ebcb71e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-9ad04e8e-f6c1-4509-bcb0-d2dfd30051d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-3b9a18ad-cc5c-4bca-b98c-bca1a2ea0df2,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-4953b997-291b-4b1d-a124-8a3c57dc87a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-afcd4dc1-a3ca-48d8-a4e7-c52790e0b9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-7a77ba2e-0527-4ead-a1fc-836ccdb496dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 5570
