reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1157013284-172.17.0.5-1596024711241:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44553,DS-b4949382-b0a6-4c6d-8748-cee310d1201b,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-9c96472b-032a-4ae2-8289-b550e592e3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-9a68a395-ec50-426d-a6ac-6cebf0daf388,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-44ec4f99-8029-4233-935f-dcfd193fed04,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-2184f8b2-e8d7-4ae6-9baf-9bc3634fd91a,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-fd3d8880-76fb-40ed-8dd4-a0115eb6e3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-63c86658-0e78-4b86-a48a-6a6eb87145dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-3516ff44-5a64-47f4-8628-5c851f659cab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1157013284-172.17.0.5-1596024711241:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44553,DS-b4949382-b0a6-4c6d-8748-cee310d1201b,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-9c96472b-032a-4ae2-8289-b550e592e3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-9a68a395-ec50-426d-a6ac-6cebf0daf388,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-44ec4f99-8029-4233-935f-dcfd193fed04,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-2184f8b2-e8d7-4ae6-9baf-9bc3634fd91a,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-fd3d8880-76fb-40ed-8dd4-a0115eb6e3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-63c86658-0e78-4b86-a48a-6a6eb87145dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-3516ff44-5a64-47f4-8628-5c851f659cab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-585853617-172.17.0.5-1596024899130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46551,DS-15274d50-489e-4aac-b241-d02892269bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-3b036a79-6a95-4b91-be97-1c4761eb2d91,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-4a3cedca-c1bf-4542-b277-a5639b5c70bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-a628706c-0a0b-435a-99b0-42841f35006e,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-92fdefb0-21b9-4088-a017-d32ff13a2d14,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-933499ba-706e-47ce-989e-47a7cbfb8710,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-ab9c16b4-f1b5-4d26-8791-cc4aadb08500,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-2c3e3199-1499-455f-9d61-1ce015260b4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-585853617-172.17.0.5-1596024899130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46551,DS-15274d50-489e-4aac-b241-d02892269bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-3b036a79-6a95-4b91-be97-1c4761eb2d91,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-4a3cedca-c1bf-4542-b277-a5639b5c70bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-a628706c-0a0b-435a-99b0-42841f35006e,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-92fdefb0-21b9-4088-a017-d32ff13a2d14,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-933499ba-706e-47ce-989e-47a7cbfb8710,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-ab9c16b4-f1b5-4d26-8791-cc4aadb08500,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-2c3e3199-1499-455f-9d61-1ce015260b4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-192679143-172.17.0.5-1596024939360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37115,DS-55c5c753-200c-444b-a38c-0a7c8642251e,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-84aa45aa-6f1e-434f-8c58-66fbd4385581,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-af77d5e4-b6b2-4fcf-a537-ad598e3bf370,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-8d0ca1d8-e74d-41b4-9b7d-15ccb9022a03,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-435a1c6b-b12f-4613-931a-4cbb6413517c,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-a3dcc413-547f-4704-9cf7-625218bf4dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-7f7b8e05-39a2-4775-a6ba-8f6315ab4592,DISK], DatanodeInfoWithStorage[127.0.0.1:34378,DS-410c8290-8a52-4bf5-b0ed-834f5eb7651f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-192679143-172.17.0.5-1596024939360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37115,DS-55c5c753-200c-444b-a38c-0a7c8642251e,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-84aa45aa-6f1e-434f-8c58-66fbd4385581,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-af77d5e4-b6b2-4fcf-a537-ad598e3bf370,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-8d0ca1d8-e74d-41b4-9b7d-15ccb9022a03,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-435a1c6b-b12f-4613-931a-4cbb6413517c,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-a3dcc413-547f-4704-9cf7-625218bf4dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-7f7b8e05-39a2-4775-a6ba-8f6315ab4592,DISK], DatanodeInfoWithStorage[127.0.0.1:34378,DS-410c8290-8a52-4bf5-b0ed-834f5eb7651f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-741913234-172.17.0.5-1596025183804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41953,DS-2830bbb3-fb82-4fab-8ccb-728532a6edff,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-acb5b1fe-19c0-499a-959e-ccbd7b9f13cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-13fe70da-cb05-49f1-bf40-3afa93b7410d,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-abfbfa70-15e2-4521-8071-2d5128c2556f,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-9c986612-0fc8-48a2-bca5-7b43bcfec04a,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-c1e0bcb5-4dd0-4fc4-83e0-4ef86a72c068,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-e80fb0a6-3fca-4583-a870-e534302a2925,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-33dc37a6-426e-4418-9e6e-b273b7fdc97a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-741913234-172.17.0.5-1596025183804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41953,DS-2830bbb3-fb82-4fab-8ccb-728532a6edff,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-acb5b1fe-19c0-499a-959e-ccbd7b9f13cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-13fe70da-cb05-49f1-bf40-3afa93b7410d,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-abfbfa70-15e2-4521-8071-2d5128c2556f,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-9c986612-0fc8-48a2-bca5-7b43bcfec04a,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-c1e0bcb5-4dd0-4fc4-83e0-4ef86a72c068,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-e80fb0a6-3fca-4583-a870-e534302a2925,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-33dc37a6-426e-4418-9e6e-b273b7fdc97a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-987130196-172.17.0.5-1596025300833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34377,DS-d4300972-a9a9-4b47-85b1-ad062521d224,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-f73f3a5e-6ed9-4451-bf7c-b298a95a35de,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-dcdc68bd-e4f2-43bf-a8eb-69052aced1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-54a2de94-9b22-4847-9c7c-494dd98a8f82,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-39286cae-5da2-4c0a-a151-c5e90552fc77,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-cc06ff3f-825e-4a5c-9e01-288153629489,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-326fb190-72c8-4b23-92d8-c04312da047f,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-362a5514-8af9-4476-a400-3ee5db487c11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-987130196-172.17.0.5-1596025300833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34377,DS-d4300972-a9a9-4b47-85b1-ad062521d224,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-f73f3a5e-6ed9-4451-bf7c-b298a95a35de,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-dcdc68bd-e4f2-43bf-a8eb-69052aced1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-54a2de94-9b22-4847-9c7c-494dd98a8f82,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-39286cae-5da2-4c0a-a151-c5e90552fc77,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-cc06ff3f-825e-4a5c-9e01-288153629489,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-326fb190-72c8-4b23-92d8-c04312da047f,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-362a5514-8af9-4476-a400-3ee5db487c11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787391865-172.17.0.5-1596025656052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46819,DS-c214e209-fdfe-4827-9f53-9af8e3af79ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-97ab4987-4570-416c-8a99-1cb8c9921178,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-2ff3611b-2b5f-4703-a64f-729fb8b10883,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-def4ea6f-5ee9-4465-98ab-f598a03f7dae,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-ff6e1f84-aae2-4ef9-a2a1-9ffa7e8f6517,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-c5dc5649-65a0-4d7f-a069-e8fc8984176c,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-37b28bb5-78d2-41e8-b1b4-a4e27c3ec164,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-18cabe15-3ea4-4fc4-afd1-29fef8d9db8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787391865-172.17.0.5-1596025656052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46819,DS-c214e209-fdfe-4827-9f53-9af8e3af79ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-97ab4987-4570-416c-8a99-1cb8c9921178,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-2ff3611b-2b5f-4703-a64f-729fb8b10883,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-def4ea6f-5ee9-4465-98ab-f598a03f7dae,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-ff6e1f84-aae2-4ef9-a2a1-9ffa7e8f6517,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-c5dc5649-65a0-4d7f-a069-e8fc8984176c,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-37b28bb5-78d2-41e8-b1b4-a4e27c3ec164,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-18cabe15-3ea4-4fc4-afd1-29fef8d9db8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-419857701-172.17.0.5-1596025813747:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36529,DS-a61e3940-2986-4041-97b6-1dcce3a890bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-0af97879-d84c-4de4-abf8-36025947cd21,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-cc0beabc-cff3-40ea-afae-ed5e44aa70fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-6b60b436-cce8-454b-97d5-ad6d2e528dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-eb06cbf4-4ce3-47fd-97e6-66ca66acfac9,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-4e9e8982-94a8-4022-b142-1f767ec19cab,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-f45bb879-1109-4e05-83f4-1dfbb0d8131d,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-381002ff-a98e-4483-b539-7dcf5351a5ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-419857701-172.17.0.5-1596025813747:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36529,DS-a61e3940-2986-4041-97b6-1dcce3a890bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-0af97879-d84c-4de4-abf8-36025947cd21,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-cc0beabc-cff3-40ea-afae-ed5e44aa70fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-6b60b436-cce8-454b-97d5-ad6d2e528dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-eb06cbf4-4ce3-47fd-97e6-66ca66acfac9,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-4e9e8982-94a8-4022-b142-1f767ec19cab,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-f45bb879-1109-4e05-83f4-1dfbb0d8131d,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-381002ff-a98e-4483-b539-7dcf5351a5ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123446525-172.17.0.5-1596026036650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40446,DS-f5d3c82c-1f50-43a6-8627-bd4a2fc12b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-c7c1727b-f261-4f25-8e98-317c8fd2d6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-98524f48-c22c-4538-a066-9896806e6c67,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-ddb6fdc6-7eae-48c6-9083-5bce7796d367,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-cde7d313-9028-4271-b28a-2cb108d63e42,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-7c07ee8a-2f40-414b-92c3-5739b003fcab,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-555e42f5-ca3e-4516-ad71-755efcfbe8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-19044515-24b9-4b32-960b-dcb191fc2e32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123446525-172.17.0.5-1596026036650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40446,DS-f5d3c82c-1f50-43a6-8627-bd4a2fc12b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-c7c1727b-f261-4f25-8e98-317c8fd2d6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-98524f48-c22c-4538-a066-9896806e6c67,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-ddb6fdc6-7eae-48c6-9083-5bce7796d367,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-cde7d313-9028-4271-b28a-2cb108d63e42,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-7c07ee8a-2f40-414b-92c3-5739b003fcab,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-555e42f5-ca3e-4516-ad71-755efcfbe8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-19044515-24b9-4b32-960b-dcb191fc2e32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537036826-172.17.0.5-1596026072032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38996,DS-0f5a5146-48b8-47d2-bcdf-dafa2be2aeba,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-c7acb561-6e6d-467a-938c-032f6fac0a79,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-fc28e5f0-8d3b-411e-87b6-d177c2fe5d06,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-2b540be3-79e0-4a58-b9d1-b2a241191d22,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-9ba8f14c-f709-4c18-89ee-05400dcbd27a,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-286a4b61-064f-4c9f-b02c-533c133791a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-81b4e1c0-50c4-46a7-8d59-78711965bed1,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-462d4e5a-7f4f-476f-9e4d-30825c954f6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537036826-172.17.0.5-1596026072032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38996,DS-0f5a5146-48b8-47d2-bcdf-dafa2be2aeba,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-c7acb561-6e6d-467a-938c-032f6fac0a79,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-fc28e5f0-8d3b-411e-87b6-d177c2fe5d06,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-2b540be3-79e0-4a58-b9d1-b2a241191d22,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-9ba8f14c-f709-4c18-89ee-05400dcbd27a,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-286a4b61-064f-4c9f-b02c-533c133791a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-81b4e1c0-50c4-46a7-8d59-78711965bed1,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-462d4e5a-7f4f-476f-9e4d-30825c954f6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31222055-172.17.0.5-1596026112371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46029,DS-6ee172fe-842d-4a43-9356-8addbace811f,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-69f2c344-1cff-41e5-81a9-58eae9862484,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-1d5ad18b-884e-450a-b4a4-193de637981c,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-a4ed05fd-325b-4799-ba85-9149c005a967,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-6cf07083-2ee3-48b0-b75b-2e6650910c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-e3fb06f1-c4e9-4a0d-99c2-51f1ec3c55b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-89e5c09d-5f32-47b0-b5dc-6de22208e8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44749,DS-37767b63-f4f9-49ec-88d0-77353553b1ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31222055-172.17.0.5-1596026112371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46029,DS-6ee172fe-842d-4a43-9356-8addbace811f,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-69f2c344-1cff-41e5-81a9-58eae9862484,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-1d5ad18b-884e-450a-b4a4-193de637981c,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-a4ed05fd-325b-4799-ba85-9149c005a967,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-6cf07083-2ee3-48b0-b75b-2e6650910c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-e3fb06f1-c4e9-4a0d-99c2-51f1ec3c55b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-89e5c09d-5f32-47b0-b5dc-6de22208e8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44749,DS-37767b63-f4f9-49ec-88d0-77353553b1ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2057293784-172.17.0.5-1596026273802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41851,DS-83b7dadb-9495-4458-a5bd-0b5acf9a8d49,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-373fed9c-f1fa-496d-9c5c-ebfc2494bf51,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-4db2ef7a-8c87-45e6-8700-f6b8b0aa0c36,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-73865296-b0fc-4028-a864-0c0a10851003,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-562a706d-c549-459f-a4d1-d4aa7a8ca8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-427ee3d1-e480-473a-9dc1-68405aa39c67,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-626139df-2071-4dca-bc1a-61623cab46ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-6169d9df-a4ff-48b0-bb93-848a6be16b1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2057293784-172.17.0.5-1596026273802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41851,DS-83b7dadb-9495-4458-a5bd-0b5acf9a8d49,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-373fed9c-f1fa-496d-9c5c-ebfc2494bf51,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-4db2ef7a-8c87-45e6-8700-f6b8b0aa0c36,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-73865296-b0fc-4028-a864-0c0a10851003,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-562a706d-c549-459f-a4d1-d4aa7a8ca8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-427ee3d1-e480-473a-9dc1-68405aa39c67,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-626139df-2071-4dca-bc1a-61623cab46ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-6169d9df-a4ff-48b0-bb93-848a6be16b1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1675373656-172.17.0.5-1596026576575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40919,DS-c2b361fa-905f-4722-a69d-b51041864f46,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-039b1818-e00a-4ad9-8dfa-bef9a0f3958a,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-885e0c35-9e68-426a-bc47-e2887ec7be67,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-b236efc6-8f8a-4c55-bc1b-42f3db5d49ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-5c6951ef-1d6b-47a8-abf2-ee7a55226d16,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-b511950b-576a-4a45-86c6-3978111d6310,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-d60410e7-2022-4e9c-acfe-917690f0a491,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-b2523e25-d1ec-4913-911a-f7fa68a874b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1675373656-172.17.0.5-1596026576575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40919,DS-c2b361fa-905f-4722-a69d-b51041864f46,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-039b1818-e00a-4ad9-8dfa-bef9a0f3958a,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-885e0c35-9e68-426a-bc47-e2887ec7be67,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-b236efc6-8f8a-4c55-bc1b-42f3db5d49ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-5c6951ef-1d6b-47a8-abf2-ee7a55226d16,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-b511950b-576a-4a45-86c6-3978111d6310,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-d60410e7-2022-4e9c-acfe-917690f0a491,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-b2523e25-d1ec-4913-911a-f7fa68a874b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2038273237-172.17.0.5-1596027042413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34862,DS-b48faa44-15cc-498e-b7df-5251b520b128,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-ae01b599-d086-4cae-bcd9-b9c744c958d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-aa40bcf4-b4aa-4637-ab17-4d719d70d213,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-fa9ef4f2-948a-4328-b6a9-f2cda44e96ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-69a38c8c-cace-4d6d-81b3-f8c95b3a4003,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-6be4a92f-ffd2-44b2-9e61-53fc93fee20b,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-bf449373-6503-412a-b3a3-03f4cb87c954,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-adf01154-8ad6-47be-8a92-4d6e551756a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2038273237-172.17.0.5-1596027042413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34862,DS-b48faa44-15cc-498e-b7df-5251b520b128,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-ae01b599-d086-4cae-bcd9-b9c744c958d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-aa40bcf4-b4aa-4637-ab17-4d719d70d213,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-fa9ef4f2-948a-4328-b6a9-f2cda44e96ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-69a38c8c-cace-4d6d-81b3-f8c95b3a4003,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-6be4a92f-ffd2-44b2-9e61-53fc93fee20b,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-bf449373-6503-412a-b3a3-03f4cb87c954,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-adf01154-8ad6-47be-8a92-4d6e551756a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1060196214-172.17.0.5-1596027633492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46543,DS-5c1d458c-09cc-480b-8454-1d53c800062d,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-32788969-0d62-44b8-be42-e355d369a939,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-568e7eee-a7ba-454b-b1d1-ff54209397ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-5270d77d-058c-4a31-92c9-e3e9f2b5938e,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-9ba14851-dbaa-440e-8b9b-1110c3b2667c,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-5632b30c-2090-49a5-bdd7-a2bf52d79d36,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-73a2b983-1063-4a4b-9581-137f15fb361a,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-e268b032-a766-4e61-acaa-20e3a6c6230b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1060196214-172.17.0.5-1596027633492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46543,DS-5c1d458c-09cc-480b-8454-1d53c800062d,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-32788969-0d62-44b8-be42-e355d369a939,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-568e7eee-a7ba-454b-b1d1-ff54209397ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-5270d77d-058c-4a31-92c9-e3e9f2b5938e,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-9ba14851-dbaa-440e-8b9b-1110c3b2667c,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-5632b30c-2090-49a5-bdd7-a2bf52d79d36,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-73a2b983-1063-4a4b-9581-137f15fb361a,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-e268b032-a766-4e61-acaa-20e3a6c6230b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-979033065-172.17.0.5-1596027755404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38605,DS-61c37a76-178d-4130-aae2-32c93467de04,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-8864da8b-fde8-449e-a6cc-c38fc34ba652,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-3c6191de-0111-40b1-bae0-a58418d6b0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-be8928c8-f8c5-4356-875f-6c42a66607c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-d6c89ed9-6a79-4b6e-b529-8e46c2b51c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-c3601eac-7df6-4557-ba61-bcbdab172361,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-9f0c3def-6bc1-45cb-8f89-ee2925a8d58b,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-cfb47758-c8d7-4264-8ee8-b863e62b9ae5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-979033065-172.17.0.5-1596027755404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38605,DS-61c37a76-178d-4130-aae2-32c93467de04,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-8864da8b-fde8-449e-a6cc-c38fc34ba652,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-3c6191de-0111-40b1-bae0-a58418d6b0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-be8928c8-f8c5-4356-875f-6c42a66607c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-d6c89ed9-6a79-4b6e-b529-8e46c2b51c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-c3601eac-7df6-4557-ba61-bcbdab172361,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-9f0c3def-6bc1-45cb-8f89-ee2925a8d58b,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-cfb47758-c8d7-4264-8ee8-b863e62b9ae5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-546420429-172.17.0.5-1596028195023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41326,DS-21b690cc-9acf-4dba-8ec7-9e33969c62ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-88b92672-6641-408a-a3a8-46a52e7b6acb,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-1d2cfb5c-e2dd-4823-b4c3-84b14a2385ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-f4239521-42a4-4c22-80c6-6fd390d60594,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-6cb092ca-8acc-4efa-bb04-2be04b71a2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-504882e6-b55c-4417-b7e6-2217a35fa566,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-120580b6-ffb0-41af-aa9c-b9767259cb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-08ce4fcf-c62d-4124-a56d-9696cb0c4977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-546420429-172.17.0.5-1596028195023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41326,DS-21b690cc-9acf-4dba-8ec7-9e33969c62ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-88b92672-6641-408a-a3a8-46a52e7b6acb,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-1d2cfb5c-e2dd-4823-b4c3-84b14a2385ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-f4239521-42a4-4c22-80c6-6fd390d60594,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-6cb092ca-8acc-4efa-bb04-2be04b71a2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-504882e6-b55c-4417-b7e6-2217a35fa566,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-120580b6-ffb0-41af-aa9c-b9767259cb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-08ce4fcf-c62d-4124-a56d-9696cb0c4977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1295347433-172.17.0.5-1596028233636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40469,DS-1f33d5e7-a116-4804-adc0-48c719568e88,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-c8a17773-98d4-4772-84df-45d51babcde2,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-7cd010f0-6279-4ed4-b527-637cb5daf29f,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-0aa8b2b7-cec3-42b5-ac40-a6cc0ce99704,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-3cffd413-7583-400a-bc97-483db4dcb87b,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-228a9ebf-586b-40b4-9ac5-905f58cb309e,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-6d92bf12-b320-4b61-ab70-be6242ddc80e,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-99aa955a-3746-4e87-9e2c-61769e74b3fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1295347433-172.17.0.5-1596028233636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40469,DS-1f33d5e7-a116-4804-adc0-48c719568e88,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-c8a17773-98d4-4772-84df-45d51babcde2,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-7cd010f0-6279-4ed4-b527-637cb5daf29f,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-0aa8b2b7-cec3-42b5-ac40-a6cc0ce99704,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-3cffd413-7583-400a-bc97-483db4dcb87b,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-228a9ebf-586b-40b4-9ac5-905f58cb309e,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-6d92bf12-b320-4b61-ab70-be6242ddc80e,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-99aa955a-3746-4e87-9e2c-61769e74b3fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1838104775-172.17.0.5-1596029284541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39509,DS-8b700084-3cf7-485a-8199-3faccc79c3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-7915daf5-0341-4d0b-b301-20c301043563,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-6267f9d0-e45b-4ab0-aa74-153c449e8ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-16e77eaa-ba45-43fc-883a-936bfee61454,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-70437b25-3200-4182-90e0-c22d27ef79e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-d2f9f6e3-13e3-401f-83e1-35f1c83ce10d,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-5381bd30-dde1-4a4d-8456-190532621971,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-7af5adc1-5e07-42a8-8905-79717fd00f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1838104775-172.17.0.5-1596029284541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39509,DS-8b700084-3cf7-485a-8199-3faccc79c3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-7915daf5-0341-4d0b-b301-20c301043563,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-6267f9d0-e45b-4ab0-aa74-153c449e8ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-16e77eaa-ba45-43fc-883a-936bfee61454,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-70437b25-3200-4182-90e0-c22d27ef79e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-d2f9f6e3-13e3-401f-83e1-35f1c83ce10d,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-5381bd30-dde1-4a4d-8456-190532621971,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-7af5adc1-5e07-42a8-8905-79717fd00f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-84293516-172.17.0.5-1596029580010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42088,DS-a07a2468-a3cb-45b1-b1f4-490d96c0cac4,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-804208b5-18ac-483d-a929-9cb7e033dff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-423a3107-c2f8-4963-bd9e-320485a853ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-28ec9f51-9743-4b5f-b742-b5797e0787b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-441b464e-e9d3-48a7-b0d6-163df423674d,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-a236417f-09c4-4bf0-a90f-8ed0f98ad828,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-b3b82224-d0f6-4c43-b5fb-6eb23bc675f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-09daf9ea-d6ec-4ebc-b184-289cd98e1afd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-84293516-172.17.0.5-1596029580010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42088,DS-a07a2468-a3cb-45b1-b1f4-490d96c0cac4,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-804208b5-18ac-483d-a929-9cb7e033dff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-423a3107-c2f8-4963-bd9e-320485a853ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-28ec9f51-9743-4b5f-b742-b5797e0787b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-441b464e-e9d3-48a7-b0d6-163df423674d,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-a236417f-09c4-4bf0-a90f-8ed0f98ad828,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-b3b82224-d0f6-4c43-b5fb-6eb23bc675f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-09daf9ea-d6ec-4ebc-b184-289cd98e1afd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5175
