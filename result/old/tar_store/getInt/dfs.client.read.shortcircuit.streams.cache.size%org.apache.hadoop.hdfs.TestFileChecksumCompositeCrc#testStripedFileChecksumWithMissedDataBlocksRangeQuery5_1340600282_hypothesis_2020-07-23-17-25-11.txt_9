reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-610436253-172.17.0.12-1595525169830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43700,DS-08939002-276a-4cdd-9159-b67ae109a7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-5b9d2daf-cc4d-4332-b10d-9e79dc8ec547,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-0d0c7175-0184-4be1-9259-46d2c99bbf8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-f0988726-6061-4a30-818e-1b60fb3b699e,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-96e394d0-ced3-42c0-a192-d8fdfe029e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-f8b93723-c1b3-4b70-9694-932f4ec0c82a,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-9ef3f544-6cbe-4783-bfa9-8a22667b5eee,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-b6a565c6-f498-432a-8373-a07bc18d85a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-610436253-172.17.0.12-1595525169830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43700,DS-08939002-276a-4cdd-9159-b67ae109a7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-5b9d2daf-cc4d-4332-b10d-9e79dc8ec547,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-0d0c7175-0184-4be1-9259-46d2c99bbf8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-f0988726-6061-4a30-818e-1b60fb3b699e,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-96e394d0-ced3-42c0-a192-d8fdfe029e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-f8b93723-c1b3-4b70-9694-932f4ec0c82a,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-9ef3f544-6cbe-4783-bfa9-8a22667b5eee,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-b6a565c6-f498-432a-8373-a07bc18d85a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-568821074-172.17.0.12-1595527638883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33953,DS-a83f4763-3e04-4bd8-b4e5-e896f08254d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-324a55bd-6b2b-4339-89aa-b7fa1ee42621,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-5f14fe3d-89cc-41c2-a744-125b351f8ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-5cbbeac1-938a-44d6-85f3-a9eee849dc07,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-f1de0146-1cab-4121-b9cf-5839d3ab68d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-8c85c0ea-4e9a-4b4a-bcba-6aaa4a6f960d,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-65f3f759-dc14-4de0-bf7b-7a07ddc05083,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-dd8537f7-1cd6-498c-b6d1-fa8948b25cc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-568821074-172.17.0.12-1595527638883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33953,DS-a83f4763-3e04-4bd8-b4e5-e896f08254d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-324a55bd-6b2b-4339-89aa-b7fa1ee42621,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-5f14fe3d-89cc-41c2-a744-125b351f8ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-5cbbeac1-938a-44d6-85f3-a9eee849dc07,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-f1de0146-1cab-4121-b9cf-5839d3ab68d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-8c85c0ea-4e9a-4b4a-bcba-6aaa4a6f960d,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-65f3f759-dc14-4de0-bf7b-7a07ddc05083,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-dd8537f7-1cd6-498c-b6d1-fa8948b25cc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1583516059-172.17.0.12-1595528013407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43977,DS-9d9d665d-dd40-409b-ba08-954334ea092c,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-6942ceda-ca46-4ddd-9c21-1ceeb09aef6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-f1bb5d9a-08c1-443c-9bbd-55402a425426,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-a928d333-08a7-4d4b-84d1-f521ce778b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-c9bcbf55-16bc-49d9-85d7-b5deaf2f7a56,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-03f74df4-2d99-4ff2-b8e7-e8c00b613e67,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-00ab8988-5b78-4c27-807d-2e7c4380f126,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-4d0efe03-09a6-4096-8ebe-dc3d26130845,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1583516059-172.17.0.12-1595528013407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43977,DS-9d9d665d-dd40-409b-ba08-954334ea092c,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-6942ceda-ca46-4ddd-9c21-1ceeb09aef6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-f1bb5d9a-08c1-443c-9bbd-55402a425426,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-a928d333-08a7-4d4b-84d1-f521ce778b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-c9bcbf55-16bc-49d9-85d7-b5deaf2f7a56,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-03f74df4-2d99-4ff2-b8e7-e8c00b613e67,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-00ab8988-5b78-4c27-807d-2e7c4380f126,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-4d0efe03-09a6-4096-8ebe-dc3d26130845,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-916384734-172.17.0.12-1595528247042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41129,DS-e8bb2d06-fd63-45ec-9eb9-73fe10407519,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-aa2a28ba-d400-4d9a-932e-f2d708ae3096,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-0f57ddbe-c36d-450e-a4d8-cd58526260ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-eedddea5-aecb-425f-a5fc-eec4a4f805a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-beae9038-0503-4472-8042-ff368470c08f,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-884710c6-0cf1-4872-8fd0-36c890acb41b,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-4dcbd545-c31e-4bb7-b5ab-c2a761311b93,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-4c62a7fd-dfb7-4dd3-a1f2-81e9ba2407b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-916384734-172.17.0.12-1595528247042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41129,DS-e8bb2d06-fd63-45ec-9eb9-73fe10407519,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-aa2a28ba-d400-4d9a-932e-f2d708ae3096,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-0f57ddbe-c36d-450e-a4d8-cd58526260ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-eedddea5-aecb-425f-a5fc-eec4a4f805a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-beae9038-0503-4472-8042-ff368470c08f,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-884710c6-0cf1-4872-8fd0-36c890acb41b,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-4dcbd545-c31e-4bb7-b5ab-c2a761311b93,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-4c62a7fd-dfb7-4dd3-a1f2-81e9ba2407b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669485893-172.17.0.12-1595528314593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43807,DS-26b0669f-d6f0-48c9-a23e-a539b519f611,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-e09b6836-f6fe-46ff-aeb9-26d611e0c076,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-403ff781-0a8c-477e-a8d9-e06f7cdc4af4,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-2298d448-bcba-4c60-a1fa-eadd685789d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-a76561e5-5336-4f87-a1ac-0640926af875,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-720003d3-9de5-433d-8ce4-c837cc6154e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-b19e191a-7b1d-4b3e-b15a-72aa117df0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-7f997b21-3641-41e0-86d3-3854a8ec08f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669485893-172.17.0.12-1595528314593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43807,DS-26b0669f-d6f0-48c9-a23e-a539b519f611,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-e09b6836-f6fe-46ff-aeb9-26d611e0c076,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-403ff781-0a8c-477e-a8d9-e06f7cdc4af4,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-2298d448-bcba-4c60-a1fa-eadd685789d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-a76561e5-5336-4f87-a1ac-0640926af875,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-720003d3-9de5-433d-8ce4-c837cc6154e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-b19e191a-7b1d-4b3e-b15a-72aa117df0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-7f997b21-3641-41e0-86d3-3854a8ec08f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102125450-172.17.0.12-1595528355670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43902,DS-bdb4bd6f-d683-4fc0-af34-a96156b0a3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-857bab8f-a96c-43be-be43-f0ef45517412,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-d1a2f287-3439-4523-b6ac-c631f5a83b55,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-0da00043-b569-4423-a5ad-e8117283e0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-2583b0a8-1f20-41b3-8ee2-6b75c50688be,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-d256f624-56b8-4f2f-9d73-16a40b4b7fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-1a48c0d8-361c-41ef-869b-5db3b07fbdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-a17ac33a-061d-4218-a1f9-be8a5b4af68e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102125450-172.17.0.12-1595528355670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43902,DS-bdb4bd6f-d683-4fc0-af34-a96156b0a3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-857bab8f-a96c-43be-be43-f0ef45517412,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-d1a2f287-3439-4523-b6ac-c631f5a83b55,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-0da00043-b569-4423-a5ad-e8117283e0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-2583b0a8-1f20-41b3-8ee2-6b75c50688be,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-d256f624-56b8-4f2f-9d73-16a40b4b7fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-1a48c0d8-361c-41ef-869b-5db3b07fbdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-a17ac33a-061d-4218-a1f9-be8a5b4af68e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-366450859-172.17.0.12-1595528576323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34651,DS-be09e7ad-8673-40fb-9e30-16bbd740f4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-be2a4246-28f8-4c1f-8f9c-90d4e6045ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-8de4391d-8c68-4555-95b2-4a7963c57ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-3d735b75-377f-4037-bdc6-33aca9b71f21,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-60dd9494-b374-459f-8721-a6bb972b93fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-63a1cbc1-0311-477d-97ac-b612af8d5e59,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-d2bf3787-5028-4313-855c-0c97d3ec536c,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-5fae9bd4-24bc-43b7-8592-326a2d65e09e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-366450859-172.17.0.12-1595528576323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34651,DS-be09e7ad-8673-40fb-9e30-16bbd740f4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-be2a4246-28f8-4c1f-8f9c-90d4e6045ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-8de4391d-8c68-4555-95b2-4a7963c57ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-3d735b75-377f-4037-bdc6-33aca9b71f21,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-60dd9494-b374-459f-8721-a6bb972b93fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-63a1cbc1-0311-477d-97ac-b612af8d5e59,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-d2bf3787-5028-4313-855c-0c97d3ec536c,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-5fae9bd4-24bc-43b7-8592-326a2d65e09e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245678930-172.17.0.12-1595528709357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43861,DS-086eaf3c-0ad7-4370-93df-3c089bad189b,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-f30a0f95-be8d-4ed5-be39-13776294870a,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-570bc486-476f-4377-8536-ead9c3c06e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-bc71a7d9-8cf5-4cf5-9869-3837e1ea9ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-275ec24c-9814-4228-81e8-c67c4ed5befd,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-2ab3a829-2282-44dc-8146-34f31455829e,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-3a25fe23-ff96-4a3a-aa5c-301048f09504,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-6c9535bd-867e-4239-be04-86aa771ab658,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245678930-172.17.0.12-1595528709357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43861,DS-086eaf3c-0ad7-4370-93df-3c089bad189b,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-f30a0f95-be8d-4ed5-be39-13776294870a,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-570bc486-476f-4377-8536-ead9c3c06e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-bc71a7d9-8cf5-4cf5-9869-3837e1ea9ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-275ec24c-9814-4228-81e8-c67c4ed5befd,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-2ab3a829-2282-44dc-8146-34f31455829e,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-3a25fe23-ff96-4a3a-aa5c-301048f09504,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-6c9535bd-867e-4239-be04-86aa771ab658,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1290537192-172.17.0.12-1595529092439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32782,DS-587ba050-738a-4287-b251-98ce63083145,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-4aff73fe-2ff4-4d9c-bd35-dbfdec39a87f,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-b7c2fe78-6d0b-46bc-8b4c-44ce00a91aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-166e1301-3171-4db4-a343-675bc48618d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-8dda0426-83e6-4473-b0e3-c98723b73ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-1256cd4d-8df6-473d-939b-8cd19c259ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-0163d4eb-502d-4e41-bbbb-9de885fdd559,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-59358acc-6008-451c-9ebb-c9ca617e6120,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1290537192-172.17.0.12-1595529092439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32782,DS-587ba050-738a-4287-b251-98ce63083145,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-4aff73fe-2ff4-4d9c-bd35-dbfdec39a87f,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-b7c2fe78-6d0b-46bc-8b4c-44ce00a91aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-166e1301-3171-4db4-a343-675bc48618d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-8dda0426-83e6-4473-b0e3-c98723b73ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-1256cd4d-8df6-473d-939b-8cd19c259ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-0163d4eb-502d-4e41-bbbb-9de885fdd559,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-59358acc-6008-451c-9ebb-c9ca617e6120,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147007885-172.17.0.12-1595529421628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33504,DS-251195aa-94f4-483f-9b73-10667286a458,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-f3d96632-a708-4837-8c29-2dc15f89d99c,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-c95b7e9e-81fa-48a1-a6ae-5a94034f47da,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-69441510-5ff8-4742-80f4-359105a009a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-2cecd800-05a7-43b8-b81b-146a70844e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-be04f68c-81ea-41e3-a312-ef474a261b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-0ad24612-d344-435b-869b-16f8b98ea48c,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-36e110d9-41c1-489d-9d0f-caba61411614,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147007885-172.17.0.12-1595529421628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33504,DS-251195aa-94f4-483f-9b73-10667286a458,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-f3d96632-a708-4837-8c29-2dc15f89d99c,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-c95b7e9e-81fa-48a1-a6ae-5a94034f47da,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-69441510-5ff8-4742-80f4-359105a009a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-2cecd800-05a7-43b8-b81b-146a70844e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-be04f68c-81ea-41e3-a312-ef474a261b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-0ad24612-d344-435b-869b-16f8b98ea48c,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-36e110d9-41c1-489d-9d0f-caba61411614,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103561032-172.17.0.12-1595529492859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38600,DS-911270cd-0053-4350-adff-77046c19879a,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-6763ca18-b7da-43e7-87d0-b3f09acea06a,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-5b403a2a-716c-49c8-abbe-f8e4e534a961,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-93f8f6c0-e2d4-4391-b45b-4158694c16bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-7a664c08-898a-4efe-bcdc-5c1b23b770ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-35a10418-d1a5-4ace-8a50-f2d43902b847,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-c774fa9c-2202-4fae-ac94-b9717e435c35,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-4cfd5e1b-d3f1-4b69-863d-1166824ac8ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103561032-172.17.0.12-1595529492859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38600,DS-911270cd-0053-4350-adff-77046c19879a,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-6763ca18-b7da-43e7-87d0-b3f09acea06a,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-5b403a2a-716c-49c8-abbe-f8e4e534a961,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-93f8f6c0-e2d4-4391-b45b-4158694c16bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-7a664c08-898a-4efe-bcdc-5c1b23b770ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-35a10418-d1a5-4ace-8a50-f2d43902b847,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-c774fa9c-2202-4fae-ac94-b9717e435c35,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-4cfd5e1b-d3f1-4b69-863d-1166824ac8ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786265094-172.17.0.12-1595529719302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44928,DS-33c81639-1472-405c-b4a0-7e58c7219df4,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-8927907f-3f5e-4fba-b704-a062293c2628,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-8c218799-0287-4647-8469-b7db03beea1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-5761c622-8430-4d33-9ddb-c23ae4bff388,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-1b7550db-b608-4fb2-9b0f-285a1af9f355,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-9a3e8ffc-ef54-4983-a6e2-622e49be4072,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-0f669086-2904-4501-8a69-71e19414c5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-fe3341ec-c634-4562-8809-84c9598d5a73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786265094-172.17.0.12-1595529719302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44928,DS-33c81639-1472-405c-b4a0-7e58c7219df4,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-8927907f-3f5e-4fba-b704-a062293c2628,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-8c218799-0287-4647-8469-b7db03beea1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-5761c622-8430-4d33-9ddb-c23ae4bff388,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-1b7550db-b608-4fb2-9b0f-285a1af9f355,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-9a3e8ffc-ef54-4983-a6e2-622e49be4072,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-0f669086-2904-4501-8a69-71e19414c5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-fe3341ec-c634-4562-8809-84c9598d5a73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148597938-172.17.0.12-1595530083945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40196,DS-359c2395-0303-4922-a537-7ec60bc07adf,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-cef51b10-a7c8-4dee-bc28-bc47846a6526,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-72527564-e4fe-41ee-b7c9-c924dbdd3517,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-b950348c-7943-49d5-8cb1-f5ae1152299c,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-cfb04b61-1d20-4098-9cb3-17816186d4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-dbf62475-c5a9-4d30-831b-de9185528b50,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-db7ce21c-72c6-4abe-9822-ca4cc2fb969f,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-526987a1-3927-4b63-9815-a6ce8a966aba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148597938-172.17.0.12-1595530083945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40196,DS-359c2395-0303-4922-a537-7ec60bc07adf,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-cef51b10-a7c8-4dee-bc28-bc47846a6526,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-72527564-e4fe-41ee-b7c9-c924dbdd3517,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-b950348c-7943-49d5-8cb1-f5ae1152299c,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-cfb04b61-1d20-4098-9cb3-17816186d4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-dbf62475-c5a9-4d30-831b-de9185528b50,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-db7ce21c-72c6-4abe-9822-ca4cc2fb969f,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-526987a1-3927-4b63-9815-a6ce8a966aba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5440
