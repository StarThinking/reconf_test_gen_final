reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1647002571-172.17.0.2-1595562128286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44518,DS-939104ef-5312-4bdd-9618-4a11af7d1d06,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-6a5412aa-ede0-4a55-abb5-14f4bb620cda,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-bb558efd-0597-428b-9bbb-9b5eb19099fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-f1a8943c-a3e5-4722-b925-992434f33c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-d00cf0af-c3ff-46cb-8b79-765b5a977e96,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-e148bb65-0f54-4fdb-be9e-bbe5d922c550,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-cd58cba1-8a4a-4fd2-a9e3-e3a26ffa1495,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-a6373507-d2f7-4ecc-9ea0-66cc0ad644ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1647002571-172.17.0.2-1595562128286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44518,DS-939104ef-5312-4bdd-9618-4a11af7d1d06,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-6a5412aa-ede0-4a55-abb5-14f4bb620cda,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-bb558efd-0597-428b-9bbb-9b5eb19099fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-f1a8943c-a3e5-4722-b925-992434f33c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-d00cf0af-c3ff-46cb-8b79-765b5a977e96,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-e148bb65-0f54-4fdb-be9e-bbe5d922c550,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-cd58cba1-8a4a-4fd2-a9e3-e3a26ffa1495,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-a6373507-d2f7-4ecc-9ea0-66cc0ad644ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713170280-172.17.0.2-1595562799464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43955,DS-8443f689-5a6e-4a0a-97a1-8798c4ed2765,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-511db2aa-5bb6-4935-8d54-df9d99c57265,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-03747b85-1fa0-4074-9bc4-d18fbf2244a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-bf2da09b-09d2-4908-ad49-a2a2919f3183,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-dee60695-7fa1-4a80-842d-d4040a1e702a,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-96109d12-00b6-456d-a434-83507b1f5a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-fec743d1-efb7-459b-b5c3-74367073ea96,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-5c3a94c1-2563-4ba3-aa2a-cf1a4e5c61aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713170280-172.17.0.2-1595562799464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43955,DS-8443f689-5a6e-4a0a-97a1-8798c4ed2765,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-511db2aa-5bb6-4935-8d54-df9d99c57265,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-03747b85-1fa0-4074-9bc4-d18fbf2244a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-bf2da09b-09d2-4908-ad49-a2a2919f3183,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-dee60695-7fa1-4a80-842d-d4040a1e702a,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-96109d12-00b6-456d-a434-83507b1f5a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-fec743d1-efb7-459b-b5c3-74367073ea96,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-5c3a94c1-2563-4ba3-aa2a-cf1a4e5c61aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2025677466-172.17.0.2-1595563355510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36385,DS-26cc8ed4-1e75-40ed-afd1-352a23eba5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-51e97f7f-fbf1-47d1-bc3b-c3b150fb6842,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-dc9a15a0-83ef-4d64-a5a9-093ed9884c52,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-e9aa3fbc-bf31-464c-9120-a42b86ca3c51,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-c2b0381c-0f47-4a88-907e-b0cf56c4a615,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-755d348c-a723-45a2-b0e9-815707036beb,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-489235d9-292f-4e30-a0d4-7b4ae8ba9cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-4046773b-815c-461e-bbf3-772a0adb440e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2025677466-172.17.0.2-1595563355510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36385,DS-26cc8ed4-1e75-40ed-afd1-352a23eba5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-51e97f7f-fbf1-47d1-bc3b-c3b150fb6842,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-dc9a15a0-83ef-4d64-a5a9-093ed9884c52,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-e9aa3fbc-bf31-464c-9120-a42b86ca3c51,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-c2b0381c-0f47-4a88-907e-b0cf56c4a615,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-755d348c-a723-45a2-b0e9-815707036beb,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-489235d9-292f-4e30-a0d4-7b4ae8ba9cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-4046773b-815c-461e-bbf3-772a0adb440e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542814448-172.17.0.2-1595564071479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34184,DS-ebb1133d-67df-414c-a153-6f541124b087,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-a312ce18-b71f-42db-9fae-fc15901b83a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-5ceb7250-d986-4066-8191-cef281c9dcb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-8e28bd40-c9f8-4a24-8848-7b7191ccfcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-2ac5ef71-380e-48ae-9eb5-a87ea004aa46,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-a9bee8d7-c131-498c-8bb7-36315b150bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-5b51dc05-ccb2-4f92-8403-af2fc4ac0992,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-c6e2a161-c4b9-444b-b115-1e675597f5b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542814448-172.17.0.2-1595564071479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34184,DS-ebb1133d-67df-414c-a153-6f541124b087,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-a312ce18-b71f-42db-9fae-fc15901b83a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-5ceb7250-d986-4066-8191-cef281c9dcb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-8e28bd40-c9f8-4a24-8848-7b7191ccfcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-2ac5ef71-380e-48ae-9eb5-a87ea004aa46,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-a9bee8d7-c131-498c-8bb7-36315b150bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-5b51dc05-ccb2-4f92-8403-af2fc4ac0992,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-c6e2a161-c4b9-444b-b115-1e675597f5b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1124543198-172.17.0.2-1595564183677:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43847,DS-4e85de23-d191-41da-80ac-4ad1434d3a45,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-9619922b-ec6b-433d-b8c9-80c121114a16,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-d830674a-c9d7-4fab-82a3-fd7ed0c3f59d,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-d244e25b-cabf-4f9d-b5b4-52f4ed2805d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-4efc2eee-69da-4b58-9096-de8803cfc441,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-2c603378-9606-45d9-8dda-3b792b86f560,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-264b4e41-895e-46bc-a517-96e6843c1465,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-fbfeec4d-0744-493c-9e59-40ae8d374d9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1124543198-172.17.0.2-1595564183677:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43847,DS-4e85de23-d191-41da-80ac-4ad1434d3a45,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-9619922b-ec6b-433d-b8c9-80c121114a16,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-d830674a-c9d7-4fab-82a3-fd7ed0c3f59d,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-d244e25b-cabf-4f9d-b5b4-52f4ed2805d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-4efc2eee-69da-4b58-9096-de8803cfc441,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-2c603378-9606-45d9-8dda-3b792b86f560,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-264b4e41-895e-46bc-a517-96e6843c1465,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-fbfeec4d-0744-493c-9e59-40ae8d374d9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2079005019-172.17.0.2-1595564764164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38130,DS-f3e43212-df76-4248-b0e4-8244c72e0e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-2554987a-d764-41f1-8858-49cb21b2b9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-3cb81efe-e6b9-40b0-a39e-71024ac003ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-b5b3460d-11b6-4c39-b940-0ee909df3202,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-d1205152-f372-4ca4-bdcc-66c096be1426,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-26396f75-d7d0-4945-bea0-cfcf1a9765a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-04f9894c-b101-43a5-aa85-56f9fca763d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-74a1e6ad-629b-4fdf-8045-ba146ed100a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2079005019-172.17.0.2-1595564764164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38130,DS-f3e43212-df76-4248-b0e4-8244c72e0e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-2554987a-d764-41f1-8858-49cb21b2b9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-3cb81efe-e6b9-40b0-a39e-71024ac003ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-b5b3460d-11b6-4c39-b940-0ee909df3202,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-d1205152-f372-4ca4-bdcc-66c096be1426,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-26396f75-d7d0-4945-bea0-cfcf1a9765a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-04f9894c-b101-43a5-aa85-56f9fca763d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-74a1e6ad-629b-4fdf-8045-ba146ed100a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-618459281-172.17.0.2-1595564943319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43248,DS-2b4fae76-d373-482c-abb2-30ce0627b38d,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-0809efe2-01ec-4074-be94-4baddcfe528e,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-3f74a2ad-7fcd-4547-bd4d-bab432e70de3,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-c23ddea4-2c19-4243-b3ef-e24540d1460c,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-d7218545-5929-4381-b1c6-8f189f0389dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-4d48b7da-705e-48b8-b61c-d8dc754e0d60,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-bd875323-ba01-4e21-b8e1-bf90664cc714,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-bdf91e28-1865-42c5-9f25-97276450c706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-618459281-172.17.0.2-1595564943319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43248,DS-2b4fae76-d373-482c-abb2-30ce0627b38d,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-0809efe2-01ec-4074-be94-4baddcfe528e,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-3f74a2ad-7fcd-4547-bd4d-bab432e70de3,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-c23ddea4-2c19-4243-b3ef-e24540d1460c,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-d7218545-5929-4381-b1c6-8f189f0389dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-4d48b7da-705e-48b8-b61c-d8dc754e0d60,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-bd875323-ba01-4e21-b8e1-bf90664cc714,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-bdf91e28-1865-42c5-9f25-97276450c706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2031518394-172.17.0.2-1595565407479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43046,DS-7ea8a8c5-b984-4fe4-866c-1804f56a4153,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-b550c597-3a94-4276-a1fb-a456bf5227b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-2864a2db-a6af-48f8-8058-91cc91fad70a,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-3efbb9bd-c5dd-41be-b5b1-ae3b17b33e80,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-e9f64862-2fb5-4136-b5f1-33d79531d7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-fceb2be5-fb07-4426-ba4c-23b04ec350b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-2cd130e0-f4ae-4cb4-a153-a513d1f22714,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-deb86fea-36a1-4738-b212-137c095eeefa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2031518394-172.17.0.2-1595565407479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43046,DS-7ea8a8c5-b984-4fe4-866c-1804f56a4153,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-b550c597-3a94-4276-a1fb-a456bf5227b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-2864a2db-a6af-48f8-8058-91cc91fad70a,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-3efbb9bd-c5dd-41be-b5b1-ae3b17b33e80,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-e9f64862-2fb5-4136-b5f1-33d79531d7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-fceb2be5-fb07-4426-ba4c-23b04ec350b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-2cd130e0-f4ae-4cb4-a153-a513d1f22714,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-deb86fea-36a1-4738-b212-137c095eeefa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-177152496-172.17.0.2-1595565444028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39752,DS-50e99b0e-4be1-4714-864f-c7b8b6fbeacc,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-2adbd175-8bd2-4b93-a21c-5a1358faf7df,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-a0d250ac-cc63-4895-b303-f8b7360d3246,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-c88a8043-77ed-4d25-a25c-3ab07834e793,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-6672279b-f74c-4f29-944e-84ddf4bb24e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-c0df73db-a803-4b4c-b3b6-81e3790b5051,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-fd1fefb4-50c6-49ee-be9c-f10e904e2e92,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-16a37760-60cf-4788-81eb-c334706db50a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-177152496-172.17.0.2-1595565444028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39752,DS-50e99b0e-4be1-4714-864f-c7b8b6fbeacc,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-2adbd175-8bd2-4b93-a21c-5a1358faf7df,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-a0d250ac-cc63-4895-b303-f8b7360d3246,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-c88a8043-77ed-4d25-a25c-3ab07834e793,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-6672279b-f74c-4f29-944e-84ddf4bb24e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-c0df73db-a803-4b4c-b3b6-81e3790b5051,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-fd1fefb4-50c6-49ee-be9c-f10e904e2e92,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-16a37760-60cf-4788-81eb-c334706db50a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1401512666-172.17.0.2-1595565523356:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36803,DS-fe98722f-f10c-4995-a98f-3de1fc6847f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-c681a682-dce7-4d87-aad7-a52d8f5d450e,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-be5f4f9d-c71b-4dc9-aec4-98239b62dbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-c1077c93-2a2f-4c81-832f-a550bbeef58a,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-acc2c913-4f46-4376-a7ea-aff8ef8bc5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-4a0010a0-5473-45a9-ba46-4de3c7f60f67,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-f6f337dd-fbc5-4f0d-b9c4-1c95d46824b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-94964ea7-d724-4025-abee-00e786827219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1401512666-172.17.0.2-1595565523356:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36803,DS-fe98722f-f10c-4995-a98f-3de1fc6847f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-c681a682-dce7-4d87-aad7-a52d8f5d450e,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-be5f4f9d-c71b-4dc9-aec4-98239b62dbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-c1077c93-2a2f-4c81-832f-a550bbeef58a,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-acc2c913-4f46-4376-a7ea-aff8ef8bc5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-4a0010a0-5473-45a9-ba46-4de3c7f60f67,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-f6f337dd-fbc5-4f0d-b9c4-1c95d46824b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-94964ea7-d724-4025-abee-00e786827219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1215272099-172.17.0.2-1595566138234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45697,DS-97b931a5-d3c8-4ccb-9aca-4e5210c30d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-63ef63c8-e4c6-439e-86b6-6da5c7a26b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-f4240b89-7288-4eef-afe9-d5c335660955,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-ff1ed371-bb4c-4e64-840d-d870db08718c,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-74a76c93-fdfe-4d26-b5e4-18e9abc7b95a,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-d0515431-ab4a-4bd1-aaee-4412965719fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-49ba664e-0c4b-404e-89ed-ba9e4d2a8e47,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-0b33311d-11ef-4d84-a751-7581c675e237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1215272099-172.17.0.2-1595566138234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45697,DS-97b931a5-d3c8-4ccb-9aca-4e5210c30d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-63ef63c8-e4c6-439e-86b6-6da5c7a26b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-f4240b89-7288-4eef-afe9-d5c335660955,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-ff1ed371-bb4c-4e64-840d-d870db08718c,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-74a76c93-fdfe-4d26-b5e4-18e9abc7b95a,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-d0515431-ab4a-4bd1-aaee-4412965719fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-49ba664e-0c4b-404e-89ed-ba9e4d2a8e47,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-0b33311d-11ef-4d84-a751-7581c675e237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-451332577-172.17.0.2-1595566326672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41383,DS-b66e5075-671b-43bc-9796-18ab0a3070eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-0f1ac2dc-eec1-409e-9ece-b6636fb239cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-89c8841a-4c25-4660-b5e9-0419ea06d17c,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-a2e54435-363a-459c-94a9-c6f9e297186f,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-e1724b76-d9ab-42ac-8bcd-5fdd2cda25f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-e04644e2-b9e4-4ade-8b7d-56f4c323b829,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-a15cb9f3-7dcd-445c-aa43-f823a0a343e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-5e0c973c-3846-466a-aedb-a928fbeece80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-451332577-172.17.0.2-1595566326672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41383,DS-b66e5075-671b-43bc-9796-18ab0a3070eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-0f1ac2dc-eec1-409e-9ece-b6636fb239cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-89c8841a-4c25-4660-b5e9-0419ea06d17c,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-a2e54435-363a-459c-94a9-c6f9e297186f,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-e1724b76-d9ab-42ac-8bcd-5fdd2cda25f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-e04644e2-b9e4-4ade-8b7d-56f4c323b829,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-a15cb9f3-7dcd-445c-aa43-f823a0a343e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-5e0c973c-3846-466a-aedb-a928fbeece80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-281159109-172.17.0.2-1595566369592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36917,DS-d70103c8-d29f-4116-b135-1c7183e7373d,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-ecb28ab9-f38d-41e8-9a79-a0792a488f86,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-3ccb35d6-2c6e-4b7a-a69c-39c4dd9a091d,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-a1e455eb-6b6e-4ee3-959b-16375eb5212a,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-56ca4b72-57d7-4ffd-84f5-01dda1e3e3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-9b7424ba-1455-4447-8e71-13c2788753d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-e8357790-3f04-4640-881d-c798b040d743,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-00112dd6-1b9e-4efa-b52b-9dbfff393c40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-281159109-172.17.0.2-1595566369592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36917,DS-d70103c8-d29f-4116-b135-1c7183e7373d,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-ecb28ab9-f38d-41e8-9a79-a0792a488f86,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-3ccb35d6-2c6e-4b7a-a69c-39c4dd9a091d,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-a1e455eb-6b6e-4ee3-959b-16375eb5212a,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-56ca4b72-57d7-4ffd-84f5-01dda1e3e3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-9b7424ba-1455-4447-8e71-13c2788753d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-e8357790-3f04-4640-881d-c798b040d743,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-00112dd6-1b9e-4efa-b52b-9dbfff393c40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118078809-172.17.0.2-1595566695957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46615,DS-263fc14a-19c2-40df-902c-1c7ff9ac54a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-9fb1d510-0232-4858-8172-59ec9d54db51,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-93211fac-eeaf-4699-b345-80e59e47f571,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-bf979e67-b46d-4bce-8d2e-e4cb04d5335b,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-4edb8172-7293-47e5-8f02-170ee2da23c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-22c0ac1f-296c-403e-8616-c0c637e4e21a,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-57088b66-519c-4091-9e5a-c2831d8bcb01,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-32abc883-a425-458f-908f-7ad154d98737,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118078809-172.17.0.2-1595566695957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46615,DS-263fc14a-19c2-40df-902c-1c7ff9ac54a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-9fb1d510-0232-4858-8172-59ec9d54db51,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-93211fac-eeaf-4699-b345-80e59e47f571,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-bf979e67-b46d-4bce-8d2e-e4cb04d5335b,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-4edb8172-7293-47e5-8f02-170ee2da23c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-22c0ac1f-296c-403e-8616-c0c637e4e21a,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-57088b66-519c-4091-9e5a-c2831d8bcb01,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-32abc883-a425-458f-908f-7ad154d98737,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-912282898-172.17.0.2-1595567098487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40469,DS-8e4883e3-6ade-49a6-8383-0e8502600fde,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-13066b7b-3f22-4080-a7cc-4ef35ba9b686,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-aee0a021-c82a-4481-a94b-007a33716a19,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-5d82abd3-6f2a-4640-8997-7d63ea42d537,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-00b4eb82-4beb-4ad3-af51-38b82137a609,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-89a446e7-1bdb-4ca7-a382-9bc4371e7e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-a7a0bb59-59e5-4ad3-a037-ce1d09db0ece,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-304d2a95-a75e-48ea-8e25-84f358b2f0d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-912282898-172.17.0.2-1595567098487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40469,DS-8e4883e3-6ade-49a6-8383-0e8502600fde,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-13066b7b-3f22-4080-a7cc-4ef35ba9b686,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-aee0a021-c82a-4481-a94b-007a33716a19,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-5d82abd3-6f2a-4640-8997-7d63ea42d537,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-00b4eb82-4beb-4ad3-af51-38b82137a609,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-89a446e7-1bdb-4ca7-a382-9bc4371e7e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-a7a0bb59-59e5-4ad3-a037-ce1d09db0ece,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-304d2a95-a75e-48ea-8e25-84f358b2f0d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5308
