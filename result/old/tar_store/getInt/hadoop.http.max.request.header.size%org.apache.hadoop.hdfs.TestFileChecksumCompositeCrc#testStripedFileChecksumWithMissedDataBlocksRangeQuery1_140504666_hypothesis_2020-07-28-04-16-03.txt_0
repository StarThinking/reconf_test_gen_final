reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-585745511-172.17.0.14-1595909875258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33753,DS-ce5657a5-f063-4720-936b-10ed960f899b,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-a69a90ec-ab94-42f6-a0c1-ce2c2e0cdb63,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-763e2a72-acb7-4c9c-941e-4a57bb57382c,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-d3ee0c91-db16-447d-89a6-81f831b6bda9,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-fef675b9-296f-407e-908a-9862fff625a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-82627938-150d-412d-82e3-1e703159cc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-f5685de4-8877-4b32-82ff-634fd6fceb05,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-b70ac44d-75a4-4a85-9c1b-0e21d5b19223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-585745511-172.17.0.14-1595909875258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33753,DS-ce5657a5-f063-4720-936b-10ed960f899b,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-a69a90ec-ab94-42f6-a0c1-ce2c2e0cdb63,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-763e2a72-acb7-4c9c-941e-4a57bb57382c,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-d3ee0c91-db16-447d-89a6-81f831b6bda9,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-fef675b9-296f-407e-908a-9862fff625a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-82627938-150d-412d-82e3-1e703159cc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-f5685de4-8877-4b32-82ff-634fd6fceb05,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-b70ac44d-75a4-4a85-9c1b-0e21d5b19223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567642836-172.17.0.14-1595910202956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33895,DS-05998d91-550f-4ba7-876f-28b3f3d2fe47,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-2917a31c-5297-4b95-9edd-0f40eaae4fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-74dea757-95f3-4020-a47d-79d30b932806,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-e920cf18-a6e2-4cbc-8cc7-e17c7fb8d77b,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-6106e118-f6b2-4eb3-b563-75cd1c1cd3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-449e2216-dd66-4f02-8825-545478db297c,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-8e92c5ff-10ba-460b-85d5-d8c25da6cec5,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-e6ee1f00-88f3-4d2e-89ee-05f79bcda8f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567642836-172.17.0.14-1595910202956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33895,DS-05998d91-550f-4ba7-876f-28b3f3d2fe47,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-2917a31c-5297-4b95-9edd-0f40eaae4fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-74dea757-95f3-4020-a47d-79d30b932806,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-e920cf18-a6e2-4cbc-8cc7-e17c7fb8d77b,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-6106e118-f6b2-4eb3-b563-75cd1c1cd3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-449e2216-dd66-4f02-8825-545478db297c,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-8e92c5ff-10ba-460b-85d5-d8c25da6cec5,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-e6ee1f00-88f3-4d2e-89ee-05f79bcda8f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201120263-172.17.0.14-1595910384967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42834,DS-2f15d2d4-ac10-4c5b-ad98-1df89220978a,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-464cf38f-1e64-496d-80e5-1e2dd5fec04c,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-1e96c761-685c-4bed-a58f-7eb0b1235121,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-cc01913c-0a7d-41c4-9425-60f55d657bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-04feb7c9-a65b-420f-812d-c2cb669e7082,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-9e2ef45a-0fa1-4f08-9de1-573d5138de91,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-44dcd00b-a281-4718-b560-53dd8ad323d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-daf83fcd-710b-4080-88e2-a030ba79841f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201120263-172.17.0.14-1595910384967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42834,DS-2f15d2d4-ac10-4c5b-ad98-1df89220978a,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-464cf38f-1e64-496d-80e5-1e2dd5fec04c,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-1e96c761-685c-4bed-a58f-7eb0b1235121,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-cc01913c-0a7d-41c4-9425-60f55d657bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-04feb7c9-a65b-420f-812d-c2cb669e7082,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-9e2ef45a-0fa1-4f08-9de1-573d5138de91,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-44dcd00b-a281-4718-b560-53dd8ad323d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-daf83fcd-710b-4080-88e2-a030ba79841f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638390685-172.17.0.14-1595910614358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37600,DS-af4e2303-edce-48e8-a2a0-d3c719460363,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-fa08592e-19a4-4512-ae70-44d9141d202e,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-69618a8d-25a3-401c-b4a4-8aac5fb292dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-ad775849-c2d0-45a1-8e88-543ba997a670,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-5866f5b8-aa16-4432-9cab-e3f9fc2c0ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-c80db2ff-f5b6-4bac-9408-74476bebb3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-9abb8fda-5928-4f0a-a7f3-9bbef6e34e50,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-7b150588-7ab8-45b3-a65f-9d78c4c141dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638390685-172.17.0.14-1595910614358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37600,DS-af4e2303-edce-48e8-a2a0-d3c719460363,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-fa08592e-19a4-4512-ae70-44d9141d202e,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-69618a8d-25a3-401c-b4a4-8aac5fb292dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-ad775849-c2d0-45a1-8e88-543ba997a670,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-5866f5b8-aa16-4432-9cab-e3f9fc2c0ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-c80db2ff-f5b6-4bac-9408-74476bebb3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-9abb8fda-5928-4f0a-a7f3-9bbef6e34e50,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-7b150588-7ab8-45b3-a65f-9d78c4c141dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-773611258-172.17.0.14-1595911307352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33613,DS-96335534-5fe7-4824-b797-7e7db1030ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-8a2075ae-c0de-4c53-935e-b583a0c34dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-47f44d5c-518d-4008-b8fa-2218eecdd392,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-4d31a33e-5ba8-4f7a-b454-21000e2cfe03,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-08e5904e-c406-4203-8b81-9f71b7dfeb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-52df047d-3501-4641-b8b0-5218d531b067,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-5fa7c9fc-38ea-47a7-a457-ea84dee6d41e,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-2d08509f-9378-428e-a6ae-76cb7fa78cc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-773611258-172.17.0.14-1595911307352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33613,DS-96335534-5fe7-4824-b797-7e7db1030ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-8a2075ae-c0de-4c53-935e-b583a0c34dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-47f44d5c-518d-4008-b8fa-2218eecdd392,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-4d31a33e-5ba8-4f7a-b454-21000e2cfe03,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-08e5904e-c406-4203-8b81-9f71b7dfeb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-52df047d-3501-4641-b8b0-5218d531b067,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-5fa7c9fc-38ea-47a7-a457-ea84dee6d41e,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-2d08509f-9378-428e-a6ae-76cb7fa78cc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1801117907-172.17.0.14-1595912148836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41809,DS-baba4b78-5def-4858-be60-cf1ac76bab2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-cd2a0155-d40f-4e28-acfa-cea0db5cb874,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-400fb6b7-981c-44db-b498-7c5ac70cc5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-35d8be87-3851-4204-9b57-594216462d73,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-ba69edaf-a93d-4642-b386-f24c0fa59dae,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-fdf57619-596a-498e-ad5e-ae896722e942,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-1e213713-a1c1-497b-bdc1-d45837035e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-7f778255-3a01-4fdf-8e4f-7ed6ab7fa60e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1801117907-172.17.0.14-1595912148836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41809,DS-baba4b78-5def-4858-be60-cf1ac76bab2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-cd2a0155-d40f-4e28-acfa-cea0db5cb874,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-400fb6b7-981c-44db-b498-7c5ac70cc5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-35d8be87-3851-4204-9b57-594216462d73,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-ba69edaf-a93d-4642-b386-f24c0fa59dae,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-fdf57619-596a-498e-ad5e-ae896722e942,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-1e213713-a1c1-497b-bdc1-d45837035e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-7f778255-3a01-4fdf-8e4f-7ed6ab7fa60e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-29519393-172.17.0.14-1595912347332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40675,DS-45b79653-ea14-48d4-9561-b255958c7f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-631aa567-1543-4c9c-92c0-0ca366bd1f89,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-80b955ce-2098-4d4f-8e80-dbc2632e8b19,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-cad9aff4-47ac-4a60-a3d0-27c8c252d04b,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-0c40f785-79b5-4eee-b68f-620f6b2a8d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-4b0696b1-a971-42e1-86dd-3e84903bcf12,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-41ca70dc-7163-4146-9736-781d511c1677,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-ab63d4b4-a557-489a-ad27-7802fcda5f3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-29519393-172.17.0.14-1595912347332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40675,DS-45b79653-ea14-48d4-9561-b255958c7f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-631aa567-1543-4c9c-92c0-0ca366bd1f89,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-80b955ce-2098-4d4f-8e80-dbc2632e8b19,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-cad9aff4-47ac-4a60-a3d0-27c8c252d04b,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-0c40f785-79b5-4eee-b68f-620f6b2a8d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-4b0696b1-a971-42e1-86dd-3e84903bcf12,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-41ca70dc-7163-4146-9736-781d511c1677,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-ab63d4b4-a557-489a-ad27-7802fcda5f3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143468209-172.17.0.14-1595912467397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45890,DS-d86235a3-c2bc-4590-a3de-b88e3e87f5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-c77d16b5-27bf-481d-aa2a-cdf0e7b3462b,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-5c280da9-7c05-4bd1-91f5-de778a7058fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-ef627011-ceac-408d-af49-ddf223da74de,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-46810cc7-44d5-423f-a7ee-5660e5cff613,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-29465839-d81c-4432-abd8-6fa80415345b,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-d066a13b-7e01-439a-85b0-b96cff3893a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-1e0ccb18-4d34-48ee-96fb-21b96323dc1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143468209-172.17.0.14-1595912467397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45890,DS-d86235a3-c2bc-4590-a3de-b88e3e87f5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-c77d16b5-27bf-481d-aa2a-cdf0e7b3462b,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-5c280da9-7c05-4bd1-91f5-de778a7058fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-ef627011-ceac-408d-af49-ddf223da74de,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-46810cc7-44d5-423f-a7ee-5660e5cff613,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-29465839-d81c-4432-abd8-6fa80415345b,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-d066a13b-7e01-439a-85b0-b96cff3893a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-1e0ccb18-4d34-48ee-96fb-21b96323dc1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186699841-172.17.0.14-1595913787225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37224,DS-a3f4352d-c2d1-4b07-9d1d-72561dc955e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-b5379122-987f-48b7-84fa-4d9fc10b430b,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-a992cc9e-e78d-4bff-b490-075b851f8c81,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-686abfcf-92a6-40e1-afdb-01b954210c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-b8502a3f-274b-4321-938f-c04e89c25b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-49e8a4e0-ed70-474c-ae86-8042ee121736,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-38b3bd1c-32b1-4c5b-b669-59f2ab29ed66,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-7a3c2a95-ea98-4ba4-b6ff-bd8ef6838fad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186699841-172.17.0.14-1595913787225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37224,DS-a3f4352d-c2d1-4b07-9d1d-72561dc955e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-b5379122-987f-48b7-84fa-4d9fc10b430b,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-a992cc9e-e78d-4bff-b490-075b851f8c81,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-686abfcf-92a6-40e1-afdb-01b954210c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-b8502a3f-274b-4321-938f-c04e89c25b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-49e8a4e0-ed70-474c-ae86-8042ee121736,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-38b3bd1c-32b1-4c5b-b669-59f2ab29ed66,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-7a3c2a95-ea98-4ba4-b6ff-bd8ef6838fad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089510113-172.17.0.14-1595914221143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34868,DS-02e1b2cf-50e6-480c-a2b2-1d3a4858f0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-2d1fdd37-0f11-4a9b-98b3-23dba18c222b,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-b62a3511-ef75-452d-be41-bc392759af74,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-cd9c1e8b-5823-4acf-9d5d-d58fdcf6cbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-c78e0c6d-00d1-4af2-8c0c-97c5433d28ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-04558c00-6751-474e-9a15-af76f4614f39,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-c7b17731-08b3-4337-9c05-724bf9ca66e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-b1da981e-cea5-42e1-ba3b-a98f21e36604,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089510113-172.17.0.14-1595914221143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34868,DS-02e1b2cf-50e6-480c-a2b2-1d3a4858f0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-2d1fdd37-0f11-4a9b-98b3-23dba18c222b,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-b62a3511-ef75-452d-be41-bc392759af74,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-cd9c1e8b-5823-4acf-9d5d-d58fdcf6cbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-c78e0c6d-00d1-4af2-8c0c-97c5433d28ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-04558c00-6751-474e-9a15-af76f4614f39,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-c7b17731-08b3-4337-9c05-724bf9ca66e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-b1da981e-cea5-42e1-ba3b-a98f21e36604,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622920557-172.17.0.14-1595914617056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38132,DS-d53650f5-78b8-4fd5-a035-b65a84366fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-9fa58ac6-e0a6-42f8-adcd-bda5b41f0cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-6d21351a-0d2c-49b4-b8d7-515885fbccc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-5f0e2309-bc38-47e6-96eb-8d999676a653,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-de347458-61ae-4aee-93db-2bcb9483e7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-c1bbd77e-b5b5-4c37-8f82-56789bcbe274,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-e0b243c6-ffdb-432a-b823-ed7727ed8cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-bdc74192-febd-40d2-9eb2-56de241b481f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622920557-172.17.0.14-1595914617056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38132,DS-d53650f5-78b8-4fd5-a035-b65a84366fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-9fa58ac6-e0a6-42f8-adcd-bda5b41f0cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-6d21351a-0d2c-49b4-b8d7-515885fbccc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-5f0e2309-bc38-47e6-96eb-8d999676a653,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-de347458-61ae-4aee-93db-2bcb9483e7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-c1bbd77e-b5b5-4c37-8f82-56789bcbe274,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-e0b243c6-ffdb-432a-b823-ed7727ed8cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-bdc74192-febd-40d2-9eb2-56de241b481f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782697428-172.17.0.14-1595915403465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38593,DS-add3cdaa-aac2-49f9-80d6-a720de6a1baf,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-98d36be0-3d5d-4fe6-a759-c76fd7edf833,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-99f497c3-d69a-4f55-9dbb-4be4e3c3ef6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-9f71e9e9-5c07-4970-802c-51fbe45906bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-2391e287-74cd-4b18-acc6-c8aba53e1673,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-eb1847b3-3add-43ad-814d-41d9f37e1c46,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-43265a51-4756-4279-a866-3689356598ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-85ea2387-ab7d-4550-82b6-d2a07e7aef09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782697428-172.17.0.14-1595915403465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38593,DS-add3cdaa-aac2-49f9-80d6-a720de6a1baf,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-98d36be0-3d5d-4fe6-a759-c76fd7edf833,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-99f497c3-d69a-4f55-9dbb-4be4e3c3ef6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-9f71e9e9-5c07-4970-802c-51fbe45906bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-2391e287-74cd-4b18-acc6-c8aba53e1673,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-eb1847b3-3add-43ad-814d-41d9f37e1c46,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-43265a51-4756-4279-a866-3689356598ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-85ea2387-ab7d-4550-82b6-d2a07e7aef09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-773217747-172.17.0.14-1595915589235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43245,DS-b4e1d2bd-baeb-4f7c-bc82-98f408c12b98,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-5fbb39aa-3662-40e7-b1e8-ffb6336c56c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-23894939-836a-4325-84f7-91414a3ad1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-ce56b67b-eb79-40d9-a027-342d70183e50,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-af290920-1d94-430d-b190-9c77fe03f015,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-77b7a581-ae8b-4c93-b1a2-8cf966fd4993,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-82aac846-8964-4bfc-b675-e7bacd3436d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-582b0c3c-c5d7-4621-baa9-d9f2ee94bf71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-773217747-172.17.0.14-1595915589235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43245,DS-b4e1d2bd-baeb-4f7c-bc82-98f408c12b98,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-5fbb39aa-3662-40e7-b1e8-ffb6336c56c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-23894939-836a-4325-84f7-91414a3ad1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-ce56b67b-eb79-40d9-a027-342d70183e50,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-af290920-1d94-430d-b190-9c77fe03f015,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-77b7a581-ae8b-4c93-b1a2-8cf966fd4993,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-82aac846-8964-4bfc-b675-e7bacd3436d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-582b0c3c-c5d7-4621-baa9-d9f2ee94bf71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1108456484-172.17.0.14-1595915811668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39003,DS-4838099d-6307-4872-9602-c74945de1a64,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-070fc40a-7ca2-431a-88ea-eb49602d8f53,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-6776057f-1be9-416a-89cd-d494deb702f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-daad0b9b-ecc4-471b-aa5f-813236fc315d,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-4a89e9f2-5efc-4d42-896f-3c2eee03bc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-a52c9637-a4ee-487b-acfb-22a91eb2a3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-9f61745c-cb0b-448c-922e-df3b3dae9447,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-81ccea89-2a28-418b-85ab-bf972b3256a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1108456484-172.17.0.14-1595915811668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39003,DS-4838099d-6307-4872-9602-c74945de1a64,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-070fc40a-7ca2-431a-88ea-eb49602d8f53,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-6776057f-1be9-416a-89cd-d494deb702f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-daad0b9b-ecc4-471b-aa5f-813236fc315d,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-4a89e9f2-5efc-4d42-896f-3c2eee03bc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-a52c9637-a4ee-487b-acfb-22a91eb2a3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-9f61745c-cb0b-448c-922e-df3b3dae9447,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-81ccea89-2a28-418b-85ab-bf972b3256a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-132766262-172.17.0.14-1595916183064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33602,DS-a8c792c8-207c-4cac-ae74-2046a87585ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-73560a0c-7e08-4985-aaa2-db3d2c9209a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-3e67e3ea-0f1f-40c0-8f99-8d630a79c8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-65be9ea3-89bf-4252-bf25-39e970774592,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-8a533749-8ae7-4594-86e3-39063e59ef20,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-3f50293b-2b94-446d-9d89-8266191b85a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-ce04e416-5cbb-4d7c-8360-f95d5c0f5a70,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-82cbae69-c977-464f-bac2-7ea3934dfe94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-132766262-172.17.0.14-1595916183064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33602,DS-a8c792c8-207c-4cac-ae74-2046a87585ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-73560a0c-7e08-4985-aaa2-db3d2c9209a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-3e67e3ea-0f1f-40c0-8f99-8d630a79c8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-65be9ea3-89bf-4252-bf25-39e970774592,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-8a533749-8ae7-4594-86e3-39063e59ef20,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-3f50293b-2b94-446d-9d89-8266191b85a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-ce04e416-5cbb-4d7c-8360-f95d5c0f5a70,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-82cbae69-c977-464f-bac2-7ea3934dfe94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6585
