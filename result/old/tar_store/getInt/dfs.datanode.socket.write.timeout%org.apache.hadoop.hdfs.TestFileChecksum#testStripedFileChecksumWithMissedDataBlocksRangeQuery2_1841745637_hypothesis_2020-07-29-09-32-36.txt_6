reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-591147760-172.17.0.12-1596015837576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46226,DS-3f4d1091-d0d5-4b17-b334-dd59153e09b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-1141095d-dc0a-4d13-9ee0-5d331afadbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-5dea2686-feb2-4f27-be29-359d14066f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-07a55d11-8444-4e0d-959f-4327db5176a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-bcccae58-d229-4885-b836-caa3dd931b63,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-be7cc9b7-44f0-4da1-8537-e1cbd6eb6c30,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-e2b83cd7-ef25-4bfa-bc7e-38e0fbc3dcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-599f9326-3cef-40b0-9c80-ff5323fdbfcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-591147760-172.17.0.12-1596015837576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46226,DS-3f4d1091-d0d5-4b17-b334-dd59153e09b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-1141095d-dc0a-4d13-9ee0-5d331afadbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-5dea2686-feb2-4f27-be29-359d14066f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-07a55d11-8444-4e0d-959f-4327db5176a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-bcccae58-d229-4885-b836-caa3dd931b63,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-be7cc9b7-44f0-4da1-8537-e1cbd6eb6c30,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-e2b83cd7-ef25-4bfa-bc7e-38e0fbc3dcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-599f9326-3cef-40b0-9c80-ff5323fdbfcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1413057756-172.17.0.12-1596016007985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36019,DS-40b90197-fa7a-47df-903c-806c42b98b95,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-6a37f270-93cd-463c-b78a-faa7cddfa24b,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-b84b72cc-4ecb-46d7-80be-aa0ce25e5802,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-c5ff208e-cc49-402b-92ef-5c6b16ef0341,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-02e0be99-69ea-4896-9fd8-ad46aebbbdef,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-b530d36a-4097-457b-942a-a2ab830b34a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-e8f79654-3ca7-488b-900c-db34c5bc9fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-27165a7c-f004-4829-b3b5-54e25ff83f99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1413057756-172.17.0.12-1596016007985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36019,DS-40b90197-fa7a-47df-903c-806c42b98b95,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-6a37f270-93cd-463c-b78a-faa7cddfa24b,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-b84b72cc-4ecb-46d7-80be-aa0ce25e5802,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-c5ff208e-cc49-402b-92ef-5c6b16ef0341,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-02e0be99-69ea-4896-9fd8-ad46aebbbdef,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-b530d36a-4097-457b-942a-a2ab830b34a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-e8f79654-3ca7-488b-900c-db34c5bc9fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-27165a7c-f004-4829-b3b5-54e25ff83f99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575431425-172.17.0.12-1596016208644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33515,DS-4f95dd46-250d-412c-9405-0fae369b8435,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-05c439aa-04fa-4ed7-ab89-03677bb9c49c,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-3dd6bee9-4a62-4109-af62-04d59b4b7f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-6fbdc999-9278-435b-8713-0c46b88a7bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-635e0bc6-fe43-4004-b92e-fd0b28daf00a,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-c57a7526-eae2-4f97-a92f-0ad9b16ac42b,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-aaf7e80b-8663-49f5-9bfe-19e22836b158,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-c18fa4b2-1ed9-4533-a31e-dac73a486b84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575431425-172.17.0.12-1596016208644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33515,DS-4f95dd46-250d-412c-9405-0fae369b8435,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-05c439aa-04fa-4ed7-ab89-03677bb9c49c,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-3dd6bee9-4a62-4109-af62-04d59b4b7f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-6fbdc999-9278-435b-8713-0c46b88a7bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-635e0bc6-fe43-4004-b92e-fd0b28daf00a,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-c57a7526-eae2-4f97-a92f-0ad9b16ac42b,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-aaf7e80b-8663-49f5-9bfe-19e22836b158,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-c18fa4b2-1ed9-4533-a31e-dac73a486b84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742248024-172.17.0.12-1596016435747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33012,DS-0f631aba-a326-477c-960d-bba96c7e455f,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-8e312fb5-e0e0-4a3f-b2cb-151588325224,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-154a277b-3138-4a8d-8215-449ce675ae5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-5304b648-ef3d-4a7a-95fc-0cb1792559c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-79dee4e9-f37c-4952-8895-032736484f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-8e326d09-9916-4d73-b7fd-4d99ed790354,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-b2b8ccc6-30f3-4cf1-8221-0b68d4296483,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-29cc5010-6c23-45d7-948a-34cc570c0033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742248024-172.17.0.12-1596016435747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33012,DS-0f631aba-a326-477c-960d-bba96c7e455f,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-8e312fb5-e0e0-4a3f-b2cb-151588325224,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-154a277b-3138-4a8d-8215-449ce675ae5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-5304b648-ef3d-4a7a-95fc-0cb1792559c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-79dee4e9-f37c-4952-8895-032736484f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-8e326d09-9916-4d73-b7fd-4d99ed790354,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-b2b8ccc6-30f3-4cf1-8221-0b68d4296483,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-29cc5010-6c23-45d7-948a-34cc570c0033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062163163-172.17.0.12-1596017089489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42692,DS-ed403216-ed10-4110-82cd-9536360e7e92,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-4c33ae55-07ca-46a5-b728-a18ae7f4fa78,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-deebd6e8-6861-42c4-a915-e0e76688b84e,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-de294953-248d-4c58-84fa-35f6bd6afb29,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-2a4b7d41-afc3-485d-9e4a-cf03784fb681,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-c90a464e-aca8-40b5-8a68-a2f14fc9f8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-232936c1-abb2-4611-938e-3f500ad1a974,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-965c1c26-2cd3-4e11-8ee7-46e2d82ca9cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062163163-172.17.0.12-1596017089489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42692,DS-ed403216-ed10-4110-82cd-9536360e7e92,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-4c33ae55-07ca-46a5-b728-a18ae7f4fa78,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-deebd6e8-6861-42c4-a915-e0e76688b84e,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-de294953-248d-4c58-84fa-35f6bd6afb29,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-2a4b7d41-afc3-485d-9e4a-cf03784fb681,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-c90a464e-aca8-40b5-8a68-a2f14fc9f8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-232936c1-abb2-4611-938e-3f500ad1a974,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-965c1c26-2cd3-4e11-8ee7-46e2d82ca9cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735988093-172.17.0.12-1596017757337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36862,DS-850d977e-4319-4165-b1a6-5c5e2878f901,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-6da77511-add5-4063-9ffa-c02812033b53,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-6c2719af-631f-47e3-aedb-2a54e8c0f93e,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-82efcac7-9a6f-4bfc-a361-a4d5547b91f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-f13c56ca-aa08-49df-b0e5-e9197abd44fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-27f45914-10fc-4d25-8a3a-4a7772ed6808,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-a5db820d-d0d4-44dd-a372-f7c7dacf891c,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-09e7bc23-7656-467b-92fa-8dbb2afa5160,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735988093-172.17.0.12-1596017757337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36862,DS-850d977e-4319-4165-b1a6-5c5e2878f901,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-6da77511-add5-4063-9ffa-c02812033b53,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-6c2719af-631f-47e3-aedb-2a54e8c0f93e,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-82efcac7-9a6f-4bfc-a361-a4d5547b91f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-f13c56ca-aa08-49df-b0e5-e9197abd44fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-27f45914-10fc-4d25-8a3a-4a7772ed6808,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-a5db820d-d0d4-44dd-a372-f7c7dacf891c,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-09e7bc23-7656-467b-92fa-8dbb2afa5160,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464819696-172.17.0.12-1596018017389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36675,DS-85f84009-9794-41ec-8412-e6da499410c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-49310214-e507-4977-8e93-7b9999b345d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-a3929b51-4bfe-4e6a-9566-608ad40b3738,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-373c599f-60f3-4025-9774-68d5326ac4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-bc0a99b6-be86-4666-b792-5edb403d2cce,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-9f9b9ef2-685e-4cc4-ae3d-b6fcf53d0d96,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-42317839-d9c3-4b09-baad-f1061457fd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-c61609ce-76dc-4d80-a408-d3d66c8790ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464819696-172.17.0.12-1596018017389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36675,DS-85f84009-9794-41ec-8412-e6da499410c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-49310214-e507-4977-8e93-7b9999b345d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-a3929b51-4bfe-4e6a-9566-608ad40b3738,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-373c599f-60f3-4025-9774-68d5326ac4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-bc0a99b6-be86-4666-b792-5edb403d2cce,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-9f9b9ef2-685e-4cc4-ae3d-b6fcf53d0d96,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-42317839-d9c3-4b09-baad-f1061457fd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-c61609ce-76dc-4d80-a408-d3d66c8790ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223592350-172.17.0.12-1596018841752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45923,DS-8eb605d0-a9e3-4512-acdf-d6928709abc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-3843e25e-27e3-4a76-8bff-b2fc15433b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-e5ec5057-fd55-4a0e-bd4a-d7cfec23e45e,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-70f57415-d696-44e8-bc02-453104e115af,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-f3298085-5e64-4ca6-8f8e-ecba33a7a52a,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-661c9fa6-8cd4-455c-9c4e-e16324801a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-17295673-a66c-47ec-9cdd-9bbba395838a,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-59687d3b-0c85-4515-9f8d-a249d8f801e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223592350-172.17.0.12-1596018841752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45923,DS-8eb605d0-a9e3-4512-acdf-d6928709abc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-3843e25e-27e3-4a76-8bff-b2fc15433b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-e5ec5057-fd55-4a0e-bd4a-d7cfec23e45e,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-70f57415-d696-44e8-bc02-453104e115af,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-f3298085-5e64-4ca6-8f8e-ecba33a7a52a,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-661c9fa6-8cd4-455c-9c4e-e16324801a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-17295673-a66c-47ec-9cdd-9bbba395838a,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-59687d3b-0c85-4515-9f8d-a249d8f801e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882830954-172.17.0.12-1596018881717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37990,DS-e49bc661-123a-40e0-80d1-94e52293c4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-b0b113c4-9921-44f4-bff7-5ca4dbc3408c,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-0feda7af-ff8e-4513-aa09-05bcb9963064,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-5196ae19-9aea-454c-8b1e-4e7d35363878,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-605d51e1-c9bf-4f5c-93e4-fd4a03740feb,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-d5a76018-cb8f-4391-beb5-fdfa98211d98,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-fa8badd0-2b74-4b87-9d7a-90a4c0c38263,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-8004cb34-c11a-4ddb-b1ad-518091ebb06e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882830954-172.17.0.12-1596018881717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37990,DS-e49bc661-123a-40e0-80d1-94e52293c4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-b0b113c4-9921-44f4-bff7-5ca4dbc3408c,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-0feda7af-ff8e-4513-aa09-05bcb9963064,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-5196ae19-9aea-454c-8b1e-4e7d35363878,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-605d51e1-c9bf-4f5c-93e4-fd4a03740feb,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-d5a76018-cb8f-4391-beb5-fdfa98211d98,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-fa8badd0-2b74-4b87-9d7a-90a4c0c38263,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-8004cb34-c11a-4ddb-b1ad-518091ebb06e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1602470596-172.17.0.12-1596019127245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42306,DS-bbb88370-b6fd-488f-bc1a-55505ed5350f,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-0ded5890-3fbb-4e1b-b59d-a37563f4bb55,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-7bf0c4c1-7bbd-48eb-9ec2-d44849115f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-01ba2480-b1de-40eb-8f36-38214c9b387f,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-f54278c9-83e4-4ef2-ac5a-c3b40aba5dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-2ba89a62-9fdb-4f1e-b5e6-cf794688f9be,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-529e6eb0-be2d-4528-9978-e58047151131,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-f438e8db-a5e6-46d1-a14f-08f0b6627916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1602470596-172.17.0.12-1596019127245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42306,DS-bbb88370-b6fd-488f-bc1a-55505ed5350f,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-0ded5890-3fbb-4e1b-b59d-a37563f4bb55,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-7bf0c4c1-7bbd-48eb-9ec2-d44849115f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-01ba2480-b1de-40eb-8f36-38214c9b387f,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-f54278c9-83e4-4ef2-ac5a-c3b40aba5dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-2ba89a62-9fdb-4f1e-b5e6-cf794688f9be,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-529e6eb0-be2d-4528-9978-e58047151131,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-f438e8db-a5e6-46d1-a14f-08f0b6627916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544843205-172.17.0.12-1596019245093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40492,DS-80bbc3f8-e7d9-4259-8614-cb47cd548114,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-0ff63dcc-6ee5-4757-a68b-4c7f320bdfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-7a3f6da8-020a-48e8-89e3-a05325d89af3,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-24800e3b-e3b4-4703-a99e-d364b40e09a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-a047484b-915d-4e97-aa20-734aa177dd66,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-f9d2cfd1-99a7-4bb9-ba69-2f7a5394e32b,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-a2eec9b4-8c89-473c-9745-af3f2a591b40,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-0afce839-ea15-4fe0-a72e-4bb1b13cb01d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544843205-172.17.0.12-1596019245093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40492,DS-80bbc3f8-e7d9-4259-8614-cb47cd548114,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-0ff63dcc-6ee5-4757-a68b-4c7f320bdfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-7a3f6da8-020a-48e8-89e3-a05325d89af3,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-24800e3b-e3b4-4703-a99e-d364b40e09a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-a047484b-915d-4e97-aa20-734aa177dd66,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-f9d2cfd1-99a7-4bb9-ba69-2f7a5394e32b,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-a2eec9b4-8c89-473c-9745-af3f2a591b40,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-0afce839-ea15-4fe0-a72e-4bb1b13cb01d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896778756-172.17.0.12-1596020128824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35458,DS-9a46edc6-72a0-449b-bdd7-a3d52e54f4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-38444ad2-75f1-4eda-9d77-7d9018bfed9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-92d48656-f208-41bc-9735-0ca3b2baa7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-bb58ad5d-7532-427e-992e-0bf9904cda57,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-192a72d6-0b96-46de-86f3-3c273d80630f,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-23f6ff89-5f25-45eb-96cc-105e93586aed,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-174e23ab-ca3d-42c8-888a-0480b9e31929,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-4910122b-1aa3-40cd-9086-23e8cd4d61d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896778756-172.17.0.12-1596020128824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35458,DS-9a46edc6-72a0-449b-bdd7-a3d52e54f4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-38444ad2-75f1-4eda-9d77-7d9018bfed9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-92d48656-f208-41bc-9735-0ca3b2baa7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-bb58ad5d-7532-427e-992e-0bf9904cda57,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-192a72d6-0b96-46de-86f3-3c273d80630f,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-23f6ff89-5f25-45eb-96cc-105e93586aed,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-174e23ab-ca3d-42c8-888a-0480b9e31929,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-4910122b-1aa3-40cd-9086-23e8cd4d61d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5524
