reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1788659914-172.17.0.16-1596009159920:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45572,DS-1ee97955-4a42-4ee2-a02f-4b0eff41e156,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-8c914779-a228-4fbd-a5d0-d8b9e28b8fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-fa338693-1626-4788-b74e-a1fde9ba7fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-c10d7902-a620-4b29-95cf-07c52f2bf321,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-35a0bbdc-05f1-43dd-997a-c186962161a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-5b177078-3585-46fa-a790-bf9f6f2ed974,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-aa5ef45c-ace1-4398-ac74-d4de99f14ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-2bd200c1-0161-4ef5-a426-4e63b47dbcbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1788659914-172.17.0.16-1596009159920:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45572,DS-1ee97955-4a42-4ee2-a02f-4b0eff41e156,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-8c914779-a228-4fbd-a5d0-d8b9e28b8fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-fa338693-1626-4788-b74e-a1fde9ba7fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-c10d7902-a620-4b29-95cf-07c52f2bf321,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-35a0bbdc-05f1-43dd-997a-c186962161a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-5b177078-3585-46fa-a790-bf9f6f2ed974,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-aa5ef45c-ace1-4398-ac74-d4de99f14ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-2bd200c1-0161-4ef5-a426-4e63b47dbcbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927939379-172.17.0.16-1596009823547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39198,DS-6e68740b-aee5-4fcd-803d-6838e8ac4b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-855a7c02-4fc6-49eb-916f-a167246d6393,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-598d16a4-af79-4451-aa2c-44c848db86e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-9eb9313a-c206-40fc-b4b8-420ee8cf4df0,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-403b3745-5383-445a-921c-13e28b83b021,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-9158b129-e94b-44d7-b032-4f5e703c2b26,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-70184aa3-413d-44c7-af04-9aabca273061,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-2c81d8d8-bd37-4d0e-a053-49a324e416b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927939379-172.17.0.16-1596009823547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39198,DS-6e68740b-aee5-4fcd-803d-6838e8ac4b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-855a7c02-4fc6-49eb-916f-a167246d6393,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-598d16a4-af79-4451-aa2c-44c848db86e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-9eb9313a-c206-40fc-b4b8-420ee8cf4df0,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-403b3745-5383-445a-921c-13e28b83b021,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-9158b129-e94b-44d7-b032-4f5e703c2b26,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-70184aa3-413d-44c7-af04-9aabca273061,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-2c81d8d8-bd37-4d0e-a053-49a324e416b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015687803-172.17.0.16-1596010041278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46095,DS-8341ae93-c2a9-4ad1-9254-b774a0fbc609,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-2f571e4e-6054-452e-8670-590758cc100c,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-93534197-9cb6-4b04-9cfc-1ebd981d92e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-272ece19-a59a-4cdd-801d-553e1316bbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-0453465c-85be-4309-bb78-fe56c0d67dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-aa8d094e-8609-4a4e-b7a1-496bae2760f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-1b276be0-ac4b-411a-8f67-bf5aa48facbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-dcd0ad90-84d0-4d33-af13-3d94a1f47218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015687803-172.17.0.16-1596010041278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46095,DS-8341ae93-c2a9-4ad1-9254-b774a0fbc609,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-2f571e4e-6054-452e-8670-590758cc100c,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-93534197-9cb6-4b04-9cfc-1ebd981d92e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-272ece19-a59a-4cdd-801d-553e1316bbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-0453465c-85be-4309-bb78-fe56c0d67dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-aa8d094e-8609-4a4e-b7a1-496bae2760f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-1b276be0-ac4b-411a-8f67-bf5aa48facbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-dcd0ad90-84d0-4d33-af13-3d94a1f47218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144616317-172.17.0.16-1596010118106:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39128,DS-1bf1cc3c-8aab-4aaa-9b69-77a40507b02e,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-cbdcaa72-85b5-4400-9424-0981e6759ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-11ba9b25-d61f-4056-bc81-b81d42ce116c,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-363b4218-3527-4cde-8484-fb050c53e28c,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-c71f6053-1b94-4e3a-be8a-97e58301d27b,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-844b21f2-1307-4567-997e-b083c473191b,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-f7a039a4-4ef8-4253-88f4-8a0282cc0827,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-b8861830-1ab6-4698-8180-5c0e328df3a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144616317-172.17.0.16-1596010118106:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39128,DS-1bf1cc3c-8aab-4aaa-9b69-77a40507b02e,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-cbdcaa72-85b5-4400-9424-0981e6759ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-11ba9b25-d61f-4056-bc81-b81d42ce116c,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-363b4218-3527-4cde-8484-fb050c53e28c,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-c71f6053-1b94-4e3a-be8a-97e58301d27b,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-844b21f2-1307-4567-997e-b083c473191b,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-f7a039a4-4ef8-4253-88f4-8a0282cc0827,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-b8861830-1ab6-4698-8180-5c0e328df3a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232311601-172.17.0.16-1596010221039:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37106,DS-ff71c243-d30e-4990-a8a8-b8bb84362c13,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-18773d39-90f7-48cf-a1e9-35f1ba19d473,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-fb4addfe-334a-42db-97e6-45950cd69b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-0cf9bf5b-f98d-4345-ade4-9cd6b3b80de5,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-b9f79eda-c2ac-48b1-b494-d862900929f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-dec3ffee-81fd-4c6f-97c0-e7514ac82ead,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-4301df87-af4e-4f87-9cbb-eea82c85bd22,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-4c7ef3ab-d03e-497b-be32-371a73ec2c2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232311601-172.17.0.16-1596010221039:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37106,DS-ff71c243-d30e-4990-a8a8-b8bb84362c13,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-18773d39-90f7-48cf-a1e9-35f1ba19d473,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-fb4addfe-334a-42db-97e6-45950cd69b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-0cf9bf5b-f98d-4345-ade4-9cd6b3b80de5,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-b9f79eda-c2ac-48b1-b494-d862900929f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-dec3ffee-81fd-4c6f-97c0-e7514ac82ead,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-4301df87-af4e-4f87-9cbb-eea82c85bd22,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-4c7ef3ab-d03e-497b-be32-371a73ec2c2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456705221-172.17.0.16-1596011185109:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44363,DS-1d941a44-5e06-4153-b1d3-b1bd22304290,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-5d4848ed-c331-44ef-aafb-b916641a57cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-f83ddc6e-d93c-4243-9f1a-80ee8f563342,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-3dc4eb50-24b4-4d51-b5cf-1fe5af8f5cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-71c1e84c-b567-41af-aeca-500c14e969ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-3c90091d-5167-4246-af3e-1dd26f31a336,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-1bde9a53-a529-447e-bbbe-76b207728457,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-3dd530d0-87a5-47db-a570-c25ae431edbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456705221-172.17.0.16-1596011185109:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44363,DS-1d941a44-5e06-4153-b1d3-b1bd22304290,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-5d4848ed-c331-44ef-aafb-b916641a57cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-f83ddc6e-d93c-4243-9f1a-80ee8f563342,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-3dc4eb50-24b4-4d51-b5cf-1fe5af8f5cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-71c1e84c-b567-41af-aeca-500c14e969ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-3c90091d-5167-4246-af3e-1dd26f31a336,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-1bde9a53-a529-447e-bbbe-76b207728457,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-3dd530d0-87a5-47db-a570-c25ae431edbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967643996-172.17.0.16-1596011300138:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46746,DS-872ae219-dfd0-4423-b0e9-2be77309564b,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-cf161bb3-8bcb-401f-8f9c-8cec3e456693,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-aef0e28d-a299-4edf-9896-7db3a54c4fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-b1be0b8c-8636-4093-8cbd-d0e9f88346d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-5af93953-47ff-4add-b5e6-afd9aa4e957a,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-23893ab3-3d5d-4db4-973d-ba70482cf64c,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-aee7268d-b678-4dd3-b545-6ce53d216962,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-4afb873b-c90f-4be9-9363-ed970c924195,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967643996-172.17.0.16-1596011300138:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46746,DS-872ae219-dfd0-4423-b0e9-2be77309564b,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-cf161bb3-8bcb-401f-8f9c-8cec3e456693,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-aef0e28d-a299-4edf-9896-7db3a54c4fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-b1be0b8c-8636-4093-8cbd-d0e9f88346d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-5af93953-47ff-4add-b5e6-afd9aa4e957a,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-23893ab3-3d5d-4db4-973d-ba70482cf64c,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-aee7268d-b678-4dd3-b545-6ce53d216962,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-4afb873b-c90f-4be9-9363-ed970c924195,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-487127499-172.17.0.16-1596011498558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45563,DS-24047ab4-c6b3-4e10-97cc-ac7787eed519,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-31a19a73-d798-4967-8763-816cb6773a03,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-cc28555f-6807-43c5-8c1b-2d1d8934e572,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-b29c4865-14c4-4023-a652-95c008914d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-0cfe67b9-2fa1-4cb1-a78a-67b6dee0b15c,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-eed8d357-da36-4ab6-aa92-cbc5a1369822,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-fa2f1f62-1c54-473f-8e4a-91feb1ba2989,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-aafa2b0a-bdda-4d5c-a9c9-ac03cc253032,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-487127499-172.17.0.16-1596011498558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45563,DS-24047ab4-c6b3-4e10-97cc-ac7787eed519,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-31a19a73-d798-4967-8763-816cb6773a03,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-cc28555f-6807-43c5-8c1b-2d1d8934e572,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-b29c4865-14c4-4023-a652-95c008914d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-0cfe67b9-2fa1-4cb1-a78a-67b6dee0b15c,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-eed8d357-da36-4ab6-aa92-cbc5a1369822,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-fa2f1f62-1c54-473f-8e4a-91feb1ba2989,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-aafa2b0a-bdda-4d5c-a9c9-ac03cc253032,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-711044300-172.17.0.16-1596011738544:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42953,DS-8473eb3d-080b-4f0f-9103-6faf38565939,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-d8c9f7e7-600d-42e6-92f8-df23ff1d50ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-369733e4-b251-4114-9075-334dd43ef213,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-f49049bc-9ca8-4476-bb37-1b9310040b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-7fa7a337-6d46-4c38-9233-268e6ed9cc06,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-0328567e-2aa3-4302-9304-9d96cb3252d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-0a4c40b2-f8a4-438c-9024-ea4442e33ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-e0343ba9-b5c6-43f6-bcf0-e6c3b4905765,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-711044300-172.17.0.16-1596011738544:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42953,DS-8473eb3d-080b-4f0f-9103-6faf38565939,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-d8c9f7e7-600d-42e6-92f8-df23ff1d50ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-369733e4-b251-4114-9075-334dd43ef213,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-f49049bc-9ca8-4476-bb37-1b9310040b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-7fa7a337-6d46-4c38-9233-268e6ed9cc06,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-0328567e-2aa3-4302-9304-9d96cb3252d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-0a4c40b2-f8a4-438c-9024-ea4442e33ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-e0343ba9-b5c6-43f6-bcf0-e6c3b4905765,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188467403-172.17.0.16-1596012261900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42113,DS-195eeafb-73f4-42b6-99bd-42c42767d4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-9c1913f2-7ce9-4c70-9e85-859e6939f0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-9921e458-031d-4a72-9cb3-1c54f2147145,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-235fb0d3-a7d2-4619-8ef2-3e439eaaebd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-4a904cea-4d79-457e-a3d2-97ff87b831db,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-3c0c957f-00c6-4569-b2d9-2cf09e7c1b11,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-60b84996-9bd3-4102-be24-ce40df6b567f,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-e2c6c53c-83a9-4725-a57e-b45a5c86ae13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188467403-172.17.0.16-1596012261900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42113,DS-195eeafb-73f4-42b6-99bd-42c42767d4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-9c1913f2-7ce9-4c70-9e85-859e6939f0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-9921e458-031d-4a72-9cb3-1c54f2147145,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-235fb0d3-a7d2-4619-8ef2-3e439eaaebd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-4a904cea-4d79-457e-a3d2-97ff87b831db,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-3c0c957f-00c6-4569-b2d9-2cf09e7c1b11,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-60b84996-9bd3-4102-be24-ce40df6b567f,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-e2c6c53c-83a9-4725-a57e-b45a5c86ae13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160124983-172.17.0.16-1596012379526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46075,DS-c7fc7fe8-f83e-4196-8cde-48ed5e4bf484,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-246d0f59-136a-4323-94f4-8ac3750dc8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-43a6bf40-92ae-4b49-b804-dc174cd04a99,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-67c23fb3-fe2b-4573-95e7-41ac746cadd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-823b07a4-02b1-4d0c-a12d-5ff5879a9276,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-f52715b2-9bf4-4a90-b580-d29edb7d15cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-3fc40953-f008-4295-9958-8ef4bdbfbc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-6859e0de-56f8-48de-9526-f35a0d66768e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160124983-172.17.0.16-1596012379526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46075,DS-c7fc7fe8-f83e-4196-8cde-48ed5e4bf484,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-246d0f59-136a-4323-94f4-8ac3750dc8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-43a6bf40-92ae-4b49-b804-dc174cd04a99,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-67c23fb3-fe2b-4573-95e7-41ac746cadd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-823b07a4-02b1-4d0c-a12d-5ff5879a9276,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-f52715b2-9bf4-4a90-b580-d29edb7d15cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-3fc40953-f008-4295-9958-8ef4bdbfbc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-6859e0de-56f8-48de-9526-f35a0d66768e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235836331-172.17.0.16-1596012417065:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35225,DS-367c26f8-fabe-4de3-a153-8489c6916f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-43cc3798-4c50-4a16-85bb-e17867f21f40,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-f702e34d-4e1d-49b9-94d8-a8aa22ef83a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-2d884ae2-3442-49ea-b9a6-f52bc5388c06,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-5791d833-112b-4ac6-bd37-02e8b1466b49,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-e226cb6e-25b1-4756-bebc-481e80ea5966,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-1736a486-4e15-4579-88cf-88afc52c70c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-2af33ed1-e401-4327-9e86-d042ed9821ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235836331-172.17.0.16-1596012417065:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35225,DS-367c26f8-fabe-4de3-a153-8489c6916f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-43cc3798-4c50-4a16-85bb-e17867f21f40,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-f702e34d-4e1d-49b9-94d8-a8aa22ef83a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-2d884ae2-3442-49ea-b9a6-f52bc5388c06,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-5791d833-112b-4ac6-bd37-02e8b1466b49,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-e226cb6e-25b1-4756-bebc-481e80ea5966,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-1736a486-4e15-4579-88cf-88afc52c70c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-2af33ed1-e401-4327-9e86-d042ed9821ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635033214-172.17.0.16-1596012654085:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37063,DS-1e1855a3-fb7c-48e3-a516-f4ca731fd70c,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-3c6dfe3d-879f-4d29-ae08-b10879477b10,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-da42a43e-c4ba-4fca-bb75-869240e0e135,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-af5ec6de-add6-4b19-ac52-fdb96dc03e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-188907db-cfac-4cd8-96cb-2b161354837e,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-7cbebbe4-2c75-41ef-8a46-be3c9528966f,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-3df76d06-7f98-4be1-a433-ee98fea622d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-af9453d3-12b7-4142-9466-eefd690a3c02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635033214-172.17.0.16-1596012654085:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37063,DS-1e1855a3-fb7c-48e3-a516-f4ca731fd70c,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-3c6dfe3d-879f-4d29-ae08-b10879477b10,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-da42a43e-c4ba-4fca-bb75-869240e0e135,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-af5ec6de-add6-4b19-ac52-fdb96dc03e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-188907db-cfac-4cd8-96cb-2b161354837e,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-7cbebbe4-2c75-41ef-8a46-be3c9528966f,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-3df76d06-7f98-4be1-a433-ee98fea622d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-af9453d3-12b7-4142-9466-eefd690a3c02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293294797-172.17.0.16-1596012839025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36752,DS-23b51070-31da-4b70-bf48-d904a2c588a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-210786cc-2e91-4b64-9442-3cec0279784a,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-44ca371b-dfe0-4eea-bccc-94d5142ca88d,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-e9f8c7f5-75d8-4c9f-9c2b-2e4563bdd1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-9ce9dd0b-5198-4791-a836-61dd8e127cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-2b5ee901-884f-4af4-b954-d7b014ab86cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-063a1c5f-3ff3-4cf0-ba66-32dc81cfeebb,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-382e0c89-5338-407c-929a-9f3f953ffaa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293294797-172.17.0.16-1596012839025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36752,DS-23b51070-31da-4b70-bf48-d904a2c588a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-210786cc-2e91-4b64-9442-3cec0279784a,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-44ca371b-dfe0-4eea-bccc-94d5142ca88d,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-e9f8c7f5-75d8-4c9f-9c2b-2e4563bdd1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-9ce9dd0b-5198-4791-a836-61dd8e127cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-2b5ee901-884f-4af4-b954-d7b014ab86cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-063a1c5f-3ff3-4cf0-ba66-32dc81cfeebb,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-382e0c89-5338-407c-929a-9f3f953ffaa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789788476-172.17.0.16-1596012906824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38350,DS-c31952c9-8318-49b1-895c-d2b015a255e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-e11738ee-4404-498c-8820-867e9e6be510,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-25511111-0462-486f-89af-eec7bcbba099,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-c953a573-e5e5-4364-8df4-ef7e144c85af,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-bd6c820b-47f0-4320-ae31-27ac76d281a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-0e847bc9-1303-4ad0-9647-1dcfe3086bab,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-6590a864-a062-4ec3-b139-029e11aa4b08,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-9198c7e2-e226-4f9b-9149-a851fb899468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789788476-172.17.0.16-1596012906824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38350,DS-c31952c9-8318-49b1-895c-d2b015a255e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-e11738ee-4404-498c-8820-867e9e6be510,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-25511111-0462-486f-89af-eec7bcbba099,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-c953a573-e5e5-4364-8df4-ef7e144c85af,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-bd6c820b-47f0-4320-ae31-27ac76d281a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-0e847bc9-1303-4ad0-9647-1dcfe3086bab,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-6590a864-a062-4ec3-b139-029e11aa4b08,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-9198c7e2-e226-4f9b-9149-a851fb899468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563153080-172.17.0.16-1596012944573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38008,DS-95245d4a-6f76-4465-a460-35e887d96ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-6d368644-6d64-41ad-ab48-4dded3d63047,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-811d6c7a-7738-4ef5-838b-8b19b0629605,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-1a357755-e94d-4216-b9f5-57e9e8231fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-cf0651b1-3e63-4fb7-8c1f-cc09da207e24,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-c46e8a0b-a814-4a71-8031-4cbd7b3b67bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-440c828c-dc3d-447b-a064-cab89b9f0a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-97714e52-dbe4-46f2-9278-925c1a023d3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563153080-172.17.0.16-1596012944573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38008,DS-95245d4a-6f76-4465-a460-35e887d96ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-6d368644-6d64-41ad-ab48-4dded3d63047,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-811d6c7a-7738-4ef5-838b-8b19b0629605,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-1a357755-e94d-4216-b9f5-57e9e8231fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-cf0651b1-3e63-4fb7-8c1f-cc09da207e24,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-c46e8a0b-a814-4a71-8031-4cbd7b3b67bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-440c828c-dc3d-447b-a064-cab89b9f0a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-97714e52-dbe4-46f2-9278-925c1a023d3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-765292717-172.17.0.16-1596013054932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38362,DS-c708d381-15b4-48cb-9a88-b5d4a32e8a03,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-285cf40f-686a-4c95-8d11-c5f267876000,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-01d8d1a4-2c5f-4d7f-852c-0531c4381a97,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-69ea9f04-9be2-4531-96e3-23487b2c07e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-b0776b5a-8a2f-47e6-bae1-c43c0ec86d80,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-5b9827bc-fd16-473a-93f6-caa47585c42d,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-62ce23f2-70cf-47ca-9fa2-3d8d9f49aaae,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-95f8378c-7dc0-4b7f-8381-a236654e84bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-765292717-172.17.0.16-1596013054932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38362,DS-c708d381-15b4-48cb-9a88-b5d4a32e8a03,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-285cf40f-686a-4c95-8d11-c5f267876000,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-01d8d1a4-2c5f-4d7f-852c-0531c4381a97,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-69ea9f04-9be2-4531-96e3-23487b2c07e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-b0776b5a-8a2f-47e6-bae1-c43c0ec86d80,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-5b9827bc-fd16-473a-93f6-caa47585c42d,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-62ce23f2-70cf-47ca-9fa2-3d8d9f49aaae,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-95f8378c-7dc0-4b7f-8381-a236654e84bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150852766-172.17.0.16-1596013535225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37118,DS-f9588263-ceb4-4da2-a4d3-4f74b5178055,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-82aacc9e-1172-454f-8f82-94c045e82b91,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-ada8ceb9-b157-49c8-837f-52cec6d38aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-d8b8a805-ba1b-44a2-ae33-6e4e854bedae,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-09a65fb9-f1d6-4551-9cbd-f92573f94a08,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-1521425a-997b-4dcb-a6f1-ce0bced75285,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-1ae985ce-29b7-4465-9cfd-5c5baf46813e,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-55a7e734-e275-4e9e-933b-55dda038c2ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150852766-172.17.0.16-1596013535225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37118,DS-f9588263-ceb4-4da2-a4d3-4f74b5178055,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-82aacc9e-1172-454f-8f82-94c045e82b91,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-ada8ceb9-b157-49c8-837f-52cec6d38aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-d8b8a805-ba1b-44a2-ae33-6e4e854bedae,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-09a65fb9-f1d6-4551-9cbd-f92573f94a08,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-1521425a-997b-4dcb-a6f1-ce0bced75285,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-1ae985ce-29b7-4465-9cfd-5c5baf46813e,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-55a7e734-e275-4e9e-933b-55dda038c2ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1042190363-172.17.0.16-1596013636380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36946,DS-788e8916-8545-4f4a-9ef9-5c7ff5a68ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-c0e35b3e-6f2a-4ff8-9e1a-041dfd1d662e,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-2440b8d1-a670-4cda-ba13-b8e81dbfed68,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-b6dc2962-e599-4735-853a-a72f7019c07b,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-6b601874-3568-45ca-a3f7-fef15abc34a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-2771ff83-c9e8-4e54-a654-6c734cbd04dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-05c88cd9-73be-486b-abab-5a4c4241ed6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-6572dfbb-3086-45e3-946b-e1a4c28903a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1042190363-172.17.0.16-1596013636380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36946,DS-788e8916-8545-4f4a-9ef9-5c7ff5a68ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-c0e35b3e-6f2a-4ff8-9e1a-041dfd1d662e,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-2440b8d1-a670-4cda-ba13-b8e81dbfed68,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-b6dc2962-e599-4735-853a-a72f7019c07b,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-6b601874-3568-45ca-a3f7-fef15abc34a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-2771ff83-c9e8-4e54-a654-6c734cbd04dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-05c88cd9-73be-486b-abab-5a4c4241ed6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-6572dfbb-3086-45e3-946b-e1a4c28903a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1105096379-172.17.0.16-1596013987876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39826,DS-75f15b72-5164-45a4-93c9-ef5a94727039,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-323d3551-87c2-44bf-a105-1e2033a1d074,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-53a0f000-b099-49d4-b302-958c270ec9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-750899a7-21c9-4480-918c-b7286e37d318,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-348e78cc-86c2-463a-80d9-13fb4890bd43,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-086322fe-e7af-4926-a61f-dcbba1dc3256,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-5565f8f9-5f9c-4a41-9b08-e6aa2fb70086,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-5868baa8-c269-461b-94c2-247177dfee2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1105096379-172.17.0.16-1596013987876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39826,DS-75f15b72-5164-45a4-93c9-ef5a94727039,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-323d3551-87c2-44bf-a105-1e2033a1d074,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-53a0f000-b099-49d4-b302-958c270ec9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-750899a7-21c9-4480-918c-b7286e37d318,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-348e78cc-86c2-463a-80d9-13fb4890bd43,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-086322fe-e7af-4926-a61f-dcbba1dc3256,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-5565f8f9-5f9c-4a41-9b08-e6aa2fb70086,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-5868baa8-c269-461b-94c2-247177dfee2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430182002-172.17.0.16-1596014298082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43489,DS-e8d45510-8ef4-4040-9cc7-d9fb1efaf05c,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-641962ac-34b6-452e-a02d-10ef4b269f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-27bf8ebc-b5f2-4727-9281-9aa7b84fae42,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-30d325e0-1133-48d8-b68f-e68be7554bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-1e15b8d8-a70c-487c-af12-45a01362d57f,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-2c67ebea-0a73-421e-b205-6f6863a36f29,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-93628e18-d888-4a2a-ada3-385cef6f9464,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-28ac5a15-9629-48fa-8ffe-50519df063cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430182002-172.17.0.16-1596014298082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43489,DS-e8d45510-8ef4-4040-9cc7-d9fb1efaf05c,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-641962ac-34b6-452e-a02d-10ef4b269f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-27bf8ebc-b5f2-4727-9281-9aa7b84fae42,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-30d325e0-1133-48d8-b68f-e68be7554bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-1e15b8d8-a70c-487c-af12-45a01362d57f,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-2c67ebea-0a73-421e-b205-6f6863a36f29,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-93628e18-d888-4a2a-ada3-385cef6f9464,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-28ac5a15-9629-48fa-8ffe-50519df063cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46835001-172.17.0.16-1596014404516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33170,DS-9ff49da0-a9fb-4b47-88a7-fbcd4bf1a56e,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-69b2ce5c-2813-4bfe-b06b-6b564a8d915c,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-4502bba3-794b-41f7-81ae-cd822cb65758,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-e51291ca-ac8f-4360-9689-6be01e305277,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-6889a7df-dbe9-41e7-8b5e-08313863e688,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-faae42fd-78e3-4b4e-a4ca-541bede0779a,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-ba96f35f-230c-4ed5-b16e-9a33e3294b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-4b8f7c5b-e2e2-484a-910e-5e8e2304a1bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46835001-172.17.0.16-1596014404516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33170,DS-9ff49da0-a9fb-4b47-88a7-fbcd4bf1a56e,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-69b2ce5c-2813-4bfe-b06b-6b564a8d915c,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-4502bba3-794b-41f7-81ae-cd822cb65758,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-e51291ca-ac8f-4360-9689-6be01e305277,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-6889a7df-dbe9-41e7-8b5e-08313863e688,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-faae42fd-78e3-4b4e-a4ca-541bede0779a,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-ba96f35f-230c-4ed5-b16e-9a33e3294b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-4b8f7c5b-e2e2-484a-910e-5e8e2304a1bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5401
