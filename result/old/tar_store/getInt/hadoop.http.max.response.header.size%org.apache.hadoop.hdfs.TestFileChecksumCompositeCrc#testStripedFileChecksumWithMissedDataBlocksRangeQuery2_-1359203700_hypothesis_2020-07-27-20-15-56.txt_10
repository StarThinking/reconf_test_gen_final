reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1780776929-172.17.0.11-1595880968024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32901,DS-1dfcff8b-2f94-493b-ac0c-3cea38cffc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-b70a09f6-6825-405d-acba-8e96fa4f12c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-50a33c10-80e4-4c66-9e67-d24982759222,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-6b5eb64d-1d88-442e-9157-5533982f066b,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-7473279c-d300-4443-adae-e43712352a71,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-19acd0c4-f5c9-4046-9d14-af07c90227a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-4ec5a134-3512-400d-9aad-3bea75b3d524,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-f8520a8c-c5f9-49b4-a49b-98b47d93b027,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1780776929-172.17.0.11-1595880968024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32901,DS-1dfcff8b-2f94-493b-ac0c-3cea38cffc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-b70a09f6-6825-405d-acba-8e96fa4f12c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-50a33c10-80e4-4c66-9e67-d24982759222,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-6b5eb64d-1d88-442e-9157-5533982f066b,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-7473279c-d300-4443-adae-e43712352a71,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-19acd0c4-f5c9-4046-9d14-af07c90227a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-4ec5a134-3512-400d-9aad-3bea75b3d524,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-f8520a8c-c5f9-49b4-a49b-98b47d93b027,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439027558-172.17.0.11-1595880999233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45541,DS-f12690a6-0d12-43ab-8600-18c66465b126,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-3802ca41-db5f-4a82-9201-7a3bb5ea045c,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-ee0060bc-e393-40b2-9d35-afe5a2aad3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-bba40a8b-a057-4f03-a599-464d1d812747,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-a03e3539-5116-42f6-a293-7c72b36575a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-e5a23c5a-68cf-447a-bc90-0c54d2466d27,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-606e339d-fa33-4e99-9dee-d060d0c39092,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-a898e909-5bd6-4efc-a00c-2fad5fae9159,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439027558-172.17.0.11-1595880999233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45541,DS-f12690a6-0d12-43ab-8600-18c66465b126,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-3802ca41-db5f-4a82-9201-7a3bb5ea045c,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-ee0060bc-e393-40b2-9d35-afe5a2aad3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-bba40a8b-a057-4f03-a599-464d1d812747,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-a03e3539-5116-42f6-a293-7c72b36575a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-e5a23c5a-68cf-447a-bc90-0c54d2466d27,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-606e339d-fa33-4e99-9dee-d060d0c39092,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-a898e909-5bd6-4efc-a00c-2fad5fae9159,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54645084-172.17.0.11-1595881597654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37582,DS-2b646465-3f22-4290-bb74-9a7949888370,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-f4fd0571-4436-4d48-a376-e93bf14370de,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-9cff5372-996e-494c-b106-636179fbe3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-672b6fa4-378a-4e89-89a9-19449de05c58,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-6522b73e-0e7e-4ffa-ad2e-adf42b33b8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-676238ff-c9c7-44c7-886e-ecc02b676ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-72bf118a-e24b-4937-aec2-cd39d3feb626,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-6bb98e54-7b1d-4f35-9b92-04a0297d153c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54645084-172.17.0.11-1595881597654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37582,DS-2b646465-3f22-4290-bb74-9a7949888370,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-f4fd0571-4436-4d48-a376-e93bf14370de,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-9cff5372-996e-494c-b106-636179fbe3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-672b6fa4-378a-4e89-89a9-19449de05c58,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-6522b73e-0e7e-4ffa-ad2e-adf42b33b8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-676238ff-c9c7-44c7-886e-ecc02b676ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-72bf118a-e24b-4937-aec2-cd39d3feb626,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-6bb98e54-7b1d-4f35-9b92-04a0297d153c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-676978159-172.17.0.11-1595881789927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40667,DS-e1de4c16-d186-471e-8467-df2e64bce5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-ecb90b98-5fde-4b15-9caa-cab56772aa1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-184618bb-1440-407e-ae66-4f81dba204bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-a38f52fd-c494-4c51-8810-f9368f10ac5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-18106e57-41f0-417a-b215-68b2eb806a45,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-9ba17be1-8786-45e7-aec7-0c6d0e45e0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-c3503fdb-a7cb-429c-af15-e4d52e60270d,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-a1c4dede-4eae-4976-90e5-8e182631a867,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-676978159-172.17.0.11-1595881789927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40667,DS-e1de4c16-d186-471e-8467-df2e64bce5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-ecb90b98-5fde-4b15-9caa-cab56772aa1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-184618bb-1440-407e-ae66-4f81dba204bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-a38f52fd-c494-4c51-8810-f9368f10ac5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-18106e57-41f0-417a-b215-68b2eb806a45,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-9ba17be1-8786-45e7-aec7-0c6d0e45e0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-c3503fdb-a7cb-429c-af15-e4d52e60270d,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-a1c4dede-4eae-4976-90e5-8e182631a867,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071105501-172.17.0.11-1595882364064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34478,DS-9e8e610c-4120-4a28-8f83-3fe718d2f0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-9082e258-5d4e-4698-800c-febb56aebd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-d9ce1f1b-baaf-418f-8b3b-c0dc41176c24,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-04c012fb-96aa-43be-bb0e-74e2ebc34903,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-0988a554-e4a8-473f-b06b-c090aaa5d12b,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-f30dec76-3f6c-40a0-954e-290db126442e,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-7072c9cc-6b1c-4abf-9087-d20310cf1328,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-d98a292d-58f9-4e05-a8db-3b165a0a1a49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071105501-172.17.0.11-1595882364064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34478,DS-9e8e610c-4120-4a28-8f83-3fe718d2f0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-9082e258-5d4e-4698-800c-febb56aebd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-d9ce1f1b-baaf-418f-8b3b-c0dc41176c24,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-04c012fb-96aa-43be-bb0e-74e2ebc34903,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-0988a554-e4a8-473f-b06b-c090aaa5d12b,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-f30dec76-3f6c-40a0-954e-290db126442e,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-7072c9cc-6b1c-4abf-9087-d20310cf1328,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-d98a292d-58f9-4e05-a8db-3b165a0a1a49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737921920-172.17.0.11-1595882412606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33010,DS-2f33bba6-188c-40ff-b771-ed292944f9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-0baa5446-64d7-40b0-bf2b-02aec00d7241,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-1c45327d-f485-4e51-bbf4-8d73dded9a09,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-449951ad-46b6-470c-b2df-260d05f25611,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-6032988c-4edc-4716-8973-b34e323cbfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-ff00932c-7b49-4e45-abd9-4f77523c2702,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-be5f999a-1ab3-4172-be7c-77561d1ea48d,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-4ad7aeb8-45ca-4bd5-ab8e-c25b2a620916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737921920-172.17.0.11-1595882412606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33010,DS-2f33bba6-188c-40ff-b771-ed292944f9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-0baa5446-64d7-40b0-bf2b-02aec00d7241,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-1c45327d-f485-4e51-bbf4-8d73dded9a09,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-449951ad-46b6-470c-b2df-260d05f25611,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-6032988c-4edc-4716-8973-b34e323cbfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-ff00932c-7b49-4e45-abd9-4f77523c2702,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-be5f999a-1ab3-4172-be7c-77561d1ea48d,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-4ad7aeb8-45ca-4bd5-ab8e-c25b2a620916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23040059-172.17.0.11-1595882572132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39513,DS-5c1241e8-97b6-4c53-a934-1a9afc09203f,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-4441282e-3e6c-42ec-a33f-16013a23e996,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-4806dd9f-5794-48c0-8e74-cd9b39739f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-4abd9fad-19a3-4c1a-af17-8dcd17624c33,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-0266b8a6-452d-4ec2-a33d-d1b25d229dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-a5126e88-26f9-4118-b93b-02b22b66c60c,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-e611c021-ec0c-4780-a2bf-47d3bb192f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-b7a86c12-f5bd-4726-b40e-507420928a25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23040059-172.17.0.11-1595882572132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39513,DS-5c1241e8-97b6-4c53-a934-1a9afc09203f,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-4441282e-3e6c-42ec-a33f-16013a23e996,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-4806dd9f-5794-48c0-8e74-cd9b39739f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-4abd9fad-19a3-4c1a-af17-8dcd17624c33,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-0266b8a6-452d-4ec2-a33d-d1b25d229dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-a5126e88-26f9-4118-b93b-02b22b66c60c,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-e611c021-ec0c-4780-a2bf-47d3bb192f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-b7a86c12-f5bd-4726-b40e-507420928a25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1713517651-172.17.0.11-1595882656112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36651,DS-abe8bf07-00c9-4c22-a2a9-6f81881d399b,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-8171ce09-4de1-43fb-86e1-3f6ab097aa9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-34dec7f3-21aa-411c-98ac-9d5883a1cc21,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-04cb8759-9d92-4d98-afc0-4e73aacead47,DISK], DatanodeInfoWithStorage[127.0.0.1:34839,DS-742b93f9-39fc-4812-bf69-00d205761ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-7759e1a3-6572-4132-b4d5-76e6f7086966,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-f5b4e0b8-319a-44cc-b418-e9bb043aa26a,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-643b86c9-fc0a-4bcb-b58a-11ddfedddae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1713517651-172.17.0.11-1595882656112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36651,DS-abe8bf07-00c9-4c22-a2a9-6f81881d399b,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-8171ce09-4de1-43fb-86e1-3f6ab097aa9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-34dec7f3-21aa-411c-98ac-9d5883a1cc21,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-04cb8759-9d92-4d98-afc0-4e73aacead47,DISK], DatanodeInfoWithStorage[127.0.0.1:34839,DS-742b93f9-39fc-4812-bf69-00d205761ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-7759e1a3-6572-4132-b4d5-76e6f7086966,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-f5b4e0b8-319a-44cc-b418-e9bb043aa26a,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-643b86c9-fc0a-4bcb-b58a-11ddfedddae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277535911-172.17.0.11-1595882741309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41396,DS-7ac10a14-f9bd-4520-bc68-bf3b63b8523b,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-85e66c51-78de-4559-bfac-dc6fbdcb0cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-7abd68ac-02df-4531-a87f-3f0e177c0257,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-d20161ee-5284-42b4-ab3b-9d15453bf231,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-9a320fd9-d31b-43d8-ac89-1e0e6846e13c,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-1c721607-af6a-434b-92bb-d37092c0d6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-d5018c4e-a5e1-412c-a733-9af9ba2f8153,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-26168894-c7f2-465e-b7f9-979bb0a89493,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277535911-172.17.0.11-1595882741309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41396,DS-7ac10a14-f9bd-4520-bc68-bf3b63b8523b,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-85e66c51-78de-4559-bfac-dc6fbdcb0cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-7abd68ac-02df-4531-a87f-3f0e177c0257,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-d20161ee-5284-42b4-ab3b-9d15453bf231,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-9a320fd9-d31b-43d8-ac89-1e0e6846e13c,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-1c721607-af6a-434b-92bb-d37092c0d6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-d5018c4e-a5e1-412c-a733-9af9ba2f8153,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-26168894-c7f2-465e-b7f9-979bb0a89493,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1859650227-172.17.0.11-1595882922914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38945,DS-e3ec691c-3258-4745-bf0e-6e517b1a1459,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-920c2f4b-2847-470e-97af-8236f6ab0bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-8cfa053f-05a0-4270-98d3-97e538f5ccef,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-e0ca9ecb-fa33-499c-a7bb-b2058fb8abcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-47821222-e88e-45a8-97fa-c498f99d0b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-9523283c-ef75-4328-8fef-bd2c6ebc4615,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-fe3881da-77f2-4901-8557-ad5ae0c95e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-ad6559d4-431f-4af2-a079-903ad2b941a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1859650227-172.17.0.11-1595882922914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38945,DS-e3ec691c-3258-4745-bf0e-6e517b1a1459,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-920c2f4b-2847-470e-97af-8236f6ab0bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-8cfa053f-05a0-4270-98d3-97e538f5ccef,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-e0ca9ecb-fa33-499c-a7bb-b2058fb8abcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-47821222-e88e-45a8-97fa-c498f99d0b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-9523283c-ef75-4328-8fef-bd2c6ebc4615,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-fe3881da-77f2-4901-8557-ad5ae0c95e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-ad6559d4-431f-4af2-a079-903ad2b941a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561099042-172.17.0.11-1595882953279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45462,DS-11099385-60db-4234-bba3-380d3cef420b,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-c18704a7-f64a-4eca-8d42-3214b6083c38,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-05d0c293-789c-4c3b-b893-5285250f83c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-7f43b2ce-a830-4463-80e0-b697ac2a91f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-4f679f4c-ec35-4653-8655-2b71eadea24c,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-eb050588-c81a-4d35-8576-faca682e83ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-dc06972d-36f0-4ce9-b8cf-2a7871d1f911,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-227f1c33-d061-4a80-9a99-f3cfc46770c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561099042-172.17.0.11-1595882953279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45462,DS-11099385-60db-4234-bba3-380d3cef420b,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-c18704a7-f64a-4eca-8d42-3214b6083c38,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-05d0c293-789c-4c3b-b893-5285250f83c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-7f43b2ce-a830-4463-80e0-b697ac2a91f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-4f679f4c-ec35-4653-8655-2b71eadea24c,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-eb050588-c81a-4d35-8576-faca682e83ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-dc06972d-36f0-4ce9-b8cf-2a7871d1f911,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-227f1c33-d061-4a80-9a99-f3cfc46770c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2111454374-172.17.0.11-1595883338847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44868,DS-eac852ed-938f-442e-af49-4194a3fa4fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-3333d218-e3b2-481c-8872-3b4f9b85dbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-2552e7f7-3915-41fc-994f-2ed83b698fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-3eb7a84e-ed13-446d-a1ea-9f28d3cd51b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-da233893-771d-4a3c-af7e-043bb9cd2754,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-95f7cb27-8cc8-4e8b-a84e-6ff3bf71adb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-5e310cee-3960-4175-928f-b19fe265802d,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-02bbec1e-16cc-465a-b60c-3a5ba4284fa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2111454374-172.17.0.11-1595883338847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44868,DS-eac852ed-938f-442e-af49-4194a3fa4fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-3333d218-e3b2-481c-8872-3b4f9b85dbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-2552e7f7-3915-41fc-994f-2ed83b698fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-3eb7a84e-ed13-446d-a1ea-9f28d3cd51b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-da233893-771d-4a3c-af7e-043bb9cd2754,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-95f7cb27-8cc8-4e8b-a84e-6ff3bf71adb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-5e310cee-3960-4175-928f-b19fe265802d,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-02bbec1e-16cc-465a-b60c-3a5ba4284fa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427270026-172.17.0.11-1595883725356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37454,DS-fcca5b16-6373-498a-8388-59fd6a24359e,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-538e968d-aafe-4a42-bf25-4d10a541925b,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-35354aa7-4b4e-4898-b51b-8339652fc7af,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-c5bb8378-84fe-4d84-9d6c-103d94be42df,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-c1d5839a-32b6-47c8-89ab-c2c30e79e626,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-e1813583-8057-4c5c-997f-0149356efc29,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-ff79c219-d40e-48a9-8232-fb1957dd12ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-3590bcad-d791-4eee-a911-e8945746894c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427270026-172.17.0.11-1595883725356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37454,DS-fcca5b16-6373-498a-8388-59fd6a24359e,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-538e968d-aafe-4a42-bf25-4d10a541925b,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-35354aa7-4b4e-4898-b51b-8339652fc7af,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-c5bb8378-84fe-4d84-9d6c-103d94be42df,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-c1d5839a-32b6-47c8-89ab-c2c30e79e626,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-e1813583-8057-4c5c-997f-0149356efc29,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-ff79c219-d40e-48a9-8232-fb1957dd12ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-3590bcad-d791-4eee-a911-e8945746894c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786124523-172.17.0.11-1595883958549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34410,DS-30972911-0477-4fb7-a509-a4c3a1806470,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-8909b2d7-36fe-4159-b316-96633951bec3,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-ab171cae-8d65-441f-a7bb-5c0968d7e915,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-9f8c0348-db56-41ad-bc3b-e711061e6d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-33a864aa-0879-4c95-bf66-98dc760c8532,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-de81cecd-5a6b-4ead-a121-0667c7046b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-dcb87521-20ff-4069-af95-ddb68bc79287,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-7a403ab8-aa0d-4be3-9a01-edde82547f86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786124523-172.17.0.11-1595883958549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34410,DS-30972911-0477-4fb7-a509-a4c3a1806470,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-8909b2d7-36fe-4159-b316-96633951bec3,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-ab171cae-8d65-441f-a7bb-5c0968d7e915,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-9f8c0348-db56-41ad-bc3b-e711061e6d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-33a864aa-0879-4c95-bf66-98dc760c8532,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-de81cecd-5a6b-4ead-a121-0667c7046b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-dcb87521-20ff-4069-af95-ddb68bc79287,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-7a403ab8-aa0d-4be3-9a01-edde82547f86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406679818-172.17.0.11-1595884236841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34581,DS-0e037203-2060-4f54-b86d-2377329fef68,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-54251b42-0d50-45ae-a5d8-019e458511c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-d60cfd64-f1aa-450e-87c3-92b402ec3f61,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-617932a2-a5d3-47bb-8260-74c7b99e142f,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-660b64cf-8078-46ce-98aa-31205ac3ba1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-c0816f46-f798-4a04-abf7-7e039e3a28ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-86196f52-68d0-404e-a9b3-50b830ce0813,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-a8f5f6d7-441c-403e-b21c-a278468e429f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406679818-172.17.0.11-1595884236841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34581,DS-0e037203-2060-4f54-b86d-2377329fef68,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-54251b42-0d50-45ae-a5d8-019e458511c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-d60cfd64-f1aa-450e-87c3-92b402ec3f61,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-617932a2-a5d3-47bb-8260-74c7b99e142f,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-660b64cf-8078-46ce-98aa-31205ac3ba1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-c0816f46-f798-4a04-abf7-7e039e3a28ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-86196f52-68d0-404e-a9b3-50b830ce0813,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-a8f5f6d7-441c-403e-b21c-a278468e429f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864778831-172.17.0.11-1595884336467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38993,DS-8eeb5189-e2e3-4d1e-a51b-266f7696af4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-ea9cd44f-368b-400c-9317-e062c7449736,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-af1f524f-6f66-4125-807c-5c20502baa22,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-2e5f9dfe-d9ac-431b-9a43-b61ffc9fd603,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-4055a799-ac03-4efd-8aae-5fee04ccde82,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-8d89f38d-92c9-4f90-9f55-439530e8fc09,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-72c70b6b-74a5-47d6-9f28-193264630cac,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-8c30a9d6-d89a-428a-9867-cd77a09be8c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864778831-172.17.0.11-1595884336467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38993,DS-8eeb5189-e2e3-4d1e-a51b-266f7696af4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-ea9cd44f-368b-400c-9317-e062c7449736,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-af1f524f-6f66-4125-807c-5c20502baa22,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-2e5f9dfe-d9ac-431b-9a43-b61ffc9fd603,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-4055a799-ac03-4efd-8aae-5fee04ccde82,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-8d89f38d-92c9-4f90-9f55-439530e8fc09,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-72c70b6b-74a5-47d6-9f28-193264630cac,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-8c30a9d6-d89a-428a-9867-cd77a09be8c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522007560-172.17.0.11-1595884540687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33633,DS-8914197b-bfe3-4eec-a4c3-59eb53677ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-53a1786c-4f55-4818-8b49-47482e222de4,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-0b4fe96b-40a1-4cd3-b8b5-4cae08939862,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-98e3da03-d988-47fe-8094-ec807c165766,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-d31af8c5-486a-40b8-80a9-3a88470fa54e,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-e913d59b-514a-4ca3-95a2-c7963714c155,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-2d9d7616-e812-4665-96c1-6c282b279e82,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-c036e676-a4f9-43c9-98e0-88533c5ca070,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522007560-172.17.0.11-1595884540687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33633,DS-8914197b-bfe3-4eec-a4c3-59eb53677ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-53a1786c-4f55-4818-8b49-47482e222de4,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-0b4fe96b-40a1-4cd3-b8b5-4cae08939862,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-98e3da03-d988-47fe-8094-ec807c165766,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-d31af8c5-486a-40b8-80a9-3a88470fa54e,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-e913d59b-514a-4ca3-95a2-c7963714c155,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-2d9d7616-e812-4665-96c1-6c282b279e82,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-c036e676-a4f9-43c9-98e0-88533c5ca070,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1331297806-172.17.0.11-1595885387050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45221,DS-88014c50-8299-4058-b877-302f5ad96708,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-35557982-4296-472c-b179-c6b579cafb12,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-9362da56-708a-4361-9320-96889bb15b21,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-4ff03725-ae77-4653-bc6c-04edd06413cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-42a22f9e-e731-468e-bd19-27c649bff388,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-450d4d6b-ab8f-43b1-a730-fc374f11271d,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-82fc5390-7ab5-43f9-b10c-1471f372b028,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-47073c42-6824-4243-b513-76b038a30e5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1331297806-172.17.0.11-1595885387050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45221,DS-88014c50-8299-4058-b877-302f5ad96708,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-35557982-4296-472c-b179-c6b579cafb12,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-9362da56-708a-4361-9320-96889bb15b21,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-4ff03725-ae77-4653-bc6c-04edd06413cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-42a22f9e-e731-468e-bd19-27c649bff388,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-450d4d6b-ab8f-43b1-a730-fc374f11271d,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-82fc5390-7ab5-43f9-b10c-1471f372b028,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-47073c42-6824-4243-b513-76b038a30e5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731793952-172.17.0.11-1595885516019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43005,DS-c122bcf2-8bb2-49c6-b2fc-50cb4a943dce,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-c02cfdaf-14ed-491b-b7e5-8c19e9471bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-01624216-15f1-452b-a6c1-e2d4a47acde8,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-bcb4e3a1-536d-44e7-be49-fa8b75cfe7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-75117dc2-ca37-43b6-b605-fa35c0bcf31b,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-c0e48696-4427-4735-836c-ec759faf2148,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-b26e77fc-81cb-46d0-bce6-2d3a7f6ceebf,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-2671cd18-c4f2-45b0-a995-d574f0c750eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731793952-172.17.0.11-1595885516019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43005,DS-c122bcf2-8bb2-49c6-b2fc-50cb4a943dce,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-c02cfdaf-14ed-491b-b7e5-8c19e9471bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-01624216-15f1-452b-a6c1-e2d4a47acde8,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-bcb4e3a1-536d-44e7-be49-fa8b75cfe7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-75117dc2-ca37-43b6-b605-fa35c0bcf31b,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-c0e48696-4427-4735-836c-ec759faf2148,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-b26e77fc-81cb-46d0-bce6-2d3a7f6ceebf,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-2671cd18-c4f2-45b0-a995-d574f0c750eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226712057-172.17.0.11-1595885780851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37760,DS-0bdbf796-48d8-477b-afc1-4df6ac91ba29,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-fd755073-c652-47d3-9d9d-91b97c4927a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-5b87a79f-3f88-4f93-a362-872b947807f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-bc94fe70-e50d-4823-8892-c651dc5dd66c,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-8cbf46ea-3c28-410a-834f-526882201878,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-be85987d-889c-461a-8d59-5e4c4eefad2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-5eedbd3c-d792-4f49-84ea-b9af35fbb94b,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-477e2df4-dd2c-449e-a8a2-8ac220ab9706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226712057-172.17.0.11-1595885780851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37760,DS-0bdbf796-48d8-477b-afc1-4df6ac91ba29,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-fd755073-c652-47d3-9d9d-91b97c4927a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-5b87a79f-3f88-4f93-a362-872b947807f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-bc94fe70-e50d-4823-8892-c651dc5dd66c,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-8cbf46ea-3c28-410a-834f-526882201878,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-be85987d-889c-461a-8d59-5e4c4eefad2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-5eedbd3c-d792-4f49-84ea-b9af35fbb94b,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-477e2df4-dd2c-449e-a8a2-8ac220ab9706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5280
