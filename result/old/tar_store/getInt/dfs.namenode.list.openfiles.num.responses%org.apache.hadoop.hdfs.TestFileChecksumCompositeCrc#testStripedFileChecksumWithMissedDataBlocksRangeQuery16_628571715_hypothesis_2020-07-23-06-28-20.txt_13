reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-143007294-172.17.0.4-1595485791436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34789,DS-c483a503-3cd0-4ddd-bfdd-086528310fca,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-7c820e80-b949-4b46-95d5-7165261b58ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-b07806c5-5499-41c4-ac6f-0bbb42bcaf62,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-b6907dd3-d515-459f-96d9-6b1c4f9b5a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-1c3dfd5e-7984-4337-a65c-f2b77af01c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-65834b48-dd3a-4399-9909-5266ce6202bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-b8b3774f-8f7a-41bb-951e-96023bde15f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-df64cb81-9ff7-4c2f-8a74-094a0da1c4e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-143007294-172.17.0.4-1595485791436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34789,DS-c483a503-3cd0-4ddd-bfdd-086528310fca,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-7c820e80-b949-4b46-95d5-7165261b58ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-b07806c5-5499-41c4-ac6f-0bbb42bcaf62,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-b6907dd3-d515-459f-96d9-6b1c4f9b5a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-1c3dfd5e-7984-4337-a65c-f2b77af01c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-65834b48-dd3a-4399-9909-5266ce6202bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-b8b3774f-8f7a-41bb-951e-96023bde15f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-df64cb81-9ff7-4c2f-8a74-094a0da1c4e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-118104307-172.17.0.4-1595486218104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41733,DS-56eeed07-d393-4feb-9ec4-3203c0ac98c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-6100c910-f0cb-4967-85d3-0e70a727f1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-b034d75b-e11d-45b5-8094-e655547b8414,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-e829b7ad-7b96-4eb3-9aaa-dfea903b5c96,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-5998bffa-29a4-485e-a301-1c4065be2ade,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-675bb2c9-95d5-4265-9518-64cfd4a14c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-b8a0e77c-d300-4ac6-8101-edfe9a186e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-2f452937-c99f-4138-9d9e-c99ae798fed9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-118104307-172.17.0.4-1595486218104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41733,DS-56eeed07-d393-4feb-9ec4-3203c0ac98c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-6100c910-f0cb-4967-85d3-0e70a727f1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-b034d75b-e11d-45b5-8094-e655547b8414,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-e829b7ad-7b96-4eb3-9aaa-dfea903b5c96,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-5998bffa-29a4-485e-a301-1c4065be2ade,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-675bb2c9-95d5-4265-9518-64cfd4a14c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-b8a0e77c-d300-4ac6-8101-edfe9a186e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-2f452937-c99f-4138-9d9e-c99ae798fed9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1929765460-172.17.0.4-1595486717674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33121,DS-4a5cbf38-e122-4bab-97f4-db1b9d52bf91,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-cdb30561-0596-4272-8838-057761e0ada8,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-95af3b19-c439-47aa-b527-a791627cfd00,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-780a6242-0f28-4905-8b77-debca43ca1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-361a642f-81ac-47e4-9f7f-2668374d1942,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-21b8e420-8bec-4a33-84a4-0f0d1e5946f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-9b0cfb4e-5916-4171-989f-3d6c160dcf0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-8b92e7a1-3687-4945-946a-3c9bcbc9bb99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1929765460-172.17.0.4-1595486717674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33121,DS-4a5cbf38-e122-4bab-97f4-db1b9d52bf91,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-cdb30561-0596-4272-8838-057761e0ada8,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-95af3b19-c439-47aa-b527-a791627cfd00,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-780a6242-0f28-4905-8b77-debca43ca1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-361a642f-81ac-47e4-9f7f-2668374d1942,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-21b8e420-8bec-4a33-84a4-0f0d1e5946f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-9b0cfb4e-5916-4171-989f-3d6c160dcf0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-8b92e7a1-3687-4945-946a-3c9bcbc9bb99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-862335306-172.17.0.4-1595486754363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41272,DS-c171fd22-fff8-4dc2-9c8b-632296716c45,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-05af1d1c-89a7-41d5-89fb-e8d9057ae02c,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-8b268d6d-64ff-461c-9dde-8a39ca1e073d,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-c72fdc62-d7a3-42d4-ba51-2730aad8e109,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-2229a146-bee3-4578-aef6-665cbec08e62,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-64dc1a60-1ced-4601-9924-6094b1092177,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-7543bde5-e2c2-4f91-ac77-23d99752a2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-73c2a753-e145-41e4-bac3-53b3e17e64fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-862335306-172.17.0.4-1595486754363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41272,DS-c171fd22-fff8-4dc2-9c8b-632296716c45,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-05af1d1c-89a7-41d5-89fb-e8d9057ae02c,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-8b268d6d-64ff-461c-9dde-8a39ca1e073d,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-c72fdc62-d7a3-42d4-ba51-2730aad8e109,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-2229a146-bee3-4578-aef6-665cbec08e62,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-64dc1a60-1ced-4601-9924-6094b1092177,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-7543bde5-e2c2-4f91-ac77-23d99752a2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-73c2a753-e145-41e4-bac3-53b3e17e64fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1901161732-172.17.0.4-1595486795263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43101,DS-c452da1a-7090-4449-9c18-d53a79c2e767,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-cce41dae-ae77-4a40-aaf2-cbe15533ec2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-6f930bc9-d966-41a4-8fc4-e63eb359846e,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-a86973b1-c64b-41ea-97e2-c9958accbd07,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-1c2c3d17-ba9d-4340-bf80-49c5512d404a,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-412fb912-3bbd-4351-9843-d56bf6cc5ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-904c7a7c-b6f1-4a53-ae21-a640a2bbe245,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-3f168db8-178c-424f-af51-b575a9121d75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1901161732-172.17.0.4-1595486795263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43101,DS-c452da1a-7090-4449-9c18-d53a79c2e767,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-cce41dae-ae77-4a40-aaf2-cbe15533ec2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-6f930bc9-d966-41a4-8fc4-e63eb359846e,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-a86973b1-c64b-41ea-97e2-c9958accbd07,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-1c2c3d17-ba9d-4340-bf80-49c5512d404a,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-412fb912-3bbd-4351-9843-d56bf6cc5ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-904c7a7c-b6f1-4a53-ae21-a640a2bbe245,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-3f168db8-178c-424f-af51-b575a9121d75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-104641269-172.17.0.4-1595486975926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46374,DS-aa086648-5d10-4f0c-95bb-99f0cb6e5e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-e62105f5-77be-4ee4-baca-a38bfb01747e,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-5befd0e9-55e5-401b-acab-8f991a246004,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-a4dfb15c-32a9-4d5d-b850-a22b4cac815c,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-c51bc46a-f825-4663-83bc-4e0e01a8615d,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-97dd07c4-d554-4098-be00-685d4a2387f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-8c0f9077-82ab-4f4d-bc7e-af228b96045d,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-534d9b85-bf16-4d9b-9ba4-2f784c579ea6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-104641269-172.17.0.4-1595486975926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46374,DS-aa086648-5d10-4f0c-95bb-99f0cb6e5e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-e62105f5-77be-4ee4-baca-a38bfb01747e,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-5befd0e9-55e5-401b-acab-8f991a246004,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-a4dfb15c-32a9-4d5d-b850-a22b4cac815c,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-c51bc46a-f825-4663-83bc-4e0e01a8615d,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-97dd07c4-d554-4098-be00-685d4a2387f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-8c0f9077-82ab-4f4d-bc7e-af228b96045d,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-534d9b85-bf16-4d9b-9ba4-2f784c579ea6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266548145-172.17.0.4-1595487114366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42041,DS-803e9b05-21c3-44dc-9dc2-cd493e8dd677,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-f87d2c33-8797-413a-afa7-1474abaf8b01,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-35acb92c-4bac-43e8-9069-f2f6c3a6727d,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-46949f14-5f45-46bc-8cb1-831e24cd8669,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-74288e5c-605d-4519-8342-66ac2ca04324,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-6d566883-0c91-42c3-97f7-d2f401947c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-d2ccdbdd-0763-449b-a2b0-ac31156ff619,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-78a53ae5-9ac1-416f-9124-4884b8b32858,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266548145-172.17.0.4-1595487114366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42041,DS-803e9b05-21c3-44dc-9dc2-cd493e8dd677,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-f87d2c33-8797-413a-afa7-1474abaf8b01,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-35acb92c-4bac-43e8-9069-f2f6c3a6727d,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-46949f14-5f45-46bc-8cb1-831e24cd8669,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-74288e5c-605d-4519-8342-66ac2ca04324,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-6d566883-0c91-42c3-97f7-d2f401947c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-d2ccdbdd-0763-449b-a2b0-ac31156ff619,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-78a53ae5-9ac1-416f-9124-4884b8b32858,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1966216138-172.17.0.4-1595487189696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36448,DS-59d0e00e-32d3-4210-aecf-44c90f72a1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-c6d07c98-1c53-4e9e-abf1-a959cd992395,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-26e475f9-634f-4c8a-b77f-e9c0acd65954,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-aab7299d-daa1-4127-af3b-f7551268e951,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-0b637759-ff96-49a4-8910-bf9a051757ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-baba8144-73ae-4573-8ab3-30b273f3b2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-0b59afac-32e0-4ec3-baca-6f71318fe807,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-66b18879-9854-4137-845f-41de9f4da581,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1966216138-172.17.0.4-1595487189696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36448,DS-59d0e00e-32d3-4210-aecf-44c90f72a1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-c6d07c98-1c53-4e9e-abf1-a959cd992395,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-26e475f9-634f-4c8a-b77f-e9c0acd65954,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-aab7299d-daa1-4127-af3b-f7551268e951,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-0b637759-ff96-49a4-8910-bf9a051757ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-baba8144-73ae-4573-8ab3-30b273f3b2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-0b59afac-32e0-4ec3-baca-6f71318fe807,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-66b18879-9854-4137-845f-41de9f4da581,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2096078273-172.17.0.4-1595487593974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45526,DS-699129d5-c1af-4e41-8697-ede90a40016f,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-862d219c-e4f1-4334-a847-787f87be5746,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-015724b0-fe79-4944-a2aa-06309546e771,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-bcba18a1-e419-4d89-8d00-250103838902,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-f95b90e8-ced3-4011-911f-ce47badf49c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-b5d30dff-234e-4e47-a6c1-e6bc418f4684,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-b363bb28-390b-411b-be34-0e2a63955d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-e7486b32-d42d-413c-a8fb-9d8bf2669307,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2096078273-172.17.0.4-1595487593974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45526,DS-699129d5-c1af-4e41-8697-ede90a40016f,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-862d219c-e4f1-4334-a847-787f87be5746,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-015724b0-fe79-4944-a2aa-06309546e771,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-bcba18a1-e419-4d89-8d00-250103838902,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-f95b90e8-ced3-4011-911f-ce47badf49c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-b5d30dff-234e-4e47-a6c1-e6bc418f4684,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-b363bb28-390b-411b-be34-0e2a63955d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-e7486b32-d42d-413c-a8fb-9d8bf2669307,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-282696647-172.17.0.4-1595487953711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46682,DS-b9f5980f-f3f8-435f-abc5-0288c53dd787,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-b69062cd-ae59-42b8-8842-bd43bdb5f0be,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-64916404-b053-4482-b942-3d8453705d37,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-6644c84c-18e7-4e8e-af6b-46256623d61a,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-6f89167c-ea7a-4656-b9ec-6941a8ec75d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-ad12cf49-2b96-49e1-a8f8-3c6f4364b621,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-27fcddbc-f493-4195-a096-7b189e86c761,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-8aa58374-37b0-4612-aab1-207b3f48da30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-282696647-172.17.0.4-1595487953711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46682,DS-b9f5980f-f3f8-435f-abc5-0288c53dd787,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-b69062cd-ae59-42b8-8842-bd43bdb5f0be,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-64916404-b053-4482-b942-3d8453705d37,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-6644c84c-18e7-4e8e-af6b-46256623d61a,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-6f89167c-ea7a-4656-b9ec-6941a8ec75d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-ad12cf49-2b96-49e1-a8f8-3c6f4364b621,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-27fcddbc-f493-4195-a096-7b189e86c761,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-8aa58374-37b0-4612-aab1-207b3f48da30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245264335-172.17.0.4-1595488870780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38302,DS-585f16ad-609f-4d17-991f-3e49fa95b34e,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-2948ebc5-f1bd-4665-aa35-5d0e7ec2ff6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-bf9a1125-ba8b-444d-8478-bbd544da68f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-0d030dd7-e8f6-47e2-ba43-87c7205409a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-ae5f0919-d2f0-48b6-be66-f8b21c141dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-a46d039d-12fd-4853-9d93-50cdf9df805f,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-b81274de-d22a-4b63-a25f-e4be77133536,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-e4db014c-fb20-450e-9640-36eaa4513270,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245264335-172.17.0.4-1595488870780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38302,DS-585f16ad-609f-4d17-991f-3e49fa95b34e,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-2948ebc5-f1bd-4665-aa35-5d0e7ec2ff6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-bf9a1125-ba8b-444d-8478-bbd544da68f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-0d030dd7-e8f6-47e2-ba43-87c7205409a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-ae5f0919-d2f0-48b6-be66-f8b21c141dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-a46d039d-12fd-4853-9d93-50cdf9df805f,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-b81274de-d22a-4b63-a25f-e4be77133536,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-e4db014c-fb20-450e-9640-36eaa4513270,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2013563313-172.17.0.4-1595488988089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32871,DS-71ed83f1-b41c-4aee-951c-a9b18a389612,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-af87e90f-9a49-4cd8-877d-bd3f26bc84e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-445d2bff-f98d-4a91-9540-0b7fc8a2e5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-36f89700-5878-4867-858b-e4785b5c0829,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-f9404382-4e1b-4587-9263-ce6ae68b7b44,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-4e45518e-8288-40a2-953c-b09bbbc83539,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-17629880-d84a-4e9a-b596-43ca3854604f,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-ce9ec42a-96f4-497c-beb2-8a6025082305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2013563313-172.17.0.4-1595488988089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32871,DS-71ed83f1-b41c-4aee-951c-a9b18a389612,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-af87e90f-9a49-4cd8-877d-bd3f26bc84e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-445d2bff-f98d-4a91-9540-0b7fc8a2e5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-36f89700-5878-4867-858b-e4785b5c0829,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-f9404382-4e1b-4587-9263-ce6ae68b7b44,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-4e45518e-8288-40a2-953c-b09bbbc83539,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-17629880-d84a-4e9a-b596-43ca3854604f,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-ce9ec42a-96f4-497c-beb2-8a6025082305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858135807-172.17.0.4-1595489620425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45272,DS-ab36f4a3-61b2-4698-8925-b154e1488737,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-897010e8-a564-416a-b5f9-37c40fc05bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-a892a545-1a8b-4731-b6db-3153c5bba9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-1f742333-4766-42f3-9a33-c3cb8a1b3e25,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-8d41c519-15ad-4ed2-8c56-f2f0e4f2eacc,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-d57b6ebe-1e9f-4008-9c90-6beb350078af,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-35268e46-530c-4adb-b53e-3518f3b6e21d,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-e3ea5fae-fa04-4c9a-be3c-f3d10f6e51af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858135807-172.17.0.4-1595489620425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45272,DS-ab36f4a3-61b2-4698-8925-b154e1488737,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-897010e8-a564-416a-b5f9-37c40fc05bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-a892a545-1a8b-4731-b6db-3153c5bba9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-1f742333-4766-42f3-9a33-c3cb8a1b3e25,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-8d41c519-15ad-4ed2-8c56-f2f0e4f2eacc,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-d57b6ebe-1e9f-4008-9c90-6beb350078af,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-35268e46-530c-4adb-b53e-3518f3b6e21d,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-e3ea5fae-fa04-4c9a-be3c-f3d10f6e51af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815188824-172.17.0.4-1595490002515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34586,DS-f58db24d-5768-4823-bce9-4dc4a257939d,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-d9f886e4-afbc-4816-9309-4f59928b5a70,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-b7388860-5fd1-4a0c-af61-abe1e75f7948,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-dfc295e3-e7ae-43e9-9cfd-4b13153a67d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-70c9fbd5-730c-4208-b236-399c721b5e96,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-bda35878-2931-4d2a-85b2-b955cad4bb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-55e38dd2-a021-4f66-8dc0-2a103f77f17e,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-23a2fb7a-e30e-43d9-9134-c9a6e14dd2f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815188824-172.17.0.4-1595490002515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34586,DS-f58db24d-5768-4823-bce9-4dc4a257939d,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-d9f886e4-afbc-4816-9309-4f59928b5a70,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-b7388860-5fd1-4a0c-af61-abe1e75f7948,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-dfc295e3-e7ae-43e9-9cfd-4b13153a67d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-70c9fbd5-730c-4208-b236-399c721b5e96,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-bda35878-2931-4d2a-85b2-b955cad4bb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-55e38dd2-a021-4f66-8dc0-2a103f77f17e,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-23a2fb7a-e30e-43d9-9134-c9a6e14dd2f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389096103-172.17.0.4-1595490462082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39926,DS-a06de290-ea33-4e53-9bf0-5858f8cbd39e,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-48fae980-10e5-4c22-b9a4-7fad8102486f,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-721c07a6-a454-4e9c-bcf3-0e83c27d6e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-36334c98-0931-4002-9094-226e5a9c0390,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-20646895-088e-4552-9409-2426e839de2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-997a89ea-d634-4063-b915-209a8b92d2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-fd6848ef-da0a-42f3-b3bc-687e3e9e4aee,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-a4ed8568-a831-4954-b0c4-42ef871359af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389096103-172.17.0.4-1595490462082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39926,DS-a06de290-ea33-4e53-9bf0-5858f8cbd39e,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-48fae980-10e5-4c22-b9a4-7fad8102486f,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-721c07a6-a454-4e9c-bcf3-0e83c27d6e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-36334c98-0931-4002-9094-226e5a9c0390,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-20646895-088e-4552-9409-2426e839de2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-997a89ea-d634-4063-b915-209a8b92d2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-fd6848ef-da0a-42f3-b3bc-687e3e9e4aee,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-a4ed8568-a831-4954-b0c4-42ef871359af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-511017501-172.17.0.4-1595490963305:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43577,DS-c8d74e5e-9bb8-41bd-a6d7-6ffad808ea10,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-304d1b0c-72b7-43d4-a42b-81d10231910f,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-10775fae-b724-42ec-af9b-848481db5fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-063f50a0-425d-49e8-a184-cd8c46410280,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-7fe07ea3-83f8-4cb0-ae51-c858499ca783,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-c8487d96-9636-4eae-8843-213a22704796,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-7cd41295-115f-4b27-858d-53a6d8d9a9db,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-7d9a2586-aa25-41fa-a081-45b7a81d6d02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-511017501-172.17.0.4-1595490963305:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43577,DS-c8d74e5e-9bb8-41bd-a6d7-6ffad808ea10,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-304d1b0c-72b7-43d4-a42b-81d10231910f,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-10775fae-b724-42ec-af9b-848481db5fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-063f50a0-425d-49e8-a184-cd8c46410280,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-7fe07ea3-83f8-4cb0-ae51-c858499ca783,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-c8487d96-9636-4eae-8843-213a22704796,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-7cd41295-115f-4b27-858d-53a6d8d9a9db,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-7d9a2586-aa25-41fa-a081-45b7a81d6d02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5456
