reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370483721-172.17.0.6-1595480295013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33085,DS-1fa2b350-d97a-47b2-880f-0f3f6fa1ca31,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-7001e785-a4ef-48bd-977d-bf967b78a0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-ef6a9479-3089-4724-9005-ef47d18fb623,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-fc93b280-f6a1-4d05-8b2f-060ff72a4105,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-23b0ad74-fce9-464f-a9d0-731b2b9c45e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-1ab0ac34-8ebb-438f-b87c-5673ee2a2846,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-c4df5d6f-4186-4b1c-adad-5b178e4cf725,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-98c57b33-9a2e-4ed9-a2a2-7cea92c61033,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370483721-172.17.0.6-1595480295013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33085,DS-1fa2b350-d97a-47b2-880f-0f3f6fa1ca31,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-7001e785-a4ef-48bd-977d-bf967b78a0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-ef6a9479-3089-4724-9005-ef47d18fb623,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-fc93b280-f6a1-4d05-8b2f-060ff72a4105,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-23b0ad74-fce9-464f-a9d0-731b2b9c45e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-1ab0ac34-8ebb-438f-b87c-5673ee2a2846,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-c4df5d6f-4186-4b1c-adad-5b178e4cf725,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-98c57b33-9a2e-4ed9-a2a2-7cea92c61033,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1920913251-172.17.0.6-1595480367135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39416,DS-bb4afc26-d885-41a8-ac6a-0bdd5e6dad14,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-a0d84b56-f17d-4114-8364-5fdb7ed217dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-025182f5-3161-4983-90b6-fa8a6a3c5108,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-0426fd47-e4e3-4402-8ac3-7daf0a130e30,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-35649649-7c26-4b00-a87e-ea8b56e1aa91,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-44b578a4-d921-4620-90ac-0204568a9bca,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-bc6195d0-6710-4f26-ba61-af92016b3ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-bcb39941-aa21-41e3-9b0c-0cd8df1d67ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1920913251-172.17.0.6-1595480367135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39416,DS-bb4afc26-d885-41a8-ac6a-0bdd5e6dad14,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-a0d84b56-f17d-4114-8364-5fdb7ed217dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-025182f5-3161-4983-90b6-fa8a6a3c5108,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-0426fd47-e4e3-4402-8ac3-7daf0a130e30,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-35649649-7c26-4b00-a87e-ea8b56e1aa91,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-44b578a4-d921-4620-90ac-0204568a9bca,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-bc6195d0-6710-4f26-ba61-af92016b3ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-bcb39941-aa21-41e3-9b0c-0cd8df1d67ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065187377-172.17.0.6-1595480506398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34606,DS-a613cb7a-b29e-4dd0-abbc-a3faf3911044,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-919b9e71-61c0-43e2-8901-74a25d914e86,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-efdccb9d-e162-46e7-9c71-fa9c95f09c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-d8a9496e-b89b-4f00-a860-ba9b2b90fdc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-c6531ca4-5dbe-467d-918f-52fe8e95a612,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-ed52da9a-6c81-45d7-a07a-3456990a6818,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-8c89631e-fc70-4e7c-b1d9-fc6a124dbc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-81c082cd-b01f-489e-a4fe-94905ebc9481,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065187377-172.17.0.6-1595480506398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34606,DS-a613cb7a-b29e-4dd0-abbc-a3faf3911044,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-919b9e71-61c0-43e2-8901-74a25d914e86,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-efdccb9d-e162-46e7-9c71-fa9c95f09c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-d8a9496e-b89b-4f00-a860-ba9b2b90fdc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-c6531ca4-5dbe-467d-918f-52fe8e95a612,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-ed52da9a-6c81-45d7-a07a-3456990a6818,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-8c89631e-fc70-4e7c-b1d9-fc6a124dbc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-81c082cd-b01f-489e-a4fe-94905ebc9481,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1236309275-172.17.0.6-1595480539417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34785,DS-b1b44644-02da-4f7b-8aa7-0d7ded9d8b49,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-6bac065c-b030-48fc-8fb3-30be5facf051,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-ab4f1688-2c37-48d8-be19-2ca45307b680,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-e9a28ba5-134f-46d5-8999-23fe2aadeca4,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-fe2776da-4d3b-4846-bed7-85a2490bc9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-f0ed5fe0-364c-4a62-83f1-ae5f9f66a7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-bc16245e-a546-4154-b7d1-acedca175416,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-ba578c34-03c7-4aac-ab7f-2bb93329e99b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1236309275-172.17.0.6-1595480539417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34785,DS-b1b44644-02da-4f7b-8aa7-0d7ded9d8b49,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-6bac065c-b030-48fc-8fb3-30be5facf051,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-ab4f1688-2c37-48d8-be19-2ca45307b680,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-e9a28ba5-134f-46d5-8999-23fe2aadeca4,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-fe2776da-4d3b-4846-bed7-85a2490bc9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-f0ed5fe0-364c-4a62-83f1-ae5f9f66a7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-bc16245e-a546-4154-b7d1-acedca175416,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-ba578c34-03c7-4aac-ab7f-2bb93329e99b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335790022-172.17.0.6-1595480782166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40661,DS-31280940-c0b3-48d6-8779-3f54ec8852cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-d950567a-d019-4b9e-9de2-1879bef9633c,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-c1579479-7929-4b05-a3d5-7e05d3c5f83a,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-5911539e-8af0-4a2b-a975-03eef3360e77,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-bd52b38e-c170-4b64-be5d-5bb8a4f1fb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-54df697b-ffcc-40f8-98f7-d144dc4ad498,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-cd0af230-205e-470c-9242-7a68fe7da232,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-80a01b37-d83b-4b05-a54d-c66c18c95874,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335790022-172.17.0.6-1595480782166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40661,DS-31280940-c0b3-48d6-8779-3f54ec8852cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-d950567a-d019-4b9e-9de2-1879bef9633c,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-c1579479-7929-4b05-a3d5-7e05d3c5f83a,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-5911539e-8af0-4a2b-a975-03eef3360e77,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-bd52b38e-c170-4b64-be5d-5bb8a4f1fb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-54df697b-ffcc-40f8-98f7-d144dc4ad498,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-cd0af230-205e-470c-9242-7a68fe7da232,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-80a01b37-d83b-4b05-a54d-c66c18c95874,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012275991-172.17.0.6-1595480932920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36444,DS-371a95c4-5697-4d04-a728-ce75396d4d91,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-39a5d170-765f-46ce-9e4a-76a88a5254dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-bd6ff82d-2299-45af-bc42-250a8cf67d21,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-7c16a839-be3c-4dda-a139-769419f2530a,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-636c492e-237d-44c7-921a-22570ba3b5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-a5a99d7d-aeb5-49d4-8258-32f42699b91d,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-f2b70f39-9826-4d29-9f88-91b52af37dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-42f5be15-6d93-4e4e-8332-03df5813ca08,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012275991-172.17.0.6-1595480932920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36444,DS-371a95c4-5697-4d04-a728-ce75396d4d91,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-39a5d170-765f-46ce-9e4a-76a88a5254dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-bd6ff82d-2299-45af-bc42-250a8cf67d21,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-7c16a839-be3c-4dda-a139-769419f2530a,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-636c492e-237d-44c7-921a-22570ba3b5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-a5a99d7d-aeb5-49d4-8258-32f42699b91d,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-f2b70f39-9826-4d29-9f88-91b52af37dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-42f5be15-6d93-4e4e-8332-03df5813ca08,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616786642-172.17.0.6-1595481066111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44600,DS-1b23bb19-2d8c-4c77-94d5-2e8f82ce8ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-72f68eee-ed81-4461-b106-fa7cb0c09761,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-86715f9c-c692-48c2-a1d4-8aef8d406843,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-6b192c08-7880-4e59-8e16-3d372160b2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-8ecde3a3-162f-41ff-a8f5-2f1fdb0dda17,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-940fb747-e9bd-43b6-bd97-c41763bd7456,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-6560dcde-bb67-4376-a9d7-bbcc4215bf00,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-62427fed-1927-4f1a-8151-216bb58032b9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616786642-172.17.0.6-1595481066111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44600,DS-1b23bb19-2d8c-4c77-94d5-2e8f82ce8ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-72f68eee-ed81-4461-b106-fa7cb0c09761,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-86715f9c-c692-48c2-a1d4-8aef8d406843,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-6b192c08-7880-4e59-8e16-3d372160b2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-8ecde3a3-162f-41ff-a8f5-2f1fdb0dda17,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-940fb747-e9bd-43b6-bd97-c41763bd7456,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-6560dcde-bb67-4376-a9d7-bbcc4215bf00,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-62427fed-1927-4f1a-8151-216bb58032b9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-791786035-172.17.0.6-1595481273622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42371,DS-74415288-d5aa-44c0-9437-835cc61ad798,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-1cc0c2de-c54a-4065-b400-27fc4f2b8f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-d562f3e7-31e6-4701-952d-82abcebc86a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-f931c97c-acf5-4a25-b753-2503d3647117,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-570b2f31-4d73-46b4-b4db-fbaacaee8fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-5d64ee73-c42b-4ade-af8e-16767d7f798a,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-f2080106-70fa-4d25-84fe-d6ef32191a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-04fcdf08-d312-49df-bcee-e70fa448a8f6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-791786035-172.17.0.6-1595481273622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42371,DS-74415288-d5aa-44c0-9437-835cc61ad798,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-1cc0c2de-c54a-4065-b400-27fc4f2b8f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-d562f3e7-31e6-4701-952d-82abcebc86a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-f931c97c-acf5-4a25-b753-2503d3647117,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-570b2f31-4d73-46b4-b4db-fbaacaee8fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-5d64ee73-c42b-4ade-af8e-16767d7f798a,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-f2080106-70fa-4d25-84fe-d6ef32191a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-04fcdf08-d312-49df-bcee-e70fa448a8f6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728355243-172.17.0.6-1595481420745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45527,DS-a46b5430-89b8-49b3-87e2-b13b802ecb60,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-3a1bd392-a788-4aaf-b40e-57c831f8d4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-7dce405f-0848-4712-b385-b7fe7c1f0535,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-297cc7a3-f13c-4805-9fc5-49fab12c9952,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-81a8a66d-ec2b-4b7e-8245-180b2423d6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-adbaa018-9c00-4c07-b38e-1bd48e5dac03,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-24ae6fa2-abb2-43a4-b115-4bf411e25a42,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-87198b4b-18ec-4b97-a124-4093925c63de,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728355243-172.17.0.6-1595481420745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45527,DS-a46b5430-89b8-49b3-87e2-b13b802ecb60,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-3a1bd392-a788-4aaf-b40e-57c831f8d4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-7dce405f-0848-4712-b385-b7fe7c1f0535,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-297cc7a3-f13c-4805-9fc5-49fab12c9952,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-81a8a66d-ec2b-4b7e-8245-180b2423d6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-adbaa018-9c00-4c07-b38e-1bd48e5dac03,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-24ae6fa2-abb2-43a4-b115-4bf411e25a42,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-87198b4b-18ec-4b97-a124-4093925c63de,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-365681343-172.17.0.6-1595481503964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45973,DS-9ca5541e-dfcf-44d4-b42d-4677f9655a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-2edd7f59-4dfb-40c9-8162-ed8c61812a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-2f16b586-913b-40e7-9521-fdd25ebbb2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-bdc55dd7-b5b7-4750-bdd3-569053fa33d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-0800a94f-aa07-4a3d-916b-79871a6f2b71,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-a07c51c3-149d-4041-aec4-8399e6db9a36,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-cf28a426-efa0-46e1-a1e2-1d096bedde28,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-d895f883-cea4-43e9-ac94-9215b834df7e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-365681343-172.17.0.6-1595481503964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45973,DS-9ca5541e-dfcf-44d4-b42d-4677f9655a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-2edd7f59-4dfb-40c9-8162-ed8c61812a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-2f16b586-913b-40e7-9521-fdd25ebbb2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-bdc55dd7-b5b7-4750-bdd3-569053fa33d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-0800a94f-aa07-4a3d-916b-79871a6f2b71,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-a07c51c3-149d-4041-aec4-8399e6db9a36,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-cf28a426-efa0-46e1-a1e2-1d096bedde28,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-d895f883-cea4-43e9-ac94-9215b834df7e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465391615-172.17.0.6-1595481809575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43420,DS-5b652e50-94af-4bc6-bc4f-a190aae0ff60,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-2c1582d1-d252-4119-a8b7-3d31a79f96e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-e0738601-d34c-412c-bff3-e929086472f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-ab30412b-dc30-4902-a675-6b886d06ac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-33f667cd-edd1-4813-8042-366558191eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-855d7b58-ee4f-4494-a839-9b3c9feb7881,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-82fc1f26-c288-42fd-bfbc-467423de0bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-74bf1178-6773-4012-b66b-707e3c3f8832,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465391615-172.17.0.6-1595481809575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43420,DS-5b652e50-94af-4bc6-bc4f-a190aae0ff60,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-2c1582d1-d252-4119-a8b7-3d31a79f96e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-e0738601-d34c-412c-bff3-e929086472f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-ab30412b-dc30-4902-a675-6b886d06ac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-33f667cd-edd1-4813-8042-366558191eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-855d7b58-ee4f-4494-a839-9b3c9feb7881,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-82fc1f26-c288-42fd-bfbc-467423de0bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-74bf1178-6773-4012-b66b-707e3c3f8832,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124142077-172.17.0.6-1595481923531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41039,DS-b38e4f6d-b711-4671-bf0f-47399b46a61d,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-9dc43271-5a46-432c-85be-2c938f5e819a,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-e6262432-18e4-4510-96a1-b960cfe84507,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-d67b069d-ef09-4bdc-bb5e-2614d86ef22c,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-8ae3c842-6b11-482c-aedf-1f8afc777c86,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-09377fe0-7b0f-47e7-90c8-ab05e9c05b40,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-4da61ca9-91e5-4b0a-9a48-bbbf9231d977,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-e6efcdf4-cf38-4864-a6cd-21faf9c7b5d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124142077-172.17.0.6-1595481923531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41039,DS-b38e4f6d-b711-4671-bf0f-47399b46a61d,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-9dc43271-5a46-432c-85be-2c938f5e819a,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-e6262432-18e4-4510-96a1-b960cfe84507,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-d67b069d-ef09-4bdc-bb5e-2614d86ef22c,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-8ae3c842-6b11-482c-aedf-1f8afc777c86,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-09377fe0-7b0f-47e7-90c8-ab05e9c05b40,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-4da61ca9-91e5-4b0a-9a48-bbbf9231d977,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-e6efcdf4-cf38-4864-a6cd-21faf9c7b5d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034847159-172.17.0.6-1595482334000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38456,DS-9efa7ac7-c670-4c02-9fa6-2f7bec0f39cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-177f64f6-22d4-4761-9cc2-788d644eea65,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-4d33077b-6229-4a78-9825-a0fe596fa4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-d0dd53d1-9384-43a3-8c13-b8f84525a7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-f2e629a6-eace-4d34-a6ab-519da934c3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-5e8fd84c-864a-45f1-9d92-ba6c154eb8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-b3de4ede-79f4-4d78-996e-87d5cc1ff5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-36c301b4-a05e-41cb-8d13-c8e999820e7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034847159-172.17.0.6-1595482334000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38456,DS-9efa7ac7-c670-4c02-9fa6-2f7bec0f39cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-177f64f6-22d4-4761-9cc2-788d644eea65,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-4d33077b-6229-4a78-9825-a0fe596fa4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-d0dd53d1-9384-43a3-8c13-b8f84525a7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-f2e629a6-eace-4d34-a6ab-519da934c3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-5e8fd84c-864a-45f1-9d92-ba6c154eb8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-b3de4ede-79f4-4d78-996e-87d5cc1ff5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-36c301b4-a05e-41cb-8d13-c8e999820e7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-790052718-172.17.0.6-1595482367452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33767,DS-2a84222b-b5c4-42d6-9915-92acf22c29b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-8898d254-c09f-4d41-a21c-50e65abb1d19,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-749d0764-d170-44d2-86cc-e0b3c742e4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-afc1b627-ef43-483c-9f0a-2a6d4b3ac52f,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-8c4b57bb-d93f-4d78-bb01-f7e3d35eadbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-3366cbee-d1a4-414d-a4e4-7e761c72f8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-4afd03e3-0876-42e4-bd5d-8da0cdeb7894,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-0c84bb88-d455-4dde-baba-b24f69f74457,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-790052718-172.17.0.6-1595482367452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33767,DS-2a84222b-b5c4-42d6-9915-92acf22c29b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-8898d254-c09f-4d41-a21c-50e65abb1d19,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-749d0764-d170-44d2-86cc-e0b3c742e4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-afc1b627-ef43-483c-9f0a-2a6d4b3ac52f,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-8c4b57bb-d93f-4d78-bb01-f7e3d35eadbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-3366cbee-d1a4-414d-a4e4-7e761c72f8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-4afd03e3-0876-42e4-bd5d-8da0cdeb7894,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-0c84bb88-d455-4dde-baba-b24f69f74457,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283713461-172.17.0.6-1595482503172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46239,DS-18b94b7d-7ff3-4b54-910d-86ab32e08646,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-132c3d27-d329-4d2c-9e2e-a9aca8f80e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-3d32fe9a-fc26-4ac5-a623-ad09b5e393e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-0885bfdb-0098-4e02-ad6a-32f6b86f077f,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-70ddd544-ea16-48c6-b570-62c94ca3e012,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-230f5b65-8056-4ff3-92d5-85e67f67ed12,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-1d60ae76-410b-4bf5-a244-5b95df3588c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-4d4b6941-e212-4b56-bb11-ce07a80e666c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283713461-172.17.0.6-1595482503172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46239,DS-18b94b7d-7ff3-4b54-910d-86ab32e08646,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-132c3d27-d329-4d2c-9e2e-a9aca8f80e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-3d32fe9a-fc26-4ac5-a623-ad09b5e393e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-0885bfdb-0098-4e02-ad6a-32f6b86f077f,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-70ddd544-ea16-48c6-b570-62c94ca3e012,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-230f5b65-8056-4ff3-92d5-85e67f67ed12,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-1d60ae76-410b-4bf5-a244-5b95df3588c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-4d4b6941-e212-4b56-bb11-ce07a80e666c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37586133-172.17.0.6-1595482856784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43391,DS-1dddceb1-8990-4b19-9b8a-0774a98e817f,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-463d79db-4748-497b-9606-35acb7b9d477,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-6222edf3-dda2-4eaf-b697-644685756def,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-11a7674f-3d84-47f7-a4b2-f5d5399ae16d,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-58bc6b79-0ba7-488c-9d8e-0ecce44d8e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-d0ef06eb-7430-494a-aad9-abf671e5a9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-bc512bbc-932c-435a-9e04-d163a452717a,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-47db267f-332b-4a54-b986-65e2d40a9822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37586133-172.17.0.6-1595482856784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43391,DS-1dddceb1-8990-4b19-9b8a-0774a98e817f,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-463d79db-4748-497b-9606-35acb7b9d477,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-6222edf3-dda2-4eaf-b697-644685756def,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-11a7674f-3d84-47f7-a4b2-f5d5399ae16d,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-58bc6b79-0ba7-488c-9d8e-0ecce44d8e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-d0ef06eb-7430-494a-aad9-abf671e5a9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-bc512bbc-932c-435a-9e04-d163a452717a,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-47db267f-332b-4a54-b986-65e2d40a9822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1247193053-172.17.0.6-1595483010475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40828,DS-97e4f239-4339-4921-8c78-b62e29aed39a,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-48e70200-1724-452e-9c72-2f10a56bdf43,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-76a25d9d-1c74-462f-90a0-5361ad5ec2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-2d8487f4-99bc-4ee4-bee8-abac8423018a,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-57e5a6f9-c327-409d-945a-7030c58684e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-e1f683d3-abcb-43cc-84e3-b3f3b8947e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-a2088c18-1718-4dde-96e9-150648ebfa24,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-7b8393c3-6dad-4635-81be-ce5651ee0328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1247193053-172.17.0.6-1595483010475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40828,DS-97e4f239-4339-4921-8c78-b62e29aed39a,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-48e70200-1724-452e-9c72-2f10a56bdf43,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-76a25d9d-1c74-462f-90a0-5361ad5ec2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-2d8487f4-99bc-4ee4-bee8-abac8423018a,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-57e5a6f9-c327-409d-945a-7030c58684e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-e1f683d3-abcb-43cc-84e3-b3f3b8947e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-a2088c18-1718-4dde-96e9-150648ebfa24,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-7b8393c3-6dad-4635-81be-ce5651ee0328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520737045-172.17.0.6-1595483058143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42296,DS-1e136435-b3e0-4bef-9af9-ffdb6848f529,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-1e66f9ea-49e0-4b04-98e6-300519b35ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-7af4e27f-c7a2-4d31-a9a1-41d9fd1ce915,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-10044bb1-1d69-4702-b585-f495583e949f,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-ce6162c1-74a8-457f-9729-756709a7f0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-8e490c23-9e0e-4c67-bc74-740e087ddf77,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-c6c0329e-352b-420f-a9bb-8ae90016b677,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-6261503b-d6e5-4866-ad03-81058831e14b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520737045-172.17.0.6-1595483058143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42296,DS-1e136435-b3e0-4bef-9af9-ffdb6848f529,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-1e66f9ea-49e0-4b04-98e6-300519b35ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-7af4e27f-c7a2-4d31-a9a1-41d9fd1ce915,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-10044bb1-1d69-4702-b585-f495583e949f,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-ce6162c1-74a8-457f-9729-756709a7f0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-8e490c23-9e0e-4c67-bc74-740e087ddf77,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-c6c0329e-352b-420f-a9bb-8ae90016b677,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-6261503b-d6e5-4866-ad03-81058831e14b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1919679881-172.17.0.6-1595483664120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37648,DS-ccf526a4-3350-4723-9d41-8bcb760716fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-2a1f797f-394f-4a47-984f-35be791472a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-25a0f716-8a78-4894-b709-b145d8a43bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-3b369b09-62e0-4f7c-994b-7ba49c3a7f01,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-7dc50088-efc5-4df1-9f65-63955d6fed2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-4f336c56-2afa-468c-a3f3-79a29a197fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-0e6aab5f-2337-4bb5-914b-06fd5c091951,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-9f3cec0c-da24-4d30-8d25-5c5792d10e14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1919679881-172.17.0.6-1595483664120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37648,DS-ccf526a4-3350-4723-9d41-8bcb760716fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-2a1f797f-394f-4a47-984f-35be791472a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-25a0f716-8a78-4894-b709-b145d8a43bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-3b369b09-62e0-4f7c-994b-7ba49c3a7f01,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-7dc50088-efc5-4df1-9f65-63955d6fed2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-4f336c56-2afa-468c-a3f3-79a29a197fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-0e6aab5f-2337-4bb5-914b-06fd5c091951,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-9f3cec0c-da24-4d30-8d25-5c5792d10e14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1125347092-172.17.0.6-1595483705984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34838,DS-e5fd4a98-3b79-4d6a-bcd0-e9bb9979fd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-e500820e-2fc1-4e84-9377-6e370cecf151,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-cae851bd-5534-4fb4-9cc6-aa4f096f1e69,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-eaae9c6a-9f83-4875-9cdd-dfa8a445a906,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-73cc8e89-bffc-4e30-aa8c-bfbcc896e64f,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-e2a45a76-ffc3-4012-92e8-8b6cbefa9711,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-591b61da-8699-4fdc-9960-a7c9baba8185,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-c823db78-4a9b-4899-8302-0ffaa4e7a973,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1125347092-172.17.0.6-1595483705984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34838,DS-e5fd4a98-3b79-4d6a-bcd0-e9bb9979fd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-e500820e-2fc1-4e84-9377-6e370cecf151,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-cae851bd-5534-4fb4-9cc6-aa4f096f1e69,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-eaae9c6a-9f83-4875-9cdd-dfa8a445a906,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-73cc8e89-bffc-4e30-aa8c-bfbcc896e64f,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-e2a45a76-ffc3-4012-92e8-8b6cbefa9711,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-591b61da-8699-4fdc-9960-a7c9baba8185,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-c823db78-4a9b-4899-8302-0ffaa4e7a973,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39064328-172.17.0.6-1595484494571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39781,DS-679ff73f-805f-4911-8b9d-b1752ccff9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-c5c93246-c289-4271-9db0-75af27849e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-bbe2eea8-6770-4721-8d4a-8e35a0ff3f67,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-f9829540-0168-4645-b221-eaf196b72697,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-65e618dc-d6b4-406e-b675-d81a04a3130a,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-d98afdc3-b01b-4c8d-a278-04fc594744ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-a7776065-78e1-4c84-b074-88ce51bf1034,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-c3946bce-638a-48da-ab7d-5a7614910c85,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39064328-172.17.0.6-1595484494571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39781,DS-679ff73f-805f-4911-8b9d-b1752ccff9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-c5c93246-c289-4271-9db0-75af27849e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-bbe2eea8-6770-4721-8d4a-8e35a0ff3f67,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-f9829540-0168-4645-b221-eaf196b72697,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-65e618dc-d6b4-406e-b675-d81a04a3130a,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-d98afdc3-b01b-4c8d-a278-04fc594744ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-a7776065-78e1-4c84-b074-88ce51bf1034,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-c3946bce-638a-48da-ab7d-5a7614910c85,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1790541695-172.17.0.6-1595484603380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42590,DS-7a9f8df9-1962-4a9c-a5dd-c80e15f08d11,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-d9472d14-4861-4dea-b02e-589a34e81f75,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-f1eb45e3-0998-4463-ba4f-1be42d21e93c,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-6b9835d6-ebc5-4290-ac6a-f0ef4aae1b32,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-9d4337a9-f1f5-4526-9d3b-c75499585adc,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-6acc9b56-a329-4050-9841-a48ce931ae2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-d237219c-5040-4906-8074-a65bf751bff4,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-2a20c9c7-0733-441d-8aa5-ee82a18bb6ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1790541695-172.17.0.6-1595484603380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42590,DS-7a9f8df9-1962-4a9c-a5dd-c80e15f08d11,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-d9472d14-4861-4dea-b02e-589a34e81f75,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-f1eb45e3-0998-4463-ba4f-1be42d21e93c,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-6b9835d6-ebc5-4290-ac6a-f0ef4aae1b32,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-9d4337a9-f1f5-4526-9d3b-c75499585adc,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-6acc9b56-a329-4050-9841-a48ce931ae2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-d237219c-5040-4906-8074-a65bf751bff4,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-2a20c9c7-0733-441d-8aa5-ee82a18bb6ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-821300008-172.17.0.6-1595484871768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34979,DS-fe4b8e8b-2a10-44c8-910c-bedd1df28b42,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-4a72e1fd-1003-4af1-a4d6-cde371d21394,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-b8858941-101c-41e9-9a1a-9cc109bb001e,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-90c99f36-48d8-4600-a1fa-b59433b84f04,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-cb6d6b89-fc1a-4b3f-931a-8b70920b542d,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-b39c77ec-e0ca-4cab-a64d-4c5c3dcda214,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-fd8be6fd-48f7-4e7b-97a2-a9dedca20b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-df72c67c-d392-4c1f-b1c1-ab06dd3b4ff1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-821300008-172.17.0.6-1595484871768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34979,DS-fe4b8e8b-2a10-44c8-910c-bedd1df28b42,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-4a72e1fd-1003-4af1-a4d6-cde371d21394,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-b8858941-101c-41e9-9a1a-9cc109bb001e,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-90c99f36-48d8-4600-a1fa-b59433b84f04,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-cb6d6b89-fc1a-4b3f-931a-8b70920b542d,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-b39c77ec-e0ca-4cab-a64d-4c5c3dcda214,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-fd8be6fd-48f7-4e7b-97a2-a9dedca20b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-df72c67c-d392-4c1f-b1c1-ab06dd3b4ff1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614540039-172.17.0.6-1595485322765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39725,DS-dd694cb3-06ba-43ff-a407-cb13ac03125d,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-db96b6f8-f6cd-429d-a07d-4c52e2390716,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-c1e67014-bb76-4799-ba26-4c272e885908,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-646b2d69-a54f-46a7-bb98-44392f9f6e93,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-83e4a461-81cf-41ea-bf62-451ea7fbb303,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-412538a1-b0aa-46b2-828a-f1233e1821e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-7d16abc3-6f6a-4df9-9022-653c0ffbf5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-309c9013-1782-4a93-baee-52343536d97f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614540039-172.17.0.6-1595485322765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39725,DS-dd694cb3-06ba-43ff-a407-cb13ac03125d,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-db96b6f8-f6cd-429d-a07d-4c52e2390716,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-c1e67014-bb76-4799-ba26-4c272e885908,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-646b2d69-a54f-46a7-bb98-44392f9f6e93,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-83e4a461-81cf-41ea-bf62-451ea7fbb303,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-412538a1-b0aa-46b2-828a-f1233e1821e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-7d16abc3-6f6a-4df9-9022-653c0ffbf5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-309c9013-1782-4a93-baee-52343536d97f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487350323-172.17.0.6-1595485354811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42519,DS-18261787-1849-4313-9960-7f0a320b5ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-b3262531-1e3a-4051-b35f-b369e49c3ead,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-facdab50-6c93-458d-9c55-7c661c7619f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-acf3d407-e6b0-4ee6-a633-eaaf38bb9d15,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-55d73b00-d21f-4e95-bf13-545b2b238b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-c058cc43-2645-4a1a-b7f7-3b803c789478,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-d238cf24-ee2b-4bd0-a863-b99275665247,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-ee22fad0-3843-4403-acf7-b1042bb09965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487350323-172.17.0.6-1595485354811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42519,DS-18261787-1849-4313-9960-7f0a320b5ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-b3262531-1e3a-4051-b35f-b369e49c3ead,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-facdab50-6c93-458d-9c55-7c661c7619f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-acf3d407-e6b0-4ee6-a633-eaaf38bb9d15,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-55d73b00-d21f-4e95-bf13-545b2b238b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-c058cc43-2645-4a1a-b7f7-3b803c789478,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-d238cf24-ee2b-4bd0-a863-b99275665247,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-ee22fad0-3843-4403-acf7-b1042bb09965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-465061134-172.17.0.6-1595485671763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38118,DS-ecfb21d4-8a33-4000-8c04-d41da4468dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-bda8eb08-23d2-4143-8be7-63315bbf6b56,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-11cd5b17-69ac-48ca-84fb-f069b56d5356,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-03db7a4e-4936-4f34-8a1e-1a085b8520d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-0bd6d5b8-2b6c-4747-bd9c-286b56cd985c,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-84dd41d1-0a0c-45e7-8e11-99a3241ce4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-e044d7c2-ed58-4ade-abfb-29d3436e4d53,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-61bb7816-e260-47f1-bf84-7d8ac993c46a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-465061134-172.17.0.6-1595485671763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38118,DS-ecfb21d4-8a33-4000-8c04-d41da4468dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-bda8eb08-23d2-4143-8be7-63315bbf6b56,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-11cd5b17-69ac-48ca-84fb-f069b56d5356,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-03db7a4e-4936-4f34-8a1e-1a085b8520d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-0bd6d5b8-2b6c-4747-bd9c-286b56cd985c,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-84dd41d1-0a0c-45e7-8e11-99a3241ce4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-e044d7c2-ed58-4ade-abfb-29d3436e4d53,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-61bb7816-e260-47f1-bf84-7d8ac993c46a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5605
