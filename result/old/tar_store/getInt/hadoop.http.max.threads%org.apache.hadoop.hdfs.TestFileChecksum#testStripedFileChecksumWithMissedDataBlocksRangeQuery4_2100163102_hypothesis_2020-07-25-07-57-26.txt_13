reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851489585-172.17.0.4-1595664286886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34871,DS-16dd920a-d3fb-4b57-8272-dc926cf8b0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-d504a780-ba68-4d0c-88a8-24c56b5b14d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-d3448d0a-5801-4c3a-af0b-0d48501decd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-3d8f99a9-59c9-4a86-a822-2b09eb6c9c68,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-ad274689-b8c8-43d7-860f-254c00e90b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-7a9ab258-b09e-49c1-9276-ebb686b91cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-00e4bde9-8818-4a42-9475-018f4a8b122d,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-efce769d-06fd-4f16-8683-1d4293c67d3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851489585-172.17.0.4-1595664286886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34871,DS-16dd920a-d3fb-4b57-8272-dc926cf8b0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-d504a780-ba68-4d0c-88a8-24c56b5b14d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-d3448d0a-5801-4c3a-af0b-0d48501decd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-3d8f99a9-59c9-4a86-a822-2b09eb6c9c68,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-ad274689-b8c8-43d7-860f-254c00e90b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-7a9ab258-b09e-49c1-9276-ebb686b91cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-00e4bde9-8818-4a42-9475-018f4a8b122d,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-efce769d-06fd-4f16-8683-1d4293c67d3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-225393825-172.17.0.4-1595664661942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39844,DS-7159b80f-ac9e-4578-ad79-46b700998687,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-5ef5dd48-fee0-471d-8536-20369ad384ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-9038b63f-8151-4494-9f93-a8c7dd96f29c,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-94632f24-7386-45d0-8478-48dce8459022,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-8bcea781-5eab-4179-bb40-ef72ae60463e,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-e3b84055-dc43-4280-9f2b-5d5117af8a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-994f3729-99c0-417f-94d1-e9fb25fb6c27,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-7388a3b6-989a-492f-b0eb-c2e3bdd297ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-225393825-172.17.0.4-1595664661942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39844,DS-7159b80f-ac9e-4578-ad79-46b700998687,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-5ef5dd48-fee0-471d-8536-20369ad384ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-9038b63f-8151-4494-9f93-a8c7dd96f29c,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-94632f24-7386-45d0-8478-48dce8459022,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-8bcea781-5eab-4179-bb40-ef72ae60463e,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-e3b84055-dc43-4280-9f2b-5d5117af8a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-994f3729-99c0-417f-94d1-e9fb25fb6c27,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-7388a3b6-989a-492f-b0eb-c2e3bdd297ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-276910416-172.17.0.4-1595664952570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44394,DS-c092a990-c0a6-4a80-a8cb-0011dfdc3573,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-810395ad-7340-43f5-bf71-9f06d89c9d65,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-48b33d9d-a5a4-4ecf-bf51-b3988897aeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-02877cfb-ae14-4d7e-a538-d514814651ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-4eec34c8-53a8-41d9-821f-79e522ea82ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-6be1392f-7176-413f-80af-e38034cfbd94,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-4c541557-d619-4bf1-8f5f-41b4a1c38d76,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-d3602e52-b7b1-46a4-8752-9eefcf1a51ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-276910416-172.17.0.4-1595664952570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44394,DS-c092a990-c0a6-4a80-a8cb-0011dfdc3573,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-810395ad-7340-43f5-bf71-9f06d89c9d65,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-48b33d9d-a5a4-4ecf-bf51-b3988897aeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-02877cfb-ae14-4d7e-a538-d514814651ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-4eec34c8-53a8-41d9-821f-79e522ea82ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-6be1392f-7176-413f-80af-e38034cfbd94,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-4c541557-d619-4bf1-8f5f-41b4a1c38d76,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-d3602e52-b7b1-46a4-8752-9eefcf1a51ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1136445098-172.17.0.4-1595664983419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40934,DS-68f07bde-9609-43c5-af31-cdda88119788,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-2d39e9e3-ff15-4ec8-a67f-612e2379cdf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-ecc0fd0f-c576-48be-9801-6a17e4612490,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-ee583a83-48cc-4f84-9dcb-ac685b269e44,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-288bb5ab-80b7-4542-b537-525b8d74f8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-9302ff3f-bb58-4fdc-bdde-df0a482bfa37,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-a5354d18-84ef-4111-9bcd-492520cece67,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-d1dab7b2-8c6f-4b38-9990-71aeffe96cf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1136445098-172.17.0.4-1595664983419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40934,DS-68f07bde-9609-43c5-af31-cdda88119788,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-2d39e9e3-ff15-4ec8-a67f-612e2379cdf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-ecc0fd0f-c576-48be-9801-6a17e4612490,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-ee583a83-48cc-4f84-9dcb-ac685b269e44,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-288bb5ab-80b7-4542-b537-525b8d74f8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-9302ff3f-bb58-4fdc-bdde-df0a482bfa37,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-a5354d18-84ef-4111-9bcd-492520cece67,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-d1dab7b2-8c6f-4b38-9990-71aeffe96cf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1794311624-172.17.0.4-1595665060984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34898,DS-23cddef8-2f30-4b3c-8ff0-b73810285c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-c3e48a60-05c8-41c9-92eb-f78ff91f717c,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-e10e14c4-b260-43ee-9089-80b8c90b1cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-eb12cc0e-3c2c-4e1f-9eda-f38ac5411eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-9fb5246e-20e5-4da6-99a2-553ad6f34b56,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-e128ac64-35a8-455d-9679-3042cf1bc66a,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-03d9258a-ad70-4ddf-a36c-91e41260a694,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-735142c4-21b8-4102-81f5-e8c8727c10ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1794311624-172.17.0.4-1595665060984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34898,DS-23cddef8-2f30-4b3c-8ff0-b73810285c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-c3e48a60-05c8-41c9-92eb-f78ff91f717c,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-e10e14c4-b260-43ee-9089-80b8c90b1cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-eb12cc0e-3c2c-4e1f-9eda-f38ac5411eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-9fb5246e-20e5-4da6-99a2-553ad6f34b56,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-e128ac64-35a8-455d-9679-3042cf1bc66a,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-03d9258a-ad70-4ddf-a36c-91e41260a694,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-735142c4-21b8-4102-81f5-e8c8727c10ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-593328211-172.17.0.4-1595665095389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40457,DS-26a31a52-c646-4c07-a103-3ce4d75f6d23,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-d5fcd0d4-006b-47f7-9636-a848b2259111,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-cca48d23-6e32-4a77-8a4a-ec1294de1017,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-c88eaa79-1ef3-4360-b04d-d2513c8be4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-e55c770a-f453-4860-b146-e44e17a136ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-74689ab7-ab55-454b-8777-23768093685f,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-8e8aaf4f-2e09-468f-adc1-32c871fcd3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-f273e49f-5fce-4c3c-a010-b2ec223f5b23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-593328211-172.17.0.4-1595665095389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40457,DS-26a31a52-c646-4c07-a103-3ce4d75f6d23,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-d5fcd0d4-006b-47f7-9636-a848b2259111,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-cca48d23-6e32-4a77-8a4a-ec1294de1017,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-c88eaa79-1ef3-4360-b04d-d2513c8be4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-e55c770a-f453-4860-b146-e44e17a136ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-74689ab7-ab55-454b-8777-23768093685f,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-8e8aaf4f-2e09-468f-adc1-32c871fcd3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-f273e49f-5fce-4c3c-a010-b2ec223f5b23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704011274-172.17.0.4-1595665242279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45091,DS-42157e39-9f13-44b3-acb0-3f072bc2df55,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-44fa25f9-d40e-4945-a3da-b3022e039a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-5bc826ef-474b-446a-9eef-464be1679191,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-920352a4-8ad1-4381-97a5-108078846041,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-f0fddbc6-7c94-4fa1-b16b-0d4d41f73e52,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-3f961bd6-3e57-4b63-aaec-d000faf4cc92,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-3033a5a1-748e-4017-99d5-7ba829c89a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46166,DS-ff4b3d78-7849-435b-b537-78688060baaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704011274-172.17.0.4-1595665242279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45091,DS-42157e39-9f13-44b3-acb0-3f072bc2df55,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-44fa25f9-d40e-4945-a3da-b3022e039a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-5bc826ef-474b-446a-9eef-464be1679191,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-920352a4-8ad1-4381-97a5-108078846041,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-f0fddbc6-7c94-4fa1-b16b-0d4d41f73e52,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-3f961bd6-3e57-4b63-aaec-d000faf4cc92,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-3033a5a1-748e-4017-99d5-7ba829c89a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46166,DS-ff4b3d78-7849-435b-b537-78688060baaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-670306217-172.17.0.4-1595665682757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36608,DS-185c8d46-72e8-4738-9035-68758aca16ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-e5953b51-ed65-475d-90fb-8799ddf4561b,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-88ad76e3-d901-4e6c-af45-c45bfc4e6c80,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-f17c04a9-c347-4779-82f2-e1d104b19333,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-57cb3742-b12e-4fa0-9a58-1890d42fce34,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-6e11e2af-e0e7-45b6-b73a-c763567a539d,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-925fced0-bcb1-4aff-8784-01d93f7a4a43,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-f90d7fc4-055c-465e-b396-eb92f2b36a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-670306217-172.17.0.4-1595665682757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36608,DS-185c8d46-72e8-4738-9035-68758aca16ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-e5953b51-ed65-475d-90fb-8799ddf4561b,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-88ad76e3-d901-4e6c-af45-c45bfc4e6c80,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-f17c04a9-c347-4779-82f2-e1d104b19333,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-57cb3742-b12e-4fa0-9a58-1890d42fce34,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-6e11e2af-e0e7-45b6-b73a-c763567a539d,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-925fced0-bcb1-4aff-8784-01d93f7a4a43,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-f90d7fc4-055c-465e-b396-eb92f2b36a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871993976-172.17.0.4-1595665860946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35679,DS-9c752c38-b406-42d2-b18b-65e5bb9b1193,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-096c4ed5-ebac-4082-b347-31fd12613166,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-9fe98861-6715-4639-ac6c-541ee4053f18,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-fca4a2b8-99be-49fe-abe8-1c4a52caaf16,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-03da193b-9f0c-4679-8c73-422d58c46cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-42df4611-2b24-4fb7-90a8-94187ec04ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-903d2bfa-db9b-4241-afb2-692df4461455,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-8cc42b5e-8418-4db8-8675-cdaaea97c5c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871993976-172.17.0.4-1595665860946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35679,DS-9c752c38-b406-42d2-b18b-65e5bb9b1193,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-096c4ed5-ebac-4082-b347-31fd12613166,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-9fe98861-6715-4639-ac6c-541ee4053f18,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-fca4a2b8-99be-49fe-abe8-1c4a52caaf16,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-03da193b-9f0c-4679-8c73-422d58c46cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-42df4611-2b24-4fb7-90a8-94187ec04ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-903d2bfa-db9b-4241-afb2-692df4461455,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-8cc42b5e-8418-4db8-8675-cdaaea97c5c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1724787700-172.17.0.4-1595666223853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35034,DS-3abcc3c9-3f65-4bac-92d5-18fee6ed53da,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-59358879-82b4-4298-962c-fc18d1732911,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-440d5fc0-79f7-4994-8957-9038eac530cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-f13ebf22-2736-43ae-bbdc-6881e607b9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-655f5a4c-357c-4a3b-909e-fcaa817bcc62,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-b1a632e9-cb41-4c08-a9a1-1d490c92ae81,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-fa0fa940-c9ba-4381-929a-0c8f1f1da66c,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-7fa77c9c-56bf-433a-8de8-f50da0273d41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1724787700-172.17.0.4-1595666223853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35034,DS-3abcc3c9-3f65-4bac-92d5-18fee6ed53da,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-59358879-82b4-4298-962c-fc18d1732911,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-440d5fc0-79f7-4994-8957-9038eac530cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-f13ebf22-2736-43ae-bbdc-6881e607b9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-655f5a4c-357c-4a3b-909e-fcaa817bcc62,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-b1a632e9-cb41-4c08-a9a1-1d490c92ae81,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-fa0fa940-c9ba-4381-929a-0c8f1f1da66c,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-7fa77c9c-56bf-433a-8de8-f50da0273d41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-200737327-172.17.0.4-1595666502304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34051,DS-e92e705c-e9b7-47a8-92df-3b645dfdaf91,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-34f16daf-3d54-46c0-90f6-a8aeb5af0932,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-c763cad7-5f78-4cca-b025-166b8e921347,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-b9735011-87c9-413b-8d7e-1b1acccac047,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-0f92b134-a14b-459e-ac3f-674af243c0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-33d0ac86-960b-400b-9265-b1c3d721fcde,DISK], DatanodeInfoWithStorage[127.0.0.1:39630,DS-495a4adf-9222-403e-b6be-64fe54b87cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-c10a8a5a-992b-4090-a678-39bf1d54933f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-200737327-172.17.0.4-1595666502304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34051,DS-e92e705c-e9b7-47a8-92df-3b645dfdaf91,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-34f16daf-3d54-46c0-90f6-a8aeb5af0932,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-c763cad7-5f78-4cca-b025-166b8e921347,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-b9735011-87c9-413b-8d7e-1b1acccac047,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-0f92b134-a14b-459e-ac3f-674af243c0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-33d0ac86-960b-400b-9265-b1c3d721fcde,DISK], DatanodeInfoWithStorage[127.0.0.1:39630,DS-495a4adf-9222-403e-b6be-64fe54b87cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-c10a8a5a-992b-4090-a678-39bf1d54933f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971843488-172.17.0.4-1595666576797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42490,DS-f3b7a0e9-94e8-4552-9c40-68efee77ce6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-d2d7f19a-b389-4976-a03a-855f6b556b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-dfc897be-e906-4e84-8c5c-2ca4be271785,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-c9b0b568-34d8-4b09-a418-e77401f82329,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-53e509d7-b04e-4d92-994c-80ff93d4a936,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-b57c382c-b6b0-46ab-b843-7d5ff73aa079,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-ab82b83b-9979-444f-a3f0-95bdd4dd58dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-0cdd14cd-cb88-4e41-96b9-48acf24ce09d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971843488-172.17.0.4-1595666576797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42490,DS-f3b7a0e9-94e8-4552-9c40-68efee77ce6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-d2d7f19a-b389-4976-a03a-855f6b556b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-dfc897be-e906-4e84-8c5c-2ca4be271785,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-c9b0b568-34d8-4b09-a418-e77401f82329,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-53e509d7-b04e-4d92-994c-80ff93d4a936,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-b57c382c-b6b0-46ab-b843-7d5ff73aa079,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-ab82b83b-9979-444f-a3f0-95bdd4dd58dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-0cdd14cd-cb88-4e41-96b9-48acf24ce09d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1228536797-172.17.0.4-1595666853051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45019,DS-63d54e7b-3a37-4cbf-a82d-8ab83923772d,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-e70eb8d1-f6cd-45f9-bdde-83a1b7402b57,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-49a2eabc-db39-4d06-9995-d9f2acd07ced,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-b83adfd2-2203-4b3d-8af2-498e7e5b0f12,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-648e473f-05ee-4ca4-b598-1844c61367b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-a6d20b61-32e9-44cc-b005-a639e54f7a60,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-a833ee61-979c-4eb6-927e-a1e57419748a,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-bc0cbb91-d051-48e0-8183-13782ae0e3de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1228536797-172.17.0.4-1595666853051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45019,DS-63d54e7b-3a37-4cbf-a82d-8ab83923772d,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-e70eb8d1-f6cd-45f9-bdde-83a1b7402b57,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-49a2eabc-db39-4d06-9995-d9f2acd07ced,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-b83adfd2-2203-4b3d-8af2-498e7e5b0f12,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-648e473f-05ee-4ca4-b598-1844c61367b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-a6d20b61-32e9-44cc-b005-a639e54f7a60,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-a833ee61-979c-4eb6-927e-a1e57419748a,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-bc0cbb91-d051-48e0-8183-13782ae0e3de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563063938-172.17.0.4-1595667503531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38999,DS-b1d9ef71-8691-45ec-9c4a-800210b59aba,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-e35575fd-9628-43a3-a71c-39e44548d73b,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-9ce4bf7f-bb5c-4493-92f4-56794baeacd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-201210c5-85dd-4669-b1e0-b9fae7dca875,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-560fde2a-beef-4da3-be4f-eebdf3e4e159,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-c0474e53-bb75-4cb4-995b-e14eaa21c67e,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-80598d6b-4917-4d86-913d-a470aa0588b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-d9a4827b-9d3f-434b-b71e-7cad4aac4c1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563063938-172.17.0.4-1595667503531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38999,DS-b1d9ef71-8691-45ec-9c4a-800210b59aba,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-e35575fd-9628-43a3-a71c-39e44548d73b,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-9ce4bf7f-bb5c-4493-92f4-56794baeacd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-201210c5-85dd-4669-b1e0-b9fae7dca875,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-560fde2a-beef-4da3-be4f-eebdf3e4e159,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-c0474e53-bb75-4cb4-995b-e14eaa21c67e,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-80598d6b-4917-4d86-913d-a470aa0588b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-d9a4827b-9d3f-434b-b71e-7cad4aac4c1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2018040095-172.17.0.4-1595667677025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32788,DS-e1427a36-1bb5-4a3b-8808-9b8cd4cbcf3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-4c67463b-c9e9-4e18-b964-4d8ccf3cac8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46166,DS-fc94f5b1-efb4-4253-8460-e5621d4171d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-3dccb993-7166-4128-b744-308b61b5b2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-92bcb2ef-f5b9-43c7-9019-c325ca09a86b,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-e4864de5-454b-49b6-ae35-f6d488624dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-43794829-23c7-4d1c-bd75-e0eaca397f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-e17990b4-63c6-4174-bc2c-272a7bcec918,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2018040095-172.17.0.4-1595667677025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32788,DS-e1427a36-1bb5-4a3b-8808-9b8cd4cbcf3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-4c67463b-c9e9-4e18-b964-4d8ccf3cac8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46166,DS-fc94f5b1-efb4-4253-8460-e5621d4171d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-3dccb993-7166-4128-b744-308b61b5b2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-92bcb2ef-f5b9-43c7-9019-c325ca09a86b,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-e4864de5-454b-49b6-ae35-f6d488624dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-43794829-23c7-4d1c-bd75-e0eaca397f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-e17990b4-63c6-4174-bc2c-272a7bcec918,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1716246305-172.17.0.4-1595668007934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38166,DS-ed3c73c6-3050-46c7-9ebb-20934920dd57,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-b6eca168-00b2-45c4-9b7e-8db0d77abc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-08839d06-cbd6-469d-b1bf-58e6583bad8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-dcef40b9-06be-46b0-8cf2-bb273146298c,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-ddb6b325-398d-4a42-bfda-c39f571c4216,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-69d795e9-35cc-4198-984d-8c32bf05edcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-f5dc67e1-a593-41b6-beca-3afa94f7fe48,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-6b9374d0-d33f-4d84-b9c8-90dcd3a13359,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1716246305-172.17.0.4-1595668007934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38166,DS-ed3c73c6-3050-46c7-9ebb-20934920dd57,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-b6eca168-00b2-45c4-9b7e-8db0d77abc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-08839d06-cbd6-469d-b1bf-58e6583bad8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-dcef40b9-06be-46b0-8cf2-bb273146298c,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-ddb6b325-398d-4a42-bfda-c39f571c4216,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-69d795e9-35cc-4198-984d-8c32bf05edcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-f5dc67e1-a593-41b6-beca-3afa94f7fe48,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-6b9374d0-d33f-4d84-b9c8-90dcd3a13359,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-26822507-172.17.0.4-1595668043229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41296,DS-d175b131-d8ce-4377-b9c5-ecf05358c6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-acd21188-094d-4cd2-a28f-02ab325d9c89,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-b1f323f9-66c1-4eaf-9b76-092cf04dc09c,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-3bf087cf-612d-47c7-b4f6-f0dc7b15ff7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-47e92908-d40b-4fe9-8383-d395e86b5876,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-4558cf8f-a719-49fd-871c-70bdfc262eae,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-236282be-3182-4f2a-93bc-3d3bb8672fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-34f221a8-169c-40c9-a351-63d48183b4a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-26822507-172.17.0.4-1595668043229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41296,DS-d175b131-d8ce-4377-b9c5-ecf05358c6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-acd21188-094d-4cd2-a28f-02ab325d9c89,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-b1f323f9-66c1-4eaf-9b76-092cf04dc09c,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-3bf087cf-612d-47c7-b4f6-f0dc7b15ff7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-47e92908-d40b-4fe9-8383-d395e86b5876,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-4558cf8f-a719-49fd-871c-70bdfc262eae,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-236282be-3182-4f2a-93bc-3d3bb8672fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-34f221a8-169c-40c9-a351-63d48183b4a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605831462-172.17.0.4-1595668475817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40318,DS-6a1de76a-d7ed-4cfd-be0c-5ead89dd566a,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-105d0c12-b258-4102-ac66-fb66d6d5ac0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-22db7cf5-9852-4885-97c9-5b9e58800fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-9d9ba823-c058-45d5-9619-a75ce2ae7a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-3150705d-3bb4-4782-84b1-ac1d886769ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-0f3ed442-279d-4ced-93fb-50166b4879d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-0bb08981-295d-492e-8d8e-ca683bfd831d,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-4fba9d3c-ed79-459c-8dea-2f2b1d9952a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605831462-172.17.0.4-1595668475817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40318,DS-6a1de76a-d7ed-4cfd-be0c-5ead89dd566a,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-105d0c12-b258-4102-ac66-fb66d6d5ac0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-22db7cf5-9852-4885-97c9-5b9e58800fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-9d9ba823-c058-45d5-9619-a75ce2ae7a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-3150705d-3bb4-4782-84b1-ac1d886769ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-0f3ed442-279d-4ced-93fb-50166b4879d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-0bb08981-295d-492e-8d8e-ca683bfd831d,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-4fba9d3c-ed79-459c-8dea-2f2b1d9952a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-256887288-172.17.0.4-1595668986718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39314,DS-3d86a91a-208e-41fe-9494-170e18d3ffa4,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-930725a5-fa7f-4d92-9939-63398e035481,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-7cd465b7-cdbc-42dd-b809-7535e172f40c,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-6d7bc506-4d26-4019-a9f1-ff647ccc0d68,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-0c9607bc-cfd9-4937-bd33-98a84c13d281,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-62eae0dc-a681-4cd3-ae17-b9ee2731fbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-5857c9b5-dfad-4ea1-aa60-79f98b4962df,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-bbebe011-c442-4eca-b2cf-a9ce5cbdf868,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-256887288-172.17.0.4-1595668986718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39314,DS-3d86a91a-208e-41fe-9494-170e18d3ffa4,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-930725a5-fa7f-4d92-9939-63398e035481,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-7cd465b7-cdbc-42dd-b809-7535e172f40c,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-6d7bc506-4d26-4019-a9f1-ff647ccc0d68,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-0c9607bc-cfd9-4937-bd33-98a84c13d281,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-62eae0dc-a681-4cd3-ae17-b9ee2731fbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-5857c9b5-dfad-4ea1-aa60-79f98b4962df,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-bbebe011-c442-4eca-b2cf-a9ce5cbdf868,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5244
