reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1944786261-172.17.0.9-1595959099866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40870,DS-d6888366-ebf3-48ce-9dcd-aa6a511aecd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-3cca6021-1adb-48a1-868b-b25d3ecefc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-3b905a52-13d5-4047-bdfb-2cc1569f3bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-16038bba-4dd0-49a1-a79a-06ebf62199b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-2a434fe5-3d29-422f-aed5-77ec9746b94d,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-ef8d4450-0faa-4f25-b8bb-401e3911d0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-011d2431-d9c9-4d17-86a4-993d8d4739e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-85f2e62c-c30a-44d8-8dea-9a6ba011189d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1944786261-172.17.0.9-1595959099866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40870,DS-d6888366-ebf3-48ce-9dcd-aa6a511aecd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-3cca6021-1adb-48a1-868b-b25d3ecefc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-3b905a52-13d5-4047-bdfb-2cc1569f3bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-16038bba-4dd0-49a1-a79a-06ebf62199b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-2a434fe5-3d29-422f-aed5-77ec9746b94d,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-ef8d4450-0faa-4f25-b8bb-401e3911d0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-011d2431-d9c9-4d17-86a4-993d8d4739e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-85f2e62c-c30a-44d8-8dea-9a6ba011189d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136974282-172.17.0.9-1595959139144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34478,DS-2a81cca8-b1fb-4bd1-950c-ccd7ee99d1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-9912ca6b-4c4c-4ab3-8b30-d58ab7fe5acc,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-025d02d8-3d64-416a-8190-323f1e6f3d28,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-4227f59c-f6f6-4066-a77f-24280dd57e69,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-c8c65adc-b82a-41fa-89bc-a61bf206ea2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-0b94f018-9e22-4450-a13f-3cac99c4291f,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-b30e4dce-a1d0-478c-8210-a88c979c8000,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-bf9b5064-8364-4d5a-8356-0f3dbc15e0c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136974282-172.17.0.9-1595959139144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34478,DS-2a81cca8-b1fb-4bd1-950c-ccd7ee99d1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-9912ca6b-4c4c-4ab3-8b30-d58ab7fe5acc,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-025d02d8-3d64-416a-8190-323f1e6f3d28,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-4227f59c-f6f6-4066-a77f-24280dd57e69,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-c8c65adc-b82a-41fa-89bc-a61bf206ea2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-0b94f018-9e22-4450-a13f-3cac99c4291f,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-b30e4dce-a1d0-478c-8210-a88c979c8000,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-bf9b5064-8364-4d5a-8356-0f3dbc15e0c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899279893-172.17.0.9-1595959202837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33539,DS-75e9d093-70e6-44b2-9167-74e9af9a435f,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-67f2b99d-e98c-4ab1-aa8e-bb7fc6fe9510,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-e16cd6dc-bc81-46fb-9906-1d7c98c5fc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-647e8c2f-4d7d-4ef5-a25b-ad2e22457b54,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-813143ab-2acb-40ef-8edd-eac4dfbf194f,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-5f6566fb-a9d7-4bfd-a059-860347e3212d,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-713117e1-f53b-4644-9099-bdb734a1769e,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-8972d13c-c076-4a76-927e-1a950e41a771,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899279893-172.17.0.9-1595959202837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33539,DS-75e9d093-70e6-44b2-9167-74e9af9a435f,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-67f2b99d-e98c-4ab1-aa8e-bb7fc6fe9510,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-e16cd6dc-bc81-46fb-9906-1d7c98c5fc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-647e8c2f-4d7d-4ef5-a25b-ad2e22457b54,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-813143ab-2acb-40ef-8edd-eac4dfbf194f,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-5f6566fb-a9d7-4bfd-a059-860347e3212d,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-713117e1-f53b-4644-9099-bdb734a1769e,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-8972d13c-c076-4a76-927e-1a950e41a771,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234448872-172.17.0.9-1595959274319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35783,DS-dfdc5758-ee40-4e9d-87e2-5973b6873c77,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-61722950-5fab-4428-81eb-497552519267,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-83a66075-559a-4f3b-b19f-e5d6582552bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-034a7910-020b-4743-a787-88d9529b9bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-5a6d5482-3cbe-4258-8afe-9b53f1556f81,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-d08295dd-ebc4-4736-80ce-533dbadf1d12,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-11a3bf9a-19dd-468e-bc82-d3ef920f6eda,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-4e6ca61d-971b-4dbe-9c42-0ccc2cb89f07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234448872-172.17.0.9-1595959274319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35783,DS-dfdc5758-ee40-4e9d-87e2-5973b6873c77,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-61722950-5fab-4428-81eb-497552519267,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-83a66075-559a-4f3b-b19f-e5d6582552bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-034a7910-020b-4743-a787-88d9529b9bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-5a6d5482-3cbe-4258-8afe-9b53f1556f81,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-d08295dd-ebc4-4736-80ce-533dbadf1d12,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-11a3bf9a-19dd-468e-bc82-d3ef920f6eda,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-4e6ca61d-971b-4dbe-9c42-0ccc2cb89f07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1222784524-172.17.0.9-1595959454421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43686,DS-7d1c131d-8453-43fa-a7b4-2e573cab5e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-bc7135dd-8bf0-4aaa-be3f-0f2366f8ee3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-8525f0e1-a566-4ddb-bd06-5d61538822a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-968bfa18-0d00-4b12-bab6-82c9fbc5e04d,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-8db4a1ba-123a-4bb9-8963-c882a44e3925,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-e3df65ca-eb6d-4e8e-993a-bc0483899cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-707c8728-a1a7-4f47-a7d4-253d093523b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-bf9a175c-5ec4-4b9e-b163-9cbda8c2ffc7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1222784524-172.17.0.9-1595959454421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43686,DS-7d1c131d-8453-43fa-a7b4-2e573cab5e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-bc7135dd-8bf0-4aaa-be3f-0f2366f8ee3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-8525f0e1-a566-4ddb-bd06-5d61538822a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-968bfa18-0d00-4b12-bab6-82c9fbc5e04d,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-8db4a1ba-123a-4bb9-8963-c882a44e3925,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-e3df65ca-eb6d-4e8e-993a-bc0483899cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-707c8728-a1a7-4f47-a7d4-253d093523b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-bf9a175c-5ec4-4b9e-b163-9cbda8c2ffc7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928838909-172.17.0.9-1595959489406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42540,DS-65e2d68f-5d5b-479c-9443-233a67aceb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-a9e4d479-c214-4db9-ac86-4dec88f5a94e,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-83c7e956-58e6-4d14-bea7-f54eec538311,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-3472c7fa-e861-4342-a797-47c105107614,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-675f6954-a8eb-4183-985a-25af8b48737a,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-f7e967a1-f15b-4c31-88b9-442f2e199dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-f2596556-b620-43ad-a96b-2fcd9171e53f,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-080816b9-a6ee-450c-bbe6-d9f09e34f1cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928838909-172.17.0.9-1595959489406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42540,DS-65e2d68f-5d5b-479c-9443-233a67aceb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-a9e4d479-c214-4db9-ac86-4dec88f5a94e,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-83c7e956-58e6-4d14-bea7-f54eec538311,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-3472c7fa-e861-4342-a797-47c105107614,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-675f6954-a8eb-4183-985a-25af8b48737a,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-f7e967a1-f15b-4c31-88b9-442f2e199dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-f2596556-b620-43ad-a96b-2fcd9171e53f,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-080816b9-a6ee-450c-bbe6-d9f09e34f1cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448316869-172.17.0.9-1595959602634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35845,DS-31d0543b-02c0-4805-9924-4f253cf2ba51,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-554062d2-1712-4369-abda-3bc9c88ddb71,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-208a7513-fdbc-436e-b0dc-7b6a397f32f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-e83a76d0-9e89-42c6-ad6c-64d0d95890ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-a4d1d67a-7945-49d1-bc6c-91926219c6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-6dbf8fc2-5b10-4767-966f-558c2a347aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-e4c78b10-d53f-4e87-8f2f-b3ebcc1e89ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-0ad1b2cb-5972-4c38-ac3f-ea65886ced6e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448316869-172.17.0.9-1595959602634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35845,DS-31d0543b-02c0-4805-9924-4f253cf2ba51,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-554062d2-1712-4369-abda-3bc9c88ddb71,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-208a7513-fdbc-436e-b0dc-7b6a397f32f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-e83a76d0-9e89-42c6-ad6c-64d0d95890ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-a4d1d67a-7945-49d1-bc6c-91926219c6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-6dbf8fc2-5b10-4767-966f-558c2a347aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-e4c78b10-d53f-4e87-8f2f-b3ebcc1e89ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-0ad1b2cb-5972-4c38-ac3f-ea65886ced6e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23712400-172.17.0.9-1595959852716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42910,DS-e1860264-fc35-4daa-995f-42f5cf6087cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-24dac00c-b69f-4b53-a302-8526ae0b605f,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-53d7a3d0-c682-4884-aa36-bdefb1e7dc46,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-e4295779-7f22-4599-96e1-7aab35c27bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-042b379c-2f76-49f3-857e-6534c37511a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-c91de4f6-8bc7-4b30-b873-48ebe25780ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-f9128314-ba53-4869-a6a6-4d8e4f4ad9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-842927ec-fcda-47b4-a6c8-b224ca490e98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23712400-172.17.0.9-1595959852716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42910,DS-e1860264-fc35-4daa-995f-42f5cf6087cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-24dac00c-b69f-4b53-a302-8526ae0b605f,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-53d7a3d0-c682-4884-aa36-bdefb1e7dc46,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-e4295779-7f22-4599-96e1-7aab35c27bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-042b379c-2f76-49f3-857e-6534c37511a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-c91de4f6-8bc7-4b30-b873-48ebe25780ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-f9128314-ba53-4869-a6a6-4d8e4f4ad9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-842927ec-fcda-47b4-a6c8-b224ca490e98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1421813799-172.17.0.9-1595959933058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44331,DS-427cad55-949b-4700-b5f9-9b21ae5c1446,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-9532bde7-81ba-413a-8fe5-c61781687053,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-32b236cd-91e6-4434-95ea-7db889fb778d,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-13d75eb0-f44c-43c6-8a70-ef7ed32c27fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-f88f9f8c-a73e-43a6-8f0e-03501195c45a,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-bd133cd1-b750-40ae-8966-55eafa6ae979,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-20a20963-4011-40b4-9631-254780c88628,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-468c7845-07f4-4afc-a50d-0043651754af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1421813799-172.17.0.9-1595959933058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44331,DS-427cad55-949b-4700-b5f9-9b21ae5c1446,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-9532bde7-81ba-413a-8fe5-c61781687053,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-32b236cd-91e6-4434-95ea-7db889fb778d,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-13d75eb0-f44c-43c6-8a70-ef7ed32c27fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-f88f9f8c-a73e-43a6-8f0e-03501195c45a,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-bd133cd1-b750-40ae-8966-55eafa6ae979,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-20a20963-4011-40b4-9631-254780c88628,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-468c7845-07f4-4afc-a50d-0043651754af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438228198-172.17.0.9-1595960045681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39744,DS-eaad4fa7-9025-4fba-bf5c-5b1e2653db9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-2c9c553c-0751-43f8-92a0-c436abe1efe8,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-767a2efa-5c5c-430c-8b6e-d50fb2ead37a,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-9bca7749-85b5-4f06-b876-8eab5c205099,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-b90c6a52-de02-4c37-96cd-b71033c51cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-e5f959f4-6846-4583-8fb5-df20c867d9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-fbe8657e-d399-4f6d-99d7-5d8496345511,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-9ee6d805-cc19-42fe-8944-008ed1daebe6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438228198-172.17.0.9-1595960045681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39744,DS-eaad4fa7-9025-4fba-bf5c-5b1e2653db9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-2c9c553c-0751-43f8-92a0-c436abe1efe8,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-767a2efa-5c5c-430c-8b6e-d50fb2ead37a,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-9bca7749-85b5-4f06-b876-8eab5c205099,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-b90c6a52-de02-4c37-96cd-b71033c51cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-e5f959f4-6846-4583-8fb5-df20c867d9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-fbe8657e-d399-4f6d-99d7-5d8496345511,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-9ee6d805-cc19-42fe-8944-008ed1daebe6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1194848884-172.17.0.9-1595960180163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43139,DS-0f7bbc1d-5880-486b-ae4d-84141819cbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-6c89ac73-5916-4512-aa41-945f53f80958,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-9b7431b6-1873-4320-9e10-9c4628724c55,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-592ee592-a483-428e-8178-6df0eb605694,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-dd27b18c-a3e3-49f7-a488-84cf5b0af9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42961,DS-1a65a697-1460-4ae2-81ae-ecda60e1dbad,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-2c7e39db-bf7c-4c55-94aa-9af6d8468c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-d6de85d4-726f-4497-a5a3-a6da282f9f31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1194848884-172.17.0.9-1595960180163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43139,DS-0f7bbc1d-5880-486b-ae4d-84141819cbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-6c89ac73-5916-4512-aa41-945f53f80958,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-9b7431b6-1873-4320-9e10-9c4628724c55,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-592ee592-a483-428e-8178-6df0eb605694,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-dd27b18c-a3e3-49f7-a488-84cf5b0af9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42961,DS-1a65a697-1460-4ae2-81ae-ecda60e1dbad,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-2c7e39db-bf7c-4c55-94aa-9af6d8468c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-d6de85d4-726f-4497-a5a3-a6da282f9f31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727656412-172.17.0.9-1595960523628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35440,DS-d24784ac-d622-460f-8b74-eb15efe9b7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-05e22596-410e-4c41-b3c8-db5f13badbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-2ca0e4b7-49ee-42ed-9d95-3579e90a7052,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-8c27d033-e332-4acb-a2e5-4173a755b2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-89fd48b5-74c1-4926-9e8c-550d1210a569,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-4e576db6-d6f5-472b-85a0-b3862127a4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-7cf25cf7-e387-4ce7-81a5-95d63cb58653,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-c57274aa-d5db-46fd-9e91-3c99fc6a7242,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727656412-172.17.0.9-1595960523628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35440,DS-d24784ac-d622-460f-8b74-eb15efe9b7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-05e22596-410e-4c41-b3c8-db5f13badbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-2ca0e4b7-49ee-42ed-9d95-3579e90a7052,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-8c27d033-e332-4acb-a2e5-4173a755b2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-89fd48b5-74c1-4926-9e8c-550d1210a569,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-4e576db6-d6f5-472b-85a0-b3862127a4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-7cf25cf7-e387-4ce7-81a5-95d63cb58653,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-c57274aa-d5db-46fd-9e91-3c99fc6a7242,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582365970-172.17.0.9-1595960866019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36923,DS-3c0a26cf-51e6-4503-bf18-3db219afdd84,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-eebdfa87-aad2-4898-92db-707475ffc75d,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-c3455dad-8554-4996-ba26-90e94be30a93,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-1831f1f4-54af-45c3-b14b-8c3d03d522d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-298a2b0a-d888-4be3-a81f-74acbbabc28b,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-597c99e8-c623-47a8-ad6b-e68fab0d482a,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-bcddd57e-1ff6-4465-9525-5b7d4ec9bbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-db89069d-c6ec-4ffd-be9c-adae1419ce11,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582365970-172.17.0.9-1595960866019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36923,DS-3c0a26cf-51e6-4503-bf18-3db219afdd84,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-eebdfa87-aad2-4898-92db-707475ffc75d,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-c3455dad-8554-4996-ba26-90e94be30a93,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-1831f1f4-54af-45c3-b14b-8c3d03d522d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-298a2b0a-d888-4be3-a81f-74acbbabc28b,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-597c99e8-c623-47a8-ad6b-e68fab0d482a,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-bcddd57e-1ff6-4465-9525-5b7d4ec9bbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-db89069d-c6ec-4ffd-be9c-adae1419ce11,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-657782260-172.17.0.9-1595960993587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44833,DS-e8104d3b-f27b-4763-a117-46f212341202,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-6f1f0baa-cad6-4dcb-8ef5-b84525846eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-24b2efa0-b777-4e50-8852-01b194c140fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-28dd0c45-34a2-497c-8bba-3badc035ebe1,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-b602e859-150d-4697-8195-175e3876fe79,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-4eba0264-38a4-470a-8d3a-197bd31f66e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-b74a4658-05de-42e4-91eb-524344c85e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-f06a37c1-f2da-46bb-845c-91f791b0265c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-657782260-172.17.0.9-1595960993587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44833,DS-e8104d3b-f27b-4763-a117-46f212341202,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-6f1f0baa-cad6-4dcb-8ef5-b84525846eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-24b2efa0-b777-4e50-8852-01b194c140fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-28dd0c45-34a2-497c-8bba-3badc035ebe1,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-b602e859-150d-4697-8195-175e3876fe79,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-4eba0264-38a4-470a-8d3a-197bd31f66e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-b74a4658-05de-42e4-91eb-524344c85e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-f06a37c1-f2da-46bb-845c-91f791b0265c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1162247574-172.17.0.9-1595961100863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39483,DS-f9d8fb58-a563-4646-91bc-2431934ff07e,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-fd5baf94-e40f-4fc1-8b05-c5759e7968a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-220bfb66-9384-434e-b7ff-f2680c3ffa99,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-1da26c1f-36c8-40d6-8da7-7e0443b1234d,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-8e2b2dbc-7b56-46d2-9b4e-54f4d8df4e59,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-c763929d-d26d-4c58-8308-293426ce5974,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-16c32a35-7373-4917-b378-11665e74d3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-e3966865-ade6-4ef4-96e6-d248cf3d4a62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1162247574-172.17.0.9-1595961100863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39483,DS-f9d8fb58-a563-4646-91bc-2431934ff07e,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-fd5baf94-e40f-4fc1-8b05-c5759e7968a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-220bfb66-9384-434e-b7ff-f2680c3ffa99,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-1da26c1f-36c8-40d6-8da7-7e0443b1234d,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-8e2b2dbc-7b56-46d2-9b4e-54f4d8df4e59,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-c763929d-d26d-4c58-8308-293426ce5974,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-16c32a35-7373-4917-b378-11665e74d3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-e3966865-ade6-4ef4-96e6-d248cf3d4a62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778040588-172.17.0.9-1595961133481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35874,DS-b6699a26-ebcb-49b8-b5c0-40fdb092bc47,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-51a3ba1b-7958-440e-9316-e63fea33d5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-63f3ba52-f926-4b60-aca8-963267a68894,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-d03a34d0-c853-4e1a-8288-0ef9568ffc41,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-729da96f-7c17-445f-94e7-d62b9398fb28,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-ce779c72-4709-4285-b904-e7868abbced2,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-1f8f156d-7b42-4460-82d6-4d979be00990,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-206993ba-3ff4-48e3-992d-f6bcd16f7f9d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778040588-172.17.0.9-1595961133481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35874,DS-b6699a26-ebcb-49b8-b5c0-40fdb092bc47,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-51a3ba1b-7958-440e-9316-e63fea33d5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-63f3ba52-f926-4b60-aca8-963267a68894,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-d03a34d0-c853-4e1a-8288-0ef9568ffc41,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-729da96f-7c17-445f-94e7-d62b9398fb28,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-ce779c72-4709-4285-b904-e7868abbced2,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-1f8f156d-7b42-4460-82d6-4d979be00990,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-206993ba-3ff4-48e3-992d-f6bcd16f7f9d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403924700-172.17.0.9-1595961240190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45998,DS-8c69fe79-1b5f-4137-8fda-1ddb07605cee,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-b6a50dd4-c364-4ccd-914a-8e1961199fab,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-1cec76fe-117c-4b24-9f2b-8c66b3aa2ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-230b0ff6-e40a-4859-a005-ea0d063f3d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-b20c198e-9c1b-402a-8c6e-6ff3d692468c,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-cedb1bf1-16f4-488c-8078-ff2ef2c89eae,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-9abb5ebf-2629-4f6d-9b92-505051592b77,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-df473cc1-379b-487e-b341-eeb5792f248a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403924700-172.17.0.9-1595961240190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45998,DS-8c69fe79-1b5f-4137-8fda-1ddb07605cee,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-b6a50dd4-c364-4ccd-914a-8e1961199fab,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-1cec76fe-117c-4b24-9f2b-8c66b3aa2ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-230b0ff6-e40a-4859-a005-ea0d063f3d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-b20c198e-9c1b-402a-8c6e-6ff3d692468c,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-cedb1bf1-16f4-488c-8078-ff2ef2c89eae,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-9abb5ebf-2629-4f6d-9b92-505051592b77,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-df473cc1-379b-487e-b341-eeb5792f248a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-585830571-172.17.0.9-1595961270695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39496,DS-f59de4e6-1c91-4d3e-bc59-0ca6dd190f51,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-78882e60-de3f-4d0a-a2ee-521d0f918758,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-94a5fdfc-bdc7-4478-95d0-7d3d963c14e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-2c7c6f8f-e77a-4f59-8a32-e56d949d7c79,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-7533c8de-97f8-4018-b127-b92360cd662a,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-a32b8013-14ca-4f53-88e2-19f496ab3c53,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-0e74c035-2846-4480-adcf-9ca36e924f38,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-d10a69ce-d59c-4997-966b-62fbfe425fed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-585830571-172.17.0.9-1595961270695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39496,DS-f59de4e6-1c91-4d3e-bc59-0ca6dd190f51,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-78882e60-de3f-4d0a-a2ee-521d0f918758,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-94a5fdfc-bdc7-4478-95d0-7d3d963c14e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-2c7c6f8f-e77a-4f59-8a32-e56d949d7c79,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-7533c8de-97f8-4018-b127-b92360cd662a,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-a32b8013-14ca-4f53-88e2-19f496ab3c53,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-0e74c035-2846-4480-adcf-9ca36e924f38,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-d10a69ce-d59c-4997-966b-62fbfe425fed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-680693680-172.17.0.9-1595961527199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42387,DS-8bd38634-9b25-4e05-99de-77b4afa0da47,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-42e799aa-b034-44cb-b9d6-6f173d30cd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-d888525c-874a-46ef-b81e-1063a2afcc09,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-7c0c4832-4670-4c5d-a8ae-cec05589e019,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-0b0de897-50f3-49d5-9be5-bdc44f79f669,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-8ee3d8a2-bca3-4938-956a-89a30943db6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-14ab1e00-de38-4301-be63-ca867bfde150,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-2ad60bb0-06da-4025-ab0e-008a5a02108e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-680693680-172.17.0.9-1595961527199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42387,DS-8bd38634-9b25-4e05-99de-77b4afa0da47,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-42e799aa-b034-44cb-b9d6-6f173d30cd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-d888525c-874a-46ef-b81e-1063a2afcc09,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-7c0c4832-4670-4c5d-a8ae-cec05589e019,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-0b0de897-50f3-49d5-9be5-bdc44f79f669,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-8ee3d8a2-bca3-4938-956a-89a30943db6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-14ab1e00-de38-4301-be63-ca867bfde150,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-2ad60bb0-06da-4025-ab0e-008a5a02108e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145530390-172.17.0.9-1595961561582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44274,DS-9221b49c-fe8b-473a-baee-6577548bf4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-413a07c8-2201-4c38-91cb-e8ada291416d,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-a656e16a-ea24-41a0-addf-3863fb34fa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-dff046fd-3411-4589-b068-5d4010e1d6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-31c861c0-7ac0-41b1-9256-6353498efe3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-28225e1f-885c-4878-9854-0345f2b82067,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-40f75d46-1057-4f39-ae1a-ea36b91cadab,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-6b525402-dc9b-4a6c-b1fd-24f8ebdeabff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145530390-172.17.0.9-1595961561582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44274,DS-9221b49c-fe8b-473a-baee-6577548bf4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-413a07c8-2201-4c38-91cb-e8ada291416d,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-a656e16a-ea24-41a0-addf-3863fb34fa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-dff046fd-3411-4589-b068-5d4010e1d6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-31c861c0-7ac0-41b1-9256-6353498efe3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-28225e1f-885c-4878-9854-0345f2b82067,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-40f75d46-1057-4f39-ae1a-ea36b91cadab,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-6b525402-dc9b-4a6c-b1fd-24f8ebdeabff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185360408-172.17.0.9-1595961698867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35416,DS-dadbed4e-b850-46a2-9fa8-554d4493fc23,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-71eb0568-5ed6-41e9-9683-b6e846c9b75b,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-5b190431-7166-479d-9f4d-884a0c8799ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-97c4a8e4-d555-441a-adbe-432db215ccf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-46107625-f062-45ed-9bc0-ef5695f2a660,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-1a120241-24b4-4e77-8d44-162d371fa8be,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-1185d48b-3f3f-492d-95f0-b15c406e701d,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-eb23d76b-1af2-4799-beb0-3ebe888d00f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185360408-172.17.0.9-1595961698867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35416,DS-dadbed4e-b850-46a2-9fa8-554d4493fc23,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-71eb0568-5ed6-41e9-9683-b6e846c9b75b,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-5b190431-7166-479d-9f4d-884a0c8799ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-97c4a8e4-d555-441a-adbe-432db215ccf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-46107625-f062-45ed-9bc0-ef5695f2a660,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-1a120241-24b4-4e77-8d44-162d371fa8be,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-1185d48b-3f3f-492d-95f0-b15c406e701d,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-eb23d76b-1af2-4799-beb0-3ebe888d00f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342272018-172.17.0.9-1595962014405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44315,DS-05293a1a-fe36-4f75-bebb-dda1cfdabbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-0bf6e009-5ed2-41b5-8a81-7fa9b095f372,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-9ef4e008-d6b2-46d7-b3a8-4d12b8f57cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-4418d366-cd26-4939-8c22-a2c3857e5c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-40b48d84-7581-412b-a05c-981c4cb1ffda,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-fac1e2ef-d0af-4e85-91be-3c0128967c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-0cf6a538-2b32-4523-8df2-da443c116464,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-95281cce-128a-47b5-ab1f-f4a82593a0d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342272018-172.17.0.9-1595962014405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44315,DS-05293a1a-fe36-4f75-bebb-dda1cfdabbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-0bf6e009-5ed2-41b5-8a81-7fa9b095f372,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-9ef4e008-d6b2-46d7-b3a8-4d12b8f57cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-4418d366-cd26-4939-8c22-a2c3857e5c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-40b48d84-7581-412b-a05c-981c4cb1ffda,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-fac1e2ef-d0af-4e85-91be-3c0128967c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-0cf6a538-2b32-4523-8df2-da443c116464,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-95281cce-128a-47b5-ab1f-f4a82593a0d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647938458-172.17.0.9-1595962661511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45479,DS-5a47b582-0d73-4cd5-a4f2-6bdd732336f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-70b41e68-2b8c-4f8e-9dcc-1d1e9749a6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-73ddd613-a8cb-4769-90c2-c633e47aa1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-d2fa9bfd-03db-4457-805f-6daf64f4b196,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-d9ef5793-bfb0-42f1-b98a-71510176e72e,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-fb1a92f7-de7d-4e28-b56f-48baf26f047b,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-22a7b736-7769-43ac-abf3-b6ae44a34783,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-4121a20c-87aa-450e-aacb-7964a1c05897,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647938458-172.17.0.9-1595962661511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45479,DS-5a47b582-0d73-4cd5-a4f2-6bdd732336f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-70b41e68-2b8c-4f8e-9dcc-1d1e9749a6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-73ddd613-a8cb-4769-90c2-c633e47aa1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-d2fa9bfd-03db-4457-805f-6daf64f4b196,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-d9ef5793-bfb0-42f1-b98a-71510176e72e,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-fb1a92f7-de7d-4e28-b56f-48baf26f047b,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-22a7b736-7769-43ac-abf3-b6ae44a34783,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-4121a20c-87aa-450e-aacb-7964a1c05897,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934042415-172.17.0.9-1595962737325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34994,DS-d282f179-3f42-4a72-8aeb-b30523243c52,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-0484115c-a11c-4de8-a290-1b769cb5d631,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-793f9b03-ea0e-49f2-b99a-4515dfde9b25,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-354eb00b-a8b6-42b5-895d-e4d6544649cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-7b0a6f8d-23fe-4714-8bec-0939150e5a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-b51bc30d-04cd-497e-ac77-fb8a84206100,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-f48ede11-df81-4860-8c97-f5b778d96c71,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-e6b99051-5500-4223-bd73-98a108d44717,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934042415-172.17.0.9-1595962737325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34994,DS-d282f179-3f42-4a72-8aeb-b30523243c52,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-0484115c-a11c-4de8-a290-1b769cb5d631,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-793f9b03-ea0e-49f2-b99a-4515dfde9b25,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-354eb00b-a8b6-42b5-895d-e4d6544649cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-7b0a6f8d-23fe-4714-8bec-0939150e5a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-b51bc30d-04cd-497e-ac77-fb8a84206100,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-f48ede11-df81-4860-8c97-f5b778d96c71,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-e6b99051-5500-4223-bd73-98a108d44717,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529354562-172.17.0.9-1595962767844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35708,DS-c925c20a-f83c-4df9-946e-e87d02f1e66c,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-b4c723fd-7ab6-426d-ae0d-2d21bc539d22,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-1dc8a8e0-db89-4fff-aa1b-13d91f05e740,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-6bd0b907-0b40-474a-9a10-f9528ed43204,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-e88350a4-b402-48cb-9c72-445ca0eeeda3,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-514e061d-1cbf-4f7e-a84d-500213e6fec3,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-065891f1-35ad-4bed-be79-d33a993f369f,DISK], DatanodeInfoWithStorage[127.0.0.1:39414,DS-5a812284-3757-4a28-b81b-072fcf3498b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529354562-172.17.0.9-1595962767844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35708,DS-c925c20a-f83c-4df9-946e-e87d02f1e66c,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-b4c723fd-7ab6-426d-ae0d-2d21bc539d22,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-1dc8a8e0-db89-4fff-aa1b-13d91f05e740,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-6bd0b907-0b40-474a-9a10-f9528ed43204,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-e88350a4-b402-48cb-9c72-445ca0eeeda3,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-514e061d-1cbf-4f7e-a84d-500213e6fec3,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-065891f1-35ad-4bed-be79-d33a993f369f,DISK], DatanodeInfoWithStorage[127.0.0.1:39414,DS-5a812284-3757-4a28-b81b-072fcf3498b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-108391807-172.17.0.9-1595963088284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41999,DS-f36ddf50-73c2-481c-9a33-5c67c22f5635,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-124011e1-f514-4d93-a653-492cb9d76c85,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-6fc0d05b-6dd3-40a1-9c2f-58ee00e79dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-e9030123-5451-4d02-8405-df0e6d58f93f,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-acc1d041-342d-4d4e-8878-e7dfc5472f07,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-4b846f8e-1e74-4fc1-9c07-a071ec771c85,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-99290f85-82db-4442-b779-5d4bfef2a38b,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-119a6b5a-f0f2-4c80-aca2-21d137730b21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-108391807-172.17.0.9-1595963088284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41999,DS-f36ddf50-73c2-481c-9a33-5c67c22f5635,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-124011e1-f514-4d93-a653-492cb9d76c85,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-6fc0d05b-6dd3-40a1-9c2f-58ee00e79dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-e9030123-5451-4d02-8405-df0e6d58f93f,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-acc1d041-342d-4d4e-8878-e7dfc5472f07,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-4b846f8e-1e74-4fc1-9c07-a071ec771c85,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-99290f85-82db-4442-b779-5d4bfef2a38b,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-119a6b5a-f0f2-4c80-aca2-21d137730b21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923936710-172.17.0.9-1595963195501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36741,DS-0487c42a-a835-4053-a41c-f9028d8343f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-ac68de0e-50c8-4df3-9882-fa3de90d416d,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-9bf981ab-0f15-44a4-8183-624ac2925169,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-238fd27f-9edc-424f-a915-e8d9dd571a13,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-a6a45dbf-543e-4c90-9ebe-f69d0578af58,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-79cdb537-1e67-4c8b-abf8-723d1f896846,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-87dbbb2f-1007-4604-a9ab-2fa8a817fa8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-3141898f-db33-43e0-a0a9-53e63e951891,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923936710-172.17.0.9-1595963195501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36741,DS-0487c42a-a835-4053-a41c-f9028d8343f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-ac68de0e-50c8-4df3-9882-fa3de90d416d,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-9bf981ab-0f15-44a4-8183-624ac2925169,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-238fd27f-9edc-424f-a915-e8d9dd571a13,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-a6a45dbf-543e-4c90-9ebe-f69d0578af58,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-79cdb537-1e67-4c8b-abf8-723d1f896846,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-87dbbb2f-1007-4604-a9ab-2fa8a817fa8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-3141898f-db33-43e0-a0a9-53e63e951891,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035634196-172.17.0.9-1595963330680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34858,DS-e2f094e3-abfc-4495-becc-d757efe10a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-70ea450b-ca6d-4540-bbda-f3519bd3129a,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-0fb4feca-4d3d-43d5-b8c2-ee38fe9bd14c,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-80e7542c-cfff-4923-af27-26ca4e5e20fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-2fbbfe34-2341-4e7e-abdb-e61ac12f4e10,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-dfc62c95-7a04-48bd-a7d1-8202e1c45232,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-7ba06f03-1c36-4a3f-b95a-3504400880ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-29c714e6-bc67-4c52-b3bb-61fb98c6f11a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035634196-172.17.0.9-1595963330680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34858,DS-e2f094e3-abfc-4495-becc-d757efe10a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-70ea450b-ca6d-4540-bbda-f3519bd3129a,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-0fb4feca-4d3d-43d5-b8c2-ee38fe9bd14c,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-80e7542c-cfff-4923-af27-26ca4e5e20fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-2fbbfe34-2341-4e7e-abdb-e61ac12f4e10,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-dfc62c95-7a04-48bd-a7d1-8202e1c45232,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-7ba06f03-1c36-4a3f-b95a-3504400880ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-29c714e6-bc67-4c52-b3bb-61fb98c6f11a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934706004-172.17.0.9-1595963361798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45763,DS-6c755a89-cf11-4aeb-9e21-170dc2c60784,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-f370845d-2d3f-41b1-a39f-e4ac62fb1432,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-78667f74-a2d9-40c2-920f-dfedf3816df1,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-0bbcd46c-b7f6-4dd4-b400-01a5361ddb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-bd667967-eaa1-4124-a4ff-b6b11523ede2,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-4f1f5586-cd50-4e0b-a21b-61d28095b142,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-8cd56def-6b47-4524-9c7b-a1ffbb682ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-397b8a13-883b-4483-901f-a0f14425582e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934706004-172.17.0.9-1595963361798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45763,DS-6c755a89-cf11-4aeb-9e21-170dc2c60784,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-f370845d-2d3f-41b1-a39f-e4ac62fb1432,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-78667f74-a2d9-40c2-920f-dfedf3816df1,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-0bbcd46c-b7f6-4dd4-b400-01a5361ddb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-bd667967-eaa1-4124-a4ff-b6b11523ede2,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-4f1f5586-cd50-4e0b-a21b-61d28095b142,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-8cd56def-6b47-4524-9c7b-a1ffbb682ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-397b8a13-883b-4483-901f-a0f14425582e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2083867752-172.17.0.9-1595963433393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45695,DS-dc43e07c-ccf1-4fbf-8860-3c5b15119c31,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-16fb4feb-504f-4474-96e4-98e13cc71f70,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-ca5ea3cc-17d0-4cc1-bd9e-5ef11c392d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-53569967-e5fb-416a-afbe-5130ae848ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-781463ee-97a4-4061-93e7-f7479897101c,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-943fe17f-473d-4aee-a3cf-bde4aab2dc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-778aa04b-c291-4707-8943-7c8dca742ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-6b8e3472-0890-48ab-81c1-2808e1d4a557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2083867752-172.17.0.9-1595963433393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45695,DS-dc43e07c-ccf1-4fbf-8860-3c5b15119c31,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-16fb4feb-504f-4474-96e4-98e13cc71f70,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-ca5ea3cc-17d0-4cc1-bd9e-5ef11c392d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-53569967-e5fb-416a-afbe-5130ae848ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-781463ee-97a4-4061-93e7-f7479897101c,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-943fe17f-473d-4aee-a3cf-bde4aab2dc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-778aa04b-c291-4707-8943-7c8dca742ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-6b8e3472-0890-48ab-81c1-2808e1d4a557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242011898-172.17.0.9-1595963475701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45271,DS-93870c29-d251-4980-a639-a0e5ca766986,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-bcafe8c7-6234-4972-afde-e5a67b1ab2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-af706af1-7e28-49d2-83ed-0a385aac3c15,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-287af665-a1eb-472b-a053-fa16dfa12a05,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-de7591dd-7600-454d-8b2c-57f00d9384f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-4d9a4d75-d135-4d8a-830e-cd65cb692736,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-97e19b83-180b-40e7-8c27-70b573486f87,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-4de0d71a-9ec7-4cd6-8a7b-11e178f0a619,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242011898-172.17.0.9-1595963475701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45271,DS-93870c29-d251-4980-a639-a0e5ca766986,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-bcafe8c7-6234-4972-afde-e5a67b1ab2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-af706af1-7e28-49d2-83ed-0a385aac3c15,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-287af665-a1eb-472b-a053-fa16dfa12a05,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-de7591dd-7600-454d-8b2c-57f00d9384f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-4d9a4d75-d135-4d8a-830e-cd65cb692736,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-97e19b83-180b-40e7-8c27-70b573486f87,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-4de0d71a-9ec7-4cd6-8a7b-11e178f0a619,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-762662157-172.17.0.9-1595963507719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36520,DS-9c9d1122-efb4-42ed-95fa-1895862e192b,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-426b862a-f06a-4016-ae01-9c456f615649,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-3658e6db-3b00-44dd-95ec-6f00485b96a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-c5ac4714-5bd6-4379-8123-982872e5474c,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-afad5335-209c-4fd5-b855-47f906c7dd13,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-d36116d7-133d-4c5f-9aa9-9971089372b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-1bcf62bc-619c-4241-b3e7-de241990d3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-94bc3a9b-0526-4452-9a28-b025e5e5a7cd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-762662157-172.17.0.9-1595963507719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36520,DS-9c9d1122-efb4-42ed-95fa-1895862e192b,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-426b862a-f06a-4016-ae01-9c456f615649,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-3658e6db-3b00-44dd-95ec-6f00485b96a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-c5ac4714-5bd6-4379-8123-982872e5474c,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-afad5335-209c-4fd5-b855-47f906c7dd13,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-d36116d7-133d-4c5f-9aa9-9971089372b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-1bcf62bc-619c-4241-b3e7-de241990d3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-94bc3a9b-0526-4452-9a28-b025e5e5a7cd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319512756-172.17.0.9-1595963748717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35037,DS-f8447d8d-7316-4073-bc5d-dc7da95bb742,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-ea4eba97-1488-4782-b436-278ce3de3636,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-995dbf85-34aa-4449-b935-1da43b17d6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-fc32646d-6093-4ce3-9d16-ef297936107a,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-280e2235-7792-41e8-b6d1-04a4cdf77359,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-0aa5cf34-088d-4ec5-a819-0969509314ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-62096921-72d4-43b7-9793-99abe2e4597a,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-7bd71072-f11e-4c41-9693-3cbb38790a76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319512756-172.17.0.9-1595963748717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35037,DS-f8447d8d-7316-4073-bc5d-dc7da95bb742,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-ea4eba97-1488-4782-b436-278ce3de3636,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-995dbf85-34aa-4449-b935-1da43b17d6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-fc32646d-6093-4ce3-9d16-ef297936107a,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-280e2235-7792-41e8-b6d1-04a4cdf77359,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-0aa5cf34-088d-4ec5-a819-0969509314ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-62096921-72d4-43b7-9793-99abe2e4597a,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-7bd71072-f11e-4c41-9693-3cbb38790a76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483908458-172.17.0.9-1595963816404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33220,DS-14b94b84-fc54-4f6b-8e26-718c7f4b4e93,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-99dc472c-3219-42ff-a991-b7f2bd492d88,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-b2610df6-5256-4bfa-a913-4a299e78e340,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-04470144-c90e-4405-af50-e9b7595a176c,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-57190e6f-bb7a-4ccf-92bd-3af41200c961,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-533ffe82-d62a-4af4-ba09-828b48a185ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-55d950db-d4b9-4020-b6e0-1d96b988531d,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-1d8fccdd-d733-4619-b6ef-fff75296a5d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483908458-172.17.0.9-1595963816404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33220,DS-14b94b84-fc54-4f6b-8e26-718c7f4b4e93,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-99dc472c-3219-42ff-a991-b7f2bd492d88,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-b2610df6-5256-4bfa-a913-4a299e78e340,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-04470144-c90e-4405-af50-e9b7595a176c,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-57190e6f-bb7a-4ccf-92bd-3af41200c961,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-533ffe82-d62a-4af4-ba09-828b48a185ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-55d950db-d4b9-4020-b6e0-1d96b988531d,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-1d8fccdd-d733-4619-b6ef-fff75296a5d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192401573-172.17.0.9-1595963842978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46778,DS-b225cbca-f69f-49fa-9dd6-e1aed938edbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-cd8ee75f-729a-4ef2-bfe9-1ba755ab2ade,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-004346cb-a61d-4fac-974d-c6fc05966ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-5991961d-114e-47cd-9230-8e383995a915,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-8e7b9429-0ac8-470c-9070-87f556247884,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-c4b1b33d-6c97-46a1-9e88-e208c565022d,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-10119083-1433-49ea-81aa-9c53ee9df0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-5692efdb-1645-4e05-9236-53a1545a96b1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192401573-172.17.0.9-1595963842978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46778,DS-b225cbca-f69f-49fa-9dd6-e1aed938edbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-cd8ee75f-729a-4ef2-bfe9-1ba755ab2ade,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-004346cb-a61d-4fac-974d-c6fc05966ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-5991961d-114e-47cd-9230-8e383995a915,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-8e7b9429-0ac8-470c-9070-87f556247884,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-c4b1b33d-6c97-46a1-9e88-e208c565022d,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-10119083-1433-49ea-81aa-9c53ee9df0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-5692efdb-1645-4e05-9236-53a1545a96b1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367663653-172.17.0.9-1595963949460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41103,DS-2733f4ff-a28d-4540-ab35-25fff734f423,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-9976c010-c38a-44b4-b76c-5b8b7045e557,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-4a34252e-5fb2-40ca-89a0-5dad4bc534db,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-8b3bc291-9f93-4f51-8e62-dcc36bb92540,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-19e8a03d-52a6-4c0d-a89b-2e11bb1802ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-6a4f3ff6-51da-446a-bfc0-c056389fce3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-938532f1-623b-4aec-b40d-14e65caaef65,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-8db7de6c-5992-41a3-bf99-9ca4abf4e1d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367663653-172.17.0.9-1595963949460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41103,DS-2733f4ff-a28d-4540-ab35-25fff734f423,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-9976c010-c38a-44b4-b76c-5b8b7045e557,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-4a34252e-5fb2-40ca-89a0-5dad4bc534db,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-8b3bc291-9f93-4f51-8e62-dcc36bb92540,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-19e8a03d-52a6-4c0d-a89b-2e11bb1802ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-6a4f3ff6-51da-446a-bfc0-c056389fce3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-938532f1-623b-4aec-b40d-14e65caaef65,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-8db7de6c-5992-41a3-bf99-9ca4abf4e1d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1368175890-172.17.0.9-1595964260259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35218,DS-6dc2882e-4e98-404e-821f-70e3ecad73a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-fea84c7a-508f-4536-bbf5-35cf7a313e85,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-a4cfbf3f-336a-4e04-bf14-1bc31a156d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-f103f15b-3ef6-44f3-9799-46da56abcb34,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-b616d02f-424f-4ec9-a4ac-bd5db72da297,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-411771aa-4412-431d-87bb-a58712d905f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-900ad123-6a9f-4493-8e15-6912b0057ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-445aaf77-2a3c-4239-b0b0-d625fd5a550f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1368175890-172.17.0.9-1595964260259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35218,DS-6dc2882e-4e98-404e-821f-70e3ecad73a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-fea84c7a-508f-4536-bbf5-35cf7a313e85,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-a4cfbf3f-336a-4e04-bf14-1bc31a156d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-f103f15b-3ef6-44f3-9799-46da56abcb34,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-b616d02f-424f-4ec9-a4ac-bd5db72da297,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-411771aa-4412-431d-87bb-a58712d905f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-900ad123-6a9f-4493-8e15-6912b0057ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-445aaf77-2a3c-4239-b0b0-d625fd5a550f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343595079-172.17.0.9-1595964365835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40995,DS-5c9e977f-16ed-4c0f-ae8b-c37e87640950,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-e9405e0a-bcb6-474b-9134-0d93801c7294,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-8437da3e-b3c1-4a24-bbcf-95e42c48ed15,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-1576ad10-5700-4a50-bc20-a4c8f3c4f7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-64fc8abe-8583-4b7a-9938-58550db97b15,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-3150df48-dc6e-411f-9778-b26154409066,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-8b879265-3767-4c9f-9e48-96fbd44312f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-ce7c8fe0-adf3-4f6e-a849-f0e38f31e87b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343595079-172.17.0.9-1595964365835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40995,DS-5c9e977f-16ed-4c0f-ae8b-c37e87640950,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-e9405e0a-bcb6-474b-9134-0d93801c7294,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-8437da3e-b3c1-4a24-bbcf-95e42c48ed15,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-1576ad10-5700-4a50-bc20-a4c8f3c4f7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-64fc8abe-8583-4b7a-9938-58550db97b15,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-3150df48-dc6e-411f-9778-b26154409066,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-8b879265-3767-4c9f-9e48-96fbd44312f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-ce7c8fe0-adf3-4f6e-a849-f0e38f31e87b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1751933869-172.17.0.9-1595964434275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32849,DS-42305f40-ce8f-49cd-91d1-93f9bc9a8cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-abf3fe63-d06a-4c72-9ecd-10c28e817e79,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-df4c2501-70a2-461a-890b-e6cc219fb384,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-a4530e4e-cce7-4dd6-9a3c-34b8303803da,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-f6d87775-987e-4170-a922-d0a88c367fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-e0feafd6-49f1-4508-a68e-fbf2893f86d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-0ba6307f-1b4b-4b43-81d3-e4d0c9d155b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-b68d7481-9c02-41f3-9ef2-b606b505a782,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1751933869-172.17.0.9-1595964434275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32849,DS-42305f40-ce8f-49cd-91d1-93f9bc9a8cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-abf3fe63-d06a-4c72-9ecd-10c28e817e79,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-df4c2501-70a2-461a-890b-e6cc219fb384,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-a4530e4e-cce7-4dd6-9a3c-34b8303803da,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-f6d87775-987e-4170-a922-d0a88c367fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-e0feafd6-49f1-4508-a68e-fbf2893f86d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-0ba6307f-1b4b-4b43-81d3-e4d0c9d155b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-b68d7481-9c02-41f3-9ef2-b606b505a782,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 14 out of 50
v1v1v2v2 failed with probability 22 out of 50
result: false positive !!!
Total execution time in seconds : 5373
