reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512467171-172.17.0.7-1595612960650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38350,DS-ca8205fd-b4ab-47fa-9735-d98ce8e31cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-e782336e-d8de-423f-8823-6bca324a4593,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-bc025ca3-97bb-4698-9650-d0358a441f52,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-adf322e5-b302-4e25-ae66-75be99462914,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-0da6190f-94aa-44d3-9921-1aec672da942,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-412c6d32-624a-4543-a664-d3e333ed2628,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-0f0c91a9-c039-4314-aec3-fb07235b372f,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-74f29b96-c6b0-4602-8d5f-f420ac54de15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512467171-172.17.0.7-1595612960650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38350,DS-ca8205fd-b4ab-47fa-9735-d98ce8e31cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-e782336e-d8de-423f-8823-6bca324a4593,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-bc025ca3-97bb-4698-9650-d0358a441f52,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-adf322e5-b302-4e25-ae66-75be99462914,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-0da6190f-94aa-44d3-9921-1aec672da942,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-412c6d32-624a-4543-a664-d3e333ed2628,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-0f0c91a9-c039-4314-aec3-fb07235b372f,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-74f29b96-c6b0-4602-8d5f-f420ac54de15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712963545-172.17.0.7-1595613526882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38526,DS-9e0f8af0-19d4-46fb-855e-afa7376745df,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-abe10a7b-950f-4ed7-9f8c-b14bb386b0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-9c908ba3-82db-48f5-83c6-268e4cced47a,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-d2d4102b-77de-45d0-87ff-a0c70363886b,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-2de5d295-72d4-44eb-a338-bc3451c5b898,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-f2e86832-8250-4a54-904a-4f0b993ecdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-2233b063-5dab-4113-8956-e2f981169533,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-08622dbd-3c51-4fb8-8ec3-efface399d41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712963545-172.17.0.7-1595613526882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38526,DS-9e0f8af0-19d4-46fb-855e-afa7376745df,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-abe10a7b-950f-4ed7-9f8c-b14bb386b0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-9c908ba3-82db-48f5-83c6-268e4cced47a,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-d2d4102b-77de-45d0-87ff-a0c70363886b,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-2de5d295-72d4-44eb-a338-bc3451c5b898,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-f2e86832-8250-4a54-904a-4f0b993ecdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-2233b063-5dab-4113-8956-e2f981169533,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-08622dbd-3c51-4fb8-8ec3-efface399d41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-887339823-172.17.0.7-1595613831360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41067,DS-1446e189-e382-42fd-81ab-76b68734ec7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-8b8fdbcc-ac5f-4d83-8ff8-df812916b261,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-b111108b-d056-479f-92a2-1eb56a82add8,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-883d9bba-354b-4302-b0b3-af059be5cfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-7a9777c3-bba2-4438-be53-2f5c7a30563f,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-dacfda82-094a-41f7-ae24-0fb8b414a10a,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-2079f1a0-427f-43fd-a05c-16a01983590e,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-f3951cd0-336a-47d9-8b2f-4ed22ef4a017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-887339823-172.17.0.7-1595613831360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41067,DS-1446e189-e382-42fd-81ab-76b68734ec7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-8b8fdbcc-ac5f-4d83-8ff8-df812916b261,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-b111108b-d056-479f-92a2-1eb56a82add8,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-883d9bba-354b-4302-b0b3-af059be5cfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-7a9777c3-bba2-4438-be53-2f5c7a30563f,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-dacfda82-094a-41f7-ae24-0fb8b414a10a,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-2079f1a0-427f-43fd-a05c-16a01983590e,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-f3951cd0-336a-47d9-8b2f-4ed22ef4a017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112808116-172.17.0.7-1595614026919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34030,DS-1593cc42-6970-4bf6-9c3a-f1a39548a9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-9ff48c4c-e268-404d-bd42-f4cb9a49dc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-5c082c94-f2da-4be2-9e92-1c4d4324f58c,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-d953d390-4f42-43bc-917c-a6458c2a2c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-876f87c1-6b02-4fae-be4e-52bb71073697,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-abb6609c-4674-4102-bcfe-d43a4f3905fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-a0bdf975-5fe6-46b0-8ac0-9f422f418042,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-e33e764c-8e1b-47df-b4c4-cc6e69523152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112808116-172.17.0.7-1595614026919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34030,DS-1593cc42-6970-4bf6-9c3a-f1a39548a9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-9ff48c4c-e268-404d-bd42-f4cb9a49dc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-5c082c94-f2da-4be2-9e92-1c4d4324f58c,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-d953d390-4f42-43bc-917c-a6458c2a2c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-876f87c1-6b02-4fae-be4e-52bb71073697,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-abb6609c-4674-4102-bcfe-d43a4f3905fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-a0bdf975-5fe6-46b0-8ac0-9f422f418042,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-e33e764c-8e1b-47df-b4c4-cc6e69523152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846625785-172.17.0.7-1595614103406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40869,DS-30424dae-49ac-4cc8-9f35-345f5bf27ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-280c7fef-f093-463d-b8ca-74a31e8a4211,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-e7264e21-603b-4dca-af51-618562af3523,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-c11c990c-d087-4084-8745-89e3e689ee21,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-b3b9d7eb-63fd-4fad-bf37-0aa2a87de522,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-c77f81d1-bf0f-4010-a1e5-b7d5adbb2f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-b14efa3f-f398-4640-bc83-e2822607ec04,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-efab885a-bce5-45cf-8799-8da300ecc191,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846625785-172.17.0.7-1595614103406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40869,DS-30424dae-49ac-4cc8-9f35-345f5bf27ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-280c7fef-f093-463d-b8ca-74a31e8a4211,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-e7264e21-603b-4dca-af51-618562af3523,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-c11c990c-d087-4084-8745-89e3e689ee21,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-b3b9d7eb-63fd-4fad-bf37-0aa2a87de522,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-c77f81d1-bf0f-4010-a1e5-b7d5adbb2f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-b14efa3f-f398-4640-bc83-e2822607ec04,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-efab885a-bce5-45cf-8799-8da300ecc191,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-59199804-172.17.0.7-1595614958582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38293,DS-39e7ba92-81f4-4bb1-8034-5337ff6691a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-842b193a-8898-42b1-9a4e-c47eedcb1a17,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-d45a94cd-d572-4f88-baa9-33a2d0568760,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-61ad3cde-a5c7-4d6f-99e6-c08cab757137,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-0198cd60-05cf-48b7-8465-5889d81a62bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-0a7e771d-1da8-47f4-9cfd-c14ab2c37198,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-ba3df8b7-435c-44bd-aad2-0e75dfb9a42c,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-89676f92-ae06-4ed1-88f8-078c43505aff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-59199804-172.17.0.7-1595614958582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38293,DS-39e7ba92-81f4-4bb1-8034-5337ff6691a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-842b193a-8898-42b1-9a4e-c47eedcb1a17,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-d45a94cd-d572-4f88-baa9-33a2d0568760,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-61ad3cde-a5c7-4d6f-99e6-c08cab757137,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-0198cd60-05cf-48b7-8465-5889d81a62bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-0a7e771d-1da8-47f4-9cfd-c14ab2c37198,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-ba3df8b7-435c-44bd-aad2-0e75dfb9a42c,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-89676f92-ae06-4ed1-88f8-078c43505aff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812915192-172.17.0.7-1595615069377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33036,DS-3f242ffd-821f-4d79-8639-3f92f66d2571,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-e26fa810-aa37-4223-8d21-921439ea5d43,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-df903371-4fc4-4e10-ada2-055867095344,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-7cf8100f-ed62-46f4-a1ff-b43a50dffb58,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-fc150afe-de78-4a1f-ad43-c34b60ace03f,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-8ccd3a37-59dc-41f8-b601-585d47b492ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-87d52b3a-7810-4625-94dc-24f27a486648,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-60b700b3-8844-4ca6-b0a6-3de75e8044c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812915192-172.17.0.7-1595615069377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33036,DS-3f242ffd-821f-4d79-8639-3f92f66d2571,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-e26fa810-aa37-4223-8d21-921439ea5d43,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-df903371-4fc4-4e10-ada2-055867095344,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-7cf8100f-ed62-46f4-a1ff-b43a50dffb58,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-fc150afe-de78-4a1f-ad43-c34b60ace03f,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-8ccd3a37-59dc-41f8-b601-585d47b492ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-87d52b3a-7810-4625-94dc-24f27a486648,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-60b700b3-8844-4ca6-b0a6-3de75e8044c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367011802-172.17.0.7-1595615220504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38950,DS-fc7ab115-c8f6-4b3e-8804-cbca3a3a0e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-f23f8fdf-f806-48a1-a6ae-74691d765717,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-bcd10d7d-01d3-4145-aa4c-fe24a7392046,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-4c7c4e38-8802-4f92-8cd3-25e2fb40f4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-0e058297-1eea-4226-8976-130950145a74,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-9e44b8f8-1204-43be-9cfc-3e756f21ecce,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-8de8c2d0-173a-4b78-922c-d8d9dca4375e,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-bf9853c3-5e5b-4871-b575-e872d4e07ea8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367011802-172.17.0.7-1595615220504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38950,DS-fc7ab115-c8f6-4b3e-8804-cbca3a3a0e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-f23f8fdf-f806-48a1-a6ae-74691d765717,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-bcd10d7d-01d3-4145-aa4c-fe24a7392046,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-4c7c4e38-8802-4f92-8cd3-25e2fb40f4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-0e058297-1eea-4226-8976-130950145a74,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-9e44b8f8-1204-43be-9cfc-3e756f21ecce,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-8de8c2d0-173a-4b78-922c-d8d9dca4375e,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-bf9853c3-5e5b-4871-b575-e872d4e07ea8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1788953536-172.17.0.7-1595615488840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41965,DS-2890bb1e-2e4c-4a83-ac67-ac35617d29f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-5e2019c4-4017-4980-bb93-f05b8f12c260,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-2f00e871-bbd2-4078-9232-b598055d48f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-f139c8b0-0aa5-4c26-a1b5-a1d23ecd0fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-8d783900-7c2a-449f-8768-3252cf48a48f,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-fcdb2d65-3815-4b10-8b4e-f6afa0fedc77,DISK], DatanodeInfoWithStorage[127.0.0.1:34010,DS-a56e5416-8024-453f-9903-98cc142c9488,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-86faf3fa-5a4c-463a-a612-f4aee854e6c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1788953536-172.17.0.7-1595615488840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41965,DS-2890bb1e-2e4c-4a83-ac67-ac35617d29f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-5e2019c4-4017-4980-bb93-f05b8f12c260,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-2f00e871-bbd2-4078-9232-b598055d48f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-f139c8b0-0aa5-4c26-a1b5-a1d23ecd0fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-8d783900-7c2a-449f-8768-3252cf48a48f,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-fcdb2d65-3815-4b10-8b4e-f6afa0fedc77,DISK], DatanodeInfoWithStorage[127.0.0.1:34010,DS-a56e5416-8024-453f-9903-98cc142c9488,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-86faf3fa-5a4c-463a-a612-f4aee854e6c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1338368828-172.17.0.7-1595615522322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45010,DS-d9c70ac5-490d-4305-a930-0149c67c15b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-aecdda6a-8b33-4cf1-8ca0-63ebb2179f76,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-da9829ba-062b-427d-9de5-492e0ce0d212,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-3301dc25-054c-42c7-aca9-b06d5b68769e,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-7b4315d0-69d2-47ac-a909-da66b92f61d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-07d927cb-0c54-4af0-a947-f8057b0dca04,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-8ab2a1ea-a1c1-44a5-9b6b-1c4c100e606c,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-0b5482bf-7147-4e2d-a205-ecd2968b5750,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1338368828-172.17.0.7-1595615522322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45010,DS-d9c70ac5-490d-4305-a930-0149c67c15b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-aecdda6a-8b33-4cf1-8ca0-63ebb2179f76,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-da9829ba-062b-427d-9de5-492e0ce0d212,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-3301dc25-054c-42c7-aca9-b06d5b68769e,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-7b4315d0-69d2-47ac-a909-da66b92f61d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-07d927cb-0c54-4af0-a947-f8057b0dca04,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-8ab2a1ea-a1c1-44a5-9b6b-1c4c100e606c,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-0b5482bf-7147-4e2d-a205-ecd2968b5750,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116256012-172.17.0.7-1595615589281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45848,DS-b5925723-069a-498b-b8ac-1221a13e62d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-41bde7c8-88e1-46f0-9feb-a42d5d16d5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-23dd1d4d-b3c7-48bb-a621-0e749a27ad4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-31109282-14d9-4e76-b7e6-a99be97ff732,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-c1cc2b2b-f47f-43c2-9cc0-e136c0a044bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-03dec302-4e0c-485c-ac98-6fe48d01ee0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-c25312db-0a6a-47b6-8e19-918d2c8d6dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-eebe545b-f55a-4099-80c0-633ad830e5cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116256012-172.17.0.7-1595615589281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45848,DS-b5925723-069a-498b-b8ac-1221a13e62d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-41bde7c8-88e1-46f0-9feb-a42d5d16d5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-23dd1d4d-b3c7-48bb-a621-0e749a27ad4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-31109282-14d9-4e76-b7e6-a99be97ff732,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-c1cc2b2b-f47f-43c2-9cc0-e136c0a044bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-03dec302-4e0c-485c-ac98-6fe48d01ee0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-c25312db-0a6a-47b6-8e19-918d2c8d6dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-eebe545b-f55a-4099-80c0-633ad830e5cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520591406-172.17.0.7-1595615742177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33883,DS-08e4225c-74b2-46ae-b9b0-4b16549fed68,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-893b685b-2483-43d3-a991-6c1358daaa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-594030b2-7d12-4135-b33e-84dd144f5d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-a29f5df3-4170-4585-87b0-09daf9dff339,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-b2d84262-7435-4b40-ac73-cdb87dd4abd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-ddeb7459-184d-4035-b1b2-a5fa54df1d99,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-e23ba3ac-6564-4bbf-84be-6b4125aa9026,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-7368c17c-a2ee-4d6a-8e33-70c6dbf9f3a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520591406-172.17.0.7-1595615742177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33883,DS-08e4225c-74b2-46ae-b9b0-4b16549fed68,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-893b685b-2483-43d3-a991-6c1358daaa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-594030b2-7d12-4135-b33e-84dd144f5d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-a29f5df3-4170-4585-87b0-09daf9dff339,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-b2d84262-7435-4b40-ac73-cdb87dd4abd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-ddeb7459-184d-4035-b1b2-a5fa54df1d99,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-e23ba3ac-6564-4bbf-84be-6b4125aa9026,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-7368c17c-a2ee-4d6a-8e33-70c6dbf9f3a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1883302382-172.17.0.7-1595615992304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46234,DS-8577d330-9f02-46a2-a04a-2b6443e671e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-7dce5c90-304e-4f54-a93b-5e73e309c886,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-8bb006e4-3274-4256-8642-54bbcab9cbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-90c76fed-f865-4578-a7a0-55edc9272377,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-2a9a4df2-37a8-43e7-af9f-7a4eaea5815c,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-b2ac11eb-5ec4-45c1-a3de-0226fbe079db,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-a5a9c4b8-fe3a-49e3-aaa6-0871d57007f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-d06bb5ae-4601-4b79-b610-3fd58f0bf7e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1883302382-172.17.0.7-1595615992304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46234,DS-8577d330-9f02-46a2-a04a-2b6443e671e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-7dce5c90-304e-4f54-a93b-5e73e309c886,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-8bb006e4-3274-4256-8642-54bbcab9cbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-90c76fed-f865-4578-a7a0-55edc9272377,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-2a9a4df2-37a8-43e7-af9f-7a4eaea5815c,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-b2ac11eb-5ec4-45c1-a3de-0226fbe079db,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-a5a9c4b8-fe3a-49e3-aaa6-0871d57007f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-d06bb5ae-4601-4b79-b610-3fd58f0bf7e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572353036-172.17.0.7-1595616022859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35469,DS-ca91d5d9-f268-481d-bf99-43817c8ad433,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-d6b36aa3-5f94-4606-b732-3dd73fa0bf27,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-c5091410-48c3-45b6-b501-85cae27d4cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-b102a6d5-0b6b-402c-ad12-b38c633d7927,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-603f937f-c4c8-4fba-a96b-cfe2672d68cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-52513a93-65c6-4cfe-9deb-0022d7a40ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-c4b3f494-0265-44c6-860c-d66ac6a1bd30,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-94d46428-d0c4-4776-8966-46b967d8fc29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572353036-172.17.0.7-1595616022859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35469,DS-ca91d5d9-f268-481d-bf99-43817c8ad433,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-d6b36aa3-5f94-4606-b732-3dd73fa0bf27,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-c5091410-48c3-45b6-b501-85cae27d4cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-b102a6d5-0b6b-402c-ad12-b38c633d7927,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-603f937f-c4c8-4fba-a96b-cfe2672d68cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-52513a93-65c6-4cfe-9deb-0022d7a40ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-c4b3f494-0265-44c6-860c-d66ac6a1bd30,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-94d46428-d0c4-4776-8966-46b967d8fc29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-535868894-172.17.0.7-1595616960962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38004,DS-ef709c8e-0a28-4b64-aba6-20aa2963d47e,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-3444bac8-ef4c-4ca3-96bd-ac82fbffd887,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-75cd15ae-4c12-43c8-89c2-7e1708e9f212,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-e7c51cae-22f1-426e-b692-e0b0a323553e,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-151f67a6-cedd-4182-9c33-29cd363fdf93,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-e4658a8b-f215-49c0-8bd2-56097fbab196,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-64668484-2aa3-4662-a7d7-146d2fc28e40,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-3d7895be-9225-44b6-a251-1b57751ab55f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-535868894-172.17.0.7-1595616960962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38004,DS-ef709c8e-0a28-4b64-aba6-20aa2963d47e,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-3444bac8-ef4c-4ca3-96bd-ac82fbffd887,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-75cd15ae-4c12-43c8-89c2-7e1708e9f212,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-e7c51cae-22f1-426e-b692-e0b0a323553e,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-151f67a6-cedd-4182-9c33-29cd363fdf93,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-e4658a8b-f215-49c0-8bd2-56097fbab196,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-64668484-2aa3-4662-a7d7-146d2fc28e40,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-3d7895be-9225-44b6-a251-1b57751ab55f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1079709266-172.17.0.7-1595616999181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35733,DS-1bace0e7-d1d1-47b1-9d3d-007e47a2beb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-e9664e93-7351-4da8-854d-25cc52fa1fef,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-fac39379-ec1e-41c4-9daf-5a1d60fd1d21,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-c30f8e65-043c-470f-87e3-630f87eb3016,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-f5b77ce9-bd67-45d1-bce7-6d9ceddad86d,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-c9cf9355-62d2-4726-b4c5-0c365cd3ada3,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-8d82f9e3-3679-4e47-af59-13d267b35810,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-ae209b3e-45dd-4a3f-99bd-6056941faa75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1079709266-172.17.0.7-1595616999181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35733,DS-1bace0e7-d1d1-47b1-9d3d-007e47a2beb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-e9664e93-7351-4da8-854d-25cc52fa1fef,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-fac39379-ec1e-41c4-9daf-5a1d60fd1d21,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-c30f8e65-043c-470f-87e3-630f87eb3016,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-f5b77ce9-bd67-45d1-bce7-6d9ceddad86d,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-c9cf9355-62d2-4726-b4c5-0c365cd3ada3,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-8d82f9e3-3679-4e47-af59-13d267b35810,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-ae209b3e-45dd-4a3f-99bd-6056941faa75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-180549981-172.17.0.7-1595617472051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35172,DS-0c191ba0-18ab-4273-8609-f28ce138717f,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-cbfc6011-ff42-46d8-a773-90ca4e7683de,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-e556d198-ff5a-4271-9357-4ed01a8fd6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-b5d3256d-8c32-41a0-917b-5b17d0d98923,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-16990f5a-1ba8-4ab1-aa29-06833976adad,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-9f71ab6f-7db9-4dee-9c69-e06839f66501,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-3d67d4df-baae-4817-bbb1-7ce873b94736,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-746176c3-7e6a-43e6-9198-e06a696113b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-180549981-172.17.0.7-1595617472051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35172,DS-0c191ba0-18ab-4273-8609-f28ce138717f,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-cbfc6011-ff42-46d8-a773-90ca4e7683de,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-e556d198-ff5a-4271-9357-4ed01a8fd6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-b5d3256d-8c32-41a0-917b-5b17d0d98923,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-16990f5a-1ba8-4ab1-aa29-06833976adad,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-9f71ab6f-7db9-4dee-9c69-e06839f66501,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-3d67d4df-baae-4817-bbb1-7ce873b94736,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-746176c3-7e6a-43e6-9198-e06a696113b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5446
