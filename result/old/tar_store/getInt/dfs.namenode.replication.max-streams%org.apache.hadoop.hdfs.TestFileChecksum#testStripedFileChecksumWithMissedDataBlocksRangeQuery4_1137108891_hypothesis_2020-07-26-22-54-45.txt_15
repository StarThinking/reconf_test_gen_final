reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-174322994-172.17.0.10-1595804294607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35755,DS-359bf8ab-320e-46d3-8b35-0c97d77d3ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-d14a65a2-001c-47ba-81ee-9353dc445756,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-449cc524-5b4f-495e-b9ef-d3396ac5b4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-1a798a85-9e35-4c2b-a3d3-e4f9180f0b91,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-58a04197-945c-4add-9f2d-b28ce168a7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-586a1bbc-d8c6-454f-9c7d-496b984af715,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-8101c4fb-8c2c-4527-8e19-ac976365a743,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-9bde6aed-31a2-477f-9d08-f27b91e26ee1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-174322994-172.17.0.10-1595804294607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35755,DS-359bf8ab-320e-46d3-8b35-0c97d77d3ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-d14a65a2-001c-47ba-81ee-9353dc445756,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-449cc524-5b4f-495e-b9ef-d3396ac5b4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-1a798a85-9e35-4c2b-a3d3-e4f9180f0b91,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-58a04197-945c-4add-9f2d-b28ce168a7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-586a1bbc-d8c6-454f-9c7d-496b984af715,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-8101c4fb-8c2c-4527-8e19-ac976365a743,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-9bde6aed-31a2-477f-9d08-f27b91e26ee1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1700446332-172.17.0.10-1595805774714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45590,DS-ed73954e-99c7-4c2c-8610-527fffb475ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-9b16ad38-f468-403b-8380-f3872d621f56,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-f8b89981-f3c1-4d7e-8de5-c8278bd9d4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-4b9a990a-7fe5-4887-925d-6bc60a511871,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-d3f5de47-2520-4110-acf0-8ef05a834a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-49a1dc60-c2f7-432c-9c12-8d40f3a8b549,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-4516ef86-0db0-4d84-9d9b-92c84a804349,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-31471c76-a74c-4654-a630-4de146b7e4c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1700446332-172.17.0.10-1595805774714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45590,DS-ed73954e-99c7-4c2c-8610-527fffb475ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-9b16ad38-f468-403b-8380-f3872d621f56,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-f8b89981-f3c1-4d7e-8de5-c8278bd9d4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-4b9a990a-7fe5-4887-925d-6bc60a511871,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-d3f5de47-2520-4110-acf0-8ef05a834a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-49a1dc60-c2f7-432c-9c12-8d40f3a8b549,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-4516ef86-0db0-4d84-9d9b-92c84a804349,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-31471c76-a74c-4654-a630-4de146b7e4c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232785810-172.17.0.10-1595805972606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33448,DS-434273c8-cd0b-4a46-861c-24910c3ca9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-033f4adf-229c-4547-a55e-4046fefadab8,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-61fc5ed1-601c-43de-84e4-cb20883aeb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-c15850e7-10af-455c-a549-eb0106aac254,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-5062a6a9-4542-4a00-a9fa-3deda835f381,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-30f71dfd-7d70-4400-8ae0-e7ac1b2275d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-86da7871-075b-402b-83cf-f38b13a295b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-7c880321-85cd-4dce-9a50-027a51e4c753,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232785810-172.17.0.10-1595805972606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33448,DS-434273c8-cd0b-4a46-861c-24910c3ca9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-033f4adf-229c-4547-a55e-4046fefadab8,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-61fc5ed1-601c-43de-84e4-cb20883aeb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-c15850e7-10af-455c-a549-eb0106aac254,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-5062a6a9-4542-4a00-a9fa-3deda835f381,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-30f71dfd-7d70-4400-8ae0-e7ac1b2275d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-86da7871-075b-402b-83cf-f38b13a295b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-7c880321-85cd-4dce-9a50-027a51e4c753,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347010923-172.17.0.10-1595806196352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41998,DS-a506aed1-b373-4fb9-b5a5-07f4d65d32ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-d393b520-a859-463e-aa75-49484214ec77,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-30161a38-67d1-4536-a55f-74edf950ab6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-8af50644-4e8d-4743-8c80-5808128238f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-f901b4f9-d261-4d49-bc34-b7c3fa4b8f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-8f9ce615-5f63-47ca-acd1-3d7c6d2560c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-aa01e29d-141b-4b71-ae64-60973a7fdd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-55fe1272-9ebf-4691-be89-193f6a0891ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347010923-172.17.0.10-1595806196352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41998,DS-a506aed1-b373-4fb9-b5a5-07f4d65d32ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-d393b520-a859-463e-aa75-49484214ec77,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-30161a38-67d1-4536-a55f-74edf950ab6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-8af50644-4e8d-4743-8c80-5808128238f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-f901b4f9-d261-4d49-bc34-b7c3fa4b8f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-8f9ce615-5f63-47ca-acd1-3d7c6d2560c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-aa01e29d-141b-4b71-ae64-60973a7fdd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-55fe1272-9ebf-4691-be89-193f6a0891ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982297691-172.17.0.10-1595806462152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44682,DS-644ec4e7-31ea-47a6-8106-bbfbd6482894,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-5b109b85-5c8d-4505-99f5-752c0a142935,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-f45f49ad-30c1-4dcc-8094-5a1adca905b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-cfacf7b6-fd87-402d-b255-d829eeeb77ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-2e7a2d0a-ea4b-4627-bc2a-1c061e01328b,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-4d1edcb0-6769-4990-9b5c-e53a88e0fbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-a9c96df8-b930-4ad2-aead-2a9eb5eadb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-aa47831e-0fe3-4cd5-9382-566eea290d7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982297691-172.17.0.10-1595806462152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44682,DS-644ec4e7-31ea-47a6-8106-bbfbd6482894,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-5b109b85-5c8d-4505-99f5-752c0a142935,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-f45f49ad-30c1-4dcc-8094-5a1adca905b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-cfacf7b6-fd87-402d-b255-d829eeeb77ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-2e7a2d0a-ea4b-4627-bc2a-1c061e01328b,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-4d1edcb0-6769-4990-9b5c-e53a88e0fbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-a9c96df8-b930-4ad2-aead-2a9eb5eadb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-aa47831e-0fe3-4cd5-9382-566eea290d7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131230149-172.17.0.10-1595806610704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45644,DS-3772f1e7-b490-4f49-a6ec-c629b78361d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-0f80e41f-e905-4755-9d5a-fc262320150b,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-9afc072f-282f-4233-b88d-0a1cadec45c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-25e967de-6cc9-4419-b68f-434486327628,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-1b007b1c-8915-4453-8120-1434698b1159,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-4c08a124-329e-44de-b097-744801885df0,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-94957530-19d8-4794-b642-76f0e905eb04,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-af01ebca-0d41-47e2-90d3-05a93a4f0092,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131230149-172.17.0.10-1595806610704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45644,DS-3772f1e7-b490-4f49-a6ec-c629b78361d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-0f80e41f-e905-4755-9d5a-fc262320150b,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-9afc072f-282f-4233-b88d-0a1cadec45c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-25e967de-6cc9-4419-b68f-434486327628,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-1b007b1c-8915-4453-8120-1434698b1159,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-4c08a124-329e-44de-b097-744801885df0,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-94957530-19d8-4794-b642-76f0e905eb04,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-af01ebca-0d41-47e2-90d3-05a93a4f0092,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170853511-172.17.0.10-1595806769917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40796,DS-dc579ac2-af24-451b-8f0f-9b88fe2dacd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-81a4e8a5-5a8d-4072-b5fb-b2f1ce5e7afe,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-460a9c55-8534-4b81-a517-0b81fcea4ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-f0c0bd07-00b6-4c58-8dec-44ebff6ff4db,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-92a696de-fb5c-48e0-bc5b-febcefaf021c,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-d2a60552-9467-4e1b-b85b-41de1305fcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-c47602aa-6b3f-426c-a3e5-436fa3015c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-15b69068-3c42-41cd-9b2a-7c8bc3f6927a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170853511-172.17.0.10-1595806769917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40796,DS-dc579ac2-af24-451b-8f0f-9b88fe2dacd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-81a4e8a5-5a8d-4072-b5fb-b2f1ce5e7afe,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-460a9c55-8534-4b81-a517-0b81fcea4ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-f0c0bd07-00b6-4c58-8dec-44ebff6ff4db,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-92a696de-fb5c-48e0-bc5b-febcefaf021c,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-d2a60552-9467-4e1b-b85b-41de1305fcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-c47602aa-6b3f-426c-a3e5-436fa3015c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-15b69068-3c42-41cd-9b2a-7c8bc3f6927a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875995947-172.17.0.10-1595807271378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43496,DS-f03db7b9-3d6e-4d84-9c44-1926ed7a408f,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-09c08f68-d94a-4368-bb82-70811b9724a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-ab76e239-2774-48d0-88cd-4c728e38d101,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-dc7b388a-ba4c-4911-8d3f-529eb87d49e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-33b194a7-357e-4db8-8fa4-05ccebc85680,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-77ac164f-ad5b-4e5d-b25b-0863768e4c07,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-ce759529-fe18-440f-ab8d-34e1648c0c41,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-1ad9f42f-686e-42ac-a030-96a5746ae16c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875995947-172.17.0.10-1595807271378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43496,DS-f03db7b9-3d6e-4d84-9c44-1926ed7a408f,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-09c08f68-d94a-4368-bb82-70811b9724a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-ab76e239-2774-48d0-88cd-4c728e38d101,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-dc7b388a-ba4c-4911-8d3f-529eb87d49e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-33b194a7-357e-4db8-8fa4-05ccebc85680,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-77ac164f-ad5b-4e5d-b25b-0863768e4c07,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-ce759529-fe18-440f-ab8d-34e1648c0c41,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-1ad9f42f-686e-42ac-a030-96a5746ae16c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376745580-172.17.0.10-1595807502789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34932,DS-8bd5da06-08ee-417b-bb3a-311d91e22d98,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-5ef9e545-3a7f-45b6-9fc0-f80019da6135,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-3a801ea5-e659-4a4b-b6f5-31626f28bfad,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-e1aa7ac1-b4e8-411b-a589-d6eba2f4b31f,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-019de142-fc5f-49be-be60-b03fca4f2c63,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-c7dc7ba3-d50b-4035-b910-dc1a2d0d3c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-09fec884-8a74-47cf-a7b4-ff752ef9794c,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-95e5f5a5-0df8-423f-84c0-3cbf50ef0499,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376745580-172.17.0.10-1595807502789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34932,DS-8bd5da06-08ee-417b-bb3a-311d91e22d98,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-5ef9e545-3a7f-45b6-9fc0-f80019da6135,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-3a801ea5-e659-4a4b-b6f5-31626f28bfad,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-e1aa7ac1-b4e8-411b-a589-d6eba2f4b31f,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-019de142-fc5f-49be-be60-b03fca4f2c63,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-c7dc7ba3-d50b-4035-b910-dc1a2d0d3c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-09fec884-8a74-47cf-a7b4-ff752ef9794c,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-95e5f5a5-0df8-423f-84c0-3cbf50ef0499,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-691896171-172.17.0.10-1595807921482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39130,DS-8724f001-3d1e-41f8-b2d3-e79ca8ed5170,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-8351781a-c6d4-40d6-84e6-4c6c2370642d,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-7328bc35-0ed6-4a9c-aa00-b553dbc14302,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-03d01ea8-c610-4750-8f94-81f02a17189b,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-44521b04-d027-4796-b96f-9fdc1524e5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-96c43909-dead-4960-a874-e5ea52b86e20,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-4108fca4-edc0-4aa8-b3dd-f0a3e9cc61d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-8ce17d83-adf3-4efb-958b-e0bc6fea478e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-691896171-172.17.0.10-1595807921482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39130,DS-8724f001-3d1e-41f8-b2d3-e79ca8ed5170,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-8351781a-c6d4-40d6-84e6-4c6c2370642d,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-7328bc35-0ed6-4a9c-aa00-b553dbc14302,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-03d01ea8-c610-4750-8f94-81f02a17189b,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-44521b04-d027-4796-b96f-9fdc1524e5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-96c43909-dead-4960-a874-e5ea52b86e20,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-4108fca4-edc0-4aa8-b3dd-f0a3e9cc61d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-8ce17d83-adf3-4efb-958b-e0bc6fea478e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-802447565-172.17.0.10-1595808186104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37006,DS-d8e07c24-52bb-454d-8961-8cc4de5478e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-3fe32d65-e968-4c84-8a2f-8ce1265de89a,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-e2cfbfad-edae-4afb-a39c-ad7a92a009c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-4ef00c2c-1161-45cd-b3d4-ca4dcc1d35d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-b366396a-2936-437d-9d6d-f6481178a290,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-14f21c4f-e167-49a3-892f-2a2498512400,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-cbbe87aa-23ff-437f-98d2-b00aaf285c75,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-94096b81-5f9a-46d1-b570-8fc099c6489d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-802447565-172.17.0.10-1595808186104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37006,DS-d8e07c24-52bb-454d-8961-8cc4de5478e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-3fe32d65-e968-4c84-8a2f-8ce1265de89a,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-e2cfbfad-edae-4afb-a39c-ad7a92a009c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-4ef00c2c-1161-45cd-b3d4-ca4dcc1d35d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-b366396a-2936-437d-9d6d-f6481178a290,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-14f21c4f-e167-49a3-892f-2a2498512400,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-cbbe87aa-23ff-437f-98d2-b00aaf285c75,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-94096b81-5f9a-46d1-b570-8fc099c6489d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-301775256-172.17.0.10-1595808464059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39180,DS-0ccaa05e-47a4-4e73-b414-8bd2f2bfaf26,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-d6e3dac1-778c-4ff8-97a4-ed0c6d35e4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-00935440-4feb-4da5-85bc-53deb7c1ede7,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-6c466136-c13f-46c3-82db-774c9f20e695,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-3f73d83f-d81c-4dbe-9d49-9fedf6df5ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-2089e7aa-de53-4545-aeda-159e84e52093,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-08414f35-e8bc-491f-a5e9-ac2667c05009,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-b16bf1c0-2767-4f0a-a0ec-378b48afaafe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-301775256-172.17.0.10-1595808464059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39180,DS-0ccaa05e-47a4-4e73-b414-8bd2f2bfaf26,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-d6e3dac1-778c-4ff8-97a4-ed0c6d35e4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-00935440-4feb-4da5-85bc-53deb7c1ede7,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-6c466136-c13f-46c3-82db-774c9f20e695,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-3f73d83f-d81c-4dbe-9d49-9fedf6df5ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-2089e7aa-de53-4545-aeda-159e84e52093,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-08414f35-e8bc-491f-a5e9-ac2667c05009,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-b16bf1c0-2767-4f0a-a0ec-378b48afaafe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1273424189-172.17.0.10-1595808723025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42869,DS-6579b28d-e1a2-4ed6-b82a-3b6c8eb09ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-39b7c7b5-a47e-4a3a-8c7d-ab1d2b91ad75,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-8f2d9f53-4150-4582-a512-67cd0c549198,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-977c700b-0d7f-4e50-83ce-6e4b40035a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-9d7ef5ae-48ad-4e80-8a3e-905bf1819abb,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-4c23f8e8-635c-4ce1-9dab-cbbeab69d472,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-c6de434e-d5da-4584-9def-d23a99ac6701,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-0eb5c497-502c-4373-9565-f0712ccfa10e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1273424189-172.17.0.10-1595808723025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42869,DS-6579b28d-e1a2-4ed6-b82a-3b6c8eb09ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-39b7c7b5-a47e-4a3a-8c7d-ab1d2b91ad75,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-8f2d9f53-4150-4582-a512-67cd0c549198,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-977c700b-0d7f-4e50-83ce-6e4b40035a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-9d7ef5ae-48ad-4e80-8a3e-905bf1819abb,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-4c23f8e8-635c-4ce1-9dab-cbbeab69d472,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-c6de434e-d5da-4584-9def-d23a99ac6701,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-0eb5c497-502c-4373-9565-f0712ccfa10e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565901281-172.17.0.10-1595809327877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37529,DS-3a0a51d9-5160-4193-ae7a-e6751d95eea6,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-47aa655c-aef8-45d4-bd7a-61ad0cc92688,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-d28e9abe-1b09-425d-8445-dd41bb722e50,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-ba3d5e2f-b5b8-4fca-b3c7-0a231b0bdc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-4b86f5db-742e-40a2-b7d0-e2be2bbf6484,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-100f454d-cd2f-4381-a58d-3da7a1407e14,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-af202667-962a-4b0f-8f48-23ac2f5085f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-97ed2958-9475-4d4f-a00d-31de32245698,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565901281-172.17.0.10-1595809327877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37529,DS-3a0a51d9-5160-4193-ae7a-e6751d95eea6,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-47aa655c-aef8-45d4-bd7a-61ad0cc92688,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-d28e9abe-1b09-425d-8445-dd41bb722e50,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-ba3d5e2f-b5b8-4fca-b3c7-0a231b0bdc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-4b86f5db-742e-40a2-b7d0-e2be2bbf6484,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-100f454d-cd2f-4381-a58d-3da7a1407e14,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-af202667-962a-4b0f-8f48-23ac2f5085f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-97ed2958-9475-4d4f-a00d-31de32245698,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639851259-172.17.0.10-1595809563567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39898,DS-93d62a4d-1e1a-42e0-b1c4-31f16797d67a,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-bfc8ecfc-238f-4662-be35-4f715317fbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-2a76266f-04ea-4e0a-9fec-b6afd1018762,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-12b997f3-4909-47be-b12b-d987c8ff4fef,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-08bcd4ef-5dfa-4afb-bb1f-02d844505feb,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-89f31320-b66b-44b3-a619-c0bee3b5d5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-41aeb4dd-9ba6-455f-a9c3-ad8b15569a28,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-e30bdef1-5c45-4921-acb6-afb1ce4202ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639851259-172.17.0.10-1595809563567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39898,DS-93d62a4d-1e1a-42e0-b1c4-31f16797d67a,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-bfc8ecfc-238f-4662-be35-4f715317fbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-2a76266f-04ea-4e0a-9fec-b6afd1018762,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-12b997f3-4909-47be-b12b-d987c8ff4fef,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-08bcd4ef-5dfa-4afb-bb1f-02d844505feb,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-89f31320-b66b-44b3-a619-c0bee3b5d5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-41aeb4dd-9ba6-455f-a9c3-ad8b15569a28,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-e30bdef1-5c45-4921-acb6-afb1ce4202ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806756580-172.17.0.10-1595809636106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38984,DS-fa66f565-5c3d-47d1-8746-80df6f92ae6d,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-d4af14d7-63f0-4efd-8c38-4ac5fa9899d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-07d1248b-af0a-4c62-9c81-690595c28c77,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-3f102c16-2c06-41f6-8f90-c52f16564861,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-09465420-c5c5-431a-9a88-988b358cdeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-ff39aa70-7b2d-4877-b284-34841996a16c,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-98865574-5123-4b5e-9495-665adf9eebf4,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-f47cb8be-d361-4748-a07e-0b5c53f6f0c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806756580-172.17.0.10-1595809636106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38984,DS-fa66f565-5c3d-47d1-8746-80df6f92ae6d,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-d4af14d7-63f0-4efd-8c38-4ac5fa9899d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-07d1248b-af0a-4c62-9c81-690595c28c77,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-3f102c16-2c06-41f6-8f90-c52f16564861,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-09465420-c5c5-431a-9a88-988b358cdeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-ff39aa70-7b2d-4877-b284-34841996a16c,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-98865574-5123-4b5e-9495-665adf9eebf4,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-f47cb8be-d361-4748-a07e-0b5c53f6f0c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5686
