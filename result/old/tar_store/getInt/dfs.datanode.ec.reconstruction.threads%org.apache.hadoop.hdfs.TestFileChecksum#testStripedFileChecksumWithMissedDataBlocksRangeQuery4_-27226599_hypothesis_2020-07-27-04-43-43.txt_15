reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1639873659-172.17.0.5-1595825038779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40761,DS-6108823e-7d04-4865-ad2a-a3477746e4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-1275faa8-2432-4524-bec5-8f3daeb22953,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-36fbeff4-4b51-474f-adc2-2dc3dc5a995c,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-a91ffb5b-db2d-4c54-8fb4-ecd6751e5bae,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-8214b671-5a16-4631-af0d-7a1384d55bde,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-55b6d056-dcfc-4dd0-90a4-2c9d38da1d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-52c27a5f-74b6-4df9-a444-f90000250b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-2f67b4f1-91de-4b2e-8d71-3a0c37a4021f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1639873659-172.17.0.5-1595825038779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40761,DS-6108823e-7d04-4865-ad2a-a3477746e4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-1275faa8-2432-4524-bec5-8f3daeb22953,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-36fbeff4-4b51-474f-adc2-2dc3dc5a995c,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-a91ffb5b-db2d-4c54-8fb4-ecd6751e5bae,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-8214b671-5a16-4631-af0d-7a1384d55bde,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-55b6d056-dcfc-4dd0-90a4-2c9d38da1d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-52c27a5f-74b6-4df9-a444-f90000250b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-2f67b4f1-91de-4b2e-8d71-3a0c37a4021f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75552393-172.17.0.5-1595825110370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34713,DS-07eba1c6-06c1-4497-adeb-4ce028c026b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-44e14a25-8464-4225-a0a8-a2551bebb5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-594250e8-e203-4a27-9839-2dff561bafe4,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-84eefe28-24de-44a2-b234-5a1fe7965b03,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-d511a64c-142d-4ea9-86ac-a203b2c46c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-26016b11-709a-436b-9097-66a9a54ccd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-824da99d-6c91-4041-a749-233d5206a07b,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-4b558f5b-b049-4e41-a26f-e3967130e420,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75552393-172.17.0.5-1595825110370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34713,DS-07eba1c6-06c1-4497-adeb-4ce028c026b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-44e14a25-8464-4225-a0a8-a2551bebb5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-594250e8-e203-4a27-9839-2dff561bafe4,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-84eefe28-24de-44a2-b234-5a1fe7965b03,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-d511a64c-142d-4ea9-86ac-a203b2c46c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-26016b11-709a-436b-9097-66a9a54ccd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-824da99d-6c91-4041-a749-233d5206a07b,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-4b558f5b-b049-4e41-a26f-e3967130e420,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-905031757-172.17.0.5-1595825526476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33805,DS-74154a3f-b2fb-4563-8e20-cf93d8b5ecc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-d6239920-df4d-477f-a886-d1f3fa2f6e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-6d2124c6-a280-4cb4-a4b5-77cac9282576,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-51d9e188-f5a0-4e1f-b402-8d17857c8ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-72abdbee-ee5c-4b70-ace9-17313b087572,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-93dc41ef-e60f-4be0-a96e-93cab0e9b199,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-78afbaa9-37fe-4783-8361-511ff19cf504,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-f684fc80-58d8-49d6-a08f-cdea17143abd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-905031757-172.17.0.5-1595825526476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33805,DS-74154a3f-b2fb-4563-8e20-cf93d8b5ecc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-d6239920-df4d-477f-a886-d1f3fa2f6e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-6d2124c6-a280-4cb4-a4b5-77cac9282576,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-51d9e188-f5a0-4e1f-b402-8d17857c8ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-72abdbee-ee5c-4b70-ace9-17313b087572,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-93dc41ef-e60f-4be0-a96e-93cab0e9b199,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-78afbaa9-37fe-4783-8361-511ff19cf504,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-f684fc80-58d8-49d6-a08f-cdea17143abd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-582726986-172.17.0.5-1595825670223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44804,DS-7e192204-cd34-4a02-b673-349d00cfdbab,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-41ee8775-9bce-4504-a076-a64bafe0ce0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-02265bb1-5e36-4675-917d-30fe87d2fe45,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-78a5ac36-691a-46c2-979b-749e0433ca40,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-071e29ec-1761-4e72-83bd-369df44dc43e,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-dc73fa7e-5f5b-449d-bb0b-2df0a8663b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-054ac2f4-be5a-475e-b552-0902b65d5cad,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-9cd7a80e-7a1e-4678-9e4f-e7c83ad31def,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-582726986-172.17.0.5-1595825670223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44804,DS-7e192204-cd34-4a02-b673-349d00cfdbab,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-41ee8775-9bce-4504-a076-a64bafe0ce0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-02265bb1-5e36-4675-917d-30fe87d2fe45,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-78a5ac36-691a-46c2-979b-749e0433ca40,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-071e29ec-1761-4e72-83bd-369df44dc43e,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-dc73fa7e-5f5b-449d-bb0b-2df0a8663b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-054ac2f4-be5a-475e-b552-0902b65d5cad,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-9cd7a80e-7a1e-4678-9e4f-e7c83ad31def,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106211683-172.17.0.5-1595826111424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35722,DS-31b8ab0a-9574-44cb-9d8e-37c45268df50,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-6411e626-a603-41b7-8c2b-3d6afd16efb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-30fab5d1-8ec2-4acc-a88d-6f429f9799c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-0510df9e-7d10-41b0-81f3-46cc634e2808,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-dc9af1a5-4daf-4370-97a5-48f7d8ad02bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-c59e81a3-a7d0-402e-a294-3d7ed4867be2,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-d63be10a-05d5-4b5e-a90d-d8f928de0cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-f128b45f-bf99-4123-80c4-3d22bbcfc220,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106211683-172.17.0.5-1595826111424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35722,DS-31b8ab0a-9574-44cb-9d8e-37c45268df50,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-6411e626-a603-41b7-8c2b-3d6afd16efb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-30fab5d1-8ec2-4acc-a88d-6f429f9799c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-0510df9e-7d10-41b0-81f3-46cc634e2808,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-dc9af1a5-4daf-4370-97a5-48f7d8ad02bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-c59e81a3-a7d0-402e-a294-3d7ed4867be2,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-d63be10a-05d5-4b5e-a90d-d8f928de0cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-f128b45f-bf99-4123-80c4-3d22bbcfc220,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-520963330-172.17.0.5-1595826369918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43664,DS-06ff3231-217a-40dc-9b56-0997cd043deb,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-93926c9e-c60e-4a53-8e5a-7114cd7d1d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-7ad5c81c-5f5a-4513-bbfa-60f87e65264a,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-04faa778-6adc-47bf-8137-49ed0ab16a31,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-ef487fb3-3c86-4644-a58f-96af6cdca2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-e0da47ce-4645-4228-8312-636d32651d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-e253edd1-dcb3-4860-b1a0-5d3e876df1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-913c588c-93fe-4656-ac9d-468e393ba976,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-520963330-172.17.0.5-1595826369918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43664,DS-06ff3231-217a-40dc-9b56-0997cd043deb,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-93926c9e-c60e-4a53-8e5a-7114cd7d1d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-7ad5c81c-5f5a-4513-bbfa-60f87e65264a,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-04faa778-6adc-47bf-8137-49ed0ab16a31,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-ef487fb3-3c86-4644-a58f-96af6cdca2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-e0da47ce-4645-4228-8312-636d32651d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-e253edd1-dcb3-4860-b1a0-5d3e876df1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-913c588c-93fe-4656-ac9d-468e393ba976,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-704292103-172.17.0.5-1595826789481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43792,DS-87e5d0ac-4a6f-440f-9fd9-20ebce51b717,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-87fd762e-d780-42c2-91ba-be043a636048,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-cb6cc391-b605-4845-8754-1d55b7fe6e59,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-cf5561d9-3807-4313-95e5-f9877cba3681,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-e57bfbc0-9511-4173-9e6f-07c5cbe74c39,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-81c6521a-959e-4300-af32-ec82e0a5825e,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-79867cc8-6e42-4d99-ada8-2a5169979c32,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-fce5a686-3001-498f-a805-68af15401582,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-704292103-172.17.0.5-1595826789481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43792,DS-87e5d0ac-4a6f-440f-9fd9-20ebce51b717,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-87fd762e-d780-42c2-91ba-be043a636048,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-cb6cc391-b605-4845-8754-1d55b7fe6e59,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-cf5561d9-3807-4313-95e5-f9877cba3681,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-e57bfbc0-9511-4173-9e6f-07c5cbe74c39,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-81c6521a-959e-4300-af32-ec82e0a5825e,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-79867cc8-6e42-4d99-ada8-2a5169979c32,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-fce5a686-3001-498f-a805-68af15401582,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1434619726-172.17.0.5-1595826933646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33593,DS-6fbb4404-9b06-457a-acef-1c3cacf6a408,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-87751c65-61b5-4939-a098-1491b5bf08ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-dc7851ce-8b50-480e-82b9-8eb7ea775f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-c7db6a78-7ed1-4730-9e28-da8daf3773d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-46aa60ba-e6ea-4d83-b4c3-8d6111a3fad5,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-4952484d-d1e0-4052-9a30-34e1fc2ef30f,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-ca3ab675-eca0-4b42-beb8-6f482146ef78,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-9483def9-fb5c-420a-828d-3c923f360706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1434619726-172.17.0.5-1595826933646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33593,DS-6fbb4404-9b06-457a-acef-1c3cacf6a408,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-87751c65-61b5-4939-a098-1491b5bf08ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-dc7851ce-8b50-480e-82b9-8eb7ea775f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-c7db6a78-7ed1-4730-9e28-da8daf3773d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-46aa60ba-e6ea-4d83-b4c3-8d6111a3fad5,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-4952484d-d1e0-4052-9a30-34e1fc2ef30f,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-ca3ab675-eca0-4b42-beb8-6f482146ef78,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-9483def9-fb5c-420a-828d-3c923f360706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918802138-172.17.0.5-1595827136230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43158,DS-982693bf-c9d8-41e2-bd41-442fbf565360,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-b1986419-5432-4f8a-9f48-f67adaed079d,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-a95fda0c-5355-4ae1-a802-0094517f490f,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-be29807f-520b-4476-afdb-3dda1557c847,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-c60d9ac8-00d4-4a72-a9f3-cd522cc5ba92,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-93b50f12-8d76-4968-a9ad-d15db72cc2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-57b21844-34f7-4290-a1d5-d197a52fe8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-3b20954f-4d10-4708-bdb5-3be884ee3d67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918802138-172.17.0.5-1595827136230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43158,DS-982693bf-c9d8-41e2-bd41-442fbf565360,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-b1986419-5432-4f8a-9f48-f67adaed079d,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-a95fda0c-5355-4ae1-a802-0094517f490f,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-be29807f-520b-4476-afdb-3dda1557c847,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-c60d9ac8-00d4-4a72-a9f3-cd522cc5ba92,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-93b50f12-8d76-4968-a9ad-d15db72cc2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-57b21844-34f7-4290-a1d5-d197a52fe8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-3b20954f-4d10-4708-bdb5-3be884ee3d67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398964253-172.17.0.5-1595827955946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43851,DS-51d76478-b316-4b54-9b62-8e495730c8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-005d9e34-d4de-40e1-9e8a-e83c26028cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-42b48c22-732f-4692-9bc9-525d70b0df8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-e6953f76-2337-4b04-a27b-d5f3d4a1ebe2,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-d451b313-c2f8-4666-a6bb-08eca69fdd30,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-c357250e-f942-453a-93e0-f91b5efe2fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-dda849ec-e819-4f50-857f-a16105e70a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-696176a3-f04c-4318-832e-b74814689697,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398964253-172.17.0.5-1595827955946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43851,DS-51d76478-b316-4b54-9b62-8e495730c8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-005d9e34-d4de-40e1-9e8a-e83c26028cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-42b48c22-732f-4692-9bc9-525d70b0df8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-e6953f76-2337-4b04-a27b-d5f3d4a1ebe2,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-d451b313-c2f8-4666-a6bb-08eca69fdd30,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-c357250e-f942-453a-93e0-f91b5efe2fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-dda849ec-e819-4f50-857f-a16105e70a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-696176a3-f04c-4318-832e-b74814689697,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-805075548-172.17.0.5-1595828724507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45267,DS-0bfda6fb-bda2-4fe9-9d29-e85c0e668155,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-7a425649-d688-44fc-9a43-9a456d81ebf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-4e2b330e-a181-4c79-9ad0-9e1a9e71e91a,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-24d780b1-e492-4d4d-b90b-52461931f28e,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-c8dc215e-f217-4de8-818f-8dad7caf40f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-2877b1ba-b4db-4fa0-9510-bfba6ccaf9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-0ea52260-9dd2-4a69-976b-dd12abaa13a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-809dba23-bb24-4351-8dfc-2dfa602851c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-805075548-172.17.0.5-1595828724507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45267,DS-0bfda6fb-bda2-4fe9-9d29-e85c0e668155,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-7a425649-d688-44fc-9a43-9a456d81ebf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-4e2b330e-a181-4c79-9ad0-9e1a9e71e91a,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-24d780b1-e492-4d4d-b90b-52461931f28e,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-c8dc215e-f217-4de8-818f-8dad7caf40f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-2877b1ba-b4db-4fa0-9510-bfba6ccaf9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-0ea52260-9dd2-4a69-976b-dd12abaa13a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-809dba23-bb24-4351-8dfc-2dfa602851c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440905863-172.17.0.5-1595829074812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45967,DS-500388e5-c322-474c-95ae-ee61ab956414,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-7cb5a637-9cfa-40b0-b688-57fb902ad9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-53b5987c-a16b-4a7d-a4cd-6afef755f877,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-633d45d6-cbdd-4a0d-8906-eee53f4123ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-3ed576f7-737e-42b0-9be3-24a7513be582,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-502bd3f9-f937-4f26-839d-34aa0d52c0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-ee2441b3-ece0-41cb-b6c8-14f7d6243571,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-3fe89eed-d407-45b7-b2bf-0fd455a8aebd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440905863-172.17.0.5-1595829074812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45967,DS-500388e5-c322-474c-95ae-ee61ab956414,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-7cb5a637-9cfa-40b0-b688-57fb902ad9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-53b5987c-a16b-4a7d-a4cd-6afef755f877,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-633d45d6-cbdd-4a0d-8906-eee53f4123ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-3ed576f7-737e-42b0-9be3-24a7513be582,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-502bd3f9-f937-4f26-839d-34aa0d52c0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-ee2441b3-ece0-41cb-b6c8-14f7d6243571,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-3fe89eed-d407-45b7-b2bf-0fd455a8aebd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560094189-172.17.0.5-1595829795065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42840,DS-d9ae8f14-edfe-42a0-a955-8737064bb0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-6729419c-2a0d-45bd-b147-d31567103385,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-3670ef7a-0f48-4c01-8924-a4401e8007a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-00060612-459d-4986-aaec-ebf40065ea8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-256f8288-f29b-4e99-ae95-2bb6c9b47be5,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-af0b7881-5c43-49bf-96af-20eb3636a395,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-ee46d767-0822-47af-a262-50cbfbf1ed14,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-9e50b858-fd59-4e9b-878b-97d58fcbc260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560094189-172.17.0.5-1595829795065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42840,DS-d9ae8f14-edfe-42a0-a955-8737064bb0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-6729419c-2a0d-45bd-b147-d31567103385,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-3670ef7a-0f48-4c01-8924-a4401e8007a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-00060612-459d-4986-aaec-ebf40065ea8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-256f8288-f29b-4e99-ae95-2bb6c9b47be5,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-af0b7881-5c43-49bf-96af-20eb3636a395,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-ee46d767-0822-47af-a262-50cbfbf1ed14,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-9e50b858-fd59-4e9b-878b-97d58fcbc260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-334880670-172.17.0.5-1595829871961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43668,DS-5bb4d3c9-e1dd-47f1-8f0f-33ad7e2f5bad,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-ac8572cf-cf28-43af-8b7f-a1d3c2fd5271,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-d16055bb-aaa2-43b1-a8e2-43c62b6d62d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-1974a8c6-34f0-4299-ab27-f560f1f90bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-11418798-75ff-43a5-bc8c-c187a3da0b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-0a8ae137-16e0-45d6-afb7-c2bd9af2f37e,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-8ae44898-9e63-4c90-8f1d-c26f82c4f1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-22edf0b3-3c97-4478-9975-63a690a2c5cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-334880670-172.17.0.5-1595829871961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43668,DS-5bb4d3c9-e1dd-47f1-8f0f-33ad7e2f5bad,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-ac8572cf-cf28-43af-8b7f-a1d3c2fd5271,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-d16055bb-aaa2-43b1-a8e2-43c62b6d62d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-1974a8c6-34f0-4299-ab27-f560f1f90bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-11418798-75ff-43a5-bc8c-c187a3da0b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-0a8ae137-16e0-45d6-afb7-c2bd9af2f37e,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-8ae44898-9e63-4c90-8f1d-c26f82c4f1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-22edf0b3-3c97-4478-9975-63a690a2c5cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715234957-172.17.0.5-1595829950518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40345,DS-645823cb-d7d7-49ad-b1c6-88bfb2d88dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-9ec7f4fb-df0b-4459-947e-c61c7955c3be,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-4157813d-b8d9-4718-bccb-4d01b8a46517,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-2fe9b479-84a3-4041-9376-c783f75e4b96,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-4be76a08-3790-4f37-bbf3-b2758a080b80,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-989e4d86-059d-4bd3-9c95-c8e51d606139,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-44cf8c28-65d7-404f-9965-fd0720836289,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-30794a25-f62f-42ba-8699-4380d7527301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715234957-172.17.0.5-1595829950518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40345,DS-645823cb-d7d7-49ad-b1c6-88bfb2d88dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-9ec7f4fb-df0b-4459-947e-c61c7955c3be,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-4157813d-b8d9-4718-bccb-4d01b8a46517,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-2fe9b479-84a3-4041-9376-c783f75e4b96,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-4be76a08-3790-4f37-bbf3-b2758a080b80,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-989e4d86-059d-4bd3-9c95-c8e51d606139,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-44cf8c28-65d7-404f-9965-fd0720836289,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-30794a25-f62f-42ba-8699-4380d7527301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330690900-172.17.0.5-1595830375341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42252,DS-fa65874d-43c7-4cbd-a8b5-4ebe546984b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-8b9447a0-0d6f-46db-9aff-0b0aadf7b868,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-b96d3c51-5e50-41af-a123-57dd11256505,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-5c562069-5ec4-4596-9010-32e118103fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-b4d5001c-cf15-420b-aaa8-56f7540ebbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-7052b115-feed-4aa3-930e-079076ab4c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-0125423c-79a4-48c2-93fc-51cde66cc406,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-c4ff6678-fd35-4922-9303-489f90c10c80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330690900-172.17.0.5-1595830375341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42252,DS-fa65874d-43c7-4cbd-a8b5-4ebe546984b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-8b9447a0-0d6f-46db-9aff-0b0aadf7b868,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-b96d3c51-5e50-41af-a123-57dd11256505,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-5c562069-5ec4-4596-9010-32e118103fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-b4d5001c-cf15-420b-aaa8-56f7540ebbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-7052b115-feed-4aa3-930e-079076ab4c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-0125423c-79a4-48c2-93fc-51cde66cc406,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-c4ff6678-fd35-4922-9303-489f90c10c80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5687
