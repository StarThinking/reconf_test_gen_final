reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1845903603-172.17.0.16-1595486692829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43741,DS-f0b6b415-7c5b-45ba-a674-f7fc0558543a,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-7b12a931-5cba-4a67-bde9-e45b6904200c,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-c4502065-63bd-4c16-8e89-8b68bbea4ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-fb3d69cc-2f0a-448f-beac-603a4a39aca9,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-fc93bf4f-aabf-4ee3-9fd6-6010b98c596f,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-6dda964f-36a1-4ee7-8938-38d3166dd88d,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-fdb8ade0-e6f4-4e0a-9d82-070c3ca501d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-a54d64f6-0fc7-496e-b2e3-2c3145776c55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1845903603-172.17.0.16-1595486692829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43741,DS-f0b6b415-7c5b-45ba-a674-f7fc0558543a,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-7b12a931-5cba-4a67-bde9-e45b6904200c,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-c4502065-63bd-4c16-8e89-8b68bbea4ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-fb3d69cc-2f0a-448f-beac-603a4a39aca9,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-fc93bf4f-aabf-4ee3-9fd6-6010b98c596f,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-6dda964f-36a1-4ee7-8938-38d3166dd88d,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-fdb8ade0-e6f4-4e0a-9d82-070c3ca501d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-a54d64f6-0fc7-496e-b2e3-2c3145776c55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1185228324-172.17.0.16-1595486763786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32827,DS-46687b8a-c4e1-430c-bb2b-860d9be0871b,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-eff64892-303c-4aa9-a255-5bce32f265da,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-aecb2c7d-35d6-4f2f-8919-a96f737f4852,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-40ed72a2-d49f-4f6f-8bc7-ee478aea7d83,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-b2c4be5d-dd3b-4298-bad6-648d1306cdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-783ea0d1-1279-4092-aebe-b0d786fdd825,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-761a7e77-29cc-4304-ad60-f61dd1b70c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-e16cb599-b512-4192-bde7-5f42cb279d70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1185228324-172.17.0.16-1595486763786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32827,DS-46687b8a-c4e1-430c-bb2b-860d9be0871b,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-eff64892-303c-4aa9-a255-5bce32f265da,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-aecb2c7d-35d6-4f2f-8919-a96f737f4852,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-40ed72a2-d49f-4f6f-8bc7-ee478aea7d83,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-b2c4be5d-dd3b-4298-bad6-648d1306cdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-783ea0d1-1279-4092-aebe-b0d786fdd825,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-761a7e77-29cc-4304-ad60-f61dd1b70c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-e16cb599-b512-4192-bde7-5f42cb279d70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1486305054-172.17.0.16-1595487274342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38974,DS-b2bec892-58c7-4055-bdf2-1db62930767c,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-b7d0e34f-b28b-4077-887a-9f7add159df5,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-3dcd03b6-6d2b-42c5-9d83-580a379b67cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-94eb7c90-5522-450b-b3ce-4fcf5df03d03,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-c6370a6e-e00b-4416-ac41-4ddc144e434d,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-9ed23721-849b-496f-8f61-2ef0aa1b14d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-153e7ae1-1e8c-481f-ae7d-923f6fa040f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-cb651f44-ba01-486e-a0b5-b431f920a6c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1486305054-172.17.0.16-1595487274342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38974,DS-b2bec892-58c7-4055-bdf2-1db62930767c,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-b7d0e34f-b28b-4077-887a-9f7add159df5,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-3dcd03b6-6d2b-42c5-9d83-580a379b67cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-94eb7c90-5522-450b-b3ce-4fcf5df03d03,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-c6370a6e-e00b-4416-ac41-4ddc144e434d,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-9ed23721-849b-496f-8f61-2ef0aa1b14d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-153e7ae1-1e8c-481f-ae7d-923f6fa040f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-cb651f44-ba01-486e-a0b5-b431f920a6c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864257283-172.17.0.16-1595487476157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33490,DS-a0518d7c-f3cf-432c-8e9c-b765523eeed4,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-7f285ff2-0664-406e-8db3-1525f2a81370,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-c9a1df9f-f417-40bb-82c6-5867866529ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-e4b7d9e9-9d1c-456d-afe4-36d08e198d11,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-8c0d5425-b6b5-40ed-99d1-920eba6b34ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-af29fd1b-b7be-4e52-b5a7-f9943055f430,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-5041b59c-60dd-497d-a03b-be664e1450e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-83816718-3eef-428b-a194-aa330868ff65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864257283-172.17.0.16-1595487476157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33490,DS-a0518d7c-f3cf-432c-8e9c-b765523eeed4,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-7f285ff2-0664-406e-8db3-1525f2a81370,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-c9a1df9f-f417-40bb-82c6-5867866529ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-e4b7d9e9-9d1c-456d-afe4-36d08e198d11,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-8c0d5425-b6b5-40ed-99d1-920eba6b34ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-af29fd1b-b7be-4e52-b5a7-f9943055f430,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-5041b59c-60dd-497d-a03b-be664e1450e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-83816718-3eef-428b-a194-aa330868ff65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1865697054-172.17.0.16-1595487580186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43343,DS-9bf6ddf4-b075-4346-b541-c980f0047217,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-cb118acd-7732-4240-a27e-9b0046fcc092,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-d6433d91-3c74-4e85-942b-2282eec5f063,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-f0f65b71-4744-4bed-8c8a-5b7725225b72,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-7126a4d5-2c02-4ebc-9c4c-a7d0d59d46d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-651c07b3-5eb1-4e79-bdc1-6fe7be180ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-ee569d55-633e-4caa-b1f7-a30bb85591f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-262672ec-f525-4d54-99de-8dd7ac81613f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1865697054-172.17.0.16-1595487580186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43343,DS-9bf6ddf4-b075-4346-b541-c980f0047217,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-cb118acd-7732-4240-a27e-9b0046fcc092,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-d6433d91-3c74-4e85-942b-2282eec5f063,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-f0f65b71-4744-4bed-8c8a-5b7725225b72,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-7126a4d5-2c02-4ebc-9c4c-a7d0d59d46d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-651c07b3-5eb1-4e79-bdc1-6fe7be180ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-ee569d55-633e-4caa-b1f7-a30bb85591f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-262672ec-f525-4d54-99de-8dd7ac81613f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1391478648-172.17.0.16-1595488023199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40260,DS-e40cd891-7fa2-437d-b043-1cf430a19ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-185408a9-b01e-43dc-867d-d35fddcd4619,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-ca6be2fd-9b77-44b5-bdfd-6e4371208253,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-a501601a-a7bc-4e16-b900-56746b37987f,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-b0754146-6dba-4b0a-a318-d48ea0190fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-1bb0fd87-d1b2-4d48-95b1-18d3d95650cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-95417552-93bd-4c9f-bf54-aaac5ced0558,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-2cfb77be-ee41-471c-b3ec-82630e3668f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1391478648-172.17.0.16-1595488023199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40260,DS-e40cd891-7fa2-437d-b043-1cf430a19ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-185408a9-b01e-43dc-867d-d35fddcd4619,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-ca6be2fd-9b77-44b5-bdfd-6e4371208253,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-a501601a-a7bc-4e16-b900-56746b37987f,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-b0754146-6dba-4b0a-a318-d48ea0190fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-1bb0fd87-d1b2-4d48-95b1-18d3d95650cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-95417552-93bd-4c9f-bf54-aaac5ced0558,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-2cfb77be-ee41-471c-b3ec-82630e3668f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216636817-172.17.0.16-1595488130977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35844,DS-8f0599ef-efd2-4a97-9822-3f6859b171e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-b7cdba92-3bd7-41b0-be65-6b2f09a417ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-229ad7f3-fc06-44df-9767-6a5b67ce81dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-ba413991-2eea-4225-a869-43cb830a5d08,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-2382fdb3-95f3-47c7-8df7-4183f0eaafa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-21269f2c-0232-4c70-a675-627ab6ba559d,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-21692629-cf0d-4265-ad50-72f800fcf9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-837bcb99-ef60-43d0-916b-e909b7075db9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216636817-172.17.0.16-1595488130977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35844,DS-8f0599ef-efd2-4a97-9822-3f6859b171e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-b7cdba92-3bd7-41b0-be65-6b2f09a417ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-229ad7f3-fc06-44df-9767-6a5b67ce81dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-ba413991-2eea-4225-a869-43cb830a5d08,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-2382fdb3-95f3-47c7-8df7-4183f0eaafa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-21269f2c-0232-4c70-a675-627ab6ba559d,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-21692629-cf0d-4265-ad50-72f800fcf9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-837bcb99-ef60-43d0-916b-e909b7075db9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722234870-172.17.0.16-1595488203487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32980,DS-e8cb8716-3a8f-496a-a6a3-e1a552d308f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-2725c523-ff13-4d53-aed6-f4453c0837ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-21b5d713-6667-4807-90d4-ab8c487c72ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-0d5a6939-9acd-4398-8165-12e5ef04649d,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-0c10d384-ee70-4af4-8ec7-f86f0bd05aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-0b8aef6a-5b2e-4930-ab59-55e02f47de50,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-9b063312-de45-4ebc-88e8-9ccaf36312e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-1262577a-dac1-431e-9bf8-95610b74dd1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722234870-172.17.0.16-1595488203487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32980,DS-e8cb8716-3a8f-496a-a6a3-e1a552d308f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-2725c523-ff13-4d53-aed6-f4453c0837ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-21b5d713-6667-4807-90d4-ab8c487c72ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-0d5a6939-9acd-4398-8165-12e5ef04649d,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-0c10d384-ee70-4af4-8ec7-f86f0bd05aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-0b8aef6a-5b2e-4930-ab59-55e02f47de50,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-9b063312-de45-4ebc-88e8-9ccaf36312e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-1262577a-dac1-431e-9bf8-95610b74dd1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874214712-172.17.0.16-1595488270389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34194,DS-4e97f696-051c-41a7-8296-e31eba1967e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-97c42c87-bfbb-416b-aecd-dbdeb4aa3fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-97741ae3-5dd6-4a2f-b6af-279ae8fcc704,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-d7ca04a7-9ece-44e7-af54-5f6e64df56f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-2f036de1-d418-4eef-9a1c-09e72ec4c716,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-9b009e48-75e3-4f1d-910d-3627bdc046f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-62b70237-80f5-4303-bb22-be48f05c0d09,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-aaac05f3-061c-4ed1-930d-b0b8aa53d7b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874214712-172.17.0.16-1595488270389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34194,DS-4e97f696-051c-41a7-8296-e31eba1967e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-97c42c87-bfbb-416b-aecd-dbdeb4aa3fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-97741ae3-5dd6-4a2f-b6af-279ae8fcc704,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-d7ca04a7-9ece-44e7-af54-5f6e64df56f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-2f036de1-d418-4eef-9a1c-09e72ec4c716,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-9b009e48-75e3-4f1d-910d-3627bdc046f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-62b70237-80f5-4303-bb22-be48f05c0d09,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-aaac05f3-061c-4ed1-930d-b0b8aa53d7b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1264901362-172.17.0.16-1595488344644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32995,DS-0525f999-31ad-4966-bc22-55f5af7b538a,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-d0b9f782-a366-40de-9e77-fcf5729f8d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-910abd93-e810-4329-add5-24a7a07fd70a,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-84a22ec3-23e1-4cc5-bcc6-3e80194c65e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-9c2e4cb0-0f19-4b93-850b-fdb0cbc4b3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-b70cc97f-403e-4558-9d40-d2dcfc6af299,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-59613ff6-abe1-416d-8636-e8f8b6ba668b,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-8fa41c03-53f3-4fdc-860e-9e34e6175a2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1264901362-172.17.0.16-1595488344644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32995,DS-0525f999-31ad-4966-bc22-55f5af7b538a,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-d0b9f782-a366-40de-9e77-fcf5729f8d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-910abd93-e810-4329-add5-24a7a07fd70a,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-84a22ec3-23e1-4cc5-bcc6-3e80194c65e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-9c2e4cb0-0f19-4b93-850b-fdb0cbc4b3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-b70cc97f-403e-4558-9d40-d2dcfc6af299,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-59613ff6-abe1-416d-8636-e8f8b6ba668b,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-8fa41c03-53f3-4fdc-860e-9e34e6175a2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1791455806-172.17.0.16-1595488511737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36705,DS-85261479-6982-4442-aa85-f13940bd1ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-27055a3d-7bad-4b98-9f55-28735a2fa605,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-5b40defc-1f3c-44d7-9d28-72b94773b03f,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-d1ea6792-a28d-4208-a137-7b03c3550425,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-7acc049a-4b8a-4666-bbde-6c34cb7ba2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-8562fe89-55b9-4130-bcd2-8f6a8da35622,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-c45d90dc-00c8-4c40-867d-1eac846aef71,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-2ef5e33f-d1a7-4d39-bcac-26ccd59d4c2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1791455806-172.17.0.16-1595488511737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36705,DS-85261479-6982-4442-aa85-f13940bd1ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-27055a3d-7bad-4b98-9f55-28735a2fa605,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-5b40defc-1f3c-44d7-9d28-72b94773b03f,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-d1ea6792-a28d-4208-a137-7b03c3550425,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-7acc049a-4b8a-4666-bbde-6c34cb7ba2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-8562fe89-55b9-4130-bcd2-8f6a8da35622,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-c45d90dc-00c8-4c40-867d-1eac846aef71,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-2ef5e33f-d1a7-4d39-bcac-26ccd59d4c2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-618729084-172.17.0.16-1595488817411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43417,DS-f82e7a67-27b3-4917-95cc-416a3159c30b,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-ac5dd7b5-8aa5-43c3-b7ac-5409e47d15da,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-b7ad225d-815d-427c-8320-c5ba0659f6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-43b33262-2c38-483d-873e-bc1910aad200,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-80eb3c0e-abbc-4891-99fb-8f3c98649f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-12439977-bced-4f6d-a4b4-e0c8f7726e50,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-b3c145de-214c-44d1-8415-483ba0047210,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-cf9f6e37-c08b-4b22-af33-337403e506c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-618729084-172.17.0.16-1595488817411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43417,DS-f82e7a67-27b3-4917-95cc-416a3159c30b,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-ac5dd7b5-8aa5-43c3-b7ac-5409e47d15da,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-b7ad225d-815d-427c-8320-c5ba0659f6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-43b33262-2c38-483d-873e-bc1910aad200,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-80eb3c0e-abbc-4891-99fb-8f3c98649f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-12439977-bced-4f6d-a4b4-e0c8f7726e50,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-b3c145de-214c-44d1-8415-483ba0047210,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-cf9f6e37-c08b-4b22-af33-337403e506c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1112713480-172.17.0.16-1595488894574:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41455,DS-6fbf8ae5-4d96-4196-98f4-1591bfa9ccee,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-819c4367-c0ab-4248-a6ec-47150b18302b,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-93ceae85-e796-4429-bac6-a8124ae7a6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-f662cfa2-67b2-4306-94ec-1852d4e09719,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-cc02cfac-c936-4156-b3c7-43e3180ddb49,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-5a2c3f55-d7d0-4376-9845-a978ce45c0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-c9d30293-5eb5-4cc0-993e-6b5336115c28,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-c4c86f1c-73c4-43e9-8415-13d4eba3f94f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1112713480-172.17.0.16-1595488894574:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41455,DS-6fbf8ae5-4d96-4196-98f4-1591bfa9ccee,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-819c4367-c0ab-4248-a6ec-47150b18302b,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-93ceae85-e796-4429-bac6-a8124ae7a6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-f662cfa2-67b2-4306-94ec-1852d4e09719,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-cc02cfac-c936-4156-b3c7-43e3180ddb49,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-5a2c3f55-d7d0-4376-9845-a978ce45c0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-c9d30293-5eb5-4cc0-993e-6b5336115c28,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-c4c86f1c-73c4-43e9-8415-13d4eba3f94f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1120432994-172.17.0.16-1595489214759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33005,DS-7aeeba23-720f-4aa1-8bff-449531b6e040,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-82caa963-593a-4040-9b35-75ad1a05a3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-c9d65e6d-ff0e-4d13-b095-733853abc1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-91a70297-220c-46b7-b9c9-8e45c7a034df,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-e32cc7e1-2370-4eda-bec4-819a09c62e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-5d14f266-664d-4a18-a4af-c4b3a7f740fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-af2d6302-9906-41c3-9546-4fe4090d40e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-c6663c3e-3200-49e0-b15d-218b91b945f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1120432994-172.17.0.16-1595489214759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33005,DS-7aeeba23-720f-4aa1-8bff-449531b6e040,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-82caa963-593a-4040-9b35-75ad1a05a3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-c9d65e6d-ff0e-4d13-b095-733853abc1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-91a70297-220c-46b7-b9c9-8e45c7a034df,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-e32cc7e1-2370-4eda-bec4-819a09c62e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-5d14f266-664d-4a18-a4af-c4b3a7f740fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-af2d6302-9906-41c3-9546-4fe4090d40e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-c6663c3e-3200-49e0-b15d-218b91b945f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-720145478-172.17.0.16-1595489738079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46160,DS-f906c286-3d4f-4ec2-9bc8-64e7eb1dba45,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-5194a54c-1a85-477b-8314-ca51a4215edc,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-6f3604af-63b8-421f-b21d-6a625fc17cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-5d044ad4-fe11-4d3d-9842-4a961d060971,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-47e95871-2309-43ec-849f-e038baf743f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-57442e1f-bcf2-4ebe-90a4-3e7dbfcdade9,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-4ec62c8e-3446-4bca-9df1-ea28f0f4d9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-c72a92b1-fd41-4ff7-9178-8aead4d36ead,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-720145478-172.17.0.16-1595489738079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46160,DS-f906c286-3d4f-4ec2-9bc8-64e7eb1dba45,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-5194a54c-1a85-477b-8314-ca51a4215edc,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-6f3604af-63b8-421f-b21d-6a625fc17cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-5d044ad4-fe11-4d3d-9842-4a961d060971,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-47e95871-2309-43ec-849f-e038baf743f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-57442e1f-bcf2-4ebe-90a4-3e7dbfcdade9,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-4ec62c8e-3446-4bca-9df1-ea28f0f4d9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-c72a92b1-fd41-4ff7-9178-8aead4d36ead,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039832738-172.17.0.16-1595489807640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35148,DS-7a100a86-129e-440c-96c9-ddc15b45fa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-cef4b319-dbc2-4a45-b888-220fd850a863,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-60e64dd7-0bd5-4e40-b66d-d3ebe05884e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-203c9636-8fe1-441b-8f89-a659f11351e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-4b3fb1a1-ff40-4e13-92e6-f3534fc7a2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-32ce43b3-11f8-4e10-ada2-ad66d44b1cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-cd855235-d05f-4eb3-b263-aac34ca073e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-8499c73f-1563-4350-81ba-1012ed60fca2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039832738-172.17.0.16-1595489807640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35148,DS-7a100a86-129e-440c-96c9-ddc15b45fa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-cef4b319-dbc2-4a45-b888-220fd850a863,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-60e64dd7-0bd5-4e40-b66d-d3ebe05884e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-203c9636-8fe1-441b-8f89-a659f11351e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-4b3fb1a1-ff40-4e13-92e6-f3534fc7a2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-32ce43b3-11f8-4e10-ada2-ad66d44b1cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-cd855235-d05f-4eb3-b263-aac34ca073e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-8499c73f-1563-4350-81ba-1012ed60fca2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1109870398-172.17.0.16-1595489842281:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40871,DS-6328bdf9-6fd5-4059-ab0e-3b8513396cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-7571cd2c-40a2-489f-a2a4-a150f5897cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-a141dd8b-2c6b-4bc7-9202-500edaac516b,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-17d33c8f-4f72-467d-9e91-b1c7c3139a52,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-e1f347d6-6fcf-4651-99a5-9394f2c28f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-a47e501a-3ef0-49a4-b62a-beff0296ab7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-461e662f-2977-4b45-b8bf-ac44a43dcdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-403e2b04-c39d-4766-adce-64452d735755,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1109870398-172.17.0.16-1595489842281:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40871,DS-6328bdf9-6fd5-4059-ab0e-3b8513396cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-7571cd2c-40a2-489f-a2a4-a150f5897cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-a141dd8b-2c6b-4bc7-9202-500edaac516b,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-17d33c8f-4f72-467d-9e91-b1c7c3139a52,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-e1f347d6-6fcf-4651-99a5-9394f2c28f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-a47e501a-3ef0-49a4-b62a-beff0296ab7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-461e662f-2977-4b45-b8bf-ac44a43dcdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-403e2b04-c39d-4766-adce-64452d735755,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588501315-172.17.0.16-1595490154612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41548,DS-b7931342-370c-451e-a5f7-7bd6872e48a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-15d8acf6-46e4-427a-9d1f-1e5f9a3769a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-f21e3902-d1ac-41db-b3fa-bfc164327f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-df1e4231-958c-4bec-b280-6456ec6534bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-f5ea24b8-bc72-42f2-b4cd-dd7da8cd14a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-998624fc-e8f9-4b48-b674-8876aa9802b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-a3e6d426-7a42-4b92-bd5f-d45e2e6aaea2,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-9bb49da9-7b84-4e2c-b922-241577f37333,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588501315-172.17.0.16-1595490154612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41548,DS-b7931342-370c-451e-a5f7-7bd6872e48a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-15d8acf6-46e4-427a-9d1f-1e5f9a3769a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-f21e3902-d1ac-41db-b3fa-bfc164327f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-df1e4231-958c-4bec-b280-6456ec6534bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-f5ea24b8-bc72-42f2-b4cd-dd7da8cd14a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-998624fc-e8f9-4b48-b674-8876aa9802b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-a3e6d426-7a42-4b92-bd5f-d45e2e6aaea2,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-9bb49da9-7b84-4e2c-b922-241577f37333,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1046417526-172.17.0.16-1595490187320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44611,DS-58ded0bf-021e-45b7-b72b-7b6c1f3ebbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-6f69e3c9-409c-46ee-80e6-2cee5a6fb33c,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-6de71a20-0034-4e90-8884-43417713280c,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-67e18b75-8bd8-4084-a379-4b47d5e29d34,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-8a46ea85-8b71-4d78-99ef-cf01abed0369,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-170d082a-daa2-42ff-af98-84d9cc2f2542,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-b533ca86-b45a-4f75-8e2e-3aee3a7fb2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-26a371c0-de24-4fd7-a9dd-e239eecf45be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1046417526-172.17.0.16-1595490187320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44611,DS-58ded0bf-021e-45b7-b72b-7b6c1f3ebbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-6f69e3c9-409c-46ee-80e6-2cee5a6fb33c,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-6de71a20-0034-4e90-8884-43417713280c,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-67e18b75-8bd8-4084-a379-4b47d5e29d34,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-8a46ea85-8b71-4d78-99ef-cf01abed0369,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-170d082a-daa2-42ff-af98-84d9cc2f2542,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-b533ca86-b45a-4f75-8e2e-3aee3a7fb2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-26a371c0-de24-4fd7-a9dd-e239eecf45be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-51695181-172.17.0.16-1595490609665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33900,DS-1e5dd988-9d56-4ac9-9009-33ee5c07f2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-10fd5764-f757-4cba-b3e1-2602f8354894,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-f9eb0ec9-e2a5-4a9f-914f-5c5460589805,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-c046b48d-eda8-4420-837b-a643eb9e815d,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-ff846207-af22-451f-98b0-7892aa44e618,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-fd3017bc-a9de-45b3-85e0-ca10fd5df584,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-f5b1c803-c712-4e42-9a90-8a17cd7fdfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-80fa4a82-f6a6-4529-8420-fa4345671d91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-51695181-172.17.0.16-1595490609665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33900,DS-1e5dd988-9d56-4ac9-9009-33ee5c07f2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-10fd5764-f757-4cba-b3e1-2602f8354894,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-f9eb0ec9-e2a5-4a9f-914f-5c5460589805,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-c046b48d-eda8-4420-837b-a643eb9e815d,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-ff846207-af22-451f-98b0-7892aa44e618,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-fd3017bc-a9de-45b3-85e0-ca10fd5df584,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-f5b1c803-c712-4e42-9a90-8a17cd7fdfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-80fa4a82-f6a6-4529-8420-fa4345671d91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1654846429-172.17.0.16-1595490649890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38803,DS-73b9068c-52c3-4f7a-b222-5e7a05b788b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-454737da-4bff-4046-ae21-50ed28260401,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-3a3db7c2-90a9-4b4d-be50-9ffa906fcacf,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-58362864-b9ff-45d4-bb8f-796cc0a2f13f,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-213c46aa-fedb-4a80-b709-da26f499144f,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-5d28745f-557d-4e73-bd6c-d7639fcfeb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-7a22fd04-faff-453c-a44a-f32f9fce2218,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-84d592ae-dba2-46bb-839f-72c70df2d018,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1654846429-172.17.0.16-1595490649890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38803,DS-73b9068c-52c3-4f7a-b222-5e7a05b788b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-454737da-4bff-4046-ae21-50ed28260401,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-3a3db7c2-90a9-4b4d-be50-9ffa906fcacf,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-58362864-b9ff-45d4-bb8f-796cc0a2f13f,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-213c46aa-fedb-4a80-b709-da26f499144f,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-5d28745f-557d-4e73-bd6c-d7639fcfeb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-7a22fd04-faff-453c-a44a-f32f9fce2218,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-84d592ae-dba2-46bb-839f-72c70df2d018,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-491413480-172.17.0.16-1595490679662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44083,DS-dbf69911-a0f9-4bed-80dd-b79e7a476064,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-b9916fd5-1223-4e45-90e7-69961c7542f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-b96797d5-d51b-4940-be0d-94e2401ba8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-056de11b-cd30-4314-ae2e-c6aaa83afb98,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-552fe4db-8815-447c-88cb-5bef0cf7fde1,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-25cc915a-45fc-4bde-b331-ce40da7b3e23,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-9053d5fe-b2a0-42f8-b6a0-b90fb5eefebb,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-d9384e5b-48b8-41dc-a9fb-bad83e46d7ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-491413480-172.17.0.16-1595490679662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44083,DS-dbf69911-a0f9-4bed-80dd-b79e7a476064,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-b9916fd5-1223-4e45-90e7-69961c7542f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-b96797d5-d51b-4940-be0d-94e2401ba8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-056de11b-cd30-4314-ae2e-c6aaa83afb98,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-552fe4db-8815-447c-88cb-5bef0cf7fde1,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-25cc915a-45fc-4bde-b331-ce40da7b3e23,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-9053d5fe-b2a0-42f8-b6a0-b90fb5eefebb,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-d9384e5b-48b8-41dc-a9fb-bad83e46d7ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-374135423-172.17.0.16-1595491430625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44442,DS-3e0d3a15-e1a4-40f4-baae-ca347a043054,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-ca5f18c4-30e1-47f1-b128-96776bc0fbca,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-a2f4e569-1a4e-4ce1-8871-84ba45d8d6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-dc438ee5-b09e-46c2-bad1-fab3ee5ed9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-e0681d6c-533f-4a73-a36c-cbb3dbd0fd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-067462c6-32fd-406a-8b90-8630620836cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-84497cda-7f26-4f45-bac8-43fc8d883d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-03d67bd8-fe3a-4d79-bd19-00291f1c21b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-374135423-172.17.0.16-1595491430625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44442,DS-3e0d3a15-e1a4-40f4-baae-ca347a043054,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-ca5f18c4-30e1-47f1-b128-96776bc0fbca,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-a2f4e569-1a4e-4ce1-8871-84ba45d8d6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-dc438ee5-b09e-46c2-bad1-fab3ee5ed9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-e0681d6c-533f-4a73-a36c-cbb3dbd0fd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-067462c6-32fd-406a-8b90-8630620836cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-84497cda-7f26-4f45-bac8-43fc8d883d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-03d67bd8-fe3a-4d79-bd19-00291f1c21b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1891409209-172.17.0.16-1595491576189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35644,DS-fc915651-e23d-461c-8d8d-d26330c21e94,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-c9a2f0a4-afed-482f-9b4c-a8270577739e,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-9b34cd3f-9517-415f-a1c9-1c52618f76d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-339e3e9b-e562-4e76-b81a-4952650a5caa,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-831a8197-c04f-4b46-9ab9-9ea6e36aee12,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-15503242-3b9b-4591-90c0-cfc92f357d85,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-0668e17b-c296-4db4-b6b5-e0e54db87f19,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-e7c5904e-36ea-436a-b64b-75853cce2884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1891409209-172.17.0.16-1595491576189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35644,DS-fc915651-e23d-461c-8d8d-d26330c21e94,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-c9a2f0a4-afed-482f-9b4c-a8270577739e,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-9b34cd3f-9517-415f-a1c9-1c52618f76d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-339e3e9b-e562-4e76-b81a-4952650a5caa,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-831a8197-c04f-4b46-9ab9-9ea6e36aee12,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-15503242-3b9b-4591-90c0-cfc92f357d85,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-0668e17b-c296-4db4-b6b5-e0e54db87f19,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-e7c5904e-36ea-436a-b64b-75853cce2884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232274347-172.17.0.16-1595491615604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39966,DS-3ae38450-acda-4800-ae4b-226e79951495,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-044fe949-0d16-4d55-b9b1-e45d6da26ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-fb3deb22-720c-4d3d-9694-3f2e856535ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-c67e9bf6-57fa-47b8-8e0b-55d53349f9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-e6c43ad3-1faf-4139-bc20-b1b4b1dc385d,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-8ea2cf57-4d15-4b8f-bdec-a64830ff5ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-2df7f0e0-10a4-4aca-94a3-b5e6935cfdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-5814e093-7b28-4e00-8089-e9e0abe08239,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232274347-172.17.0.16-1595491615604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39966,DS-3ae38450-acda-4800-ae4b-226e79951495,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-044fe949-0d16-4d55-b9b1-e45d6da26ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-fb3deb22-720c-4d3d-9694-3f2e856535ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-c67e9bf6-57fa-47b8-8e0b-55d53349f9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-e6c43ad3-1faf-4139-bc20-b1b4b1dc385d,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-8ea2cf57-4d15-4b8f-bdec-a64830ff5ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-2df7f0e0-10a4-4aca-94a3-b5e6935cfdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-5814e093-7b28-4e00-8089-e9e0abe08239,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1414609879-172.17.0.16-1595491687812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38647,DS-6a393c06-eb55-4255-8576-604f7d16606d,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-a72c8cf8-440a-420e-8de1-89a31884f21d,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-51edcb05-b20e-4852-8b6a-d4715718c8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-4fdbd0e0-c307-473f-a33b-32a9017343a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-14befa29-6e4c-42ef-9cad-d412027204e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-934cbecd-df3b-420e-853f-dd525c9a03da,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-948d3a9e-ac6a-471b-a41d-f76fa61bf88f,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-4229a1bc-3f7c-4fd8-bf17-7eb0cfa43ba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1414609879-172.17.0.16-1595491687812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38647,DS-6a393c06-eb55-4255-8576-604f7d16606d,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-a72c8cf8-440a-420e-8de1-89a31884f21d,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-51edcb05-b20e-4852-8b6a-d4715718c8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-4fdbd0e0-c307-473f-a33b-32a9017343a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-14befa29-6e4c-42ef-9cad-d412027204e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-934cbecd-df3b-420e-853f-dd525c9a03da,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-948d3a9e-ac6a-471b-a41d-f76fa61bf88f,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-4229a1bc-3f7c-4fd8-bf17-7eb0cfa43ba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5344
