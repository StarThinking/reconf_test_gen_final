reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721000765-172.17.0.17-1595621340049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46604,DS-dd3fe83f-fcf0-4ccc-b924-bd28b7e0591c,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-764b562b-0ddf-4ca3-a76f-99f37e5b088f,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-a467dbe5-d388-4e2f-8926-b354f703d7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-0f437269-78d5-4479-8a33-e11088520450,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-c6c2e3b8-2f98-41a1-b2b8-633e157b83de,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-93f4d385-3bb7-40b7-98d5-4fda1fecab62,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-1e7736d7-4c7d-4856-a470-3f7ccb084691,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-80a76afa-392e-422b-baa7-0af298622f86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721000765-172.17.0.17-1595621340049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46604,DS-dd3fe83f-fcf0-4ccc-b924-bd28b7e0591c,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-764b562b-0ddf-4ca3-a76f-99f37e5b088f,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-a467dbe5-d388-4e2f-8926-b354f703d7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-0f437269-78d5-4479-8a33-e11088520450,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-c6c2e3b8-2f98-41a1-b2b8-633e157b83de,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-93f4d385-3bb7-40b7-98d5-4fda1fecab62,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-1e7736d7-4c7d-4856-a470-3f7ccb084691,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-80a76afa-392e-422b-baa7-0af298622f86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-137316866-172.17.0.17-1595621781147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39013,DS-fc231b47-c2a3-4c20-84e6-a67ea55ee859,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-60c07130-8b18-4c0c-ad90-c69a9e3d901e,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-f59e77f7-0261-44d3-9a13-fed0bd6f3590,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-6a4ed99f-dcc6-4d41-b3db-5c7491dea4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-23bd78e2-b0c3-447e-8e77-774e17349ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-e5fae35f-d705-4064-a3b7-cb2163875718,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-394c9a3a-3b93-405a-8ff8-7f4e32d2a0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-68f9fe87-f00b-4fd4-9221-c0669ab63963,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-137316866-172.17.0.17-1595621781147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39013,DS-fc231b47-c2a3-4c20-84e6-a67ea55ee859,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-60c07130-8b18-4c0c-ad90-c69a9e3d901e,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-f59e77f7-0261-44d3-9a13-fed0bd6f3590,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-6a4ed99f-dcc6-4d41-b3db-5c7491dea4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-23bd78e2-b0c3-447e-8e77-774e17349ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-e5fae35f-d705-4064-a3b7-cb2163875718,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-394c9a3a-3b93-405a-8ff8-7f4e32d2a0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-68f9fe87-f00b-4fd4-9221-c0669ab63963,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1648568712-172.17.0.17-1595622110645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35178,DS-882b8a86-9b06-4815-9ab8-15be1fb2f25b,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-02d17d28-970a-4b71-b220-58f1f393de2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-895e02ad-33b6-4742-9823-1d094fa6d160,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-5e3b4b85-a714-4cea-a4ce-82eeda58bde5,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-18d23821-ddf3-4a02-9b18-3984392dac41,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-3b49ed0e-3931-491d-aef8-cd622c28ff95,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-86aab187-2f84-4f50-bfe6-395dcc206b29,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-8a2d5aa5-c305-4319-9a0d-9c083200e8f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1648568712-172.17.0.17-1595622110645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35178,DS-882b8a86-9b06-4815-9ab8-15be1fb2f25b,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-02d17d28-970a-4b71-b220-58f1f393de2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-895e02ad-33b6-4742-9823-1d094fa6d160,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-5e3b4b85-a714-4cea-a4ce-82eeda58bde5,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-18d23821-ddf3-4a02-9b18-3984392dac41,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-3b49ed0e-3931-491d-aef8-cd622c28ff95,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-86aab187-2f84-4f50-bfe6-395dcc206b29,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-8a2d5aa5-c305-4319-9a0d-9c083200e8f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797638560-172.17.0.17-1595622191010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35143,DS-97494c00-a5ae-4bd7-9242-04df1020df11,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-e4d248f7-8656-4a4b-a478-3ab1b0fa2da4,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-9a8e8425-e3fa-4f59-a83a-167ced13c325,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-a46b8726-c288-46e6-833e-5a27ddaebe1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-03a8b0b9-af39-4461-bb6c-34e03b237ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-a4236cce-64da-47c7-b1dd-34def65e1c43,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-f07bffe2-6ba8-45e8-8d92-24f116e10d62,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-11280be7-449b-4f61-914a-7d7b7fc3b02a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797638560-172.17.0.17-1595622191010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35143,DS-97494c00-a5ae-4bd7-9242-04df1020df11,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-e4d248f7-8656-4a4b-a478-3ab1b0fa2da4,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-9a8e8425-e3fa-4f59-a83a-167ced13c325,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-a46b8726-c288-46e6-833e-5a27ddaebe1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-03a8b0b9-af39-4461-bb6c-34e03b237ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-a4236cce-64da-47c7-b1dd-34def65e1c43,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-f07bffe2-6ba8-45e8-8d92-24f116e10d62,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-11280be7-449b-4f61-914a-7d7b7fc3b02a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689347834-172.17.0.17-1595622514845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37877,DS-4327cd92-c289-4295-9702-4a0d0d6b1564,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-544967eb-81cd-480a-8297-b85d354b23fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-8230c8d4-1358-4318-a19f-bdb10c8f85f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-25ebcea6-e60d-4055-8802-794adea0d541,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-c320fb19-173c-4427-905c-075d02dfc790,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-7a940fbd-d5a9-46a4-8d48-32771234892f,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-ab00c99b-65ed-4d64-8901-2ba97fb8b316,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-a8f3c3d4-7da9-4651-a153-13e840c8ca2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689347834-172.17.0.17-1595622514845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37877,DS-4327cd92-c289-4295-9702-4a0d0d6b1564,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-544967eb-81cd-480a-8297-b85d354b23fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-8230c8d4-1358-4318-a19f-bdb10c8f85f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-25ebcea6-e60d-4055-8802-794adea0d541,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-c320fb19-173c-4427-905c-075d02dfc790,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-7a940fbd-d5a9-46a4-8d48-32771234892f,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-ab00c99b-65ed-4d64-8901-2ba97fb8b316,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-a8f3c3d4-7da9-4651-a153-13e840c8ca2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1750114849-172.17.0.17-1595622558958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38549,DS-3c8e949f-f6d6-470f-8a9e-602dddfffed6,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-5590a142-e26a-4e33-9e21-2fbbb518e77e,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-56555904-385e-4e1a-8ef9-2ffe6f2a9af9,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-057946fc-4fa6-4372-97c6-ebe12fe518f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-c2905bae-ce86-43b1-95c9-98168ea8f7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-833af990-1600-4be1-bcdb-a82171d59913,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-5356157b-0378-4992-be91-b19461d49bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-eb3b9919-98af-49f2-8cdd-1c086e34132b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1750114849-172.17.0.17-1595622558958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38549,DS-3c8e949f-f6d6-470f-8a9e-602dddfffed6,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-5590a142-e26a-4e33-9e21-2fbbb518e77e,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-56555904-385e-4e1a-8ef9-2ffe6f2a9af9,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-057946fc-4fa6-4372-97c6-ebe12fe518f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-c2905bae-ce86-43b1-95c9-98168ea8f7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-833af990-1600-4be1-bcdb-a82171d59913,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-5356157b-0378-4992-be91-b19461d49bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-eb3b9919-98af-49f2-8cdd-1c086e34132b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-993302828-172.17.0.17-1595622787296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45629,DS-2653f811-f3d0-4c8a-a608-7e258a216bba,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-d5eecb7c-af4e-435e-95f1-492c8addf1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-8681deb0-988c-48c8-8f68-695e2d10843d,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-bf2e0c18-e86b-4c7e-857d-90f52b30aa55,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-19af7b68-23e1-41a5-8db0-614cc183e5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-8f177288-9f33-4c73-9d9c-c9d1adf41a27,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-602f9ded-b257-4c7b-a46c-d3df928f6137,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-41eca184-ecd2-4448-b7bc-91e997ea3bd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-993302828-172.17.0.17-1595622787296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45629,DS-2653f811-f3d0-4c8a-a608-7e258a216bba,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-d5eecb7c-af4e-435e-95f1-492c8addf1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-8681deb0-988c-48c8-8f68-695e2d10843d,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-bf2e0c18-e86b-4c7e-857d-90f52b30aa55,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-19af7b68-23e1-41a5-8db0-614cc183e5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-8f177288-9f33-4c73-9d9c-c9d1adf41a27,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-602f9ded-b257-4c7b-a46c-d3df928f6137,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-41eca184-ecd2-4448-b7bc-91e997ea3bd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754615447-172.17.0.17-1595622887121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45682,DS-2f1097cb-2798-48c8-b9ac-26c9751e536a,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-d9e003e1-ab3d-43fa-b0b3-a0c3433c91e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-20d2e1a0-f6c8-4cfc-90f5-ff79d6c5405a,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-d25536ac-911e-4685-9546-7a673874f1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-fe293211-a1b6-4b22-b21b-916232b8f186,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-27a2bc1d-e3e4-4373-aec2-08cdb5ceaa53,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-4d034147-72a7-407f-988e-97ccfc370017,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-6f865d04-8791-4cf0-923c-2336c986f6a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754615447-172.17.0.17-1595622887121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45682,DS-2f1097cb-2798-48c8-b9ac-26c9751e536a,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-d9e003e1-ab3d-43fa-b0b3-a0c3433c91e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-20d2e1a0-f6c8-4cfc-90f5-ff79d6c5405a,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-d25536ac-911e-4685-9546-7a673874f1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-fe293211-a1b6-4b22-b21b-916232b8f186,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-27a2bc1d-e3e4-4373-aec2-08cdb5ceaa53,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-4d034147-72a7-407f-988e-97ccfc370017,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-6f865d04-8791-4cf0-923c-2336c986f6a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467626154-172.17.0.17-1595623152573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45919,DS-27ab92f5-d669-4b4c-af49-854cc02cf25c,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-62809e69-62d2-408a-a421-536a2b9bdffd,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-c3734610-1005-4616-94c3-dca9897b7f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-9641263c-32fd-417e-ba19-c9d5e607c8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-17a6ceaa-b12a-4414-a216-4fb3a985f04a,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-5eb9d4ce-462b-4ea8-a6df-4660b606080b,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-cfa53f0c-1e17-43d9-aa3a-b1b7a00f56ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-9e31a2ea-3663-4ed7-99a9-3e34e5b10110,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467626154-172.17.0.17-1595623152573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45919,DS-27ab92f5-d669-4b4c-af49-854cc02cf25c,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-62809e69-62d2-408a-a421-536a2b9bdffd,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-c3734610-1005-4616-94c3-dca9897b7f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-9641263c-32fd-417e-ba19-c9d5e607c8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-17a6ceaa-b12a-4414-a216-4fb3a985f04a,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-5eb9d4ce-462b-4ea8-a6df-4660b606080b,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-cfa53f0c-1e17-43d9-aa3a-b1b7a00f56ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-9e31a2ea-3663-4ed7-99a9-3e34e5b10110,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183153288-172.17.0.17-1595623850043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38560,DS-da47acea-e4a7-4160-bcc1-343b286e7b90,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-ab26352e-bc6a-4f79-8002-c4e0194c4c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-54680634-cc7f-44f2-adb1-0add5a83fef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-5922ea6b-217d-464f-9a35-14fab43db1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-f116e208-0ad7-446c-9036-d6d713d3e2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-39a5f39b-6d3f-400a-a656-a3b4b2aa5d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-3f826f4a-f9fa-4c99-b0a2-1e3b0458f4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-ac479914-fcb6-4a2d-98ba-5737ef848de5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183153288-172.17.0.17-1595623850043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38560,DS-da47acea-e4a7-4160-bcc1-343b286e7b90,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-ab26352e-bc6a-4f79-8002-c4e0194c4c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-54680634-cc7f-44f2-adb1-0add5a83fef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-5922ea6b-217d-464f-9a35-14fab43db1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-f116e208-0ad7-446c-9036-d6d713d3e2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-39a5f39b-6d3f-400a-a656-a3b4b2aa5d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-3f826f4a-f9fa-4c99-b0a2-1e3b0458f4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-ac479914-fcb6-4a2d-98ba-5737ef848de5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2005255146-172.17.0.17-1595624010729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46391,DS-672c94de-4b34-427d-b7c0-eaaad0146887,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-248cfeed-2108-46e2-8e31-bf47a673964b,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-d919bb47-22af-4367-b831-27abbedc25e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-dc136151-5843-4829-ad7b-42c6a13c7fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-56405479-f65e-4c25-a47b-4022cf04d2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-4a1ff72a-1782-431c-8d46-3678f2d8f1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-e56b3b72-2102-4ef2-9e73-4f19331b343a,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-7eaa5f78-c4b3-4c21-8c7f-d01ac3742bf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2005255146-172.17.0.17-1595624010729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46391,DS-672c94de-4b34-427d-b7c0-eaaad0146887,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-248cfeed-2108-46e2-8e31-bf47a673964b,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-d919bb47-22af-4367-b831-27abbedc25e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-dc136151-5843-4829-ad7b-42c6a13c7fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-56405479-f65e-4c25-a47b-4022cf04d2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-4a1ff72a-1782-431c-8d46-3678f2d8f1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-e56b3b72-2102-4ef2-9e73-4f19331b343a,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-7eaa5f78-c4b3-4c21-8c7f-d01ac3742bf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739474199-172.17.0.17-1595624141980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40408,DS-a77f8a0a-079c-4ce2-a0da-b59ec2f79d24,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-33c8be33-a3da-4f56-8d3c-b16a05678a72,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-713e42e8-aae6-4c42-a4b2-c5326722e9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-037dc3cb-74d9-400e-a8d4-095d5cf5fe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-dc6e0710-df4b-4d9a-823d-03281ee13db4,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-45c295ea-ee3a-4e03-8ad0-c7dddf820a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-46ea7020-14d7-4800-b036-58cd533655b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-008b6118-4e69-4c62-be17-8ba977d81b34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739474199-172.17.0.17-1595624141980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40408,DS-a77f8a0a-079c-4ce2-a0da-b59ec2f79d24,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-33c8be33-a3da-4f56-8d3c-b16a05678a72,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-713e42e8-aae6-4c42-a4b2-c5326722e9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-037dc3cb-74d9-400e-a8d4-095d5cf5fe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-dc6e0710-df4b-4d9a-823d-03281ee13db4,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-45c295ea-ee3a-4e03-8ad0-c7dddf820a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-46ea7020-14d7-4800-b036-58cd533655b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-008b6118-4e69-4c62-be17-8ba977d81b34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282166099-172.17.0.17-1595624188645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46382,DS-e07ac0c4-bb28-47a5-b7b0-a021854eae59,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-350e8b8e-cbf3-4bfe-9eba-2a4280b750d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-b08e80c1-814b-4ba9-ad9a-b52b497814fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-d2705513-a7e7-40be-ad5b-4931bc71b56d,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-01a704c1-584c-44e8-b447-5c24359d11d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-30765c47-0672-40a7-a747-c4bde47bbb34,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-f54ea010-f43b-42d7-acd0-85a7c234978f,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-a6b628e7-05b3-4f2a-8312-792dda07a66c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282166099-172.17.0.17-1595624188645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46382,DS-e07ac0c4-bb28-47a5-b7b0-a021854eae59,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-350e8b8e-cbf3-4bfe-9eba-2a4280b750d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-b08e80c1-814b-4ba9-ad9a-b52b497814fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-d2705513-a7e7-40be-ad5b-4931bc71b56d,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-01a704c1-584c-44e8-b447-5c24359d11d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-30765c47-0672-40a7-a747-c4bde47bbb34,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-f54ea010-f43b-42d7-acd0-85a7c234978f,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-a6b628e7-05b3-4f2a-8312-792dda07a66c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474041786-172.17.0.17-1595624336311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40263,DS-05f2466f-24f6-45d5-8b6b-43f0231886c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-06fa7390-a7cc-4c56-a4ff-ae20dac98ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-f76f509f-479b-4364-8791-798486ee0beb,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-3ccd7f1a-1a0d-4f46-9954-12d4c50b7e82,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-9789e6a7-3c74-41bc-b0cf-af365b9435c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-421a68cd-3ed1-4b73-883e-85bbbfa1f3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-cf528b29-83de-4ca9-9978-a2bec7bbae81,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-bd011c5e-609e-4191-9048-bb23638948c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474041786-172.17.0.17-1595624336311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40263,DS-05f2466f-24f6-45d5-8b6b-43f0231886c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-06fa7390-a7cc-4c56-a4ff-ae20dac98ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-f76f509f-479b-4364-8791-798486ee0beb,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-3ccd7f1a-1a0d-4f46-9954-12d4c50b7e82,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-9789e6a7-3c74-41bc-b0cf-af365b9435c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-421a68cd-3ed1-4b73-883e-85bbbfa1f3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-cf528b29-83de-4ca9-9978-a2bec7bbae81,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-bd011c5e-609e-4191-9048-bb23638948c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48376731-172.17.0.17-1595624846876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34788,DS-085b1f62-11dd-49ca-8f23-f88e6560eba6,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-8786b6c4-c4f3-421c-bb71-9e771b47a6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-d455bdcc-cd77-4d3d-9d7c-bc872c581937,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-c972f31c-7b75-413d-b742-2a878b964885,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-805bf246-8969-468b-9dfd-0437f80be599,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-c6b3b3df-2493-4240-a821-1bae9b8b9f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-356c694b-9c92-4bf7-9dde-424c89ce75cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-0958eb93-04b5-4ae7-9c8c-9f18b5e39112,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48376731-172.17.0.17-1595624846876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34788,DS-085b1f62-11dd-49ca-8f23-f88e6560eba6,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-8786b6c4-c4f3-421c-bb71-9e771b47a6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-d455bdcc-cd77-4d3d-9d7c-bc872c581937,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-c972f31c-7b75-413d-b742-2a878b964885,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-805bf246-8969-468b-9dfd-0437f80be599,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-c6b3b3df-2493-4240-a821-1bae9b8b9f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-356c694b-9c92-4bf7-9dde-424c89ce75cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-0958eb93-04b5-4ae7-9c8c-9f18b5e39112,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440167281-172.17.0.17-1595625059806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33912,DS-77abda86-f9b4-4285-9520-9bb883818051,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-a5a6966b-8c8f-4155-b56a-afc300b966a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-3e601426-ff42-429c-91c5-3e1dd7036b19,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-02044705-f405-479d-beeb-0fa027d74281,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-1ca5bf37-a133-4898-8310-502dacebd0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-f26be472-fc33-434f-b5ff-ccec19656a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-19fa839e-97d4-45ec-8648-d656b6cf4f43,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-75956ac3-a9c8-4b79-b322-ff120eb68cc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440167281-172.17.0.17-1595625059806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33912,DS-77abda86-f9b4-4285-9520-9bb883818051,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-a5a6966b-8c8f-4155-b56a-afc300b966a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-3e601426-ff42-429c-91c5-3e1dd7036b19,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-02044705-f405-479d-beeb-0fa027d74281,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-1ca5bf37-a133-4898-8310-502dacebd0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-f26be472-fc33-434f-b5ff-ccec19656a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-19fa839e-97d4-45ec-8648-d656b6cf4f43,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-75956ac3-a9c8-4b79-b322-ff120eb68cc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1985133821-172.17.0.17-1595625412074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36526,DS-96673974-ccc2-423a-a807-c7a85c4615e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-18b5c9c0-d33b-4ca1-b167-670d32f207b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-51205b4a-c98f-4316-aee5-71223183d53e,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-100dfdb6-155c-406f-8778-91ae91d9b1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-5d1b7921-5e7f-4788-b1a0-17379e6bb39e,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-af128ee0-2c7d-4d3e-81fe-27758795374b,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-e5a833db-99be-4d72-8220-60d95a09a63b,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-fa5c494b-6ed3-43b5-be4a-d5eb9cd2619a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1985133821-172.17.0.17-1595625412074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36526,DS-96673974-ccc2-423a-a807-c7a85c4615e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-18b5c9c0-d33b-4ca1-b167-670d32f207b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-51205b4a-c98f-4316-aee5-71223183d53e,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-100dfdb6-155c-406f-8778-91ae91d9b1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-5d1b7921-5e7f-4788-b1a0-17379e6bb39e,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-af128ee0-2c7d-4d3e-81fe-27758795374b,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-e5a833db-99be-4d72-8220-60d95a09a63b,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-fa5c494b-6ed3-43b5-be4a-d5eb9cd2619a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430000800-172.17.0.17-1595625458005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36179,DS-6505fbcc-4a77-4ad8-b8d4-bb8377036812,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-17ded96a-3adb-4271-a4de-05a0ab1606a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-3e156dba-673b-4839-8dc7-6218c2e02890,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-9de49e03-c76c-4ef5-a77c-5ab4136d8d17,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-57f5be19-b653-4c43-b751-bab4c00b6480,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-ff6f4ac2-06f3-466a-a07d-5f94df507303,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-2b56c69d-a151-41c8-9e51-6c06bee634fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-e740c89b-26a8-4577-9c8a-66903b1f0c2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430000800-172.17.0.17-1595625458005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36179,DS-6505fbcc-4a77-4ad8-b8d4-bb8377036812,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-17ded96a-3adb-4271-a4de-05a0ab1606a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-3e156dba-673b-4839-8dc7-6218c2e02890,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-9de49e03-c76c-4ef5-a77c-5ab4136d8d17,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-57f5be19-b653-4c43-b751-bab4c00b6480,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-ff6f4ac2-06f3-466a-a07d-5f94df507303,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-2b56c69d-a151-41c8-9e51-6c06bee634fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-e740c89b-26a8-4577-9c8a-66903b1f0c2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1547466651-172.17.0.17-1595625717856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42131,DS-936f3bbd-3fe4-4cbf-aa1d-94c321e0ce9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-be98bae9-58bf-4dd6-a251-855805fd4d97,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-839f3676-8902-4d5f-9993-ccd1f3050494,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-86297951-1c6d-4b1f-b8b7-a1c95f7f470c,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-a0f7e53d-d969-4999-8cf0-3760b201f058,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-b05a022f-9709-4f9a-addd-019a69a847ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-4df52634-3b60-4b46-a4c2-67d1301dd0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-7ea408a5-e338-4bce-8595-6cbf80d29316,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1547466651-172.17.0.17-1595625717856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42131,DS-936f3bbd-3fe4-4cbf-aa1d-94c321e0ce9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-be98bae9-58bf-4dd6-a251-855805fd4d97,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-839f3676-8902-4d5f-9993-ccd1f3050494,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-86297951-1c6d-4b1f-b8b7-a1c95f7f470c,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-a0f7e53d-d969-4999-8cf0-3760b201f058,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-b05a022f-9709-4f9a-addd-019a69a847ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-4df52634-3b60-4b46-a4c2-67d1301dd0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-7ea408a5-e338-4bce-8595-6cbf80d29316,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-965405188-172.17.0.17-1595626053397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36249,DS-42e3a603-7365-4808-b7ea-c1182cc1558f,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-7fd9c4f3-e108-46ce-b1a5-619e166dfacf,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-4070b706-44f8-4de0-90b4-9a79dcb05f91,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-1ff9a419-5b30-470f-8929-6c08c3d2a291,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-5e7330dd-d41d-40ed-a087-53f2ac172671,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-d1292155-7304-411e-8e80-afec2ac7e97e,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-63fdf4fc-806d-4042-adca-09c0af508271,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-f9b90679-f75f-44e2-98fe-747e5055be0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-965405188-172.17.0.17-1595626053397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36249,DS-42e3a603-7365-4808-b7ea-c1182cc1558f,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-7fd9c4f3-e108-46ce-b1a5-619e166dfacf,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-4070b706-44f8-4de0-90b4-9a79dcb05f91,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-1ff9a419-5b30-470f-8929-6c08c3d2a291,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-5e7330dd-d41d-40ed-a087-53f2ac172671,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-d1292155-7304-411e-8e80-afec2ac7e97e,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-63fdf4fc-806d-4042-adca-09c0af508271,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-f9b90679-f75f-44e2-98fe-747e5055be0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236261996-172.17.0.17-1595626096711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42583,DS-35e6ecb8-71b0-455a-8e0d-b1afac0c723b,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-6d331232-856f-4a16-93c8-1616faecd2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-4fbc185c-5473-48c0-88cf-1f696ab7e477,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-a3fb9003-0aa4-4bb5-8aef-1e68abde14e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-c26081d1-8a07-459f-8c7e-e002eafcfa6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-529fa672-0963-4955-a15f-70b20a5bba54,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-dc60b78b-137b-42b7-93fd-d6cf963a83ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-19b31e5c-9c49-460a-89a7-71ee40a5e2aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236261996-172.17.0.17-1595626096711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42583,DS-35e6ecb8-71b0-455a-8e0d-b1afac0c723b,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-6d331232-856f-4a16-93c8-1616faecd2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-4fbc185c-5473-48c0-88cf-1f696ab7e477,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-a3fb9003-0aa4-4bb5-8aef-1e68abde14e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-c26081d1-8a07-459f-8c7e-e002eafcfa6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-529fa672-0963-4955-a15f-70b20a5bba54,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-dc60b78b-137b-42b7-93fd-d6cf963a83ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-19b31e5c-9c49-460a-89a7-71ee40a5e2aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1646176202-172.17.0.17-1595626439698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42202,DS-7116d049-d528-4126-ac33-596f88e8f716,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-046ad2f8-f3fa-431e-b972-568a9b7d3187,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-2698549d-cebd-4a1c-aced-29e8710c2ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-2793b658-052f-4005-8dd8-35ea2bb9548f,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-48bd5081-4559-49c2-a338-885d04c4a1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-29ce23de-87bc-473a-a3bc-ad04af37b17c,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-e486ac4b-3674-48db-bbaf-3e957b5c516e,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-d1317b8e-e77a-4cbf-9261-403443ec1403,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1646176202-172.17.0.17-1595626439698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42202,DS-7116d049-d528-4126-ac33-596f88e8f716,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-046ad2f8-f3fa-431e-b972-568a9b7d3187,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-2698549d-cebd-4a1c-aced-29e8710c2ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-2793b658-052f-4005-8dd8-35ea2bb9548f,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-48bd5081-4559-49c2-a338-885d04c4a1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-29ce23de-87bc-473a-a3bc-ad04af37b17c,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-e486ac4b-3674-48db-bbaf-3e957b5c516e,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-d1317b8e-e77a-4cbf-9261-403443ec1403,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-522175455-172.17.0.17-1595627168217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36351,DS-80e21698-b392-4967-8354-3a8a26faa9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-ee30d5e3-ba2c-4ff9-8664-c9f1c4ac8b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-a951a52f-1ad9-42f9-b785-e92f27f0514c,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-6a67b9da-beee-453d-8ffe-f05ad5448546,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-523c4e8a-abda-464d-8861-7a9404c265ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-d85a9374-a749-4dea-a01b-f558c5000051,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-44e151a0-baa1-479d-8766-904ee87695ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-18a20d1d-4d1c-4f7c-9fc8-c02bba4630c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-522175455-172.17.0.17-1595627168217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36351,DS-80e21698-b392-4967-8354-3a8a26faa9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-ee30d5e3-ba2c-4ff9-8664-c9f1c4ac8b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-a951a52f-1ad9-42f9-b785-e92f27f0514c,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-6a67b9da-beee-453d-8ffe-f05ad5448546,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-523c4e8a-abda-464d-8861-7a9404c265ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-d85a9374-a749-4dea-a01b-f558c5000051,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-44e151a0-baa1-479d-8766-904ee87695ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-18a20d1d-4d1c-4f7c-9fc8-c02bba4630c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6541
