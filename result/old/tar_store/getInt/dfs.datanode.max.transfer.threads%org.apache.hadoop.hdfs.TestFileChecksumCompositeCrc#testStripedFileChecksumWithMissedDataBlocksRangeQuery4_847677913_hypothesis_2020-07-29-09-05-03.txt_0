reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113314085-172.17.0.2-1596013890605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33295,DS-290d2a98-5480-4f32-a021-154e1e8bd7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-0963ebc0-a16e-49d0-83b2-7afddda7d3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-3cbd4f71-bc03-4b08-9df6-909445753d69,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-8f62d24b-7351-4af4-b314-9ee3a3902d14,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-9ab01364-980a-43d8-8f9b-8d88976c24c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-c66cb2a5-9d60-435f-a785-b3fa6b207f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-7b9ce497-bc17-47ef-ae87-911c83594d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-62fc7a41-473c-4ed4-8c18-8627945ceb2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113314085-172.17.0.2-1596013890605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33295,DS-290d2a98-5480-4f32-a021-154e1e8bd7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-0963ebc0-a16e-49d0-83b2-7afddda7d3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-3cbd4f71-bc03-4b08-9df6-909445753d69,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-8f62d24b-7351-4af4-b314-9ee3a3902d14,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-9ab01364-980a-43d8-8f9b-8d88976c24c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-c66cb2a5-9d60-435f-a785-b3fa6b207f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-7b9ce497-bc17-47ef-ae87-911c83594d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-62fc7a41-473c-4ed4-8c18-8627945ceb2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1657051156-172.17.0.2-1596014081247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35909,DS-9ddb267a-e59f-4d37-a7fc-77a4f114132a,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-f5353d06-6b03-476b-86b8-95d5f7b19a57,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-10887eba-f2ef-4153-97a0-08154ab299aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-484bb723-59d4-4389-bb8a-88f187a05917,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-47a78412-2218-49cd-a6c1-8631865f5830,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-f8a2d48a-ef04-4f84-a15e-367273fc2537,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-fc436997-efe3-4bc4-a258-b0b1343b7923,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-5eefa872-61db-40a7-8166-337bf1a85deb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1657051156-172.17.0.2-1596014081247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35909,DS-9ddb267a-e59f-4d37-a7fc-77a4f114132a,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-f5353d06-6b03-476b-86b8-95d5f7b19a57,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-10887eba-f2ef-4153-97a0-08154ab299aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-484bb723-59d4-4389-bb8a-88f187a05917,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-47a78412-2218-49cd-a6c1-8631865f5830,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-f8a2d48a-ef04-4f84-a15e-367273fc2537,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-fc436997-efe3-4bc4-a258-b0b1343b7923,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-5eefa872-61db-40a7-8166-337bf1a85deb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1408054899-172.17.0.2-1596014217545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37771,DS-7d07e026-7c6b-4dbf-967e-3fd078e2d9db,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-33e1b091-7f61-43d5-9330-26c327a6fa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-600fecf8-2f3b-4a93-9ac8-7a6f07eb1850,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-586cc92a-6a7a-44ee-a19e-a05aa698cabb,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-800d80ee-26ea-4811-b6b2-2c692f5500e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-466e6253-019d-4096-bfcd-9c2b8db1892a,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-448e937d-110f-412a-b5ac-d42e86e7cbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-34b4e9ba-a031-42a3-8445-af94d042e8cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1408054899-172.17.0.2-1596014217545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37771,DS-7d07e026-7c6b-4dbf-967e-3fd078e2d9db,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-33e1b091-7f61-43d5-9330-26c327a6fa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-600fecf8-2f3b-4a93-9ac8-7a6f07eb1850,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-586cc92a-6a7a-44ee-a19e-a05aa698cabb,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-800d80ee-26ea-4811-b6b2-2c692f5500e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-466e6253-019d-4096-bfcd-9c2b8db1892a,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-448e937d-110f-412a-b5ac-d42e86e7cbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-34b4e9ba-a031-42a3-8445-af94d042e8cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1632930415-172.17.0.2-1596014283735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42047,DS-6573d848-77c8-4be5-8d2a-e64f6ad37eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-0faae3b2-1a3c-45a3-a99e-d44a7d93fd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-e0320e5a-d56a-42d2-a951-07f460dd978b,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-b91e3619-6fcb-4a4a-8b77-234f11d19b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-fbd39c40-2877-4d26-9896-afee6fa7994c,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-2d7c3e23-bc58-4412-8e59-1bec319b2379,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-f5795d74-5afe-4ba8-b3b1-fa9fd9d35f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-34f8f7f2-e099-49d0-9ae1-507859bcce42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1632930415-172.17.0.2-1596014283735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42047,DS-6573d848-77c8-4be5-8d2a-e64f6ad37eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-0faae3b2-1a3c-45a3-a99e-d44a7d93fd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-e0320e5a-d56a-42d2-a951-07f460dd978b,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-b91e3619-6fcb-4a4a-8b77-234f11d19b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-fbd39c40-2877-4d26-9896-afee6fa7994c,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-2d7c3e23-bc58-4412-8e59-1bec319b2379,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-f5795d74-5afe-4ba8-b3b1-fa9fd9d35f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-34f8f7f2-e099-49d0-9ae1-507859bcce42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611793610-172.17.0.2-1596014682592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44538,DS-b43003a1-6aed-475d-9de4-fe44c6f2a68f,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-54f8a028-fe3b-4173-aef3-0171b8f63fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-c2d29d44-1ddd-4649-88c3-3a3a490b00c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-d397e43b-24dd-4157-ac99-87c61b7ab903,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-c9ba3851-f1c6-4b55-90f4-a9eb27cfaea0,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-1bfa4d44-9db2-47a2-a869-5e586237e2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-c64bc2b0-9bf1-4b50-81cb-9b935735a58f,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-77426768-4100-466e-a45e-de52ef7eab54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611793610-172.17.0.2-1596014682592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44538,DS-b43003a1-6aed-475d-9de4-fe44c6f2a68f,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-54f8a028-fe3b-4173-aef3-0171b8f63fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-c2d29d44-1ddd-4649-88c3-3a3a490b00c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-d397e43b-24dd-4157-ac99-87c61b7ab903,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-c9ba3851-f1c6-4b55-90f4-a9eb27cfaea0,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-1bfa4d44-9db2-47a2-a869-5e586237e2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-c64bc2b0-9bf1-4b50-81cb-9b935735a58f,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-77426768-4100-466e-a45e-de52ef7eab54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011231038-172.17.0.2-1596015142838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37370,DS-d9aaca76-f099-4571-98bf-4384f167c3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-71b57c18-5921-47fc-b8fe-73db4aa88c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-9e208e2e-d742-4f4a-b589-f7e9cabdaf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-5cdbc819-9918-4d12-b411-b3d40e9cafd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-1ff5479b-fce1-4d4e-b95b-4cf1f60ace69,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-a4dd9bd3-611e-4dc3-ae17-e82e73888a58,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-1a2cbc49-c864-4ba5-8f4b-1534b37dbb29,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-047ee1ac-2aab-4019-9d1a-662e7f217d4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011231038-172.17.0.2-1596015142838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37370,DS-d9aaca76-f099-4571-98bf-4384f167c3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-71b57c18-5921-47fc-b8fe-73db4aa88c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-9e208e2e-d742-4f4a-b589-f7e9cabdaf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-5cdbc819-9918-4d12-b411-b3d40e9cafd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-1ff5479b-fce1-4d4e-b95b-4cf1f60ace69,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-a4dd9bd3-611e-4dc3-ae17-e82e73888a58,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-1a2cbc49-c864-4ba5-8f4b-1534b37dbb29,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-047ee1ac-2aab-4019-9d1a-662e7f217d4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-401309743-172.17.0.2-1596015180017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44829,DS-4e9542ad-87f2-4390-a7b8-1f9585b32eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-e9b0493d-b38d-4988-9c72-b6ddbd828f81,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-7725b139-01f7-4715-9c9a-d423dc0f3892,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-b772f216-ed54-4f91-ace4-da91809f95a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-a411a280-abbf-41a3-b7e0-a95799316060,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-5afde8e1-863e-43bd-972e-79861b018f95,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-28789451-bd91-4ab0-8f58-811917c366f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-fddf5fcb-50c7-4478-9c8a-bc9f19923543,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-401309743-172.17.0.2-1596015180017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44829,DS-4e9542ad-87f2-4390-a7b8-1f9585b32eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-e9b0493d-b38d-4988-9c72-b6ddbd828f81,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-7725b139-01f7-4715-9c9a-d423dc0f3892,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-b772f216-ed54-4f91-ace4-da91809f95a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-a411a280-abbf-41a3-b7e0-a95799316060,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-5afde8e1-863e-43bd-972e-79861b018f95,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-28789451-bd91-4ab0-8f58-811917c366f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-fddf5fcb-50c7-4478-9c8a-bc9f19923543,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-773999773-172.17.0.2-1596015771770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46149,DS-6034ecdf-ea01-4c3f-b3d8-59bbd6359910,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-d2e0c0fb-9519-4720-b84a-7d66c43dcb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-1eefedcb-0e6d-4ce0-afb8-1da316f9bb20,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-d0f199b9-d4a0-402e-8820-101711ee4861,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-e8801a7c-9130-4b9c-a627-9e3a5dce8424,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-daf4c4bc-204d-4471-b953-1d1ee9c45084,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-52684773-9caf-463a-9056-ce82e889f404,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-fe0e20d0-03e7-4969-9297-427e849d6a49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-773999773-172.17.0.2-1596015771770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46149,DS-6034ecdf-ea01-4c3f-b3d8-59bbd6359910,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-d2e0c0fb-9519-4720-b84a-7d66c43dcb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-1eefedcb-0e6d-4ce0-afb8-1da316f9bb20,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-d0f199b9-d4a0-402e-8820-101711ee4861,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-e8801a7c-9130-4b9c-a627-9e3a5dce8424,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-daf4c4bc-204d-4471-b953-1d1ee9c45084,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-52684773-9caf-463a-9056-ce82e889f404,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-fe0e20d0-03e7-4969-9297-427e849d6a49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-671973661-172.17.0.2-1596015807309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33348,DS-96e2c37a-b808-463f-83a4-21e8eb6e9963,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-990e0796-ebd0-42ac-93d6-dd2caf5470ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-d484e6fe-562f-42b1-9c4a-dc3a290ac5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-f1e7d50b-e667-4796-8a02-81522298ee00,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-221a79eb-890d-4003-8114-db4a67b54570,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-4fe36bde-2b35-48b1-a844-619e029ed4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-92fa93f0-5329-449e-8e0f-52c1f4a156c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-ab23f9b0-2918-4685-9b11-6e1295be6e7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-671973661-172.17.0.2-1596015807309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33348,DS-96e2c37a-b808-463f-83a4-21e8eb6e9963,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-990e0796-ebd0-42ac-93d6-dd2caf5470ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-d484e6fe-562f-42b1-9c4a-dc3a290ac5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-f1e7d50b-e667-4796-8a02-81522298ee00,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-221a79eb-890d-4003-8114-db4a67b54570,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-4fe36bde-2b35-48b1-a844-619e029ed4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-92fa93f0-5329-449e-8e0f-52c1f4a156c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-ab23f9b0-2918-4685-9b11-6e1295be6e7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209104365-172.17.0.2-1596016149414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42489,DS-e6bf6cef-3a32-4d69-b1b1-7eafd1ffaa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-3bd5d45b-6c41-4a4b-bfba-83588ed1b751,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-206bce7a-55e3-462f-bbe3-4257651621bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-f035a8f5-4fa9-4a92-880b-b4b3af552cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-07242d85-3c9c-4488-8889-5ce83cf50b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-52e214bf-9024-4fc8-9d15-353f6cb987a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-d7663533-2431-4088-a674-010a35c854a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-364c48d3-df00-483c-b819-032761758a9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209104365-172.17.0.2-1596016149414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42489,DS-e6bf6cef-3a32-4d69-b1b1-7eafd1ffaa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-3bd5d45b-6c41-4a4b-bfba-83588ed1b751,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-206bce7a-55e3-462f-bbe3-4257651621bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-f035a8f5-4fa9-4a92-880b-b4b3af552cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-07242d85-3c9c-4488-8889-5ce83cf50b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-52e214bf-9024-4fc8-9d15-353f6cb987a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-d7663533-2431-4088-a674-010a35c854a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-364c48d3-df00-483c-b819-032761758a9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015059938-172.17.0.2-1596016341673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44518,DS-2abf5d02-e863-488e-904c-38d0c682cb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-95ead636-1fcd-4d44-877b-72bab75b79e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-f0cf8fe0-2fd4-4a98-9ea2-4c069cd84bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-e19d6cd7-ebfc-455d-a808-af09ebe810b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-61833817-eff1-48e4-9d6c-32e7c6641472,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-5f38e782-a8df-43e6-b2ad-54ec264ea44c,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-34963c18-50ec-47c9-a08e-6f0e1b22cc89,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-503bd724-d85a-4919-b3a1-0cc3ed967adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015059938-172.17.0.2-1596016341673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44518,DS-2abf5d02-e863-488e-904c-38d0c682cb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-95ead636-1fcd-4d44-877b-72bab75b79e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-f0cf8fe0-2fd4-4a98-9ea2-4c069cd84bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-e19d6cd7-ebfc-455d-a808-af09ebe810b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-61833817-eff1-48e4-9d6c-32e7c6641472,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-5f38e782-a8df-43e6-b2ad-54ec264ea44c,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-34963c18-50ec-47c9-a08e-6f0e1b22cc89,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-503bd724-d85a-4919-b3a1-0cc3ed967adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563382031-172.17.0.2-1596016531144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33509,DS-a3ee7260-5cf8-42b3-97bd-36affa247a81,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-ad14c9a8-ba6b-4f4b-87ee-e57ca50f44aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-d52108c7-f231-4229-918a-1029be863bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-424c8ab8-e3e4-41eb-9285-0e48ea638618,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-d48823b1-dbd0-44bb-88bb-fb98e83dce05,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-c4a83bc5-82fa-4628-b969-30ff1bad5586,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-c9c3b420-4732-4fb5-9821-a439e9fd519e,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-687c5f15-fc44-4edb-9aea-c27d5bd5d0a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563382031-172.17.0.2-1596016531144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33509,DS-a3ee7260-5cf8-42b3-97bd-36affa247a81,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-ad14c9a8-ba6b-4f4b-87ee-e57ca50f44aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-d52108c7-f231-4229-918a-1029be863bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-424c8ab8-e3e4-41eb-9285-0e48ea638618,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-d48823b1-dbd0-44bb-88bb-fb98e83dce05,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-c4a83bc5-82fa-4628-b969-30ff1bad5586,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-c9c3b420-4732-4fb5-9821-a439e9fd519e,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-687c5f15-fc44-4edb-9aea-c27d5bd5d0a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166900755-172.17.0.2-1596016864972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39752,DS-baf3e774-c588-4ca8-b4a3-904412c07f89,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-2ed014e3-0856-466e-82fd-a0c652f0881c,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-af7e02e4-b2c8-45b4-8b22-6d7d7eb7ef0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-5f697f32-3f4f-44dd-8930-cc9fc1c738b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-04250182-7449-4ae9-a879-a9306e37a95c,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-501c3f86-9ff7-42b2-a004-307b1475eec3,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-df4645c2-ce49-4a75-a111-eb47057f2330,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-525af602-5415-422f-a31d-7b800d9abc50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166900755-172.17.0.2-1596016864972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39752,DS-baf3e774-c588-4ca8-b4a3-904412c07f89,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-2ed014e3-0856-466e-82fd-a0c652f0881c,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-af7e02e4-b2c8-45b4-8b22-6d7d7eb7ef0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-5f697f32-3f4f-44dd-8930-cc9fc1c738b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-04250182-7449-4ae9-a879-a9306e37a95c,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-501c3f86-9ff7-42b2-a004-307b1475eec3,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-df4645c2-ce49-4a75-a111-eb47057f2330,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-525af602-5415-422f-a31d-7b800d9abc50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132525596-172.17.0.2-1596016966998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34388,DS-cc895421-5998-4235-8836-f2b92e4be62f,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-7577df05-90fd-4b6e-8fac-37fd67a8f7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-3eddaf55-951b-4d46-9589-92cfc2f4c700,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-484dc247-ac3f-4194-aaed-5d57496090cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-e5930035-8240-4bb0-a4e4-a30b708f002e,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-a1a15045-a4b2-4556-a879-f57e453c98b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-f2370f4d-bf2a-49dc-a07c-6e5e985976ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-595c245b-3e40-4142-be97-a3a1ca050313,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132525596-172.17.0.2-1596016966998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34388,DS-cc895421-5998-4235-8836-f2b92e4be62f,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-7577df05-90fd-4b6e-8fac-37fd67a8f7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-3eddaf55-951b-4d46-9589-92cfc2f4c700,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-484dc247-ac3f-4194-aaed-5d57496090cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-e5930035-8240-4bb0-a4e4-a30b708f002e,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-a1a15045-a4b2-4556-a879-f57e453c98b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-f2370f4d-bf2a-49dc-a07c-6e5e985976ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-595c245b-3e40-4142-be97-a3a1ca050313,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630828447-172.17.0.2-1596017201360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39913,DS-a61ca557-7851-409c-bb80-ae5801a089d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-f9301b59-38b7-4e1e-afb8-b782e4081597,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-5e1c5dcc-d664-49fb-8b37-266e4e2bfdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-6630682e-6fee-4cb3-a9ed-cbfece0ba43d,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-7f68dad7-e356-4f43-ae63-e118337fda0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-9de0901d-9fc6-4e14-9990-d80e3e46079e,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-13df2633-c097-494b-b2dd-3be7b2f3cb44,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-02292508-3de8-4e10-8ecd-f0c25ed25ffc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630828447-172.17.0.2-1596017201360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39913,DS-a61ca557-7851-409c-bb80-ae5801a089d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-f9301b59-38b7-4e1e-afb8-b782e4081597,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-5e1c5dcc-d664-49fb-8b37-266e4e2bfdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-6630682e-6fee-4cb3-a9ed-cbfece0ba43d,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-7f68dad7-e356-4f43-ae63-e118337fda0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-9de0901d-9fc6-4e14-9990-d80e3e46079e,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-13df2633-c097-494b-b2dd-3be7b2f3cb44,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-02292508-3de8-4e10-8ecd-f0c25ed25ffc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1674962706-172.17.0.2-1596017314247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43809,DS-7bae80f7-e155-41ef-8ce5-7a302c10c7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-2ee0c772-fb48-4de4-b7e0-9299c3336235,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-dc929c38-8b6e-45b1-a175-b3ed0b3c20e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-56b60bf1-98cc-4092-b744-f518e299c12f,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-bdc990af-0dcc-4091-9b32-ddebcd7aa914,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-c8118e40-3093-4466-9b1d-f46992dca14b,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-2f7b4fb8-6c29-4bb3-9690-a356b6bb4737,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-f86f974d-2324-4964-805d-a9a421577657,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1674962706-172.17.0.2-1596017314247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43809,DS-7bae80f7-e155-41ef-8ce5-7a302c10c7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-2ee0c772-fb48-4de4-b7e0-9299c3336235,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-dc929c38-8b6e-45b1-a175-b3ed0b3c20e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-56b60bf1-98cc-4092-b744-f518e299c12f,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-bdc990af-0dcc-4091-9b32-ddebcd7aa914,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-c8118e40-3093-4466-9b1d-f46992dca14b,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-2f7b4fb8-6c29-4bb3-9690-a356b6bb4737,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-f86f974d-2324-4964-805d-a9a421577657,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1755100214-172.17.0.2-1596017427976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34835,DS-a308da09-9da4-4289-8978-5900c9a63eff,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-6424cd24-30aa-467c-a9ba-95244f9d6a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-1105fa2c-6ae9-4367-975d-7e75e31e19aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-ab9fa6af-cd74-4f42-afef-9ab4a75fdb02,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-c75281d3-64f7-4dfb-ae30-91f8726ac8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-14db75f3-e778-4794-9144-e2fdc85c6046,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-7efb3246-9c9d-4d2e-865a-16ede426fa4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-c849a265-0e1d-4f75-b099-d847b6f6199a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1755100214-172.17.0.2-1596017427976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34835,DS-a308da09-9da4-4289-8978-5900c9a63eff,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-6424cd24-30aa-467c-a9ba-95244f9d6a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-1105fa2c-6ae9-4367-975d-7e75e31e19aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-ab9fa6af-cd74-4f42-afef-9ab4a75fdb02,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-c75281d3-64f7-4dfb-ae30-91f8726ac8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-14db75f3-e778-4794-9144-e2fdc85c6046,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-7efb3246-9c9d-4d2e-865a-16ede426fa4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-c849a265-0e1d-4f75-b099-d847b6f6199a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394107255-172.17.0.2-1596017756995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36931,DS-3c5eb6b4-72fa-4d5d-8257-4a5493a450d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-fca4f1e6-4229-4679-a736-d4076937bf94,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-4251919a-b84d-491d-8e0b-0494d73d7a33,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-a08e25ec-4d17-4656-bea5-2be02a737195,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-5aea5b06-3cea-48a4-bcf1-c3ea0cbbe62d,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-16979f04-58f8-4e84-97c8-02dc7002e154,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-c01ef2e7-d8b7-4013-8158-90f46b621d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-c5764c62-1f1b-46ee-8bb6-37676d51bd80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394107255-172.17.0.2-1596017756995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36931,DS-3c5eb6b4-72fa-4d5d-8257-4a5493a450d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-fca4f1e6-4229-4679-a736-d4076937bf94,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-4251919a-b84d-491d-8e0b-0494d73d7a33,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-a08e25ec-4d17-4656-bea5-2be02a737195,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-5aea5b06-3cea-48a4-bcf1-c3ea0cbbe62d,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-16979f04-58f8-4e84-97c8-02dc7002e154,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-c01ef2e7-d8b7-4013-8158-90f46b621d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-c5764c62-1f1b-46ee-8bb6-37676d51bd80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062043408-172.17.0.2-1596018107218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33562,DS-7abca440-5349-4dd1-837a-70197b2cc6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-af9878dd-5a7b-4c16-ab48-1129b1e894ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-f3ce3077-d291-4d62-bb16-194c0607e25f,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-8addbd42-285b-4049-86b5-b779d0acad32,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-1a4f247d-5656-4cdc-898d-4114f7013410,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-94e518d9-ba9d-463b-a22e-b5b272e236e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-2a6b9646-d6a8-44ab-9d36-48475a21e556,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-07c41dee-0ccf-48fd-837f-d889b677e230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062043408-172.17.0.2-1596018107218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33562,DS-7abca440-5349-4dd1-837a-70197b2cc6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-af9878dd-5a7b-4c16-ab48-1129b1e894ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-f3ce3077-d291-4d62-bb16-194c0607e25f,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-8addbd42-285b-4049-86b5-b779d0acad32,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-1a4f247d-5656-4cdc-898d-4114f7013410,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-94e518d9-ba9d-463b-a22e-b5b272e236e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-2a6b9646-d6a8-44ab-9d36-48475a21e556,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-07c41dee-0ccf-48fd-837f-d889b677e230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352472485-172.17.0.2-1596018290008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38057,DS-966b7dc7-f9b4-4d8f-b16d-0949e4061ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-3078ec80-3e70-49f5-ae25-8e87ecd64422,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-f43cc2fc-da9e-4176-9773-95c487ad9e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-c0714bf2-a4b3-4ff9-8acd-7d31482d4465,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-189ef3dc-cf96-4949-aec5-ea88e1a8f3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-d8aa9e67-a10a-4bec-805d-4d020bad8c16,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-2c555c3e-dbf8-4e2a-89ca-3ac2b5e7c2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-24dceda2-b7d1-42b8-9374-7d7ae9e71bf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352472485-172.17.0.2-1596018290008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38057,DS-966b7dc7-f9b4-4d8f-b16d-0949e4061ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-3078ec80-3e70-49f5-ae25-8e87ecd64422,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-f43cc2fc-da9e-4176-9773-95c487ad9e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-c0714bf2-a4b3-4ff9-8acd-7d31482d4465,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-189ef3dc-cf96-4949-aec5-ea88e1a8f3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-d8aa9e67-a10a-4bec-805d-4d020bad8c16,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-2c555c3e-dbf8-4e2a-89ca-3ac2b5e7c2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-24dceda2-b7d1-42b8-9374-7d7ae9e71bf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-661603437-172.17.0.2-1596018581268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46736,DS-d498fbdc-333b-4645-8dae-13ebae87e716,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-c0571c58-e2b5-4b48-9e2b-ed4416a0e44f,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-9ab7bc39-36ac-4341-88b8-dbc8fcc3c3de,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-dd4a57c4-0bcb-4aa3-b56d-a59d35ef7756,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-7d9d7303-4355-4777-b3a8-33f363df8b95,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-4547d939-ba9c-4961-90d8-8daf2e33d1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-fbf3992b-25f3-47f1-a10e-f851c38f9fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-53989995-df0b-48a7-8d00-1b3c57d2a47a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-661603437-172.17.0.2-1596018581268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46736,DS-d498fbdc-333b-4645-8dae-13ebae87e716,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-c0571c58-e2b5-4b48-9e2b-ed4416a0e44f,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-9ab7bc39-36ac-4341-88b8-dbc8fcc3c3de,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-dd4a57c4-0bcb-4aa3-b56d-a59d35ef7756,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-7d9d7303-4355-4777-b3a8-33f363df8b95,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-4547d939-ba9c-4961-90d8-8daf2e33d1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-fbf3992b-25f3-47f1-a10e-f851c38f9fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-53989995-df0b-48a7-8d00-1b3c57d2a47a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5282
