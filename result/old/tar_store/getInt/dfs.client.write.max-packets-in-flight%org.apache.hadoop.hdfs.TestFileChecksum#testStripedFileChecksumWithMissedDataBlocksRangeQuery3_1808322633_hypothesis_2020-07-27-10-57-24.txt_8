reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248093003-172.17.0.14-1595847495054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41456,DS-5c776b20-d31f-4b00-a6e2-a1a6a64eb796,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-ce849016-f55f-4e00-9011-e5b5fa384dce,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-6426fe6d-1fbf-41e2-99fa-329cdec4d1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-d9fd7783-54f4-4fb2-9fc3-a0b569d81dce,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-bd2851f7-17c6-422e-8875-e940145f0de0,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-0ac32a33-69d4-49a8-abba-428094d64816,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-fd74ac3c-6fde-4660-84f8-59e77638a27e,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-a71f571c-0b0a-48be-a33e-6e5ec4d55059,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248093003-172.17.0.14-1595847495054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41456,DS-5c776b20-d31f-4b00-a6e2-a1a6a64eb796,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-ce849016-f55f-4e00-9011-e5b5fa384dce,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-6426fe6d-1fbf-41e2-99fa-329cdec4d1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-d9fd7783-54f4-4fb2-9fc3-a0b569d81dce,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-bd2851f7-17c6-422e-8875-e940145f0de0,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-0ac32a33-69d4-49a8-abba-428094d64816,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-fd74ac3c-6fde-4660-84f8-59e77638a27e,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-a71f571c-0b0a-48be-a33e-6e5ec4d55059,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131478618-172.17.0.14-1595847574555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38768,DS-04d4e44d-432d-4ecc-a456-09165992bd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-3bad1d2a-c7be-497c-8179-ba0394bffdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-7676bc70-8d34-4130-9ad9-e4a694f8f478,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-744ba144-3af3-4745-937c-68c168df2517,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-58da4d28-b551-4356-b81f-924436e372fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-a3cc28cf-34c3-47e0-ae6b-e2e9464f3b52,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-17ae7fb9-a7db-4072-aa72-6ee8505bd4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-268899ae-c3a0-4f21-bb34-6f1e0f7e00d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131478618-172.17.0.14-1595847574555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38768,DS-04d4e44d-432d-4ecc-a456-09165992bd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-3bad1d2a-c7be-497c-8179-ba0394bffdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-7676bc70-8d34-4130-9ad9-e4a694f8f478,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-744ba144-3af3-4745-937c-68c168df2517,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-58da4d28-b551-4356-b81f-924436e372fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-a3cc28cf-34c3-47e0-ae6b-e2e9464f3b52,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-17ae7fb9-a7db-4072-aa72-6ee8505bd4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-268899ae-c3a0-4f21-bb34-6f1e0f7e00d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-624577461-172.17.0.14-1595847805209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36393,DS-f1066f63-1d56-4336-8874-0adeacf26c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-033391f4-ca88-468d-b16f-39bb58e853d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-dd85ccee-e0a3-40fd-a988-8b7a82bfc07f,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-335003bb-e0d7-4404-b5fb-26024db521da,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-d55e1128-8b38-4fdf-b0f5-81f53823a4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-8525cf22-07f2-4db2-9698-c663b2ad61e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-89abbc62-e755-4eb5-abe4-d7ca9e840ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-e18f2a7e-410d-4cf6-a74f-6dc79c264952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-624577461-172.17.0.14-1595847805209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36393,DS-f1066f63-1d56-4336-8874-0adeacf26c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-033391f4-ca88-468d-b16f-39bb58e853d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-dd85ccee-e0a3-40fd-a988-8b7a82bfc07f,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-335003bb-e0d7-4404-b5fb-26024db521da,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-d55e1128-8b38-4fdf-b0f5-81f53823a4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-8525cf22-07f2-4db2-9698-c663b2ad61e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-89abbc62-e755-4eb5-abe4-d7ca9e840ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-e18f2a7e-410d-4cf6-a74f-6dc79c264952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-261897048-172.17.0.14-1595847956671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43512,DS-9dd58a42-5e41-4a22-ac31-20c731cc7fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-7d1ac7ea-0b1c-4cb3-9b29-f0a6636895d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-8aae0c64-7cb4-485e-8e25-713de833399a,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-b0c31e53-743e-4584-8c5a-68a1d8af5105,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-69fccc8c-7fe0-4146-9dc5-695a18c47b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-8fc49cf0-0a96-418e-846e-6976211bdf94,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-34fe9e6d-31a7-4233-9c26-e8f36d0b00e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-107ac80a-847a-4c99-8d15-b80e9793d774,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-261897048-172.17.0.14-1595847956671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43512,DS-9dd58a42-5e41-4a22-ac31-20c731cc7fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-7d1ac7ea-0b1c-4cb3-9b29-f0a6636895d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-8aae0c64-7cb4-485e-8e25-713de833399a,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-b0c31e53-743e-4584-8c5a-68a1d8af5105,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-69fccc8c-7fe0-4146-9dc5-695a18c47b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-8fc49cf0-0a96-418e-846e-6976211bdf94,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-34fe9e6d-31a7-4233-9c26-e8f36d0b00e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-107ac80a-847a-4c99-8d15-b80e9793d774,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456951565-172.17.0.14-1595847999481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32976,DS-c908e135-766f-4af5-98d4-99abbd0a2332,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-887adf60-3683-44c2-878f-fe2bc074b3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-33bb4922-f646-409c-9302-ec12ca260d63,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-0677ed4f-e248-434e-b646-bc1586ca17c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-61db2ad6-3b6c-40ad-9079-0c7de2a9b6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-4a496add-569b-476a-a0ab-35f1df3f2f76,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-88e56467-4ab0-431b-b74d-acfce04f2f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-5a56ffd8-7425-4266-bc2c-0e552985cbc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456951565-172.17.0.14-1595847999481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32976,DS-c908e135-766f-4af5-98d4-99abbd0a2332,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-887adf60-3683-44c2-878f-fe2bc074b3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-33bb4922-f646-409c-9302-ec12ca260d63,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-0677ed4f-e248-434e-b646-bc1586ca17c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-61db2ad6-3b6c-40ad-9079-0c7de2a9b6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-4a496add-569b-476a-a0ab-35f1df3f2f76,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-88e56467-4ab0-431b-b74d-acfce04f2f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-5a56ffd8-7425-4266-bc2c-0e552985cbc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102651652-172.17.0.14-1595848088643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38859,DS-9977a60d-48a5-487a-b40a-bda1abb19b39,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-4d5ab808-20dd-4fa3-a61c-95e298d6eda2,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-9d07d2aa-007e-466b-a348-c89105bac9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-8f0a3c71-b656-4d30-b064-0b3140bafca8,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-d677983b-429b-49f0-8421-421e33df8811,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-48370f19-2345-431b-8afe-85c36bea6228,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-56f998bd-636d-4a88-8cac-80921010cc03,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-3eae75fb-bc8d-4e65-9c8b-428a049af5b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102651652-172.17.0.14-1595848088643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38859,DS-9977a60d-48a5-487a-b40a-bda1abb19b39,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-4d5ab808-20dd-4fa3-a61c-95e298d6eda2,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-9d07d2aa-007e-466b-a348-c89105bac9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-8f0a3c71-b656-4d30-b064-0b3140bafca8,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-d677983b-429b-49f0-8421-421e33df8811,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-48370f19-2345-431b-8afe-85c36bea6228,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-56f998bd-636d-4a88-8cac-80921010cc03,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-3eae75fb-bc8d-4e65-9c8b-428a049af5b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325026906-172.17.0.14-1595848527233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43626,DS-87029bf0-5c61-4de4-9d53-bd45c89c726c,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-4a373b82-a5f5-4933-92e2-507d3152c28b,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-f702e7da-d948-4a7c-992d-015e7c0d623d,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-1fab8baf-e875-4c96-8eb8-1360645b4964,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-5fc016f9-f756-4f39-b545-0b549790382d,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-8279786e-c312-41ec-b2da-e377ebf37aee,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-517cc559-3ae4-4245-8131-34add37163d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-a5344525-432f-4a04-975f-0d74dc223df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325026906-172.17.0.14-1595848527233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43626,DS-87029bf0-5c61-4de4-9d53-bd45c89c726c,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-4a373b82-a5f5-4933-92e2-507d3152c28b,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-f702e7da-d948-4a7c-992d-015e7c0d623d,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-1fab8baf-e875-4c96-8eb8-1360645b4964,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-5fc016f9-f756-4f39-b545-0b549790382d,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-8279786e-c312-41ec-b2da-e377ebf37aee,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-517cc559-3ae4-4245-8131-34add37163d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-a5344525-432f-4a04-975f-0d74dc223df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061281295-172.17.0.14-1595848636803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41028,DS-5f3741a6-f592-4bc1-872e-b6026919684f,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-d41a6214-4f63-4560-960a-7dfed2e05295,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-b9b7f31b-200c-4bf4-9f5c-84c0c6c76ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-94a29d3a-16ee-47e9-8fc2-9b38d503ed6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-cff31691-2859-4f4f-8be0-5e9abd7eb8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-189103c9-1e57-4fc5-b00b-040f6ebfaf51,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-4d377f83-c089-428c-9d0a-27a5fae5a5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-35978cb5-67d5-4eb4-9d15-e19d5d78667f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061281295-172.17.0.14-1595848636803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41028,DS-5f3741a6-f592-4bc1-872e-b6026919684f,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-d41a6214-4f63-4560-960a-7dfed2e05295,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-b9b7f31b-200c-4bf4-9f5c-84c0c6c76ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-94a29d3a-16ee-47e9-8fc2-9b38d503ed6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-cff31691-2859-4f4f-8be0-5e9abd7eb8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-189103c9-1e57-4fc5-b00b-040f6ebfaf51,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-4d377f83-c089-428c-9d0a-27a5fae5a5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-35978cb5-67d5-4eb4-9d15-e19d5d78667f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23557847-172.17.0.14-1595848871623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37908,DS-69edd27f-897f-465e-8a22-2994711660ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-3dda60ad-90aa-4b59-93d0-653e84ad8154,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-b42e6a6f-b1ee-4566-8d51-25b60f22bbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-80a93365-338a-4024-99df-33057838de92,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-70485c5e-6ebf-4267-b269-1cfd25334e60,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-33dd31a0-9982-444b-95e9-9f0ffcff70cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-e2c7d52d-bab2-4242-86de-59a726cd052e,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-176ba548-2938-491f-946b-3e201fe710b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23557847-172.17.0.14-1595848871623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37908,DS-69edd27f-897f-465e-8a22-2994711660ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-3dda60ad-90aa-4b59-93d0-653e84ad8154,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-b42e6a6f-b1ee-4566-8d51-25b60f22bbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-80a93365-338a-4024-99df-33057838de92,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-70485c5e-6ebf-4267-b269-1cfd25334e60,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-33dd31a0-9982-444b-95e9-9f0ffcff70cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-e2c7d52d-bab2-4242-86de-59a726cd052e,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-176ba548-2938-491f-946b-3e201fe710b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39395074-172.17.0.14-1595848963393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45012,DS-30a75473-df75-42b7-b6c3-535fac70c801,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-bba3ed31-c8be-4484-b702-8fa7362f9fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-0f6f4a77-2625-4359-9d7d-7614b88ec37a,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-82dc2ea9-accf-498c-9010-16faed85b07d,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-dd31dd2e-f088-4a70-afa3-6904994433c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-fe503224-5507-4a94-8757-4ee9187bd132,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-54282760-2040-4afb-be2f-bbee7f020e09,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-aefe4492-982e-4774-a541-f8937731a723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39395074-172.17.0.14-1595848963393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45012,DS-30a75473-df75-42b7-b6c3-535fac70c801,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-bba3ed31-c8be-4484-b702-8fa7362f9fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-0f6f4a77-2625-4359-9d7d-7614b88ec37a,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-82dc2ea9-accf-498c-9010-16faed85b07d,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-dd31dd2e-f088-4a70-afa3-6904994433c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-fe503224-5507-4a94-8757-4ee9187bd132,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-54282760-2040-4afb-be2f-bbee7f020e09,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-aefe4492-982e-4774-a541-f8937731a723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399254739-172.17.0.14-1595849159464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34698,DS-66d4332f-a1ea-402e-a103-80a680f7e1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-d39e976a-b7bf-4bb1-b671-18fbe686dbac,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-a4491345-2eaa-450b-be1f-1caeace2f548,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-fca27870-c2f4-4965-8d84-240ad607406e,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-4b4c8d03-bde1-474d-89ca-ae20c1ed73af,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-450471b5-fbd7-4688-aba4-c92002857aad,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-953afce2-8991-4b97-b7d6-c35b20a1e915,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-3e9b13ab-8405-45db-87db-9f6761e0f4b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399254739-172.17.0.14-1595849159464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34698,DS-66d4332f-a1ea-402e-a103-80a680f7e1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-d39e976a-b7bf-4bb1-b671-18fbe686dbac,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-a4491345-2eaa-450b-be1f-1caeace2f548,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-fca27870-c2f4-4965-8d84-240ad607406e,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-4b4c8d03-bde1-474d-89ca-ae20c1ed73af,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-450471b5-fbd7-4688-aba4-c92002857aad,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-953afce2-8991-4b97-b7d6-c35b20a1e915,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-3e9b13ab-8405-45db-87db-9f6761e0f4b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896516841-172.17.0.14-1595849482954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46209,DS-9e802a7d-b9bc-49bc-914f-a4606d49fe9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-9254c2fa-7336-4c0e-b2d9-b26a688c3594,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-92bd8d48-5ae0-48a9-8aee-0c6f48d665c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-44633701-370b-4009-b16e-5427506b8ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-7327faec-b2ba-4e19-83f5-afcbb0193a25,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-dabd821c-597f-4072-aa21-797c386be898,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-e2ed9954-5dc2-46cd-9f9e-a76c3fa492ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-c29ce33c-c809-4bb3-847f-a956c377f0f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896516841-172.17.0.14-1595849482954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46209,DS-9e802a7d-b9bc-49bc-914f-a4606d49fe9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-9254c2fa-7336-4c0e-b2d9-b26a688c3594,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-92bd8d48-5ae0-48a9-8aee-0c6f48d665c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-44633701-370b-4009-b16e-5427506b8ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-7327faec-b2ba-4e19-83f5-afcbb0193a25,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-dabd821c-597f-4072-aa21-797c386be898,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-e2ed9954-5dc2-46cd-9f9e-a76c3fa492ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-c29ce33c-c809-4bb3-847f-a956c377f0f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864077645-172.17.0.14-1595849527643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43971,DS-f2bb4234-a1a2-4833-9a40-9c24d9f2c4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-7252be68-3a45-4df1-ad1c-64f38f1349e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-e8e700b5-aa6c-4b1b-aab5-962f3fa6e3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-8b86bae9-84fd-42f3-bffd-e917e3dd72a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-4f2f4ed9-9dd7-4e4c-ba5e-d21cd45230a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-b4fe67a2-eab2-447f-9609-297be19205ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-6d484bd7-1b1a-4e23-a0a6-f8865bb6022f,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-c0f6120c-f378-4a2c-8107-54f73929fa34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864077645-172.17.0.14-1595849527643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43971,DS-f2bb4234-a1a2-4833-9a40-9c24d9f2c4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-7252be68-3a45-4df1-ad1c-64f38f1349e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-e8e700b5-aa6c-4b1b-aab5-962f3fa6e3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-8b86bae9-84fd-42f3-bffd-e917e3dd72a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-4f2f4ed9-9dd7-4e4c-ba5e-d21cd45230a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-b4fe67a2-eab2-447f-9609-297be19205ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-6d484bd7-1b1a-4e23-a0a6-f8865bb6022f,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-c0f6120c-f378-4a2c-8107-54f73929fa34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430123977-172.17.0.14-1595849615330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46279,DS-5d957c36-eeff-4f22-a91e-de1b1e05c241,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-7202754c-908f-4e1d-9390-eb28ca93ce28,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-cc7c089e-58ec-468a-9039-3114c3f6a5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-763cf37d-e55a-4b15-b756-77a8877e37a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-4b600032-e08a-44d8-8a84-cc5db95c4600,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-eab5daf5-79ef-4d44-b411-fa046a0c8055,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-aea82a74-5e88-4560-b03e-9dbcec23bda0,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-e1a3b32f-467e-44d8-84bd-a3791e3986b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430123977-172.17.0.14-1595849615330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46279,DS-5d957c36-eeff-4f22-a91e-de1b1e05c241,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-7202754c-908f-4e1d-9390-eb28ca93ce28,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-cc7c089e-58ec-468a-9039-3114c3f6a5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-763cf37d-e55a-4b15-b756-77a8877e37a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-4b600032-e08a-44d8-8a84-cc5db95c4600,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-eab5daf5-79ef-4d44-b411-fa046a0c8055,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-aea82a74-5e88-4560-b03e-9dbcec23bda0,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-e1a3b32f-467e-44d8-84bd-a3791e3986b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253087883-172.17.0.14-1595850429957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40042,DS-3530544f-b237-4820-a9d0-1f472be9bef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-900ebb8a-7102-47d1-b627-da440da70af1,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-37a67b70-8d53-4153-92b0-fab2b52ad5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-04411754-6921-42ef-bd0f-54578f2b2c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-5ab3c8de-e661-4e9a-b3c2-4df3e7b3d6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-45130dcd-cfdb-4cd3-bea9-e977ddd663ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-a74d5b4b-1c90-4dc9-b89f-fb69af92496b,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-e6a82456-8224-45ba-aaf9-8f09521445bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253087883-172.17.0.14-1595850429957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40042,DS-3530544f-b237-4820-a9d0-1f472be9bef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-900ebb8a-7102-47d1-b627-da440da70af1,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-37a67b70-8d53-4153-92b0-fab2b52ad5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-04411754-6921-42ef-bd0f-54578f2b2c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-5ab3c8de-e661-4e9a-b3c2-4df3e7b3d6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-45130dcd-cfdb-4cd3-bea9-e977ddd663ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-a74d5b4b-1c90-4dc9-b89f-fb69af92496b,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-e6a82456-8224-45ba-aaf9-8f09521445bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728532577-172.17.0.14-1595850732184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39875,DS-c9fd9b76-1e92-45fc-a86e-7274189be8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-f5bad268-9ab4-487a-9cdc-a7a37a0dd422,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-5f7834a0-bdc0-4ddf-b662-d683ea0898a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-38311dde-f080-4405-a91e-9872b18386ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-6b472a06-a91e-4c8f-9b1e-1db901dae54e,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-14ac40bb-823d-4e7b-85b2-797b7b10786e,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-0c2eeff3-188c-4b2e-811d-fbf079d1ef8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-4a9f10b7-13ae-4646-a6b0-184df523ce34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728532577-172.17.0.14-1595850732184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39875,DS-c9fd9b76-1e92-45fc-a86e-7274189be8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-f5bad268-9ab4-487a-9cdc-a7a37a0dd422,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-5f7834a0-bdc0-4ddf-b662-d683ea0898a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-38311dde-f080-4405-a91e-9872b18386ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-6b472a06-a91e-4c8f-9b1e-1db901dae54e,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-14ac40bb-823d-4e7b-85b2-797b7b10786e,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-0c2eeff3-188c-4b2e-811d-fbf079d1ef8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-4a9f10b7-13ae-4646-a6b0-184df523ce34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294702998-172.17.0.14-1595850840691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41134,DS-74b692be-51ea-4a20-a4e1-5e7dcf8d4b70,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-24364399-942e-4cce-bda3-e585fcb38a93,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-b04a7695-1551-4b35-a422-e940da28daee,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-fb4fa6ae-234b-4dde-ba6f-771bf51e0cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-0e97063b-7435-411d-8960-2533a2ed3eee,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-db015e39-2b1b-4b48-8e27-bae7573edb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-8bc82087-73b7-4f37-943f-36767b8e59c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-43a30f02-bd9c-4c60-a927-fe57f067005c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294702998-172.17.0.14-1595850840691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41134,DS-74b692be-51ea-4a20-a4e1-5e7dcf8d4b70,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-24364399-942e-4cce-bda3-e585fcb38a93,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-b04a7695-1551-4b35-a422-e940da28daee,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-fb4fa6ae-234b-4dde-ba6f-771bf51e0cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-0e97063b-7435-411d-8960-2533a2ed3eee,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-db015e39-2b1b-4b48-8e27-bae7573edb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-8bc82087-73b7-4f37-943f-36767b8e59c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-43a30f02-bd9c-4c60-a927-fe57f067005c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20739747-172.17.0.14-1595851317536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33820,DS-d17ddaa2-3058-41ab-8a1c-038619ce1032,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-8c3145a9-f260-4220-a0c2-4462cecc29ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-a172419c-cf6e-4832-bf7a-fecf8b2a8947,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-2b1ee6c6-b827-4e62-b7cb-22f611c0bbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-263fb25a-667d-47ef-b4d4-af80f4435daf,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-38517220-7fb4-4822-8cf9-77c5fc891636,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-2573eb12-5ad5-45e4-a66a-ea130bf72416,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-56e935e6-1365-45d6-a154-970189b3670c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20739747-172.17.0.14-1595851317536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33820,DS-d17ddaa2-3058-41ab-8a1c-038619ce1032,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-8c3145a9-f260-4220-a0c2-4462cecc29ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-a172419c-cf6e-4832-bf7a-fecf8b2a8947,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-2b1ee6c6-b827-4e62-b7cb-22f611c0bbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-263fb25a-667d-47ef-b4d4-af80f4435daf,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-38517220-7fb4-4822-8cf9-77c5fc891636,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-2573eb12-5ad5-45e4-a66a-ea130bf72416,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-56e935e6-1365-45d6-a154-970189b3670c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-820401725-172.17.0.14-1595851354648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40013,DS-2fb28717-0bf3-4132-a95e-5c3e1984b832,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-90eede3f-c9b4-4753-b8bb-d8e3f87e9482,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-15bc2abf-7fcc-4009-958e-acccaff515d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-4f039772-9eb8-449f-ad15-c8dc863f15a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-64c16e0c-108c-47ea-967f-9e7cee1f83e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-45bae8d3-dcc6-48f3-9256-ee6af7372da7,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-4eb0c7a5-cf20-49a9-b296-9f55562fd82e,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-9300fbaa-3706-4037-abc7-db59be06978c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-820401725-172.17.0.14-1595851354648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40013,DS-2fb28717-0bf3-4132-a95e-5c3e1984b832,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-90eede3f-c9b4-4753-b8bb-d8e3f87e9482,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-15bc2abf-7fcc-4009-958e-acccaff515d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-4f039772-9eb8-449f-ad15-c8dc863f15a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-64c16e0c-108c-47ea-967f-9e7cee1f83e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-45bae8d3-dcc6-48f3-9256-ee6af7372da7,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-4eb0c7a5-cf20-49a9-b296-9f55562fd82e,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-9300fbaa-3706-4037-abc7-db59be06978c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038988088-172.17.0.14-1595851541808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40857,DS-03b5bd57-afef-409c-9a28-55152af1242a,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-66aee9ff-1652-422d-860e-6804323b6670,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-4ac3213c-3d96-4d73-be34-ddf6915dc3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-b6855c2f-9562-4010-b705-03730905b80f,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-22419f67-4fda-4956-acc1-c352a9eeea42,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-01a3dcd6-4479-42ee-b2dc-7d3ed8f03d69,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-4f8d4c5b-77c5-4d66-ac0e-669a6bd8e7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-d275e582-7117-4f62-87f9-f8f0f907bc47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038988088-172.17.0.14-1595851541808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40857,DS-03b5bd57-afef-409c-9a28-55152af1242a,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-66aee9ff-1652-422d-860e-6804323b6670,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-4ac3213c-3d96-4d73-be34-ddf6915dc3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-b6855c2f-9562-4010-b705-03730905b80f,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-22419f67-4fda-4956-acc1-c352a9eeea42,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-01a3dcd6-4479-42ee-b2dc-7d3ed8f03d69,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-4f8d4c5b-77c5-4d66-ac0e-669a6bd8e7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-d275e582-7117-4f62-87f9-f8f0f907bc47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1506251306-172.17.0.14-1595851861190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35695,DS-f143bfa6-2102-4d37-a1e7-5114621a48a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-943e992f-c9de-4ca4-b11d-2b0838989e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-fc099d7a-2d5e-4f16-8ce0-e9b50611eddb,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-38121802-83de-4590-8ad6-4e248bf4ef93,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-69e80699-215f-4077-b05b-cbc1fbb8ea92,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-eabb6629-9587-422a-9508-843b0ed4c6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-9960c1d3-4aa8-4084-a5d3-c44037e2729c,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-c709254a-2d77-4171-849e-d8ed88509764,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1506251306-172.17.0.14-1595851861190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35695,DS-f143bfa6-2102-4d37-a1e7-5114621a48a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-943e992f-c9de-4ca4-b11d-2b0838989e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-fc099d7a-2d5e-4f16-8ce0-e9b50611eddb,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-38121802-83de-4590-8ad6-4e248bf4ef93,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-69e80699-215f-4077-b05b-cbc1fbb8ea92,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-eabb6629-9587-422a-9508-843b0ed4c6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-9960c1d3-4aa8-4084-a5d3-c44037e2729c,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-c709254a-2d77-4171-849e-d8ed88509764,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-173737650-172.17.0.14-1595852045789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44567,DS-03733729-3204-487b-aeee-00c1c66be923,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-a75a669b-d549-4e9e-993d-2a927e550bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-57931c12-2f33-4128-bd15-b4187c269ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-d03ed77b-3f2f-4ba0-87bc-cbb9db58392c,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-902b38bb-41a5-4df0-ad0c-dea614eb1eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-a8e1d503-2970-4272-b6d6-4ab2fc5906f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-74aeda02-3472-4329-9558-eec9d874646d,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-a7ce1ec3-feef-4a2b-b9c2-a90ced26a689,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-173737650-172.17.0.14-1595852045789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44567,DS-03733729-3204-487b-aeee-00c1c66be923,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-a75a669b-d549-4e9e-993d-2a927e550bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-57931c12-2f33-4128-bd15-b4187c269ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-d03ed77b-3f2f-4ba0-87bc-cbb9db58392c,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-902b38bb-41a5-4df0-ad0c-dea614eb1eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-a8e1d503-2970-4272-b6d6-4ab2fc5906f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-74aeda02-3472-4329-9558-eec9d874646d,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-a7ce1ec3-feef-4a2b-b9c2-a90ced26a689,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960303785-172.17.0.14-1595852782538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38759,DS-de703d02-05b2-4404-b6ec-0d3344c49e42,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-dcefd96b-f431-4336-9d96-ec2cd931460a,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-b7f41e55-bb26-4ccf-bf4b-efc99c81f162,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-85b37ea1-ce2b-4943-aa16-530fd3248a71,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-8f41db1e-e1cc-4e3c-85ba-4c58f88e978b,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-23edcf6b-8ad6-4034-b2cf-f8ad317dbf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-ddeecd2b-cb4f-48c5-99b5-9f28fa275bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-c185c0ea-73cc-4b3e-909b-2ac257fea588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960303785-172.17.0.14-1595852782538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38759,DS-de703d02-05b2-4404-b6ec-0d3344c49e42,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-dcefd96b-f431-4336-9d96-ec2cd931460a,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-b7f41e55-bb26-4ccf-bf4b-efc99c81f162,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-85b37ea1-ce2b-4943-aa16-530fd3248a71,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-8f41db1e-e1cc-4e3c-85ba-4c58f88e978b,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-23edcf6b-8ad6-4034-b2cf-f8ad317dbf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-ddeecd2b-cb4f-48c5-99b5-9f28fa275bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-c185c0ea-73cc-4b3e-909b-2ac257fea588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494263717-172.17.0.14-1595852823385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34251,DS-abd25487-8dba-4824-a264-af5bed4ab26a,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-92e2cc58-c2c4-4f46-86ec-edc8c921c18a,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-5b23e988-991b-4b2c-b652-b576ac05e1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-79bba168-12e1-4055-a62a-37bc21a921ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-75f6f060-dba1-402e-aa0c-e880441662b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-b1be99fd-80e7-4cf8-bf35-56c9d5dba6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-3c290b4f-1590-43a1-a58e-ad9313fec622,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-ba9a7591-cff9-40ab-a3e9-9f72d3622b76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494263717-172.17.0.14-1595852823385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34251,DS-abd25487-8dba-4824-a264-af5bed4ab26a,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-92e2cc58-c2c4-4f46-86ec-edc8c921c18a,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-5b23e988-991b-4b2c-b652-b576ac05e1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-79bba168-12e1-4055-a62a-37bc21a921ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-75f6f060-dba1-402e-aa0c-e880441662b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-b1be99fd-80e7-4cf8-bf35-56c9d5dba6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-3c290b4f-1590-43a1-a58e-ad9313fec622,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-ba9a7591-cff9-40ab-a3e9-9f72d3622b76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.max-packets-in-flight
component: hdfs:NameNode
v1: 80
v2: 80000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1741969704-172.17.0.14-1595852937997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42648,DS-b4f9510c-216d-41d0-92e2-9191f73b4eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-757ea451-ec57-44f7-ace4-c27831f4bd45,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-c5b63be3-f5c1-40f7-8c6f-b9de17db862d,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-27508df0-d3b0-445e-b36d-70e96c2d8a25,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-7918faee-20ab-479f-81f1-2641d6a91f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-ca0e89d3-88f5-4437-a57f-d3cd4c8e46e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-862c8693-4a17-4862-86e2-06064f0d96b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-48427aa1-3ca3-4e8b-8fc8-5c14482b7286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1741969704-172.17.0.14-1595852937997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42648,DS-b4f9510c-216d-41d0-92e2-9191f73b4eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-757ea451-ec57-44f7-ace4-c27831f4bd45,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-c5b63be3-f5c1-40f7-8c6f-b9de17db862d,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-27508df0-d3b0-445e-b36d-70e96c2d8a25,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-7918faee-20ab-479f-81f1-2641d6a91f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-ca0e89d3-88f5-4437-a57f-d3cd4c8e46e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-862c8693-4a17-4862-86e2-06064f0d96b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-48427aa1-3ca3-4e8b-8fc8-5c14482b7286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5665
