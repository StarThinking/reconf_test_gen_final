reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-521942093-172.17.0.12-1595877425663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43360,DS-18537b13-247b-48e6-87ab-be8fc09e7fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-4affb469-0642-447a-8f34-8a8f09614f83,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-986afabb-2aee-46bd-a30c-9dcfb2ca53fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-4461f980-52a0-48ca-b285-ad03384e9bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-d18d9af2-ccb7-4fd9-9e76-56ec53cb8494,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-8cc3dbe2-0203-4da4-8423-27bddfafd8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-95d94dc0-d325-4d3e-a40d-4b644cc5b8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-21b62fb5-30f3-4131-93a9-eafbca65d319,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-521942093-172.17.0.12-1595877425663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43360,DS-18537b13-247b-48e6-87ab-be8fc09e7fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-4affb469-0642-447a-8f34-8a8f09614f83,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-986afabb-2aee-46bd-a30c-9dcfb2ca53fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-4461f980-52a0-48ca-b285-ad03384e9bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-d18d9af2-ccb7-4fd9-9e76-56ec53cb8494,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-8cc3dbe2-0203-4da4-8423-27bddfafd8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-95d94dc0-d325-4d3e-a40d-4b644cc5b8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-21b62fb5-30f3-4131-93a9-eafbca65d319,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1596415193-172.17.0.12-1595877695041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41615,DS-c221ee9c-1346-478c-8cf4-0acea5cbdfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-56f9d9e5-62b9-4394-bee0-d0ccc8c193ed,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-98bf46c3-006d-492c-afe7-679d2774ddc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-75979eee-56b8-44f7-badb-8524cd568896,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-ea60376d-b73a-4b9e-b85c-3bca61008a43,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-5a03346e-adb2-45df-a390-9fb36783c6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-3f2fcaad-a218-42ca-9564-963d3556be7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-4df9011e-a728-4436-92bb-ca1b8a2f5f3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1596415193-172.17.0.12-1595877695041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41615,DS-c221ee9c-1346-478c-8cf4-0acea5cbdfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-56f9d9e5-62b9-4394-bee0-d0ccc8c193ed,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-98bf46c3-006d-492c-afe7-679d2774ddc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-75979eee-56b8-44f7-badb-8524cd568896,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-ea60376d-b73a-4b9e-b85c-3bca61008a43,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-5a03346e-adb2-45df-a390-9fb36783c6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-3f2fcaad-a218-42ca-9564-963d3556be7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-4df9011e-a728-4436-92bb-ca1b8a2f5f3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983055892-172.17.0.12-1595878079479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35128,DS-1f8976e7-1467-43e6-87ab-32e26e2299fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-563abffa-9f3c-49b9-a161-bff7ab0c3cef,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-e8f51c7b-0cd4-425b-b488-0307c8a09b23,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-519e852c-8df5-4bca-ada8-2b08b394fe72,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-92a30d8e-a49b-4db1-b464-ccbf5fc8a9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-864685ca-1ef2-4fab-b4df-af0dc2f2d2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-f0ce0779-301d-45b3-8d4a-56bc17ac5ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-89851668-65ae-4a34-8f02-2c2c9272c8e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983055892-172.17.0.12-1595878079479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35128,DS-1f8976e7-1467-43e6-87ab-32e26e2299fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-563abffa-9f3c-49b9-a161-bff7ab0c3cef,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-e8f51c7b-0cd4-425b-b488-0307c8a09b23,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-519e852c-8df5-4bca-ada8-2b08b394fe72,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-92a30d8e-a49b-4db1-b464-ccbf5fc8a9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-864685ca-1ef2-4fab-b4df-af0dc2f2d2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-f0ce0779-301d-45b3-8d4a-56bc17ac5ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-89851668-65ae-4a34-8f02-2c2c9272c8e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-448180754-172.17.0.12-1595878116481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42909,DS-6e61f1d9-b0b6-41cc-9d32-afc2b80b18c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-860ab943-dca6-4d95-8e3c-8965471792c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39383,DS-0a8e877a-bb99-4623-bfa7-f27841f705b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-ba1bc931-2470-4577-bf35-4518922186b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-fc3278e6-278b-4032-89d7-f795b0b8d544,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-8ffb192c-5366-4535-aca2-ce79c81c23ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-e055c2b8-871f-4533-9f05-64b158fc80a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-69074f78-1159-43fc-9f41-45e69b3b63ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-448180754-172.17.0.12-1595878116481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42909,DS-6e61f1d9-b0b6-41cc-9d32-afc2b80b18c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-860ab943-dca6-4d95-8e3c-8965471792c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39383,DS-0a8e877a-bb99-4623-bfa7-f27841f705b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-ba1bc931-2470-4577-bf35-4518922186b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-fc3278e6-278b-4032-89d7-f795b0b8d544,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-8ffb192c-5366-4535-aca2-ce79c81c23ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-e055c2b8-871f-4533-9f05-64b158fc80a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-69074f78-1159-43fc-9f41-45e69b3b63ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-479724936-172.17.0.12-1595878225625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32782,DS-be3c8dfc-ca42-4a22-9e23-a0631665a9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-8bb56a5a-068d-42ee-acea-03ca2ef54909,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-44fb122c-e47c-4f1b-87c6-17ca4f19eb46,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-539e3612-164e-41f9-8e44-0de695a0afb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-732c2f71-9722-456c-9c3c-3c0832846e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-ad2f97a0-be90-4e54-832f-25533fc7c5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-11bcd63e-6e36-4cc6-a680-efa90fca8c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-c898ed6d-879b-4482-a3cc-a0646c7346d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-479724936-172.17.0.12-1595878225625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32782,DS-be3c8dfc-ca42-4a22-9e23-a0631665a9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-8bb56a5a-068d-42ee-acea-03ca2ef54909,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-44fb122c-e47c-4f1b-87c6-17ca4f19eb46,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-539e3612-164e-41f9-8e44-0de695a0afb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-732c2f71-9722-456c-9c3c-3c0832846e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-ad2f97a0-be90-4e54-832f-25533fc7c5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-11bcd63e-6e36-4cc6-a680-efa90fca8c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-c898ed6d-879b-4482-a3cc-a0646c7346d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2055005642-172.17.0.12-1595878299521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40879,DS-0486537d-00ee-4118-8454-b6770bd4e7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-01fdd5fc-4b26-4b24-8b02-000e967f460f,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-2f27a311-0ea5-4fcb-88d0-9435973c0fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-578fa29d-1c69-4369-9bfc-51357fe092d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-210a2721-147f-421c-a32e-51d0e6d93cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-69b0fa91-2bc2-48e1-8e2c-3d2adf192b37,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-4cd26e8a-0f00-4a5f-b3aa-e4dfa22ae56c,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-b17b187c-8d60-4b45-808c-2f6032588c52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2055005642-172.17.0.12-1595878299521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40879,DS-0486537d-00ee-4118-8454-b6770bd4e7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-01fdd5fc-4b26-4b24-8b02-000e967f460f,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-2f27a311-0ea5-4fcb-88d0-9435973c0fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-578fa29d-1c69-4369-9bfc-51357fe092d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-210a2721-147f-421c-a32e-51d0e6d93cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-69b0fa91-2bc2-48e1-8e2c-3d2adf192b37,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-4cd26e8a-0f00-4a5f-b3aa-e4dfa22ae56c,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-b17b187c-8d60-4b45-808c-2f6032588c52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1729289353-172.17.0.12-1595878335931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43312,DS-3044d772-2dec-45b3-b85d-bc278e1a0e93,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-53f5ef19-bf17-4c13-b200-12e0a5681a30,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-edf2deb4-4165-4ebc-bf22-b49aadab9f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-f55d6755-5867-423d-abfc-8de4f4fa2e48,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-88517026-c859-45f8-a7a6-14b71e342ced,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-e38f0344-f83c-44f0-8113-c9766ccc4330,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-e0b2eb94-ed0b-48f6-bcde-0b928cae0b53,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-9728355a-627c-435b-8c0d-0c7b33cdac5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1729289353-172.17.0.12-1595878335931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43312,DS-3044d772-2dec-45b3-b85d-bc278e1a0e93,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-53f5ef19-bf17-4c13-b200-12e0a5681a30,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-edf2deb4-4165-4ebc-bf22-b49aadab9f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-f55d6755-5867-423d-abfc-8de4f4fa2e48,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-88517026-c859-45f8-a7a6-14b71e342ced,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-e38f0344-f83c-44f0-8113-c9766ccc4330,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-e0b2eb94-ed0b-48f6-bcde-0b928cae0b53,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-9728355a-627c-435b-8c0d-0c7b33cdac5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1980960820-172.17.0.12-1595878672272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33517,DS-6ea632b5-79ae-45bf-9b02-0c271a037a32,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-6dd5cdfd-89c4-429f-8fd6-bf40e0aa04b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-a0f98c99-c5e3-45aa-9429-7f47b021ef0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-9ba85ddd-7468-4015-878f-a7f5208a02e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-70992433-1ed5-4f07-a331-76c39012e7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-6e433355-f0c6-4b70-ab65-1ed85304dec2,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-1849c801-aca4-48c8-86d8-0e4910e85732,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-582a0fdc-328d-4341-9b0f-5d87b65c22c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1980960820-172.17.0.12-1595878672272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33517,DS-6ea632b5-79ae-45bf-9b02-0c271a037a32,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-6dd5cdfd-89c4-429f-8fd6-bf40e0aa04b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-a0f98c99-c5e3-45aa-9429-7f47b021ef0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-9ba85ddd-7468-4015-878f-a7f5208a02e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-70992433-1ed5-4f07-a331-76c39012e7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-6e433355-f0c6-4b70-ab65-1ed85304dec2,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-1849c801-aca4-48c8-86d8-0e4910e85732,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-582a0fdc-328d-4341-9b0f-5d87b65c22c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-323683024-172.17.0.12-1595878786540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40666,DS-e3739d7b-42eb-4b69-9708-326156f4d0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-09e41e37-62ec-4ac3-b699-921a4c82c5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-dd5eb59b-ca84-4700-92bf-2827ca3a7127,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-5836e542-9f3a-4085-b1f4-92ed16780d58,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-9339b3e6-b13e-469d-b0bd-1eb45e81311d,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-be31c3cb-4447-429c-8aad-96e4c5dba9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-dc61c668-8c69-4755-8f4f-3a75f97e317c,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-db33b729-64a0-4adc-8fcc-76782446c4da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-323683024-172.17.0.12-1595878786540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40666,DS-e3739d7b-42eb-4b69-9708-326156f4d0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-09e41e37-62ec-4ac3-b699-921a4c82c5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-dd5eb59b-ca84-4700-92bf-2827ca3a7127,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-5836e542-9f3a-4085-b1f4-92ed16780d58,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-9339b3e6-b13e-469d-b0bd-1eb45e81311d,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-be31c3cb-4447-429c-8aad-96e4c5dba9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-dc61c668-8c69-4755-8f4f-3a75f97e317c,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-db33b729-64a0-4adc-8fcc-76782446c4da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311235051-172.17.0.12-1595878994296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41635,DS-4c6ef684-d3df-4d1e-997b-d07f5cf0c624,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-e969ba6f-5021-4745-9de0-d36ea04264af,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-4c708b14-ecc9-4a21-9f0c-2c9ca1fe2bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-c0c5d8ef-0848-4c1b-a219-b6efadc8151d,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-f9990979-d03e-4c20-a93e-1b585428d01a,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-79ec2365-c8dc-4740-b1ca-2a245c3b59ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-62251b42-511d-4cfc-bc77-1d58fbe4fc26,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-29fe3540-088e-429a-9e39-153dc428ee75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311235051-172.17.0.12-1595878994296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41635,DS-4c6ef684-d3df-4d1e-997b-d07f5cf0c624,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-e969ba6f-5021-4745-9de0-d36ea04264af,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-4c708b14-ecc9-4a21-9f0c-2c9ca1fe2bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-c0c5d8ef-0848-4c1b-a219-b6efadc8151d,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-f9990979-d03e-4c20-a93e-1b585428d01a,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-79ec2365-c8dc-4740-b1ca-2a245c3b59ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-62251b42-511d-4cfc-bc77-1d58fbe4fc26,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-29fe3540-088e-429a-9e39-153dc428ee75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-375303892-172.17.0.12-1595879170800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41126,DS-32f09614-96f8-452f-bcb1-edd08c6e7786,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-01884b19-10e3-4724-b6aa-49ab6fe58c75,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-e3c9fec0-4569-42de-ad64-6d0b8f6983c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-b754e9e8-ac93-4661-b51f-f3472b972b66,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-8da67c81-efa3-43c2-94f9-d6876d70c7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-22b1c634-6020-4451-a375-19fbdc11dc30,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-085d9da1-ecd4-442f-ae43-f51377497459,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-33a7a3e3-d3b5-4c2b-b0b9-cb56eae54db6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-375303892-172.17.0.12-1595879170800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41126,DS-32f09614-96f8-452f-bcb1-edd08c6e7786,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-01884b19-10e3-4724-b6aa-49ab6fe58c75,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-e3c9fec0-4569-42de-ad64-6d0b8f6983c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-b754e9e8-ac93-4661-b51f-f3472b972b66,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-8da67c81-efa3-43c2-94f9-d6876d70c7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-22b1c634-6020-4451-a375-19fbdc11dc30,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-085d9da1-ecd4-442f-ae43-f51377497459,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-33a7a3e3-d3b5-4c2b-b0b9-cb56eae54db6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1738990435-172.17.0.12-1595879348184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35791,DS-66382593-27b9-406c-b259-81ab80feaec7,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-cfc3e597-a0ce-4d8e-b301-223b05f3b854,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-30d83a00-8380-4648-98d9-5334d11f38a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-d0c245ab-837d-45d3-9f5d-bfd6c8fc24f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-ee373dcc-3631-405d-8a13-d37b1b1d94a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-e03914ca-0b6c-4510-921a-5facdb7c517c,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-00006490-e9a3-43cf-9482-9a0638e99586,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-e97dfc81-b925-46c3-9f1e-6ee147b913b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1738990435-172.17.0.12-1595879348184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35791,DS-66382593-27b9-406c-b259-81ab80feaec7,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-cfc3e597-a0ce-4d8e-b301-223b05f3b854,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-30d83a00-8380-4648-98d9-5334d11f38a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-d0c245ab-837d-45d3-9f5d-bfd6c8fc24f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-ee373dcc-3631-405d-8a13-d37b1b1d94a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-e03914ca-0b6c-4510-921a-5facdb7c517c,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-00006490-e9a3-43cf-9482-9a0638e99586,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-e97dfc81-b925-46c3-9f1e-6ee147b913b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-140389180-172.17.0.12-1595879493692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46724,DS-673194fd-f6bd-4e68-b3a2-7a69750155e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-4c6dbecb-5c0e-4aed-b2eb-99c9845c18ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-2c14d8b3-a1a3-437a-b1a1-255a62036481,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-883bcde8-9948-46ad-a3e6-f20d6f1ae23f,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-2d113677-28ea-4ddf-8533-031ea50364a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-5f78e383-15e9-4994-8183-6db945c45d58,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-11781759-9c71-487d-8ff9-73e44c4fc75f,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-4c34b9d9-45d9-420b-9dfa-d6d1005e91cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-140389180-172.17.0.12-1595879493692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46724,DS-673194fd-f6bd-4e68-b3a2-7a69750155e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-4c6dbecb-5c0e-4aed-b2eb-99c9845c18ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-2c14d8b3-a1a3-437a-b1a1-255a62036481,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-883bcde8-9948-46ad-a3e6-f20d6f1ae23f,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-2d113677-28ea-4ddf-8533-031ea50364a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-5f78e383-15e9-4994-8183-6db945c45d58,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-11781759-9c71-487d-8ff9-73e44c4fc75f,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-4c34b9d9-45d9-420b-9dfa-d6d1005e91cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-871343332-172.17.0.12-1595879527478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40574,DS-3633a84e-2626-479d-817f-54e55b2d7bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-ea549a03-4fc3-4b3e-9e95-ed75d71cdecb,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-523e3b40-fd15-49b3-897f-d9f9d49e5feb,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-9e6a7c30-cb26-4038-b0b2-f905e419d393,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-42d84721-8b70-4caf-9c90-cdc7159b6379,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-87f377c2-c9ab-468a-bc73-15ede8601d74,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-14fefea9-0304-4e55-a5c4-27ed5dff3495,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-0cf8ebcc-c44a-4aed-8752-b4036602253f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-871343332-172.17.0.12-1595879527478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40574,DS-3633a84e-2626-479d-817f-54e55b2d7bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-ea549a03-4fc3-4b3e-9e95-ed75d71cdecb,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-523e3b40-fd15-49b3-897f-d9f9d49e5feb,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-9e6a7c30-cb26-4038-b0b2-f905e419d393,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-42d84721-8b70-4caf-9c90-cdc7159b6379,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-87f377c2-c9ab-468a-bc73-15ede8601d74,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-14fefea9-0304-4e55-a5c4-27ed5dff3495,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-0cf8ebcc-c44a-4aed-8752-b4036602253f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-362444152-172.17.0.12-1595879743387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34567,DS-177f5b72-d0a0-48fd-a6cc-588a24093c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-a38a6a80-8224-4eba-a544-1cc3e10309e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-c5aa1cef-05e5-48a3-88e7-62dff602a702,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-ab48d6d0-0399-42d0-a41b-b6851327eacf,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-c2852031-194e-427d-9ad2-349c28234a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-63ab3541-bb19-480c-a5e9-ab3a18e7a255,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-7aa03b7d-3aa4-4032-ad18-be1787202c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-e35ba91f-b00f-4d67-9310-76f0aa1d54ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-362444152-172.17.0.12-1595879743387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34567,DS-177f5b72-d0a0-48fd-a6cc-588a24093c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-a38a6a80-8224-4eba-a544-1cc3e10309e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-c5aa1cef-05e5-48a3-88e7-62dff602a702,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-ab48d6d0-0399-42d0-a41b-b6851327eacf,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-c2852031-194e-427d-9ad2-349c28234a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-63ab3541-bb19-480c-a5e9-ab3a18e7a255,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-7aa03b7d-3aa4-4032-ad18-be1787202c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-e35ba91f-b00f-4d67-9310-76f0aa1d54ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1477601476-172.17.0.12-1595879814656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37602,DS-1ed98dcc-6d76-48c7-9b73-05b3631dfdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-bfcb4685-a050-498d-8283-69126fc61818,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-a00e2f92-2cc2-4419-b118-8f259e728275,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-63605e35-ebc0-4cfe-9d23-f8ef3b487378,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-2e2fe97c-2a29-4874-a0e9-34352ee253ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-a83ef139-62ce-47a0-885b-1ddcb2b2b552,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-147b9854-6de3-4b4f-b278-dbd2554f02b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-c2e1ec7a-ef92-40ed-a94f-b3c2b451b251,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1477601476-172.17.0.12-1595879814656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37602,DS-1ed98dcc-6d76-48c7-9b73-05b3631dfdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-bfcb4685-a050-498d-8283-69126fc61818,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-a00e2f92-2cc2-4419-b118-8f259e728275,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-63605e35-ebc0-4cfe-9d23-f8ef3b487378,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-2e2fe97c-2a29-4874-a0e9-34352ee253ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-a83ef139-62ce-47a0-885b-1ddcb2b2b552,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-147b9854-6de3-4b4f-b278-dbd2554f02b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-c2e1ec7a-ef92-40ed-a94f-b3c2b451b251,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-585542303-172.17.0.12-1595880150460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46539,DS-85cfb26a-7a97-448f-b9fc-f862b24d756d,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-25194f42-bed0-481d-a334-e031076c710e,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-fb870e6c-c35e-4cb9-98ff-5075cd987442,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-679e2f4e-ef32-4f4b-bd5f-1a3849cab35e,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-0c40ee94-efae-45ea-b397-ecc4a2a61c00,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-65ad9697-9111-43cf-bbbf-b0ae96364248,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-7fe41615-edde-4ebd-9329-4cb706117619,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-cfb90087-82a0-4469-950d-767b1cde1fcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-585542303-172.17.0.12-1595880150460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46539,DS-85cfb26a-7a97-448f-b9fc-f862b24d756d,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-25194f42-bed0-481d-a334-e031076c710e,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-fb870e6c-c35e-4cb9-98ff-5075cd987442,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-679e2f4e-ef32-4f4b-bd5f-1a3849cab35e,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-0c40ee94-efae-45ea-b397-ecc4a2a61c00,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-65ad9697-9111-43cf-bbbf-b0ae96364248,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-7fe41615-edde-4ebd-9329-4cb706117619,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-cfb90087-82a0-4469-950d-767b1cde1fcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490404828-172.17.0.12-1595880413675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35437,DS-9a7ce190-2733-4c05-bcdb-74c5eec8550c,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-67417fb6-e68c-4a05-a2d9-e25029ab0571,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-3ec91fdd-1a1e-4230-b04e-9d4bbfef1801,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-43fbcdb3-6dd5-40eb-8182-27ef12b3f0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-6b8f9069-f170-461a-b890-f39b1b1929ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-0a4ec2c4-a453-4c2e-b013-41255c77eb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-4b723eb4-1955-4a45-aa53-7b06d56716e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-8fdaf42f-ea86-49b5-bb30-ed33ee586cd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490404828-172.17.0.12-1595880413675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35437,DS-9a7ce190-2733-4c05-bcdb-74c5eec8550c,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-67417fb6-e68c-4a05-a2d9-e25029ab0571,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-3ec91fdd-1a1e-4230-b04e-9d4bbfef1801,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-43fbcdb3-6dd5-40eb-8182-27ef12b3f0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-6b8f9069-f170-461a-b890-f39b1b1929ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-0a4ec2c4-a453-4c2e-b013-41255c77eb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-4b723eb4-1955-4a45-aa53-7b06d56716e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-8fdaf42f-ea86-49b5-bb30-ed33ee586cd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1558084420-172.17.0.12-1595880620875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42182,DS-7623eb18-ee8e-462e-a750-b81b4028343a,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-156e4d21-d9f1-4eac-a25b-ec51d41b0c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-f7f1cdc7-8202-4c8b-a8df-9b3464184b59,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-0f02e22e-746c-498a-99f1-c9e8a4a64b17,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-e1698c8e-fa79-4de1-a300-48f84e6a30ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-9b1a9ffd-f8ea-410f-945d-05b57897984e,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-09a21b8d-cc21-4ad2-be91-2a9fe3cde947,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-657391b7-238d-475f-a2eb-44107f05502f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1558084420-172.17.0.12-1595880620875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42182,DS-7623eb18-ee8e-462e-a750-b81b4028343a,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-156e4d21-d9f1-4eac-a25b-ec51d41b0c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-f7f1cdc7-8202-4c8b-a8df-9b3464184b59,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-0f02e22e-746c-498a-99f1-c9e8a4a64b17,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-e1698c8e-fa79-4de1-a300-48f84e6a30ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-9b1a9ffd-f8ea-410f-945d-05b57897984e,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-09a21b8d-cc21-4ad2-be91-2a9fe3cde947,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-657391b7-238d-475f-a2eb-44107f05502f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756026418-172.17.0.12-1595880945467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35357,DS-a05c5b1d-398b-4593-b5b6-fd41fd63b3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-de435bd3-8d04-4448-a8b6-4d91fc744c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-60b0f934-c3bc-4801-a62e-160460c31743,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-ea405740-3e04-4842-ab56-d03332c00cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-c8fe381e-1f1d-4e8e-95b5-7b5b0ff9f6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-b5b3b6c2-b9e2-48e3-8310-5d31f95a8732,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-a6057a1f-7fc0-4941-af29-a57603c05ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-75553810-624d-4ad8-8c92-ec4fda7d2e48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756026418-172.17.0.12-1595880945467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35357,DS-a05c5b1d-398b-4593-b5b6-fd41fd63b3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-de435bd3-8d04-4448-a8b6-4d91fc744c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-60b0f934-c3bc-4801-a62e-160460c31743,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-ea405740-3e04-4842-ab56-d03332c00cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-c8fe381e-1f1d-4e8e-95b5-7b5b0ff9f6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-b5b3b6c2-b9e2-48e3-8310-5d31f95a8732,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-a6057a1f-7fc0-4941-af29-a57603c05ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-75553810-624d-4ad8-8c92-ec4fda7d2e48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-998530809-172.17.0.12-1595881470304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45152,DS-329ee120-b791-49be-ad4b-34d087482638,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-d6284d62-0fb3-43ba-be33-229f019f5589,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-68c13efe-071e-44eb-bcd9-b489a73b9e02,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-c43a7977-be06-4a28-847d-b5d8effb6743,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-3a95bd63-3361-44f6-ae9f-c1e764cf5a14,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-b2f9ac8f-38fb-4134-b8ae-32aa76531e29,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-92194093-7ef0-43bc-8ef8-6ecf348c914e,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-461fa2ae-32b1-4680-9ae1-c30ce6660279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-998530809-172.17.0.12-1595881470304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45152,DS-329ee120-b791-49be-ad4b-34d087482638,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-d6284d62-0fb3-43ba-be33-229f019f5589,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-68c13efe-071e-44eb-bcd9-b489a73b9e02,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-c43a7977-be06-4a28-847d-b5d8effb6743,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-3a95bd63-3361-44f6-ae9f-c1e764cf5a14,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-b2f9ac8f-38fb-4134-b8ae-32aa76531e29,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-92194093-7ef0-43bc-8ef8-6ecf348c914e,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-461fa2ae-32b1-4680-9ae1-c30ce6660279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-539834938-172.17.0.12-1595881549449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33476,DS-89753179-86e3-41cb-b77e-f504b4ff2208,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-8783e059-6fb9-4dfc-99a8-8e475abaa58c,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-7642361f-43ea-41be-a8b8-e8a454076057,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-5eb00196-9760-4a3d-92d0-e51b895e669b,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-8aaf2967-8a21-41db-aaa5-9e2152e22464,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-198b054f-4f32-4445-b572-7cdf375c97c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-314c186a-4379-4f55-babb-9b8cc0681790,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-ca164f45-85f2-45e5-b904-69978f55267e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-539834938-172.17.0.12-1595881549449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33476,DS-89753179-86e3-41cb-b77e-f504b4ff2208,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-8783e059-6fb9-4dfc-99a8-8e475abaa58c,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-7642361f-43ea-41be-a8b8-e8a454076057,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-5eb00196-9760-4a3d-92d0-e51b895e669b,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-8aaf2967-8a21-41db-aaa5-9e2152e22464,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-198b054f-4f32-4445-b572-7cdf375c97c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-314c186a-4379-4f55-babb-9b8cc0681790,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-ca164f45-85f2-45e5-b904-69978f55267e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1247698551-172.17.0.12-1595881651760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45178,DS-870bab10-d395-46b2-98df-93abbfdf20cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-4e7290df-1246-484f-87cc-b962f6a4a5db,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-d09e282e-836d-46e2-8f22-60fd500bd7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-cde7daed-96bc-49ff-bc17-3c3785a3fdc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-98813029-75eb-4a9b-a7bd-7bf454905f04,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-d68b07d6-0086-4873-8a02-4d7d4f6f849e,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-f7dd4b11-e580-4256-85c4-70d1feb61074,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-e9476a7b-ee63-4835-9c4a-8ce8afa1301e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1247698551-172.17.0.12-1595881651760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45178,DS-870bab10-d395-46b2-98df-93abbfdf20cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-4e7290df-1246-484f-87cc-b962f6a4a5db,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-d09e282e-836d-46e2-8f22-60fd500bd7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-cde7daed-96bc-49ff-bc17-3c3785a3fdc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-98813029-75eb-4a9b-a7bd-7bf454905f04,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-d68b07d6-0086-4873-8a02-4d7d4f6f849e,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-f7dd4b11-e580-4256-85c4-70d1feb61074,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-e9476a7b-ee63-4835-9c4a-8ce8afa1301e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680255826-172.17.0.12-1595882153400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35603,DS-ab88e73b-4fc6-466f-b33d-bbe34a878d80,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-e93480ae-cb3c-4dda-a859-6bb9403a185c,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-c969bf7c-8ace-4608-8e7d-d4061cac0bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-cbb35bfd-789d-44ab-a52d-85dada2ea520,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-e472d820-2260-49f7-9335-8a34bd738e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-48496f59-2c7e-4b10-bcdb-f266dce483d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-bbdc32a3-a1f5-4413-b20a-032e112f6e73,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-2e1eee34-078d-43f6-ace3-8ae0bb5c96dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680255826-172.17.0.12-1595882153400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35603,DS-ab88e73b-4fc6-466f-b33d-bbe34a878d80,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-e93480ae-cb3c-4dda-a859-6bb9403a185c,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-c969bf7c-8ace-4608-8e7d-d4061cac0bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-cbb35bfd-789d-44ab-a52d-85dada2ea520,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-e472d820-2260-49f7-9335-8a34bd738e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-48496f59-2c7e-4b10-bcdb-f266dce483d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-bbdc32a3-a1f5-4413-b20a-032e112f6e73,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-2e1eee34-078d-43f6-ace3-8ae0bb5c96dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5351
