reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2070458162-172.17.0.4-1595932801684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35912,DS-4ceec7b4-b506-44a1-bfcd-0e7de86bfa5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-78adbaff-497e-4a05-8fc3-1d257a0a8f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-0c5495e5-59c7-4d54-ad40-712ec6f8f012,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-3700f714-818e-4d1b-95de-c842b1370375,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-623b2a58-2332-41c0-93a3-5f2363cfe049,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-e9504e4c-12d1-403b-92da-e668b8d6d477,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-dd0ce778-db04-48ed-83c7-5d0fde539c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-41becb40-16fb-42e9-be83-44e3724f1dd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2070458162-172.17.0.4-1595932801684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35912,DS-4ceec7b4-b506-44a1-bfcd-0e7de86bfa5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-78adbaff-497e-4a05-8fc3-1d257a0a8f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-0c5495e5-59c7-4d54-ad40-712ec6f8f012,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-3700f714-818e-4d1b-95de-c842b1370375,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-623b2a58-2332-41c0-93a3-5f2363cfe049,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-e9504e4c-12d1-403b-92da-e668b8d6d477,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-dd0ce778-db04-48ed-83c7-5d0fde539c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-41becb40-16fb-42e9-be83-44e3724f1dd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244103037-172.17.0.4-1595933278761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37962,DS-d65437cd-b51c-4b1a-9efe-c82e1ecc9c28,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-d0604491-3ad4-449e-946e-cb420f19785b,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-04627056-1c9a-4e33-a25d-5072c6d63de4,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-ee3df6d3-c1db-48f4-94b0-c53f5686d558,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-be087e4a-72dd-4154-9ae8-94c15d8c87d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-a5b967fa-c53e-41fd-b9d2-4176a0aa82d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-c56c1374-a26c-4b8c-b68f-abc18de01874,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-a81634ff-5a9b-4868-9c31-7146fe39cd20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244103037-172.17.0.4-1595933278761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37962,DS-d65437cd-b51c-4b1a-9efe-c82e1ecc9c28,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-d0604491-3ad4-449e-946e-cb420f19785b,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-04627056-1c9a-4e33-a25d-5072c6d63de4,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-ee3df6d3-c1db-48f4-94b0-c53f5686d558,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-be087e4a-72dd-4154-9ae8-94c15d8c87d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-a5b967fa-c53e-41fd-b9d2-4176a0aa82d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-c56c1374-a26c-4b8c-b68f-abc18de01874,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-a81634ff-5a9b-4868-9c31-7146fe39cd20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397707523-172.17.0.4-1595933356951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42557,DS-c262da14-29a0-4bd6-864f-4d940def5078,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-645e7d48-2f5e-4398-ba66-f06a4bef28b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-116b1b37-e4d2-40c8-9857-61f7f44588d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-51e7ea2c-3235-45bd-ad8e-990c6ec61acb,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-58c3e821-446e-4db2-875a-cf2d18623893,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-8e9e5de0-2374-4568-b3eb-da949a68c993,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-e7243f8b-f1e8-433c-9db9-3c09b40a1de4,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-f5058068-d3cd-4dcf-ad4d-2769a1aec15a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397707523-172.17.0.4-1595933356951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42557,DS-c262da14-29a0-4bd6-864f-4d940def5078,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-645e7d48-2f5e-4398-ba66-f06a4bef28b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-116b1b37-e4d2-40c8-9857-61f7f44588d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-51e7ea2c-3235-45bd-ad8e-990c6ec61acb,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-58c3e821-446e-4db2-875a-cf2d18623893,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-8e9e5de0-2374-4568-b3eb-da949a68c993,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-e7243f8b-f1e8-433c-9db9-3c09b40a1de4,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-f5058068-d3cd-4dcf-ad4d-2769a1aec15a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238384388-172.17.0.4-1595933447875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35610,DS-5cd0dee0-9fb5-4117-a063-aa88c46496a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-bbe45ebb-01f1-4188-b109-f09d16c32f41,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-fdb3337f-d0a1-4b69-a716-8b5bda2b4597,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-774a1845-33c0-4752-ab92-bd64429caf77,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-b4182133-c934-4215-b95c-38d23dcbecd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-4aa161d3-2e02-4ed4-a4a7-9f95bde8e1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-594e56a9-ab5d-4c96-9cb5-3ad06b24aa77,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-ffd4cd7b-c529-4135-a13e-16942ba1651f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238384388-172.17.0.4-1595933447875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35610,DS-5cd0dee0-9fb5-4117-a063-aa88c46496a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-bbe45ebb-01f1-4188-b109-f09d16c32f41,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-fdb3337f-d0a1-4b69-a716-8b5bda2b4597,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-774a1845-33c0-4752-ab92-bd64429caf77,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-b4182133-c934-4215-b95c-38d23dcbecd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-4aa161d3-2e02-4ed4-a4a7-9f95bde8e1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-594e56a9-ab5d-4c96-9cb5-3ad06b24aa77,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-ffd4cd7b-c529-4135-a13e-16942ba1651f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872129375-172.17.0.4-1595933632415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37647,DS-5b363b44-abb5-4a77-bffe-43080fe310b2,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-e962d37a-253e-45ea-9de2-092654431ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-532fa355-7dff-4910-8cde-7a0848de8495,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-b21e4e9a-d9b0-4258-a87d-2e8d3228600b,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-3dc7ece9-ca6d-47a6-baa3-7c740652560b,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-73cbf9a3-8b4f-4208-9ebb-e92c48f078d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-ea288966-026c-4090-b468-2566c010f60d,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-20e21ede-7c54-4c00-985c-33c15befb891,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872129375-172.17.0.4-1595933632415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37647,DS-5b363b44-abb5-4a77-bffe-43080fe310b2,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-e962d37a-253e-45ea-9de2-092654431ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-532fa355-7dff-4910-8cde-7a0848de8495,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-b21e4e9a-d9b0-4258-a87d-2e8d3228600b,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-3dc7ece9-ca6d-47a6-baa3-7c740652560b,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-73cbf9a3-8b4f-4208-9ebb-e92c48f078d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-ea288966-026c-4090-b468-2566c010f60d,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-20e21ede-7c54-4c00-985c-33c15befb891,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418772754-172.17.0.4-1595934401472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34734,DS-774c86ba-2b9f-42ff-803f-27a7eb4d9e14,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-0ec93349-8b1e-4dc0-9402-0d3e3480fac1,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-6b7c0452-e9cf-4451-9119-25700d964f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-b9c5cc72-4582-4bef-92c0-7bdb523b45e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-a8dfe36f-0ec4-4961-97d4-9b302b700dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-10610b68-eb5f-4db5-8117-66761b9151a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-b3838ff9-3c45-4627-9382-0f4a83ed6cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-bd667180-9880-4e99-966b-f135e16ff78b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418772754-172.17.0.4-1595934401472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34734,DS-774c86ba-2b9f-42ff-803f-27a7eb4d9e14,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-0ec93349-8b1e-4dc0-9402-0d3e3480fac1,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-6b7c0452-e9cf-4451-9119-25700d964f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-b9c5cc72-4582-4bef-92c0-7bdb523b45e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-a8dfe36f-0ec4-4961-97d4-9b302b700dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-10610b68-eb5f-4db5-8117-66761b9151a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-b3838ff9-3c45-4627-9382-0f4a83ed6cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-bd667180-9880-4e99-966b-f135e16ff78b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160014166-172.17.0.4-1595936228335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41142,DS-b625436b-16ce-4980-beaa-cfc80a1e2a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-33a9db93-652c-4d77-80b4-b9504f7e6bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-b893180a-df5f-4884-89b6-229882363a54,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-9a83fd76-2a03-4fc3-93b1-086eb0286afd,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-86016983-be3e-479b-8a08-99824f103a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-439939d1-57c9-4369-98d7-c1ef12e7ef64,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-6bb8fe7a-be80-4e8c-a84e-84a70a184f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-9f9a8756-f70e-4b97-8a75-9edfbcf4420f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160014166-172.17.0.4-1595936228335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41142,DS-b625436b-16ce-4980-beaa-cfc80a1e2a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-33a9db93-652c-4d77-80b4-b9504f7e6bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-b893180a-df5f-4884-89b6-229882363a54,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-9a83fd76-2a03-4fc3-93b1-086eb0286afd,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-86016983-be3e-479b-8a08-99824f103a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-439939d1-57c9-4369-98d7-c1ef12e7ef64,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-6bb8fe7a-be80-4e8c-a84e-84a70a184f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-9f9a8756-f70e-4b97-8a75-9edfbcf4420f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414608636-172.17.0.4-1595936698273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35056,DS-e21f78ae-122e-412c-903f-e4946dd1e55f,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-6a125b88-5a2f-4af7-bab1-735297914931,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-fa482cee-3b05-4b5f-bc93-862aa9e7b407,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-39a0236f-6660-494e-bdb4-1ecf41263ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-8e67f0bb-2a95-4894-bff6-466540167344,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-2519a48f-1527-4ed7-8578-c7de505e6f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-3309571c-4f9b-4763-84d2-cef8c5599cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-01d7f7c7-e27c-4bb6-b520-543550e7df68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414608636-172.17.0.4-1595936698273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35056,DS-e21f78ae-122e-412c-903f-e4946dd1e55f,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-6a125b88-5a2f-4af7-bab1-735297914931,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-fa482cee-3b05-4b5f-bc93-862aa9e7b407,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-39a0236f-6660-494e-bdb4-1ecf41263ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-8e67f0bb-2a95-4894-bff6-466540167344,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-2519a48f-1527-4ed7-8578-c7de505e6f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-3309571c-4f9b-4763-84d2-cef8c5599cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-01d7f7c7-e27c-4bb6-b520-543550e7df68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-989090218-172.17.0.4-1595936975085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46165,DS-48d4084b-a605-4d3a-8d7e-169dbb218394,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-ee248a75-a457-4292-b8cc-a6c3ed0d7095,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-55d859d3-2920-4f0c-b8ec-1e602cc169d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-9b236742-1e84-43c5-90ea-b035f74cbd18,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-764caf62-0a7c-41ac-afc1-172ea2d4530a,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-36d8405b-4e7a-4ad2-a021-d8fbc3c67d95,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-4fe9001b-b1e3-4c80-842d-42232412eb73,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-3620ab90-d18c-40f6-bf97-baa6c386b465,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-989090218-172.17.0.4-1595936975085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46165,DS-48d4084b-a605-4d3a-8d7e-169dbb218394,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-ee248a75-a457-4292-b8cc-a6c3ed0d7095,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-55d859d3-2920-4f0c-b8ec-1e602cc169d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-9b236742-1e84-43c5-90ea-b035f74cbd18,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-764caf62-0a7c-41ac-afc1-172ea2d4530a,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-36d8405b-4e7a-4ad2-a021-d8fbc3c67d95,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-4fe9001b-b1e3-4c80-842d-42232412eb73,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-3620ab90-d18c-40f6-bf97-baa6c386b465,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-646918628-172.17.0.4-1595937016316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45592,DS-4ce0a62e-a505-49d2-b1db-6f8c75d3e6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-9625fcd0-e9eb-4610-968d-55654bf5f8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-aa44d2e7-9d28-4930-a942-9264cd2e0f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-ed466d2a-acf4-4cfa-8f32-23df92170e16,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-47ed8701-695a-4b8d-bfd9-4c9e8a82d3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-a2dc5e27-bb32-44d2-be77-eeced44cb705,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-3c500fbe-d148-4315-a553-91dd932f9b41,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-b8c23cf6-d184-4c6a-98c1-7dee8957459d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-646918628-172.17.0.4-1595937016316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45592,DS-4ce0a62e-a505-49d2-b1db-6f8c75d3e6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-9625fcd0-e9eb-4610-968d-55654bf5f8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-aa44d2e7-9d28-4930-a942-9264cd2e0f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-ed466d2a-acf4-4cfa-8f32-23df92170e16,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-47ed8701-695a-4b8d-bfd9-4c9e8a82d3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-a2dc5e27-bb32-44d2-be77-eeced44cb705,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-3c500fbe-d148-4315-a553-91dd932f9b41,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-b8c23cf6-d184-4c6a-98c1-7dee8957459d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700647845-172.17.0.4-1595937237320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42435,DS-3cc4867e-5eec-436e-81bf-278881ea2816,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-774d5a4f-bd65-4dd6-85a4-188ba8005949,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-9d4fbe19-f005-496a-879b-ddc2c6ca5a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-e0eae0f4-9874-46a6-bf02-e911c749c462,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-c0b480c1-ea44-4344-a55b-cceec929129c,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-02fc8bc2-9049-410c-a349-67a8611792d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-4e5310fa-af60-4c4e-b2cd-d69d89a9dafc,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-7099ad52-6be3-4dc0-8438-95913c5ed1a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700647845-172.17.0.4-1595937237320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42435,DS-3cc4867e-5eec-436e-81bf-278881ea2816,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-774d5a4f-bd65-4dd6-85a4-188ba8005949,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-9d4fbe19-f005-496a-879b-ddc2c6ca5a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-e0eae0f4-9874-46a6-bf02-e911c749c462,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-c0b480c1-ea44-4344-a55b-cceec929129c,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-02fc8bc2-9049-410c-a349-67a8611792d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-4e5310fa-af60-4c4e-b2cd-d69d89a9dafc,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-7099ad52-6be3-4dc0-8438-95913c5ed1a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143128212-172.17.0.4-1595937415363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34755,DS-dbc8fcf5-7bd1-44f8-a73c-8f9741a2dbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-edbb13c5-fea7-42fb-8566-cd5596c1a447,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-22b1f2a8-c247-4743-8e65-3323e1168635,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-ad7175e2-9a7d-4b5f-a16f-c02b97487300,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-7353ea45-e0cf-4ebe-ac10-6e010fa1da22,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-9d0897b5-7331-4eae-ab9a-12962d5c9939,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-8bb80b7d-ab88-4120-95d7-2bd8a45fd36b,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-f11c5150-f9d6-4051-83b3-ee65df3633cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143128212-172.17.0.4-1595937415363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34755,DS-dbc8fcf5-7bd1-44f8-a73c-8f9741a2dbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-edbb13c5-fea7-42fb-8566-cd5596c1a447,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-22b1f2a8-c247-4743-8e65-3323e1168635,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-ad7175e2-9a7d-4b5f-a16f-c02b97487300,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-7353ea45-e0cf-4ebe-ac10-6e010fa1da22,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-9d0897b5-7331-4eae-ab9a-12962d5c9939,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-8bb80b7d-ab88-4120-95d7-2bd8a45fd36b,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-f11c5150-f9d6-4051-83b3-ee65df3633cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90996426-172.17.0.4-1595937463257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46664,DS-22d87365-7279-4c36-a0ac-99307cf169f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-dabc6840-6989-48b5-94ca-c8d293abd9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-f480d42f-2ac7-4cea-bee1-10eed5928b09,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-bfebc08c-f5c9-40c9-95c8-9e8a355fb727,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-7903103b-d859-4344-8218-c1527ec37c09,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-cbcd969e-8509-44e7-a54e-8cc78fcb8a77,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-8144b825-c33f-4dd9-997f-a3eae34e9f11,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-314d10e0-6d95-45e6-b21f-5bfe425d362e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90996426-172.17.0.4-1595937463257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46664,DS-22d87365-7279-4c36-a0ac-99307cf169f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-dabc6840-6989-48b5-94ca-c8d293abd9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-f480d42f-2ac7-4cea-bee1-10eed5928b09,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-bfebc08c-f5c9-40c9-95c8-9e8a355fb727,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-7903103b-d859-4344-8218-c1527ec37c09,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-cbcd969e-8509-44e7-a54e-8cc78fcb8a77,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-8144b825-c33f-4dd9-997f-a3eae34e9f11,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-314d10e0-6d95-45e6-b21f-5bfe425d362e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143092209-172.17.0.4-1595937501193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38387,DS-98bf973f-6e29-41fa-b6c0-1faf237271ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-7685c1cb-e798-431c-be28-4d3d0fb200f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-be6b2974-cafc-4a4f-a2b8-d27cea821b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-adc32466-93cb-4c4d-ab41-368ddede295e,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-a8aa2897-8490-49a8-910a-b567770bb7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-72b277f1-3cc9-4792-bf63-a0a5c31f50bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-7f8e76df-96b5-478f-a06a-bb271e4230f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-6b8a6a54-c655-4b25-90bd-779b902110cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143092209-172.17.0.4-1595937501193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38387,DS-98bf973f-6e29-41fa-b6c0-1faf237271ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-7685c1cb-e798-431c-be28-4d3d0fb200f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-be6b2974-cafc-4a4f-a2b8-d27cea821b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-adc32466-93cb-4c4d-ab41-368ddede295e,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-a8aa2897-8490-49a8-910a-b567770bb7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-72b277f1-3cc9-4792-bf63-a0a5c31f50bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-7f8e76df-96b5-478f-a06a-bb271e4230f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-6b8a6a54-c655-4b25-90bd-779b902110cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403596914-172.17.0.4-1595938142413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37818,DS-0e0b74b0-3185-4e78-98cf-42675b77ba8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-2ff25f53-727f-4187-86b3-b2b218c012b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-cda9cc01-abb8-4b8e-be7a-456be22ee4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-49552b83-3915-4a70-8426-27a786cc0b37,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-c2add188-c855-4fc5-9f49-f22a4c6bfc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-9fba6f72-842e-4066-ad8f-59769d00d5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-a0e532e7-2d89-4b14-8a7f-c3ffce0f451b,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-e3c166ad-1de1-4777-9209-f697bc15f08b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403596914-172.17.0.4-1595938142413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37818,DS-0e0b74b0-3185-4e78-98cf-42675b77ba8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-2ff25f53-727f-4187-86b3-b2b218c012b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-cda9cc01-abb8-4b8e-be7a-456be22ee4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-49552b83-3915-4a70-8426-27a786cc0b37,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-c2add188-c855-4fc5-9f49-f22a4c6bfc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-9fba6f72-842e-4066-ad8f-59769d00d5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-a0e532e7-2d89-4b14-8a7f-c3ffce0f451b,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-e3c166ad-1de1-4777-9209-f697bc15f08b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165613237-172.17.0.4-1595938268915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41393,DS-80104870-2627-4ec4-aebc-258ef2eddad9,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-c3a6e335-5329-466e-9647-921fe8ee5791,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-c04e0273-b1d9-4f26-9232-ac9e8e86cfab,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-028b9b00-0cd1-4dd7-a2da-92128ecf3bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-698d49dc-9d52-405b-ba51-e37afe0636df,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-94c38334-be7d-4de1-879b-e2c3f1e50190,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-63158b90-f606-4ab0-9035-191a18d9115f,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-195b086f-2e26-47f4-a154-e4670767ca81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165613237-172.17.0.4-1595938268915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41393,DS-80104870-2627-4ec4-aebc-258ef2eddad9,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-c3a6e335-5329-466e-9647-921fe8ee5791,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-c04e0273-b1d9-4f26-9232-ac9e8e86cfab,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-028b9b00-0cd1-4dd7-a2da-92128ecf3bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-698d49dc-9d52-405b-ba51-e37afe0636df,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-94c38334-be7d-4de1-879b-e2c3f1e50190,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-63158b90-f606-4ab0-9035-191a18d9115f,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-195b086f-2e26-47f4-a154-e4670767ca81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1414322686-172.17.0.4-1595938526991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32943,DS-00ae4645-3422-4e0b-b70b-82ee9845f093,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-ce869682-b552-4517-bc92-5e0f901640bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-fce0e3f7-9014-4898-8be4-b6d22b6c9db6,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-e698e7a4-95b6-4432-96c3-e6b2c5d51220,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-f9d3b0a0-b753-40a5-a66a-a26247f268e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-0153e6d7-957c-4269-a976-eb1434256cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-a688cfc3-6f1b-4f3b-aec3-7eb14a695282,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-4ab73012-d1d1-43bd-8464-7be05c83aa90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1414322686-172.17.0.4-1595938526991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32943,DS-00ae4645-3422-4e0b-b70b-82ee9845f093,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-ce869682-b552-4517-bc92-5e0f901640bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-fce0e3f7-9014-4898-8be4-b6d22b6c9db6,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-e698e7a4-95b6-4432-96c3-e6b2c5d51220,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-f9d3b0a0-b753-40a5-a66a-a26247f268e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-0153e6d7-957c-4269-a976-eb1434256cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-a688cfc3-6f1b-4f3b-aec3-7eb14a695282,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-4ab73012-d1d1-43bd-8464-7be05c83aa90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-691660310-172.17.0.4-1595938566220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46543,DS-fa830ffd-900e-4b55-8223-4271c9b8cb20,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-38efb0a7-03a2-4afd-bc6c-7308030c04f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-3079bdb5-bb97-4430-b5f0-4c1ecfc2265d,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-8de9e935-d82f-4fcd-9070-4cb90c41fb36,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-64305724-d3e9-41f8-aeae-02d3c15e28a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-a9f33566-50d5-4ca2-80a7-249b4d14695a,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-3befa6c6-608f-4aad-8e2c-e4a37537f93a,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-0305cb9e-44e1-4654-ba1b-d797209136d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-691660310-172.17.0.4-1595938566220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46543,DS-fa830ffd-900e-4b55-8223-4271c9b8cb20,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-38efb0a7-03a2-4afd-bc6c-7308030c04f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-3079bdb5-bb97-4430-b5f0-4c1ecfc2265d,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-8de9e935-d82f-4fcd-9070-4cb90c41fb36,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-64305724-d3e9-41f8-aeae-02d3c15e28a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-a9f33566-50d5-4ca2-80a7-249b4d14695a,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-3befa6c6-608f-4aad-8e2c-e4a37537f93a,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-0305cb9e-44e1-4654-ba1b-d797209136d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6632
