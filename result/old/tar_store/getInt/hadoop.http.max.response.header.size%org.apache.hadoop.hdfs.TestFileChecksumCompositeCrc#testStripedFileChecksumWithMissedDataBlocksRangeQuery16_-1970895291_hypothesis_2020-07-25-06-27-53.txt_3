reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-100898805-172.17.0.12-1595658489361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33976,DS-170fe828-9c9b-4cd8-a0b4-fcdbf76b7fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-4fcb3c2f-8daf-44a2-9262-2a8bd7740bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-f18662f6-8cdd-4814-9154-f5a590b5edcc,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-5e959d95-777d-474a-8e79-a8a47196660e,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-e9349395-5d12-498c-a00d-73ce0cbca0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-1d6bd3ce-5005-4477-ad56-a7868cf7b7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-1ea1489e-8114-409f-87f5-af640ed18290,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-dda112e5-4bb8-4a08-83f9-382c1b095635,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-100898805-172.17.0.12-1595658489361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33976,DS-170fe828-9c9b-4cd8-a0b4-fcdbf76b7fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-4fcb3c2f-8daf-44a2-9262-2a8bd7740bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-f18662f6-8cdd-4814-9154-f5a590b5edcc,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-5e959d95-777d-474a-8e79-a8a47196660e,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-e9349395-5d12-498c-a00d-73ce0cbca0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-1d6bd3ce-5005-4477-ad56-a7868cf7b7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-1ea1489e-8114-409f-87f5-af640ed18290,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-dda112e5-4bb8-4a08-83f9-382c1b095635,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1073106261-172.17.0.12-1595658534110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35214,DS-2e0e11d1-b14d-4d0c-96f5-a3638787c921,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-0f93371c-9678-4356-aad7-6ccbafabb611,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-a1c7ff7a-06c5-46ed-81dc-eebfd2aa7d83,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-eba5f3da-aec3-4253-94de-c417bdfb551e,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-60a257a6-a85f-45c0-8089-f9501a6db51b,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-c65fb10a-f885-4660-bcbe-d2618e5da025,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-9f2b2ae9-251e-42d1-adcb-cc849b908732,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-47537a70-3481-4dc9-a209-a83f7ffb1b10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1073106261-172.17.0.12-1595658534110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35214,DS-2e0e11d1-b14d-4d0c-96f5-a3638787c921,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-0f93371c-9678-4356-aad7-6ccbafabb611,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-a1c7ff7a-06c5-46ed-81dc-eebfd2aa7d83,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-eba5f3da-aec3-4253-94de-c417bdfb551e,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-60a257a6-a85f-45c0-8089-f9501a6db51b,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-c65fb10a-f885-4660-bcbe-d2618e5da025,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-9f2b2ae9-251e-42d1-adcb-cc849b908732,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-47537a70-3481-4dc9-a209-a83f7ffb1b10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1444800321-172.17.0.12-1595658622472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40342,DS-c77755bd-ec04-4a7d-bf7d-f570833a5258,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-bf6c85e2-c1e3-469b-a6bc-4bea346a548a,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-c39be215-7aa0-477e-8aa8-00e10f4d04e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-18a1d131-85fc-4d77-afca-5c0524711122,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-681bb15d-90cf-4889-8956-3ba9e7244903,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-68cfefc8-cab3-414f-b0b0-73f1a1e35a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-496eede8-ffe7-4146-846e-962de051c6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-cd9af034-95b4-4cb3-80ff-6372a21c6de7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1444800321-172.17.0.12-1595658622472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40342,DS-c77755bd-ec04-4a7d-bf7d-f570833a5258,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-bf6c85e2-c1e3-469b-a6bc-4bea346a548a,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-c39be215-7aa0-477e-8aa8-00e10f4d04e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-18a1d131-85fc-4d77-afca-5c0524711122,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-681bb15d-90cf-4889-8956-3ba9e7244903,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-68cfefc8-cab3-414f-b0b0-73f1a1e35a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-496eede8-ffe7-4146-846e-962de051c6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-cd9af034-95b4-4cb3-80ff-6372a21c6de7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1003455279-172.17.0.12-1595658721822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38437,DS-e359279f-e290-408d-a7e0-08bcdf0a07e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-a4fff438-229e-48d2-acc7-82e327dfea32,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-a89fef8f-96d7-42c3-acd7-5487483667d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-2acee47b-de32-4602-a625-b5160d796d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-b484565d-e732-40c8-a458-d7cd0414edf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-e7867be7-9c57-4a14-a181-63f259e7068f,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-f1026d61-b86e-4ada-a07c-8b564fa68b61,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-93c81c4e-94ae-4085-8e3a-2f270ee3826b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1003455279-172.17.0.12-1595658721822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38437,DS-e359279f-e290-408d-a7e0-08bcdf0a07e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-a4fff438-229e-48d2-acc7-82e327dfea32,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-a89fef8f-96d7-42c3-acd7-5487483667d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-2acee47b-de32-4602-a625-b5160d796d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-b484565d-e732-40c8-a458-d7cd0414edf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-e7867be7-9c57-4a14-a181-63f259e7068f,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-f1026d61-b86e-4ada-a07c-8b564fa68b61,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-93c81c4e-94ae-4085-8e3a-2f270ee3826b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-543327694-172.17.0.12-1595658808847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33825,DS-c1af77e4-e1d7-488f-b3b7-a1768d70f241,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-0885165b-eecb-47aa-a123-1bfda9e05eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-cdab0f83-7c44-45d7-945a-696638e48445,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-027b8789-0d1d-46dc-8103-a769eb65c3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-de46e9c4-4d13-47cc-a6e0-2e5d6da5dcee,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-baf3f141-eead-4700-abee-7278c08a4b00,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-e9c46206-5b34-4598-a384-fce2a7ae2633,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-f63ea486-f916-400f-86e9-c9e588a575d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-543327694-172.17.0.12-1595658808847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33825,DS-c1af77e4-e1d7-488f-b3b7-a1768d70f241,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-0885165b-eecb-47aa-a123-1bfda9e05eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-cdab0f83-7c44-45d7-945a-696638e48445,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-027b8789-0d1d-46dc-8103-a769eb65c3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-de46e9c4-4d13-47cc-a6e0-2e5d6da5dcee,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-baf3f141-eead-4700-abee-7278c08a4b00,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-e9c46206-5b34-4598-a384-fce2a7ae2633,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-f63ea486-f916-400f-86e9-c9e588a575d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-528970100-172.17.0.12-1595658855167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45703,DS-c8c9df15-1449-4f85-83ee-a134c6fd63f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-ccd61afa-f212-4bef-9ecc-4d75aabc5b80,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-16f5d745-3f22-4b69-8cdf-0f7fcb46d644,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-61e87c62-7e3e-4c1f-b3f3-5173ef51dcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-436948ae-9f70-460f-87f2-c123eece5dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-a1c520aa-84bc-4250-9274-0838b1529dab,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-e975861c-5289-45c0-bc42-5f955e74956d,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-7385e9a3-c08a-4313-954d-c954bbbe1dbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-528970100-172.17.0.12-1595658855167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45703,DS-c8c9df15-1449-4f85-83ee-a134c6fd63f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-ccd61afa-f212-4bef-9ecc-4d75aabc5b80,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-16f5d745-3f22-4b69-8cdf-0f7fcb46d644,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-61e87c62-7e3e-4c1f-b3f3-5173ef51dcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-436948ae-9f70-460f-87f2-c123eece5dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-a1c520aa-84bc-4250-9274-0838b1529dab,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-e975861c-5289-45c0-bc42-5f955e74956d,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-7385e9a3-c08a-4313-954d-c954bbbe1dbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-288012216-172.17.0.12-1595658940092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38292,DS-c52df445-8802-425f-99da-7127a4bf96bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-4bb78cfc-4215-4adc-ac36-3f0ae0a6c64c,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-ed3ab50b-e3bf-4a07-8f55-b5557e529d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-20309854-2f88-4c42-956e-5fa84776a923,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-62476261-ab1e-4f9a-867b-8713c8550cab,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-8ba1009e-d337-4b7a-92de-fe77cac72cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-32b5a3b7-e963-46ca-9a4a-a69f6bff6da1,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-bbef626d-f446-457b-a309-dcf6ffabc589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-288012216-172.17.0.12-1595658940092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38292,DS-c52df445-8802-425f-99da-7127a4bf96bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-4bb78cfc-4215-4adc-ac36-3f0ae0a6c64c,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-ed3ab50b-e3bf-4a07-8f55-b5557e529d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-20309854-2f88-4c42-956e-5fa84776a923,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-62476261-ab1e-4f9a-867b-8713c8550cab,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-8ba1009e-d337-4b7a-92de-fe77cac72cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-32b5a3b7-e963-46ca-9a4a-a69f6bff6da1,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-bbef626d-f446-457b-a309-dcf6ffabc589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-820052203-172.17.0.12-1595659352434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33020,DS-146e744c-4674-4ecc-b3d6-312656433ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-f6ab20fe-608b-44f1-abc5-92f7c0760317,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-19db5dd0-8fa4-4ae2-9322-73af8abf5dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-004c5a0c-ec34-4301-89ce-4846edd6956a,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-063e2a5e-4bdb-4450-bfce-2528bb59360f,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-d4351a7f-55fa-4c91-8864-272800c4149e,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-80561e6c-e850-4f58-af27-294a9e1fd0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-9f5e521b-d95a-41f6-8f95-15caea49d326,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-820052203-172.17.0.12-1595659352434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33020,DS-146e744c-4674-4ecc-b3d6-312656433ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-f6ab20fe-608b-44f1-abc5-92f7c0760317,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-19db5dd0-8fa4-4ae2-9322-73af8abf5dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-004c5a0c-ec34-4301-89ce-4846edd6956a,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-063e2a5e-4bdb-4450-bfce-2528bb59360f,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-d4351a7f-55fa-4c91-8864-272800c4149e,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-80561e6c-e850-4f58-af27-294a9e1fd0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-9f5e521b-d95a-41f6-8f95-15caea49d326,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1221594746-172.17.0.12-1595660546121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33957,DS-ebee9e6d-8ad7-4fd2-a4ab-6d1411051bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-060099d8-d099-449e-8744-d67a78e8b781,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-d239ee61-7036-4442-b206-8069fd9c75f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-0d8c5ed8-b7b8-42b4-9312-19195e701115,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-94a7e488-f0aa-44e8-b412-c46c351f6486,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-f5279d2b-c3b9-4e97-98d9-13858539b0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-a6df6302-df02-48ea-b3b6-cb40e0cf2a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-bb195262-e70f-4dfa-ab1b-f37b03396330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1221594746-172.17.0.12-1595660546121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33957,DS-ebee9e6d-8ad7-4fd2-a4ab-6d1411051bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-060099d8-d099-449e-8744-d67a78e8b781,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-d239ee61-7036-4442-b206-8069fd9c75f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-0d8c5ed8-b7b8-42b4-9312-19195e701115,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-94a7e488-f0aa-44e8-b412-c46c351f6486,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-f5279d2b-c3b9-4e97-98d9-13858539b0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-a6df6302-df02-48ea-b3b6-cb40e0cf2a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-bb195262-e70f-4dfa-ab1b-f37b03396330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1916548886-172.17.0.12-1595661504824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39748,DS-24b9e45a-2fa5-4d32-8bb5-cfab330c19a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-6655120e-cdf1-4053-897c-dcccd699c662,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-bf3b3b8a-1be0-4eff-b526-13a90acfbf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-94c36afd-3b0d-4a00-9b67-6edcea3a0a72,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-3d8325cb-6349-4055-98bc-bdd2b35a8b89,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-830733c3-386d-4981-9db1-ca064222f408,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-ece609a0-05e4-465a-a13b-ff401a8295fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-e35138e2-78e0-4d7c-b5da-9212d2b2ac02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1916548886-172.17.0.12-1595661504824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39748,DS-24b9e45a-2fa5-4d32-8bb5-cfab330c19a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-6655120e-cdf1-4053-897c-dcccd699c662,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-bf3b3b8a-1be0-4eff-b526-13a90acfbf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-94c36afd-3b0d-4a00-9b67-6edcea3a0a72,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-3d8325cb-6349-4055-98bc-bdd2b35a8b89,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-830733c3-386d-4981-9db1-ca064222f408,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-ece609a0-05e4-465a-a13b-ff401a8295fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-e35138e2-78e0-4d7c-b5da-9212d2b2ac02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1332675646-172.17.0.12-1595661583751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39144,DS-18f3c637-229c-4031-ab1b-354ddcbe28b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-72f546b8-04ad-4330-890a-d0100fccf0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-66358ab9-83e5-48b1-8db6-f422760860c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-7fb8224f-5603-487b-8f90-d709967ae847,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-0ef5d90a-57ce-4631-bb58-c95d0670ec8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-c52f568a-a2a3-419b-9f88-3982278bf336,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-7358df25-b3e7-425d-ba71-e68c7ec4c707,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-f6d0ba7e-d7d5-42c6-b7ac-6a2327401812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1332675646-172.17.0.12-1595661583751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39144,DS-18f3c637-229c-4031-ab1b-354ddcbe28b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-72f546b8-04ad-4330-890a-d0100fccf0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-66358ab9-83e5-48b1-8db6-f422760860c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-7fb8224f-5603-487b-8f90-d709967ae847,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-0ef5d90a-57ce-4631-bb58-c95d0670ec8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-c52f568a-a2a3-419b-9f88-3982278bf336,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-7358df25-b3e7-425d-ba71-e68c7ec4c707,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-f6d0ba7e-d7d5-42c6-b7ac-6a2327401812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-710779277-172.17.0.12-1595661716501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42267,DS-e5217ced-d04e-4db4-9557-0308914ef9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-86bd212b-b99c-4e67-859e-921fecaecf59,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-71ed1c33-e6af-4408-a370-757fb26facf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-758f5c90-b752-41ed-8a57-821d077901e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-6ae415d9-e62f-4808-9f11-b24a76c14c41,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-fb364b24-d7cd-4171-bee1-cdf4f30d23af,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-3c82d48f-3387-4f50-8e68-c406da650f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-d866a4bf-5352-4b1a-baae-bfa9ab279dc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-710779277-172.17.0.12-1595661716501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42267,DS-e5217ced-d04e-4db4-9557-0308914ef9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-86bd212b-b99c-4e67-859e-921fecaecf59,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-71ed1c33-e6af-4408-a370-757fb26facf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-758f5c90-b752-41ed-8a57-821d077901e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-6ae415d9-e62f-4808-9f11-b24a76c14c41,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-fb364b24-d7cd-4171-bee1-cdf4f30d23af,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-3c82d48f-3387-4f50-8e68-c406da650f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-d866a4bf-5352-4b1a-baae-bfa9ab279dc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-598028458-172.17.0.12-1595662065379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45944,DS-f71f25cf-808a-4c29-923f-f7571722156c,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-2957a655-279d-4904-bb66-142fd9d05851,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-5e41db05-cf60-45f6-b748-ed317c124877,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-6d1b8c30-1993-4b60-ba4b-cd72c9b32b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-fdf75b5f-cc27-4611-9076-f299649cb9af,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-267a4a85-491b-4900-b6e4-802d2ebef08b,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-9f82ead3-4e17-42e1-a5d5-cef00b449c47,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-ae62379a-eabf-4da3-8d39-1a1c6058eb16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-598028458-172.17.0.12-1595662065379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45944,DS-f71f25cf-808a-4c29-923f-f7571722156c,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-2957a655-279d-4904-bb66-142fd9d05851,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-5e41db05-cf60-45f6-b748-ed317c124877,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-6d1b8c30-1993-4b60-ba4b-cd72c9b32b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-fdf75b5f-cc27-4611-9076-f299649cb9af,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-267a4a85-491b-4900-b6e4-802d2ebef08b,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-9f82ead3-4e17-42e1-a5d5-cef00b449c47,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-ae62379a-eabf-4da3-8d39-1a1c6058eb16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-17720898-172.17.0.12-1595662184536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46796,DS-dfb0fea5-d529-476e-8ce1-7f24d9648b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-2aebad6e-5513-46e5-81f5-a1d95e003dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-3334cfa2-71e6-461e-bd25-a30a97950f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-5dfb37ad-97b8-4ad5-b828-248785e0f246,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-d481a769-867d-4c44-823c-e75e49968176,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-104a49bf-acb2-4ffe-9d5a-d68a508e621f,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-4e7e6490-887a-4c88-a20d-0542591f2e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-0ed33376-1687-465d-9237-ef4ea3e7572e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-17720898-172.17.0.12-1595662184536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46796,DS-dfb0fea5-d529-476e-8ce1-7f24d9648b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-2aebad6e-5513-46e5-81f5-a1d95e003dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-3334cfa2-71e6-461e-bd25-a30a97950f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-5dfb37ad-97b8-4ad5-b828-248785e0f246,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-d481a769-867d-4c44-823c-e75e49968176,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-104a49bf-acb2-4ffe-9d5a-d68a508e621f,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-4e7e6490-887a-4c88-a20d-0542591f2e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-0ed33376-1687-465d-9237-ef4ea3e7572e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-855079674-172.17.0.12-1595662230911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42155,DS-6ca1c5cf-dba2-450f-8129-9084a7e3c1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-7f880f84-8486-4d1c-8672-4cfc0fe6af81,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-42bc2b76-b052-427d-b629-65422ecffaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-a039dc0f-68bd-4139-926b-06781e551c88,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-80b2826e-4bdd-48aa-9552-fdfd3a9f489a,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-9bbcb81e-3027-4466-af2c-584c3a54a860,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-12535e15-8092-4a24-a3f5-582b003c01d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-721d23bd-865e-408a-a607-d47d89ee6590,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-855079674-172.17.0.12-1595662230911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42155,DS-6ca1c5cf-dba2-450f-8129-9084a7e3c1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-7f880f84-8486-4d1c-8672-4cfc0fe6af81,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-42bc2b76-b052-427d-b629-65422ecffaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-a039dc0f-68bd-4139-926b-06781e551c88,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-80b2826e-4bdd-48aa-9552-fdfd3a9f489a,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-9bbcb81e-3027-4466-af2c-584c3a54a860,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-12535e15-8092-4a24-a3f5-582b003c01d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-721d23bd-865e-408a-a607-d47d89ee6590,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52337527-172.17.0.12-1595663342108:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45514,DS-b910b046-1216-4038-b5e2-d8411bda1fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-6589b92a-95cc-41ed-aaa3-e0dd0f71316a,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-ce54eecf-ed20-4d8e-9ae7-a60b4d01c881,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-ec394e74-1201-47f4-8a31-0e7b174c056f,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-78da7ed5-d89e-4960-a43b-78fe8b3051d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-a7320581-abf9-4ef3-80fb-bc277910c0da,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-ccd5c129-2f60-4f31-a81b-570ae687daa3,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-716348dc-cc48-48a7-8210-a35c3da7f122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52337527-172.17.0.12-1595663342108:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45514,DS-b910b046-1216-4038-b5e2-d8411bda1fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-6589b92a-95cc-41ed-aaa3-e0dd0f71316a,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-ce54eecf-ed20-4d8e-9ae7-a60b4d01c881,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-ec394e74-1201-47f4-8a31-0e7b174c056f,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-78da7ed5-d89e-4960-a43b-78fe8b3051d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-a7320581-abf9-4ef3-80fb-bc277910c0da,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-ccd5c129-2f60-4f31-a81b-570ae687daa3,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-716348dc-cc48-48a7-8210-a35c3da7f122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1843552943-172.17.0.12-1595663546732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45447,DS-35f7c727-c5f1-4909-a773-0e5dd0b3418f,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-9aa59b61-3f36-411c-9728-599196aec0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-b10136e8-e498-4fad-ad3d-a82c2d12fd85,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-34b9974e-7f33-422b-855d-5a2476ba3b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-c348a8f4-a499-4861-8aae-4f6eb437f117,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-1dba4b09-802e-4c82-901f-64bb14b19b06,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-c0600ce4-212e-4490-86b9-cfed9c80ad00,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-58159854-670e-4a4b-9a48-5dd560e19094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1843552943-172.17.0.12-1595663546732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45447,DS-35f7c727-c5f1-4909-a773-0e5dd0b3418f,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-9aa59b61-3f36-411c-9728-599196aec0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-b10136e8-e498-4fad-ad3d-a82c2d12fd85,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-34b9974e-7f33-422b-855d-5a2476ba3b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-c348a8f4-a499-4861-8aae-4f6eb437f117,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-1dba4b09-802e-4c82-901f-64bb14b19b06,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-c0600ce4-212e-4490-86b9-cfed9c80ad00,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-58159854-670e-4a4b-9a48-5dd560e19094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2079757317-172.17.0.12-1595663671213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45527,DS-50568141-5187-45ca-b595-68d9ee3bb995,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-c3ec2352-9551-434a-a8b5-514fb251e235,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-a7120c41-6526-44cc-9454-18df70b4c13f,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-c41719c4-21cc-45c0-80b9-9ae2d3eb3baa,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-beaf0410-061f-4c75-8a35-d1882420c65c,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-bec1b6ca-dc48-4fbc-b84e-639b7721d414,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-53f8b9a3-d9bc-4ef6-9614-139494fdf8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-9b45e465-61ef-44b1-94c9-ef2d907db5a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2079757317-172.17.0.12-1595663671213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45527,DS-50568141-5187-45ca-b595-68d9ee3bb995,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-c3ec2352-9551-434a-a8b5-514fb251e235,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-a7120c41-6526-44cc-9454-18df70b4c13f,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-c41719c4-21cc-45c0-80b9-9ae2d3eb3baa,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-beaf0410-061f-4c75-8a35-d1882420c65c,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-bec1b6ca-dc48-4fbc-b84e-639b7721d414,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-53f8b9a3-d9bc-4ef6-9614-139494fdf8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-9b45e465-61ef-44b1-94c9-ef2d907db5a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1700248533-172.17.0.12-1595664148651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42275,DS-8ca327f7-8916-46cf-9fa8-80b31e1e1bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-a41e7f88-4242-40d7-a1d9-a1c9bd4d7e84,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-68527906-143f-49b5-96d8-a3d4ade84d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-f069af23-0d26-4f91-8235-a4042a637951,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-d9959a89-e4aa-4df3-adea-86df1a204978,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-afff94f5-2be2-4d93-80af-661ff14e9b52,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-b6337dd7-eeae-4947-a693-e56f3d268b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-c7cecca7-bf78-405b-8dc5-ed71998e1975,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1700248533-172.17.0.12-1595664148651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42275,DS-8ca327f7-8916-46cf-9fa8-80b31e1e1bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-a41e7f88-4242-40d7-a1d9-a1c9bd4d7e84,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-68527906-143f-49b5-96d8-a3d4ade84d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-f069af23-0d26-4f91-8235-a4042a637951,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-d9959a89-e4aa-4df3-adea-86df1a204978,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-afff94f5-2be2-4d93-80af-661ff14e9b52,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-b6337dd7-eeae-4947-a693-e56f3d268b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-c7cecca7-bf78-405b-8dc5-ed71998e1975,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1832300490-172.17.0.12-1595664448489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33180,DS-eb875bbe-d630-4a20-9c62-70e8b40967c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-51f2882c-1dba-4b32-9bcd-c61a84da06e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-d91be36c-c2d4-4566-b8ab-cff7babe5055,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-3dbefc99-b0c4-4a13-8164-b86fbdcc3ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-66e117ec-707d-4ca0-a857-3c6316a6e159,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-f626e49a-fba2-4faa-90c6-ba44d37b02ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-6148d1a5-50de-4423-8b12-2e46c373e90c,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-1a4ec9dd-d032-48bf-828f-0f80ab505047,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1832300490-172.17.0.12-1595664448489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33180,DS-eb875bbe-d630-4a20-9c62-70e8b40967c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-51f2882c-1dba-4b32-9bcd-c61a84da06e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-d91be36c-c2d4-4566-b8ab-cff7babe5055,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-3dbefc99-b0c4-4a13-8164-b86fbdcc3ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-66e117ec-707d-4ca0-a857-3c6316a6e159,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-f626e49a-fba2-4faa-90c6-ba44d37b02ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-6148d1a5-50de-4423-8b12-2e46c373e90c,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-1a4ec9dd-d032-48bf-828f-0f80ab505047,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2048377408-172.17.0.12-1595664671378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44566,DS-cb039489-d176-413a-b2d7-ee16361bd639,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-bec52f44-1e75-4ef9-87df-b2aa6e17d585,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-6874aa6e-45c1-4599-ad75-8a0b37a986cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-3a35fa1e-b768-4a4e-a4d0-b007fc2aa4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-07593da8-c0d1-4427-a6b6-242fa2fb5313,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-e0d8369a-a3d0-4000-9326-cb4b6f5a4b45,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-4242bb6c-ad9a-4cd1-9fb8-a1c58ff253a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-29dc57c4-2722-4b4e-9b3a-b4383be39822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2048377408-172.17.0.12-1595664671378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44566,DS-cb039489-d176-413a-b2d7-ee16361bd639,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-bec52f44-1e75-4ef9-87df-b2aa6e17d585,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-6874aa6e-45c1-4599-ad75-8a0b37a986cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-3a35fa1e-b768-4a4e-a4d0-b007fc2aa4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-07593da8-c0d1-4427-a6b6-242fa2fb5313,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-e0d8369a-a3d0-4000-9326-cb4b6f5a4b45,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-4242bb6c-ad9a-4cd1-9fb8-a1c58ff253a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-29dc57c4-2722-4b4e-9b3a-b4383be39822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6490
