reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1841781262-172.17.0.19-1596047871565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38940,DS-d49bb72f-1ab8-45d0-ac4c-a30b1e6533bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-b140b201-11af-434d-a7a2-94fa6e5d9b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-c3ec1280-a181-416a-b76e-5e76c587c57c,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-ce01d382-f9b3-4c9f-8de5-ea0e82595382,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-322dcdb5-a806-4435-8f2d-31452e429d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-c1441435-21a1-415f-83c7-2d77f1ffd3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-77d1fc1a-2c64-4859-91f0-35b8b3f537c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-8afc7936-aa8e-499c-896a-70dfefea7f68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1841781262-172.17.0.19-1596047871565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38940,DS-d49bb72f-1ab8-45d0-ac4c-a30b1e6533bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-b140b201-11af-434d-a7a2-94fa6e5d9b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-c3ec1280-a181-416a-b76e-5e76c587c57c,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-ce01d382-f9b3-4c9f-8de5-ea0e82595382,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-322dcdb5-a806-4435-8f2d-31452e429d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-c1441435-21a1-415f-83c7-2d77f1ffd3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-77d1fc1a-2c64-4859-91f0-35b8b3f537c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-8afc7936-aa8e-499c-896a-70dfefea7f68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511255122-172.17.0.19-1596049177425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43132,DS-81ecce24-00bc-46f2-89ce-f1f5d34b6424,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-db18d335-f45d-48fe-8860-9d79ce97d945,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-52073979-4523-4013-bf61-c561e4e5b537,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-92775e1c-7b71-405f-aa69-9c94dba163b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-ace1b89f-821f-4d22-90f5-6eaab6bd9162,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-aeb85944-7108-4c38-aca6-cbe12f33408c,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-b870b818-69c1-4544-a529-3c632f6bffe7,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-bafd6681-70ff-4f0c-8cf7-852a99c63336,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511255122-172.17.0.19-1596049177425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43132,DS-81ecce24-00bc-46f2-89ce-f1f5d34b6424,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-db18d335-f45d-48fe-8860-9d79ce97d945,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-52073979-4523-4013-bf61-c561e4e5b537,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-92775e1c-7b71-405f-aa69-9c94dba163b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-ace1b89f-821f-4d22-90f5-6eaab6bd9162,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-aeb85944-7108-4c38-aca6-cbe12f33408c,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-b870b818-69c1-4544-a529-3c632f6bffe7,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-bafd6681-70ff-4f0c-8cf7-852a99c63336,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-550117865-172.17.0.19-1596049466412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39157,DS-ac1a51d5-8352-4fbc-9dbb-6cda6705cce8,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-272684ce-202b-453a-9fc1-e70dd94163a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-5dc8de9c-4d8f-4533-91b4-a7dbcebcf051,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-722cf72c-9aa7-4d2f-8b87-13afca36d9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-e5e0a6f4-19a7-45fa-927b-edaaa85a9334,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-b4847a4e-909b-4cc8-971f-c550277dc420,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-ff8a1c2b-a166-4ffd-b75a-4ce732cf4c70,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-a226de24-7739-4370-b087-b435ff031544,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-550117865-172.17.0.19-1596049466412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39157,DS-ac1a51d5-8352-4fbc-9dbb-6cda6705cce8,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-272684ce-202b-453a-9fc1-e70dd94163a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-5dc8de9c-4d8f-4533-91b4-a7dbcebcf051,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-722cf72c-9aa7-4d2f-8b87-13afca36d9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-e5e0a6f4-19a7-45fa-927b-edaaa85a9334,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-b4847a4e-909b-4cc8-971f-c550277dc420,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-ff8a1c2b-a166-4ffd-b75a-4ce732cf4c70,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-a226de24-7739-4370-b087-b435ff031544,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1418781355-172.17.0.19-1596049689878:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46118,DS-10d9b201-1f7f-4fc1-baf9-151e55579f43,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-a00596c5-7a44-486c-a86b-4ced4f72e6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-6d476cf7-8a42-4c31-a565-11a3ffdbaa1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-64e36575-135e-4013-9a4e-31ffd5ee904a,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-a15af0c7-4069-4d56-8014-2447919d39e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-c69793fb-4af7-4693-9bc8-3b41cfe9f3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-7c93a879-06d0-48d5-baed-74482b0832ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-d369d79b-279e-41c1-bc62-494fb6774770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1418781355-172.17.0.19-1596049689878:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46118,DS-10d9b201-1f7f-4fc1-baf9-151e55579f43,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-a00596c5-7a44-486c-a86b-4ced4f72e6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-6d476cf7-8a42-4c31-a565-11a3ffdbaa1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-64e36575-135e-4013-9a4e-31ffd5ee904a,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-a15af0c7-4069-4d56-8014-2447919d39e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-c69793fb-4af7-4693-9bc8-3b41cfe9f3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-7c93a879-06d0-48d5-baed-74482b0832ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-d369d79b-279e-41c1-bc62-494fb6774770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-33005889-172.17.0.19-1596050002620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34157,DS-cb801feb-0c47-4634-8ed8-8d0272ec354b,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-d6e3fed4-d4ac-48af-8857-3a2a8ad0bd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-061dd11f-05ea-4484-9050-e48dc47214ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-f15868b1-c322-4c8d-8264-ce2263f89e72,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-f5285c65-870d-4283-a548-cdcc934b2596,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-1fc5e3f8-1848-46c8-9f2e-9b8de2f92ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-4ea83168-9548-4f3e-ba6e-fc5123e3f051,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-1047db0f-fa10-439d-ac55-9d1e5dd6e18e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-33005889-172.17.0.19-1596050002620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34157,DS-cb801feb-0c47-4634-8ed8-8d0272ec354b,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-d6e3fed4-d4ac-48af-8857-3a2a8ad0bd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-061dd11f-05ea-4484-9050-e48dc47214ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-f15868b1-c322-4c8d-8264-ce2263f89e72,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-f5285c65-870d-4283-a548-cdcc934b2596,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-1fc5e3f8-1848-46c8-9f2e-9b8de2f92ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-4ea83168-9548-4f3e-ba6e-fc5123e3f051,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-1047db0f-fa10-439d-ac55-9d1e5dd6e18e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1423525217-172.17.0.19-1596050062152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39482,DS-72661892-ce84-4f07-ab3e-54d6eeeefc24,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-450f9347-11b6-422a-9d9b-6c0faf904d86,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-9268107c-dc1a-4875-8ed8-ceed3f518a80,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-52b9616e-e859-4161-b890-8a1c916ece35,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-329f20dd-08ce-4746-a7c4-42b47cf84ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-36ae7fdc-fffb-42f0-8b0e-f253cff2cae2,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-7fdd20ec-c3df-4c06-a94d-dca0acbf1e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-82b5437b-114d-4897-849a-4a54c7ef3679,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1423525217-172.17.0.19-1596050062152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39482,DS-72661892-ce84-4f07-ab3e-54d6eeeefc24,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-450f9347-11b6-422a-9d9b-6c0faf904d86,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-9268107c-dc1a-4875-8ed8-ceed3f518a80,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-52b9616e-e859-4161-b890-8a1c916ece35,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-329f20dd-08ce-4746-a7c4-42b47cf84ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-36ae7fdc-fffb-42f0-8b0e-f253cff2cae2,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-7fdd20ec-c3df-4c06-a94d-dca0acbf1e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-82b5437b-114d-4897-849a-4a54c7ef3679,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1114224994-172.17.0.19-1596050881103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38394,DS-13e1d86e-5e03-47f7-973f-1f2390f4d78a,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-dc7df968-aa93-4c04-a848-c1cf295cfc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-063baca8-f353-446e-9772-c7d052b143a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-0bfd04e7-bb86-44c7-8856-bde16effbcee,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-6b6b7599-ccf1-4de9-a5d0-30adf5dafa9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-33e8704b-fa64-4ff0-aff7-566538294a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-cbec2029-bbcc-4aed-a040-15ec3a1a07f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-5cda6d33-9e15-4079-967c-afe69dd38362,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1114224994-172.17.0.19-1596050881103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38394,DS-13e1d86e-5e03-47f7-973f-1f2390f4d78a,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-dc7df968-aa93-4c04-a848-c1cf295cfc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-063baca8-f353-446e-9772-c7d052b143a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-0bfd04e7-bb86-44c7-8856-bde16effbcee,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-6b6b7599-ccf1-4de9-a5d0-30adf5dafa9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-33e8704b-fa64-4ff0-aff7-566538294a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-cbec2029-bbcc-4aed-a040-15ec3a1a07f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-5cda6d33-9e15-4079-967c-afe69dd38362,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1824432747-172.17.0.19-1596051249039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34541,DS-c2796698-5580-4e7b-9dae-fcec1a789b98,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-c6e82f94-280e-4cdf-9e3f-f9af86629933,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-375d2541-46f7-415e-8946-5d09fae0a800,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-facd0f84-d248-436b-a8fd-73217eab0115,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-3e9b95a0-75cc-4cb5-9572-e36b366788ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-132bb04b-ecf9-4c16-a68b-0c9a3c58b615,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-93f29577-e372-45b8-913d-6fe67976efdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-4476b076-681a-436d-b9b5-adaadda5199c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1824432747-172.17.0.19-1596051249039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34541,DS-c2796698-5580-4e7b-9dae-fcec1a789b98,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-c6e82f94-280e-4cdf-9e3f-f9af86629933,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-375d2541-46f7-415e-8946-5d09fae0a800,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-facd0f84-d248-436b-a8fd-73217eab0115,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-3e9b95a0-75cc-4cb5-9572-e36b366788ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-132bb04b-ecf9-4c16-a68b-0c9a3c58b615,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-93f29577-e372-45b8-913d-6fe67976efdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-4476b076-681a-436d-b9b5-adaadda5199c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-648592820-172.17.0.19-1596051332163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38297,DS-9d27b436-3f6d-4036-b149-7c3201299b90,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-4f3d0367-5091-4ad3-9b82-281439a28ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-4bc62e32-e464-4783-86d7-695ad3cf5473,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-6ad99874-9143-4afc-8a31-2c0a8bb46c23,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-99f2a2d6-fc20-49ec-8326-7e48c5a4253d,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-61901480-1490-403f-b8c8-e814bfb7510c,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-672847b8-be71-48e7-bf00-6c1bac35100b,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-5bce43fe-a9da-48fe-aa3a-8e0e72b53a2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-648592820-172.17.0.19-1596051332163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38297,DS-9d27b436-3f6d-4036-b149-7c3201299b90,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-4f3d0367-5091-4ad3-9b82-281439a28ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-4bc62e32-e464-4783-86d7-695ad3cf5473,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-6ad99874-9143-4afc-8a31-2c0a8bb46c23,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-99f2a2d6-fc20-49ec-8326-7e48c5a4253d,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-61901480-1490-403f-b8c8-e814bfb7510c,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-672847b8-be71-48e7-bf00-6c1bac35100b,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-5bce43fe-a9da-48fe-aa3a-8e0e72b53a2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731195381-172.17.0.19-1596051647676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37944,DS-8b8476ea-8b57-4456-b3d4-6921d6400865,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-360a98a3-c21d-4b03-9a64-7a23ff9411a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-1c365cca-1831-401a-bf69-a734adc286d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-855fb2c1-20d3-4004-8d57-75b7c76948f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-465bdb66-7bd5-40cc-b347-0062c1532c90,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-7c88871b-e270-4154-bb66-249b0b7c5293,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-a70fdbe5-6c94-43f1-aae2-727b3fe6d543,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-5af5cbb7-77a6-4556-a5c1-4ad4357a468e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731195381-172.17.0.19-1596051647676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37944,DS-8b8476ea-8b57-4456-b3d4-6921d6400865,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-360a98a3-c21d-4b03-9a64-7a23ff9411a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-1c365cca-1831-401a-bf69-a734adc286d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-855fb2c1-20d3-4004-8d57-75b7c76948f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-465bdb66-7bd5-40cc-b347-0062c1532c90,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-7c88871b-e270-4154-bb66-249b0b7c5293,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-a70fdbe5-6c94-43f1-aae2-727b3fe6d543,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-5af5cbb7-77a6-4556-a5c1-4ad4357a468e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-292127482-172.17.0.19-1596052117983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43094,DS-a300af2e-6de9-48ed-abf1-5608ebb6b4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-39046d9b-4b72-4631-b539-0d39f3977fca,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-c39e858f-5a28-4030-a1cb-d46fe8548965,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-7f4bdc2f-99f7-4760-a918-891ed069b669,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-f02a4644-c70c-4bc0-b5a0-4685a0c8b79e,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-a69d57c8-a0e4-49ac-a447-14023922e08f,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-aaa6423f-6237-4feb-aff8-a6f7949de6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-1d8f3b89-e416-4ab6-9cc0-c361c60cd273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-292127482-172.17.0.19-1596052117983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43094,DS-a300af2e-6de9-48ed-abf1-5608ebb6b4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-39046d9b-4b72-4631-b539-0d39f3977fca,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-c39e858f-5a28-4030-a1cb-d46fe8548965,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-7f4bdc2f-99f7-4760-a918-891ed069b669,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-f02a4644-c70c-4bc0-b5a0-4685a0c8b79e,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-a69d57c8-a0e4-49ac-a447-14023922e08f,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-aaa6423f-6237-4feb-aff8-a6f7949de6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-1d8f3b89-e416-4ab6-9cc0-c361c60cd273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-930879215-172.17.0.19-1596052293858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43522,DS-127163eb-41ad-4943-8d02-6e7bf2343df2,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-cb423183-43e0-46cf-af11-24a37d7ed2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-7cc5e646-9fb9-4ece-bc99-e9272c64ad34,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-b95fac20-7c76-445a-98b2-71bad0eb44dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-9f208137-b4af-4914-992d-87e59b693d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-9d224ce1-cb2b-4234-9cb5-ef8ccdc5354c,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-19313fab-6dbd-423f-884e-545fdd8f9223,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-39087ba1-7a35-47e5-bab3-5d6556a9aa77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-930879215-172.17.0.19-1596052293858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43522,DS-127163eb-41ad-4943-8d02-6e7bf2343df2,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-cb423183-43e0-46cf-af11-24a37d7ed2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-7cc5e646-9fb9-4ece-bc99-e9272c64ad34,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-b95fac20-7c76-445a-98b2-71bad0eb44dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-9f208137-b4af-4914-992d-87e59b693d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-9d224ce1-cb2b-4234-9cb5-ef8ccdc5354c,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-19313fab-6dbd-423f-884e-545fdd8f9223,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-39087ba1-7a35-47e5-bab3-5d6556a9aa77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1469619196-172.17.0.19-1596052538134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42450,DS-6acadebf-8a1a-4680-81ac-296dee8d34d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-265edf41-aded-4314-b50b-0beb13ad76e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-45b23f2f-af54-44cf-9fd1-6bbff19c40d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-b97a2a16-ec83-491f-83e3-d6723fcb9f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-b845f100-161a-4c43-b8d2-536806bde479,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-16a01fa5-463e-450b-946f-e3abbe61bb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-0f8beb7b-6e89-460e-9a88-f45f9929a7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-38703353-fcd2-472c-9283-34ce8f57ad73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1469619196-172.17.0.19-1596052538134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42450,DS-6acadebf-8a1a-4680-81ac-296dee8d34d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-265edf41-aded-4314-b50b-0beb13ad76e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-45b23f2f-af54-44cf-9fd1-6bbff19c40d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-b97a2a16-ec83-491f-83e3-d6723fcb9f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-b845f100-161a-4c43-b8d2-536806bde479,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-16a01fa5-463e-450b-946f-e3abbe61bb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-0f8beb7b-6e89-460e-9a88-f45f9929a7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-38703353-fcd2-472c-9283-34ce8f57ad73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-844826852-172.17.0.19-1596053089855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33975,DS-71b56383-546d-40ff-a42d-235ada85e775,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-d3afee6b-be6c-4e70-9475-02e8620e7e75,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-19137ba0-c12f-4e2a-a0ad-47f4d35f16f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-5c04aaec-edd2-4e16-a2e8-4ceeef4e4b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-30fdf6e0-b626-4ddb-ba15-86070efc5165,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-d2f20976-2e05-4619-9b87-91524588a018,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-f49a873b-c2b0-41e4-a68a-2af8a833e810,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-e855703d-54e4-4721-8509-0a5eb9b879b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-844826852-172.17.0.19-1596053089855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33975,DS-71b56383-546d-40ff-a42d-235ada85e775,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-d3afee6b-be6c-4e70-9475-02e8620e7e75,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-19137ba0-c12f-4e2a-a0ad-47f4d35f16f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-5c04aaec-edd2-4e16-a2e8-4ceeef4e4b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-30fdf6e0-b626-4ddb-ba15-86070efc5165,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-d2f20976-2e05-4619-9b87-91524588a018,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-f49a873b-c2b0-41e4-a68a-2af8a833e810,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-e855703d-54e4-4721-8509-0a5eb9b879b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1105639030-172.17.0.19-1596053759805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42302,DS-9e432f63-6ff1-4abe-b22b-f53d6fb3971f,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-ae2743b0-a1b3-4e42-a1f4-b9581ce23b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-76071ff0-989d-4286-9f61-ff87876b496b,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-f0c7e1a2-56d8-47d2-99cd-df082d300aca,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-c831d422-79fc-4afd-8989-d0a3c0c55fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-393bb5dc-7288-472d-8d80-87073c49d66d,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-16a45925-628d-4ac8-926d-c76abcd21b30,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-2c63718b-5561-4b19-afee-90db4eed89bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1105639030-172.17.0.19-1596053759805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42302,DS-9e432f63-6ff1-4abe-b22b-f53d6fb3971f,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-ae2743b0-a1b3-4e42-a1f4-b9581ce23b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-76071ff0-989d-4286-9f61-ff87876b496b,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-f0c7e1a2-56d8-47d2-99cd-df082d300aca,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-c831d422-79fc-4afd-8989-d0a3c0c55fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-393bb5dc-7288-472d-8d80-87073c49d66d,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-16a45925-628d-4ac8-926d-c76abcd21b30,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-2c63718b-5561-4b19-afee-90db4eed89bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2114468577-172.17.0.19-1596053833811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36553,DS-25a52f63-baf9-4d3d-8c4e-3a50ddd5fe9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-31a3442d-bd1c-40cf-af4e-04a8c60a08c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-4c983399-f4f6-4b6c-b0e0-b676438354e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-27dbc815-b517-4344-ad95-4d4f4be0bcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-ccb5d581-4019-407f-be15-064c24f260bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-5bd3372d-01a7-4353-9d0e-9f3c507d48aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-d5009dc6-9f3d-4265-8bb2-f552c3276715,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-078cc567-936c-4ccc-b4dc-5ed3d0ccdc77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2114468577-172.17.0.19-1596053833811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36553,DS-25a52f63-baf9-4d3d-8c4e-3a50ddd5fe9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-31a3442d-bd1c-40cf-af4e-04a8c60a08c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-4c983399-f4f6-4b6c-b0e0-b676438354e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-27dbc815-b517-4344-ad95-4d4f4be0bcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-ccb5d581-4019-407f-be15-064c24f260bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-5bd3372d-01a7-4353-9d0e-9f3c507d48aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-d5009dc6-9f3d-4265-8bb2-f552c3276715,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-078cc567-936c-4ccc-b4dc-5ed3d0ccdc77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2095985707-172.17.0.19-1596053967277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46857,DS-2395d5c2-738f-46e6-b7c0-6cc24b31ec56,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-e0835447-cf7e-4b88-934c-78752f9e6eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-05293097-d6d5-4ccb-af11-e5291be7f0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-77dff5dd-c332-4fa4-8b88-07a09d125730,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-939529b5-2c53-4bc6-843b-2b8e9fbc57a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-44905b7f-7673-465e-a8ef-520a0bc622a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-2ca3eff6-1e18-42f4-b8b1-e99a312902a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-eb4efb80-65af-444c-a354-dd1569b56507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2095985707-172.17.0.19-1596053967277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46857,DS-2395d5c2-738f-46e6-b7c0-6cc24b31ec56,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-e0835447-cf7e-4b88-934c-78752f9e6eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-05293097-d6d5-4ccb-af11-e5291be7f0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-77dff5dd-c332-4fa4-8b88-07a09d125730,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-939529b5-2c53-4bc6-843b-2b8e9fbc57a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-44905b7f-7673-465e-a8ef-520a0bc622a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-2ca3eff6-1e18-42f4-b8b1-e99a312902a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-eb4efb80-65af-444c-a354-dd1569b56507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1450646816-172.17.0.19-1596054130195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37326,DS-d27855c1-0307-4ac9-b450-e99a5917854a,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-b0333682-1f09-4cc4-adf3-7e95ff8162ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-4bf22e0d-33fc-4427-bfa0-8c8d2dd36b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-ce91a400-67a6-4470-bae6-26b62f2d7c25,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-56ff4f2e-c9d6-4216-be6a-541f3964f140,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-de65cfd2-6e73-42cd-9c86-d055fdc1f526,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-b9fc785e-69cd-4455-a680-286fee0f1d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-aea0400e-20f8-42af-9952-12f52f61ae36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1450646816-172.17.0.19-1596054130195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37326,DS-d27855c1-0307-4ac9-b450-e99a5917854a,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-b0333682-1f09-4cc4-adf3-7e95ff8162ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-4bf22e0d-33fc-4427-bfa0-8c8d2dd36b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-ce91a400-67a6-4470-bae6-26b62f2d7c25,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-56ff4f2e-c9d6-4216-be6a-541f3964f140,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-de65cfd2-6e73-42cd-9c86-d055fdc1f526,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-b9fc785e-69cd-4455-a680-286fee0f1d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-aea0400e-20f8-42af-9952-12f52f61ae36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 6496
