reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-605038951-172.17.0.20-1596002197651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41979,DS-fcb69d39-a04b-450a-92f4-19ed066d42ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-4a939a42-bd12-4bb3-8b3b-b593ba34228b,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-e3c15216-651e-47d6-842b-6bb7bba47d90,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-065c7fa7-69df-4d32-8489-9f32510c4835,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-0710e3e4-bac5-4af8-a8bb-24b61881be27,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-00cbd9c7-adf8-45ee-9132-b4ce845e3dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-9bd32af8-42df-417e-a95a-a548fcea3bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-28d262cb-d3d0-4755-af4e-f44bf5d45ee7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-605038951-172.17.0.20-1596002197651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41979,DS-fcb69d39-a04b-450a-92f4-19ed066d42ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-4a939a42-bd12-4bb3-8b3b-b593ba34228b,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-e3c15216-651e-47d6-842b-6bb7bba47d90,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-065c7fa7-69df-4d32-8489-9f32510c4835,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-0710e3e4-bac5-4af8-a8bb-24b61881be27,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-00cbd9c7-adf8-45ee-9132-b4ce845e3dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-9bd32af8-42df-417e-a95a-a548fcea3bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-28d262cb-d3d0-4755-af4e-f44bf5d45ee7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1273726149-172.17.0.20-1596002281192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43096,DS-741742b5-6db0-44d4-a9d0-9a4de138de1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-20be8c00-884f-43af-bdf4-4570b3f6ef45,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-769f5471-ec1a-4e72-b0d8-69002fd39fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-88cee356-612d-4b8d-bc7c-426fdc84e190,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-bfb51fc0-4e5c-48be-84c2-f69059d544f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-04bde0ad-cc9c-4705-b76e-9a237f6efe05,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-1545d21d-d2ba-4e43-963f-0bf0f421c30c,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-69a46c61-8ddd-4a98-9cb5-fbe82714e595,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1273726149-172.17.0.20-1596002281192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43096,DS-741742b5-6db0-44d4-a9d0-9a4de138de1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-20be8c00-884f-43af-bdf4-4570b3f6ef45,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-769f5471-ec1a-4e72-b0d8-69002fd39fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-88cee356-612d-4b8d-bc7c-426fdc84e190,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-bfb51fc0-4e5c-48be-84c2-f69059d544f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-04bde0ad-cc9c-4705-b76e-9a237f6efe05,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-1545d21d-d2ba-4e43-963f-0bf0f421c30c,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-69a46c61-8ddd-4a98-9cb5-fbe82714e595,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1201419141-172.17.0.20-1596002321444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38919,DS-457777a2-98d8-48b0-8632-ae43784687ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-29b6f88b-16c6-4f80-840e-7877919dde4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-2c91fba5-eaed-4a1d-94f0-2ea02e0a1dee,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-719640ac-2639-4aa9-a8e2-517a61be773d,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-78e93eb3-9b0a-4fd8-969b-74bc42d88af7,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-c6ca0218-51b0-4bde-a3a3-463580c995a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-cd96396a-666a-4c10-bf16-143669853aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-7d4e9a9d-895b-416c-9645-82a883a388e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1201419141-172.17.0.20-1596002321444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38919,DS-457777a2-98d8-48b0-8632-ae43784687ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-29b6f88b-16c6-4f80-840e-7877919dde4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-2c91fba5-eaed-4a1d-94f0-2ea02e0a1dee,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-719640ac-2639-4aa9-a8e2-517a61be773d,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-78e93eb3-9b0a-4fd8-969b-74bc42d88af7,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-c6ca0218-51b0-4bde-a3a3-463580c995a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-cd96396a-666a-4c10-bf16-143669853aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-7d4e9a9d-895b-416c-9645-82a883a388e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1731345878-172.17.0.20-1596002359502:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38679,DS-6b9e9ab2-b650-4cfe-88ef-d951c2df4493,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-8a0aaa42-29c5-43a5-873e-ac06aa5e1686,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-5f83f777-aff5-4a77-b620-37ed3281cd82,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-d291c9d7-835d-4d2f-8216-b6e41411b96f,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-5c06350b-84bf-4053-895b-0875986a7562,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-b769937e-a1d7-4c85-9064-4d56f38f6dad,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-c2e54ba7-cbe6-4f4d-bb07-06eafbcf5d27,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-e85ddc1e-6011-4a33-bad5-6188d758b3a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1731345878-172.17.0.20-1596002359502:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38679,DS-6b9e9ab2-b650-4cfe-88ef-d951c2df4493,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-8a0aaa42-29c5-43a5-873e-ac06aa5e1686,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-5f83f777-aff5-4a77-b620-37ed3281cd82,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-d291c9d7-835d-4d2f-8216-b6e41411b96f,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-5c06350b-84bf-4053-895b-0875986a7562,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-b769937e-a1d7-4c85-9064-4d56f38f6dad,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-c2e54ba7-cbe6-4f4d-bb07-06eafbcf5d27,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-e85ddc1e-6011-4a33-bad5-6188d758b3a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2066049763-172.17.0.20-1596003601602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35654,DS-4fec2c70-94d2-42a1-a3cc-c0b33da9f211,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-0adf8932-ecd6-4787-863a-c2abf0f078f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-631c69ec-6ebc-48d9-b68c-19ee59c3ef6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-e5ddaf73-cce3-4e7b-a1c8-9394ae1357e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-becb7dd7-9452-45c7-ba28-415cf0906f52,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-056a96ff-9b55-4b4f-9a4a-00cec6efbed7,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-3d7cea98-cc0a-46e6-8f84-5d96da4f35a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-a8f9aafa-90eb-40a7-92d8-e2faec247949,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2066049763-172.17.0.20-1596003601602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35654,DS-4fec2c70-94d2-42a1-a3cc-c0b33da9f211,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-0adf8932-ecd6-4787-863a-c2abf0f078f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-631c69ec-6ebc-48d9-b68c-19ee59c3ef6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-e5ddaf73-cce3-4e7b-a1c8-9394ae1357e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-becb7dd7-9452-45c7-ba28-415cf0906f52,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-056a96ff-9b55-4b4f-9a4a-00cec6efbed7,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-3d7cea98-cc0a-46e6-8f84-5d96da4f35a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-a8f9aafa-90eb-40a7-92d8-e2faec247949,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1727072844-172.17.0.20-1596003944393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46061,DS-20ff6816-2c8a-4135-a873-9e28d2e6a70a,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-343683a0-59ce-4c79-ad09-3cb3cee51870,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-90982141-aaac-487d-96f9-7f42dad2549b,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-06edc325-bec2-475f-a801-c62c43da0b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-8c6700c8-c1a9-4112-ac8e-0bb848acf2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-37008597-c768-46ba-88ba-e3d94ad1f9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-431a57fc-4bc5-44b4-8c18-ccc96520f13d,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-b615c4ae-024e-4c73-9468-561aaecb4b22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1727072844-172.17.0.20-1596003944393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46061,DS-20ff6816-2c8a-4135-a873-9e28d2e6a70a,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-343683a0-59ce-4c79-ad09-3cb3cee51870,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-90982141-aaac-487d-96f9-7f42dad2549b,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-06edc325-bec2-475f-a801-c62c43da0b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-8c6700c8-c1a9-4112-ac8e-0bb848acf2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-37008597-c768-46ba-88ba-e3d94ad1f9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-431a57fc-4bc5-44b4-8c18-ccc96520f13d,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-b615c4ae-024e-4c73-9468-561aaecb4b22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402142198-172.17.0.20-1596004213609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38339,DS-8c1e885d-443e-48a2-83ea-40d6b944f6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-2614075f-246e-4562-81f1-29b7d37ae992,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-4046bebe-a3ed-4e31-b0f5-ed78b5d796c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-3fae6c4a-81c5-4aea-b42f-3d822643efc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-f0daba59-1298-4f6d-a32c-1500912f747e,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-d1483da0-97ff-4997-8ed7-2192c0dc438b,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-b0aeede1-4188-4c9a-82fb-6110dd7b9bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-d6321d41-3eed-4ad0-83c8-1ae934519063,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402142198-172.17.0.20-1596004213609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38339,DS-8c1e885d-443e-48a2-83ea-40d6b944f6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-2614075f-246e-4562-81f1-29b7d37ae992,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-4046bebe-a3ed-4e31-b0f5-ed78b5d796c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-3fae6c4a-81c5-4aea-b42f-3d822643efc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-f0daba59-1298-4f6d-a32c-1500912f747e,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-d1483da0-97ff-4997-8ed7-2192c0dc438b,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-b0aeede1-4188-4c9a-82fb-6110dd7b9bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-d6321d41-3eed-4ad0-83c8-1ae934519063,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1851539811-172.17.0.20-1596004279597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36900,DS-addb8293-8025-4be1-ac84-de0571bae4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-2a992e38-e51b-4f58-87d4-f85d29a6d165,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-6d992e71-f3d7-4486-9e82-43d464bfa565,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-4e3f7298-d3d7-4ffa-b6c1-3e1546d8e973,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-0bc0644e-4702-4743-a752-a01ba1a5ea4a,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-42c91430-0d5d-4f3f-a8ab-2c3d3073a135,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-2c9ad3aa-64b0-4777-841a-b045e26482b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-854652db-e835-4ba2-8e3b-6defdf4f1f75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1851539811-172.17.0.20-1596004279597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36900,DS-addb8293-8025-4be1-ac84-de0571bae4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-2a992e38-e51b-4f58-87d4-f85d29a6d165,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-6d992e71-f3d7-4486-9e82-43d464bfa565,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-4e3f7298-d3d7-4ffa-b6c1-3e1546d8e973,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-0bc0644e-4702-4743-a752-a01ba1a5ea4a,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-42c91430-0d5d-4f3f-a8ab-2c3d3073a135,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-2c9ad3aa-64b0-4777-841a-b045e26482b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-854652db-e835-4ba2-8e3b-6defdf4f1f75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1679853871-172.17.0.20-1596004312185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34817,DS-7e3ec060-ecc9-4fee-9038-e5db2311c09e,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-c2fcaefb-47cf-4d53-90c9-add57f428628,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-1a839d52-5126-4611-9314-accb9041d008,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-07cf0d1a-0189-480b-a87c-88f6d1ad431e,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-c99096c4-6f30-4326-bb5b-a323c70b68f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-5f648b6c-892b-450e-b30d-0aad2b3f3951,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-c755928d-1b4a-4b9d-b9d9-ac6475a700ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-fe2da605-a813-45a1-8170-9521504ca2bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1679853871-172.17.0.20-1596004312185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34817,DS-7e3ec060-ecc9-4fee-9038-e5db2311c09e,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-c2fcaefb-47cf-4d53-90c9-add57f428628,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-1a839d52-5126-4611-9314-accb9041d008,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-07cf0d1a-0189-480b-a87c-88f6d1ad431e,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-c99096c4-6f30-4326-bb5b-a323c70b68f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-5f648b6c-892b-450e-b30d-0aad2b3f3951,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-c755928d-1b4a-4b9d-b9d9-ac6475a700ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-fe2da605-a813-45a1-8170-9521504ca2bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2046677430-172.17.0.20-1596004349546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37130,DS-ead3ad47-f07d-4dc6-b6bd-15d669d4dc68,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-61d38cdc-7be3-4f8a-a41a-c76bad85c6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-d449521c-0353-417a-a834-cb6b9bd32fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-3c9b92b8-498d-4129-8ef2-3ad2a59c22d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-9eb2da26-548a-4e7b-8a36-1bd50e75a9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-9298e998-0af5-4024-b559-05549a7f0589,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-be6677ac-cfbd-4ab6-8a1a-5338f3b696b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-649c3da2-0d11-4507-9f85-9cb0c851465e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2046677430-172.17.0.20-1596004349546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37130,DS-ead3ad47-f07d-4dc6-b6bd-15d669d4dc68,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-61d38cdc-7be3-4f8a-a41a-c76bad85c6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-d449521c-0353-417a-a834-cb6b9bd32fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-3c9b92b8-498d-4129-8ef2-3ad2a59c22d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-9eb2da26-548a-4e7b-8a36-1bd50e75a9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-9298e998-0af5-4024-b559-05549a7f0589,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-be6677ac-cfbd-4ab6-8a1a-5338f3b696b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-649c3da2-0d11-4507-9f85-9cb0c851465e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-334820430-172.17.0.20-1596004523737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39674,DS-4063b232-8fc1-4fb4-bf9c-7d5a8ffd608f,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-30d0dbb8-c6cb-4446-a3ee-2ee300ca651d,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-16e3cfac-566a-4377-9854-b482b4dd0fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-8f98c142-5470-4821-8b7a-1fa280a80ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-f66be96c-80b4-4735-81e7-1eb128f2eade,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-1ee1dc35-877e-4033-adb5-de2ba628ae7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-a4aad9fb-dcd1-4451-8d10-10e7a2ffd1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-a3e60b05-5029-4858-8ee6-0d87156199af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-334820430-172.17.0.20-1596004523737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39674,DS-4063b232-8fc1-4fb4-bf9c-7d5a8ffd608f,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-30d0dbb8-c6cb-4446-a3ee-2ee300ca651d,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-16e3cfac-566a-4377-9854-b482b4dd0fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-8f98c142-5470-4821-8b7a-1fa280a80ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-f66be96c-80b4-4735-81e7-1eb128f2eade,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-1ee1dc35-877e-4033-adb5-de2ba628ae7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-a4aad9fb-dcd1-4451-8d10-10e7a2ffd1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-a3e60b05-5029-4858-8ee6-0d87156199af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2089817887-172.17.0.20-1596004741668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44405,DS-c450aacd-2ce6-409c-ae33-227ee3a6de16,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-021d96bc-5084-4d9e-901a-d59b6cdeabd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-59a843c4-0944-4a93-856a-d796781abd30,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-6ea52f12-418f-4cc7-9a0a-b635bb4f1164,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-b37530f8-e7de-482f-84b0-9e0ca12a4805,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-45e63ad0-fc41-41f4-86d1-7af1fa056c97,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-d9c0f25c-050c-426b-b1ee-f2e758d80085,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-94e15885-6f31-400a-9a64-6053fd9f16f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2089817887-172.17.0.20-1596004741668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44405,DS-c450aacd-2ce6-409c-ae33-227ee3a6de16,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-021d96bc-5084-4d9e-901a-d59b6cdeabd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-59a843c4-0944-4a93-856a-d796781abd30,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-6ea52f12-418f-4cc7-9a0a-b635bb4f1164,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-b37530f8-e7de-482f-84b0-9e0ca12a4805,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-45e63ad0-fc41-41f4-86d1-7af1fa056c97,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-d9c0f25c-050c-426b-b1ee-f2e758d80085,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-94e15885-6f31-400a-9a64-6053fd9f16f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1260316554-172.17.0.20-1596005026518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40309,DS-7ae908e7-a912-41ac-a286-fe010e59eee9,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-86d13eb0-8102-49a7-9bfc-4555010cec49,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-8df4bdea-cde2-4b9b-ac29-46691add4e82,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-43b6e342-c0dc-46b8-826c-f62637e30ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-37bc1194-33e8-4038-a7b6-51b7ac2442a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-60f8a731-26cb-4abc-b720-6966a5fc4b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-abd5c114-c9f0-4d9a-824d-3c48cf4fae33,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-2bb04da0-8ae8-4993-a88e-06eae0c87b41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1260316554-172.17.0.20-1596005026518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40309,DS-7ae908e7-a912-41ac-a286-fe010e59eee9,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-86d13eb0-8102-49a7-9bfc-4555010cec49,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-8df4bdea-cde2-4b9b-ac29-46691add4e82,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-43b6e342-c0dc-46b8-826c-f62637e30ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-37bc1194-33e8-4038-a7b6-51b7ac2442a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-60f8a731-26cb-4abc-b720-6966a5fc4b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-abd5c114-c9f0-4d9a-824d-3c48cf4fae33,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-2bb04da0-8ae8-4993-a88e-06eae0c87b41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119274175-172.17.0.20-1596005167684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38521,DS-aa4860d4-22c0-407e-94d6-1da6f0a65495,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-c5f47466-1fde-4209-b16a-35e1fd86cf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-317327d0-b0a8-456e-8fd9-935f7e538672,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-545da218-36ac-4672-8c75-91c4d3b5197a,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-99494fb2-2a1d-4175-a916-78757ba9ec4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-85786760-7de6-4ea0-8976-b2292fb1e4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-618192cf-509c-4bdc-abee-f2958da09cce,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-c3a815dc-bc17-4a8e-a4c8-5f90614b2286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119274175-172.17.0.20-1596005167684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38521,DS-aa4860d4-22c0-407e-94d6-1da6f0a65495,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-c5f47466-1fde-4209-b16a-35e1fd86cf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-317327d0-b0a8-456e-8fd9-935f7e538672,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-545da218-36ac-4672-8c75-91c4d3b5197a,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-99494fb2-2a1d-4175-a916-78757ba9ec4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-85786760-7de6-4ea0-8976-b2292fb1e4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-618192cf-509c-4bdc-abee-f2958da09cce,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-c3a815dc-bc17-4a8e-a4c8-5f90614b2286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-485884027-172.17.0.20-1596005245029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36385,DS-851d5efe-0eba-4dd9-8311-208be61c00ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-aa230d5a-8ba7-404d-9483-5beae2434beb,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-543d2026-b9a1-46c0-8d7e-dd7b906f632a,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-3bad24fb-9917-438e-ac67-8827708e99d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-ca1b1694-35da-4424-a0ae-5af7bfc7e91f,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-fb3cfbdb-71c9-4e8e-a7de-010dab5527e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-e30aa117-ad97-4785-87bc-226ebce5c1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-82e35cce-2c0e-44db-a6b1-210d0f4077d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-485884027-172.17.0.20-1596005245029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36385,DS-851d5efe-0eba-4dd9-8311-208be61c00ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-aa230d5a-8ba7-404d-9483-5beae2434beb,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-543d2026-b9a1-46c0-8d7e-dd7b906f632a,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-3bad24fb-9917-438e-ac67-8827708e99d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-ca1b1694-35da-4424-a0ae-5af7bfc7e91f,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-fb3cfbdb-71c9-4e8e-a7de-010dab5527e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-e30aa117-ad97-4785-87bc-226ebce5c1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-82e35cce-2c0e-44db-a6b1-210d0f4077d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-526764082-172.17.0.20-1596005422286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37340,DS-ccc8d740-1f99-406c-9c58-aefd1f5270c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-74b9bfde-47bb-427f-8d4e-23528dd7c999,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-cb794a76-d7c6-4442-b8e9-cd5afbf4e9db,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-de8d070c-7b91-4b6d-a73b-aee2e66be9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-01c986ee-1255-464d-b894-fbec187de0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-af8be29b-369e-4715-bc59-4eb3b8ad53f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-d41040f5-e807-475d-8e03-2c93affbe43b,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-fdbf3bd5-1f27-4f18-b8dc-6065ef200dfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-526764082-172.17.0.20-1596005422286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37340,DS-ccc8d740-1f99-406c-9c58-aefd1f5270c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-74b9bfde-47bb-427f-8d4e-23528dd7c999,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-cb794a76-d7c6-4442-b8e9-cd5afbf4e9db,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-de8d070c-7b91-4b6d-a73b-aee2e66be9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-01c986ee-1255-464d-b894-fbec187de0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-af8be29b-369e-4715-bc59-4eb3b8ad53f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-d41040f5-e807-475d-8e03-2c93affbe43b,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-fdbf3bd5-1f27-4f18-b8dc-6065ef200dfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311679480-172.17.0.20-1596005712309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32894,DS-74e051dc-5030-49d3-ac07-11bbfa19f340,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-710eef51-3f0d-4c99-9700-db1e0593a3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-69a5c8b5-84c3-4917-80a8-e8273e72274a,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-3914eb48-f138-4afd-a37a-008298a075d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-3f371829-91a3-4c92-ba75-75e971febdad,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-e1b0a58e-f87a-4c38-85dd-e7a4c0a934c2,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-30bbdac9-b2ce-4a0f-b9b6-dae8ed20fed4,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-499dacc7-427f-430e-bed6-59a13feac94a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311679480-172.17.0.20-1596005712309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32894,DS-74e051dc-5030-49d3-ac07-11bbfa19f340,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-710eef51-3f0d-4c99-9700-db1e0593a3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-69a5c8b5-84c3-4917-80a8-e8273e72274a,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-3914eb48-f138-4afd-a37a-008298a075d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-3f371829-91a3-4c92-ba75-75e971febdad,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-e1b0a58e-f87a-4c38-85dd-e7a4c0a934c2,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-30bbdac9-b2ce-4a0f-b9b6-dae8ed20fed4,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-499dacc7-427f-430e-bed6-59a13feac94a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1178116076-172.17.0.20-1596005788637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34501,DS-71e552c2-a6c2-418d-946a-dca128f5643f,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-91d2293f-065f-4b04-bb4c-d7ee4659ec5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-3f2a0caa-3bc0-4a09-bb0e-6c4cae23d005,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-9ee62370-bf2d-4362-8674-bce9c42d4388,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-8a58e3b4-b5af-4d1b-8a5e-b18a85b2927c,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-b11e4208-85e0-4d8c-8ccc-43b7d5475352,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-2d5a7217-3588-4b1c-b1d8-adb88ffca113,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-66541bbb-c56e-43be-bdb2-f6b17b382fed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1178116076-172.17.0.20-1596005788637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34501,DS-71e552c2-a6c2-418d-946a-dca128f5643f,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-91d2293f-065f-4b04-bb4c-d7ee4659ec5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-3f2a0caa-3bc0-4a09-bb0e-6c4cae23d005,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-9ee62370-bf2d-4362-8674-bce9c42d4388,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-8a58e3b4-b5af-4d1b-8a5e-b18a85b2927c,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-b11e4208-85e0-4d8c-8ccc-43b7d5475352,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-2d5a7217-3588-4b1c-b1d8-adb88ffca113,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-66541bbb-c56e-43be-bdb2-f6b17b382fed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110703033-172.17.0.20-1596006437133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40152,DS-4095ed41-fdc1-4903-a138-6edd8026acb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-1bb7d2ad-da63-4c76-9fc1-460830f3cec6,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-ce6433b2-3ec2-449b-b9a5-5dba76e30e11,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-0ae237a1-6009-4153-9cf4-4e94e303816f,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-84407506-430b-4e95-9cbf-a83d319ac6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-bd1fa2b6-3b7b-4830-9b3f-0623516a641a,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-17cc715d-43e4-48b5-a3a0-1ebb570cadf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-d2804e6a-d49c-4b20-a9d2-786a2e81048e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110703033-172.17.0.20-1596006437133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40152,DS-4095ed41-fdc1-4903-a138-6edd8026acb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-1bb7d2ad-da63-4c76-9fc1-460830f3cec6,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-ce6433b2-3ec2-449b-b9a5-5dba76e30e11,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-0ae237a1-6009-4153-9cf4-4e94e303816f,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-84407506-430b-4e95-9cbf-a83d319ac6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-bd1fa2b6-3b7b-4830-9b3f-0623516a641a,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-17cc715d-43e4-48b5-a3a0-1ebb570cadf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-d2804e6a-d49c-4b20-a9d2-786a2e81048e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-634668998-172.17.0.20-1596006693135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39224,DS-da30adfe-1f23-4c9f-b493-9fc5e85c9dda,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-2058d9d1-748c-40e2-a27d-958b310c0230,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-f0110988-8cf5-40c1-b394-c9b3c443e473,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-c26ad8f7-7307-4f7c-af04-7b7ddb7a8f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-dafe5409-ccac-415a-b646-364eabef0e85,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-b50a070f-0e6e-431b-b26c-f2df4c1911ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-acee869b-0fd6-4f07-bf2d-761e2f0aafd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-ce4a5deb-cc0e-45fb-ae77-a5d38c9d1636,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-634668998-172.17.0.20-1596006693135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39224,DS-da30adfe-1f23-4c9f-b493-9fc5e85c9dda,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-2058d9d1-748c-40e2-a27d-958b310c0230,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-f0110988-8cf5-40c1-b394-c9b3c443e473,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-c26ad8f7-7307-4f7c-af04-7b7ddb7a8f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-dafe5409-ccac-415a-b646-364eabef0e85,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-b50a070f-0e6e-431b-b26c-f2df4c1911ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-acee869b-0fd6-4f07-bf2d-761e2f0aafd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-ce4a5deb-cc0e-45fb-ae77-a5d38c9d1636,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-950616424-172.17.0.20-1596006934662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44333,DS-9de2c78f-49ec-4f4e-8fd1-4dd698e3e929,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-a80bc681-5e39-4132-bea4-e39678ec46bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-43c95b6d-984c-4f7c-88a3-e3b4df1a446a,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-0493e5e6-23fb-4265-a4df-cc0a7200dc21,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-acca3874-d57b-4d09-9067-d61270cfc79f,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-2cfae2ca-6dde-4474-96c9-7393c8c5d120,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-b23c11d7-b408-4f83-afa9-8adbe6d21989,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-63010ccb-8acc-4340-8bf0-f78242b9a1ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-950616424-172.17.0.20-1596006934662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44333,DS-9de2c78f-49ec-4f4e-8fd1-4dd698e3e929,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-a80bc681-5e39-4132-bea4-e39678ec46bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-43c95b6d-984c-4f7c-88a3-e3b4df1a446a,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-0493e5e6-23fb-4265-a4df-cc0a7200dc21,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-acca3874-d57b-4d09-9067-d61270cfc79f,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-2cfae2ca-6dde-4474-96c9-7393c8c5d120,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-b23c11d7-b408-4f83-afa9-8adbe6d21989,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-63010ccb-8acc-4340-8bf0-f78242b9a1ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-117542765-172.17.0.20-1596007305008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41519,DS-cbddb50c-c862-4b4b-8b39-70085ede5d22,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-233f3aae-d9f9-45b5-b542-4f36717f59b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-3d0b8acc-29f4-4ccc-a681-67438f7a475b,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-0aab46a3-5132-45d1-8856-f316c75c9339,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-07ab8d15-26a4-45df-b344-279e4944097a,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-8e085d2e-b428-46a9-a01d-8a0ec9d85f54,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-4f5edac7-c2bf-4391-8023-4ec52da4c1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-5fd59595-c18c-4b0e-8f7b-c330b1cf8ab2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-117542765-172.17.0.20-1596007305008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41519,DS-cbddb50c-c862-4b4b-8b39-70085ede5d22,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-233f3aae-d9f9-45b5-b542-4f36717f59b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-3d0b8acc-29f4-4ccc-a681-67438f7a475b,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-0aab46a3-5132-45d1-8856-f316c75c9339,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-07ab8d15-26a4-45df-b344-279e4944097a,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-8e085d2e-b428-46a9-a01d-8a0ec9d85f54,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-4f5edac7-c2bf-4391-8023-4ec52da4c1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-5fd59595-c18c-4b0e-8f7b-c330b1cf8ab2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5402
