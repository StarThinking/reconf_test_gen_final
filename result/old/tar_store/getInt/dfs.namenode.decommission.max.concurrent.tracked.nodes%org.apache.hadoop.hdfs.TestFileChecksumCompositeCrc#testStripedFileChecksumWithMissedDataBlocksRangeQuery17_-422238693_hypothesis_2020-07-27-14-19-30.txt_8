reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-839553164-172.17.0.7-1595861104137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46383,DS-8f4ba416-ac1a-40c0-85d1-dea59fc0a74d,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-5d6d8f96-30c1-4048-b3d7-6f280ea03f41,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-3cee6d4b-997a-4d8c-90aa-7f7e8035e90f,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-c047b367-fe05-4e50-bdef-e5499e3b4d11,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-02404e5f-a2ea-4da2-ae0a-c239cecb6eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-f7477d58-ca7f-4d43-a72b-3a4dd23f8e58,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-4fb05ace-3644-4250-9060-19c09a4d9194,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-edfa1e88-f267-4c9f-965b-6c2bb92a3e5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-839553164-172.17.0.7-1595861104137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46383,DS-8f4ba416-ac1a-40c0-85d1-dea59fc0a74d,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-5d6d8f96-30c1-4048-b3d7-6f280ea03f41,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-3cee6d4b-997a-4d8c-90aa-7f7e8035e90f,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-c047b367-fe05-4e50-bdef-e5499e3b4d11,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-02404e5f-a2ea-4da2-ae0a-c239cecb6eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-f7477d58-ca7f-4d43-a72b-3a4dd23f8e58,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-4fb05ace-3644-4250-9060-19c09a4d9194,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-edfa1e88-f267-4c9f-965b-6c2bb92a3e5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1502139942-172.17.0.7-1595861138389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46050,DS-fac37de5-48ef-45fc-9d12-9a771c262405,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-3949d976-d7ff-4f0e-a064-3a175efcd88d,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-4585b33c-475f-4be6-afb7-69a054f24cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-25f634f5-1477-433f-b508-1e48d9321725,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-b48a51d6-3a86-4979-a592-f412b40da1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-2f0fa161-97a5-499b-8e81-187124aa2529,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-7b2e93cd-aaed-43d2-b733-04b09f2a0d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-a4fdd0e7-3e6a-43a3-94b7-a6b74037db07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1502139942-172.17.0.7-1595861138389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46050,DS-fac37de5-48ef-45fc-9d12-9a771c262405,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-3949d976-d7ff-4f0e-a064-3a175efcd88d,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-4585b33c-475f-4be6-afb7-69a054f24cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-25f634f5-1477-433f-b508-1e48d9321725,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-b48a51d6-3a86-4979-a592-f412b40da1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-2f0fa161-97a5-499b-8e81-187124aa2529,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-7b2e93cd-aaed-43d2-b733-04b09f2a0d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-a4fdd0e7-3e6a-43a3-94b7-a6b74037db07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1335228884-172.17.0.7-1595861549609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34814,DS-80096724-1845-4e1c-97aa-3e3418525f01,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-7dbae665-84b5-4da6-bacc-1b2096f7be41,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-2ae258cc-03ba-4800-9e48-ec823d6dc086,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-62350187-77e2-43fb-a44a-4a489997db7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-a4c6834a-4a2f-4120-97a9-fbfae64b135b,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-ad7d1a18-ca0a-4d2f-9528-a8d36848f750,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-8838d5aa-c170-43c4-b38e-91ac1a7a75ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-664a11e4-13ab-4582-b035-d1ec930f686a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1335228884-172.17.0.7-1595861549609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34814,DS-80096724-1845-4e1c-97aa-3e3418525f01,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-7dbae665-84b5-4da6-bacc-1b2096f7be41,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-2ae258cc-03ba-4800-9e48-ec823d6dc086,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-62350187-77e2-43fb-a44a-4a489997db7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-a4c6834a-4a2f-4120-97a9-fbfae64b135b,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-ad7d1a18-ca0a-4d2f-9528-a8d36848f750,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-8838d5aa-c170-43c4-b38e-91ac1a7a75ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-664a11e4-13ab-4582-b035-d1ec930f686a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1639790440-172.17.0.7-1595861900812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44676,DS-3856838b-e1ad-4cc8-a728-57a60b685c66,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-ef0b3437-fbf9-4548-a1b3-fbdfe2fcceca,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-517c683b-0305-4f15-ba38-88c369a85b17,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-61f76fdc-1fa7-43ea-b555-d3b4a01572a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-dd010977-aba5-4d17-8810-051d36cb7886,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-8375462b-5ff4-4c15-abbb-de5fee853978,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-d4baf51e-45ee-4cab-bdfb-0767414f3c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-54828f21-7499-4f29-936d-b8459056351b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1639790440-172.17.0.7-1595861900812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44676,DS-3856838b-e1ad-4cc8-a728-57a60b685c66,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-ef0b3437-fbf9-4548-a1b3-fbdfe2fcceca,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-517c683b-0305-4f15-ba38-88c369a85b17,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-61f76fdc-1fa7-43ea-b555-d3b4a01572a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-dd010977-aba5-4d17-8810-051d36cb7886,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-8375462b-5ff4-4c15-abbb-de5fee853978,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-d4baf51e-45ee-4cab-bdfb-0767414f3c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-54828f21-7499-4f29-936d-b8459056351b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371887690-172.17.0.7-1595863038628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45674,DS-28cec520-af52-44dc-97bf-9b36e9eb8984,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-ff7ab3e0-6708-4220-8d3c-e4f69a7314ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-c5c85c75-4d86-43f6-9831-60717e728312,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-20c9b579-60bb-4d76-adef-4fd7164b9596,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-118a36c1-2b8c-4b57-85c0-d1ee75a3e9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-cd60bdb4-2277-4246-8617-5004a813da02,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-731f2d92-e7a1-4299-b2e9-14a1e1da8fed,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-810420fe-3e28-4b33-9298-9628cc51c21f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371887690-172.17.0.7-1595863038628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45674,DS-28cec520-af52-44dc-97bf-9b36e9eb8984,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-ff7ab3e0-6708-4220-8d3c-e4f69a7314ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-c5c85c75-4d86-43f6-9831-60717e728312,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-20c9b579-60bb-4d76-adef-4fd7164b9596,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-118a36c1-2b8c-4b57-85c0-d1ee75a3e9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-cd60bdb4-2277-4246-8617-5004a813da02,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-731f2d92-e7a1-4299-b2e9-14a1e1da8fed,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-810420fe-3e28-4b33-9298-9628cc51c21f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-812693289-172.17.0.7-1595863387451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40458,DS-e6b4a3fc-f0e4-41e0-8064-5a03181bef14,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-fa580dfc-643c-40f0-9d4e-c2603d98570a,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-5467f8db-9526-474d-be09-1cddf861d3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-3dccfbd9-9199-43cc-8255-4a690c860be6,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-bf4c8179-03fe-4aa3-a7d4-232c30b534fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-31a76c07-ddf9-462d-98ad-0d6a298a7fed,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-40beec08-9462-438a-a47e-c30c380e3e57,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-8b86930c-32c7-4534-a234-c8571c78443e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-812693289-172.17.0.7-1595863387451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40458,DS-e6b4a3fc-f0e4-41e0-8064-5a03181bef14,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-fa580dfc-643c-40f0-9d4e-c2603d98570a,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-5467f8db-9526-474d-be09-1cddf861d3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-3dccfbd9-9199-43cc-8255-4a690c860be6,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-bf4c8179-03fe-4aa3-a7d4-232c30b534fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-31a76c07-ddf9-462d-98ad-0d6a298a7fed,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-40beec08-9462-438a-a47e-c30c380e3e57,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-8b86930c-32c7-4534-a234-c8571c78443e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1961002268-172.17.0.7-1595863663665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41671,DS-04a72cfc-fa50-4cad-a6b6-b2c000897515,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-6d6a74b8-a6e5-43e0-8a10-603ce42a6a83,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-350f286f-8f9b-4fe2-a866-dfa61fe34ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-d46ebcc7-9b15-4eae-b634-43ddc4698f17,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-298705d6-21f6-4cf6-af0c-ec515495a178,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-47b6755d-7f56-4471-8c0f-c310fa3e9a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-9ebd008a-e43d-4b4a-978b-6cdaa3f25e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-6f2f4f92-3bf3-4c4a-9efe-004eae8d2d4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1961002268-172.17.0.7-1595863663665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41671,DS-04a72cfc-fa50-4cad-a6b6-b2c000897515,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-6d6a74b8-a6e5-43e0-8a10-603ce42a6a83,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-350f286f-8f9b-4fe2-a866-dfa61fe34ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-d46ebcc7-9b15-4eae-b634-43ddc4698f17,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-298705d6-21f6-4cf6-af0c-ec515495a178,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-47b6755d-7f56-4471-8c0f-c310fa3e9a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-9ebd008a-e43d-4b4a-978b-6cdaa3f25e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-6f2f4f92-3bf3-4c4a-9efe-004eae8d2d4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-662788533-172.17.0.7-1595863777260:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42818,DS-fb953163-2c6f-4c45-8d2a-8b2501f42ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-a2497a79-3dec-4d52-9771-8c4eb2d52679,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-64ae4898-16c9-4620-9194-1b1b881808c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-ed398d25-cd65-4bce-bd91-e6007272e235,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-8dbaf2f2-6379-4074-bf8d-4137fc4eb12f,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-71f017ce-54e8-4e09-aa81-0036b70cac8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-8c0a2160-90c2-4bb2-b5c8-eaec92fca664,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-d540aff3-2954-406a-8d45-ae62f3bf08a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-662788533-172.17.0.7-1595863777260:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42818,DS-fb953163-2c6f-4c45-8d2a-8b2501f42ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-a2497a79-3dec-4d52-9771-8c4eb2d52679,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-64ae4898-16c9-4620-9194-1b1b881808c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-ed398d25-cd65-4bce-bd91-e6007272e235,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-8dbaf2f2-6379-4074-bf8d-4137fc4eb12f,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-71f017ce-54e8-4e09-aa81-0036b70cac8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-8c0a2160-90c2-4bb2-b5c8-eaec92fca664,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-d540aff3-2954-406a-8d45-ae62f3bf08a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-887967370-172.17.0.7-1595863954435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44686,DS-c4ce185a-4373-484e-8fa5-fd1cc91a6818,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-7f37468a-2930-4709-be8c-2a22278e6511,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-c643539e-ff2d-43d4-a872-30186b7e6c16,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-0a9df736-3c39-45e2-84ff-a96cac05d9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-7bd427a7-4362-487e-b687-a8ae5d79c895,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-2abf3fc3-8f79-4ecd-9b7b-08fb75baff8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-9fa475d4-38c8-48dc-809e-17a5a6720caa,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-f0b8b9bf-92e0-42c6-9055-58f1530696a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-887967370-172.17.0.7-1595863954435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44686,DS-c4ce185a-4373-484e-8fa5-fd1cc91a6818,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-7f37468a-2930-4709-be8c-2a22278e6511,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-c643539e-ff2d-43d4-a872-30186b7e6c16,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-0a9df736-3c39-45e2-84ff-a96cac05d9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-7bd427a7-4362-487e-b687-a8ae5d79c895,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-2abf3fc3-8f79-4ecd-9b7b-08fb75baff8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-9fa475d4-38c8-48dc-809e-17a5a6720caa,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-f0b8b9bf-92e0-42c6-9055-58f1530696a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-727558800-172.17.0.7-1595864128074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41598,DS-671ccfa5-c7ec-41e9-8575-41f570b889fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-09610cc5-250d-4cfe-8e2d-2a7e6567ca4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-8f53b3ad-af0d-4333-8e79-68855970ae78,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-2de58168-fd94-4e5b-ac63-6b1e0546a597,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-902c9f7d-0de4-4bd1-8e07-8683bcf89206,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-b27c024d-ee91-4478-8834-83471a1a6398,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-762abc8e-e4ab-4774-9ebd-6d1b8b2131e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-ff123d83-b47d-4e19-8bfe-bc231deed0e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-727558800-172.17.0.7-1595864128074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41598,DS-671ccfa5-c7ec-41e9-8575-41f570b889fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-09610cc5-250d-4cfe-8e2d-2a7e6567ca4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-8f53b3ad-af0d-4333-8e79-68855970ae78,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-2de58168-fd94-4e5b-ac63-6b1e0546a597,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-902c9f7d-0de4-4bd1-8e07-8683bcf89206,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-b27c024d-ee91-4478-8834-83471a1a6398,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-762abc8e-e4ab-4774-9ebd-6d1b8b2131e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-ff123d83-b47d-4e19-8bfe-bc231deed0e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5146
