reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327574509-172.17.0.19-1595884280517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33442,DS-5a229d0f-cd41-46b1-9c66-95e69486f7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-fb8ddcd3-55b8-4741-8564-145b05a7e7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-c1cd4f40-d6b9-423c-a238-2b8710e17830,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-aaeeb2fb-a0d3-40d6-836e-24000b827469,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-5bc83a53-6f38-48a0-9af9-969e069931e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-e5ae9829-de7f-4761-8f84-cc3543064057,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-3980cdd0-6419-44f1-99d0-3b182110f947,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-8dea28e8-615a-4c2b-9ef5-da64a198133c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327574509-172.17.0.19-1595884280517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33442,DS-5a229d0f-cd41-46b1-9c66-95e69486f7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-fb8ddcd3-55b8-4741-8564-145b05a7e7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-c1cd4f40-d6b9-423c-a238-2b8710e17830,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-aaeeb2fb-a0d3-40d6-836e-24000b827469,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-5bc83a53-6f38-48a0-9af9-969e069931e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-e5ae9829-de7f-4761-8f84-cc3543064057,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-3980cdd0-6419-44f1-99d0-3b182110f947,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-8dea28e8-615a-4c2b-9ef5-da64a198133c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1824577146-172.17.0.19-1595884650534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45185,DS-982f4329-80a3-404a-a104-064333b912bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-0abacb01-4c0f-4b1a-ba7b-133a1680236d,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-f6d7f861-0af9-49c6-b66d-1e09f9abfa67,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-2735f228-a1d4-4b5c-a359-34fae35e0750,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-32c88bc4-ca42-4a7c-bf4c-39d55bb2bd39,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-32b8c02b-ed82-4a95-b04a-dd3a03d58245,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-60352b83-7a88-4b8b-a676-2d2c4217e3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-2eb6b848-7d64-431d-8987-532aa0858836,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1824577146-172.17.0.19-1595884650534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45185,DS-982f4329-80a3-404a-a104-064333b912bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-0abacb01-4c0f-4b1a-ba7b-133a1680236d,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-f6d7f861-0af9-49c6-b66d-1e09f9abfa67,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-2735f228-a1d4-4b5c-a359-34fae35e0750,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-32c88bc4-ca42-4a7c-bf4c-39d55bb2bd39,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-32b8c02b-ed82-4a95-b04a-dd3a03d58245,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-60352b83-7a88-4b8b-a676-2d2c4217e3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-2eb6b848-7d64-431d-8987-532aa0858836,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-752924687-172.17.0.19-1595884723953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34804,DS-edd142fe-5a76-4346-b78b-793243b4eb84,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-5d3043be-aa44-4034-ab32-9f9a7f4ae945,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-2dca5b91-d8c2-443e-9167-3af5d7279154,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-c78c4816-29ec-4e4d-8955-c310c0c6dac0,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-73ada116-3a76-4f1b-a756-8c7562ee137f,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-6daf6628-0631-4c53-bd64-e9c624c1a35e,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-d5150ffa-9861-4981-be85-50365725c3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-d6afc17a-0c52-434d-be71-1ef69848496d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-752924687-172.17.0.19-1595884723953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34804,DS-edd142fe-5a76-4346-b78b-793243b4eb84,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-5d3043be-aa44-4034-ab32-9f9a7f4ae945,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-2dca5b91-d8c2-443e-9167-3af5d7279154,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-c78c4816-29ec-4e4d-8955-c310c0c6dac0,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-73ada116-3a76-4f1b-a756-8c7562ee137f,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-6daf6628-0631-4c53-bd64-e9c624c1a35e,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-d5150ffa-9861-4981-be85-50365725c3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-d6afc17a-0c52-434d-be71-1ef69848496d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-366300937-172.17.0.19-1595885506477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34114,DS-b415ad02-52b6-435d-91df-b83d80485464,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-1a592e84-ecd3-47fe-817d-489b81a48c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-f9a9da31-e1e7-4fbd-b88f-b319e80ad4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-f404ae63-9b04-465d-92eb-09672ec9c8af,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-3a45aec6-47bd-4c3d-98ab-69bbc7db0936,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-0ad7f8fa-dc40-4451-8f60-77e544560cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-493461fb-ecff-457e-b267-ce168a232639,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-d050d3ce-bfa4-428c-9a92-c0e0e6f245b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-366300937-172.17.0.19-1595885506477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34114,DS-b415ad02-52b6-435d-91df-b83d80485464,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-1a592e84-ecd3-47fe-817d-489b81a48c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-f9a9da31-e1e7-4fbd-b88f-b319e80ad4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-f404ae63-9b04-465d-92eb-09672ec9c8af,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-3a45aec6-47bd-4c3d-98ab-69bbc7db0936,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-0ad7f8fa-dc40-4451-8f60-77e544560cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-493461fb-ecff-457e-b267-ce168a232639,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-d050d3ce-bfa4-428c-9a92-c0e0e6f245b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106697455-172.17.0.19-1595885641739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38276,DS-570d37f6-64a1-4807-bbc0-1befac312c13,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-9b5c18a7-9241-4ac2-afc6-1ee49dee5a48,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-9cd84bf0-85ba-477b-8229-f8d04ae74c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-d57da3f7-b5a7-4bde-8ca6-c06864ef3de0,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-917f100f-a36f-4189-8df4-556aec70a366,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-778d7f91-00db-410c-b544-814775a5fecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-56ce0c91-28f7-4736-a807-d73c4288d3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34291,DS-94d11e39-e7bf-4f39-899b-fb7845c716d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106697455-172.17.0.19-1595885641739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38276,DS-570d37f6-64a1-4807-bbc0-1befac312c13,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-9b5c18a7-9241-4ac2-afc6-1ee49dee5a48,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-9cd84bf0-85ba-477b-8229-f8d04ae74c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-d57da3f7-b5a7-4bde-8ca6-c06864ef3de0,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-917f100f-a36f-4189-8df4-556aec70a366,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-778d7f91-00db-410c-b544-814775a5fecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-56ce0c91-28f7-4736-a807-d73c4288d3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34291,DS-94d11e39-e7bf-4f39-899b-fb7845c716d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482691185-172.17.0.19-1595886035793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41938,DS-67a08e32-bfa9-49a1-aa20-cbde8a5d3ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-9d9046f5-73e6-4c73-b551-a10bc63d889c,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-41e7b898-cdfa-4a60-be8e-8ab2c932788b,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-2c637845-8e56-4f1f-8190-5860fdb8af6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-4f79e7f5-2908-4669-8146-420a9fa370fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-2840dbcd-d0b4-4d28-aba5-f12726f11eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-d6588b95-a7ea-4a96-b628-522b8e4c6256,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-6df20c73-9784-4824-be25-0a9842615524,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482691185-172.17.0.19-1595886035793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41938,DS-67a08e32-bfa9-49a1-aa20-cbde8a5d3ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-9d9046f5-73e6-4c73-b551-a10bc63d889c,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-41e7b898-cdfa-4a60-be8e-8ab2c932788b,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-2c637845-8e56-4f1f-8190-5860fdb8af6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-4f79e7f5-2908-4669-8146-420a9fa370fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-2840dbcd-d0b4-4d28-aba5-f12726f11eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-d6588b95-a7ea-4a96-b628-522b8e4c6256,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-6df20c73-9784-4824-be25-0a9842615524,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-550966428-172.17.0.19-1595887365596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44579,DS-da0a1d91-898b-40c0-a703-caef2951c981,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-650b075e-fc86-4ff6-8922-07789de2e5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-6dcb4c6f-2503-4472-9fbe-f45fd95a2323,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-7183e983-de28-447c-88d4-546cef7ced6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-8993bf19-5213-431d-b82e-efebef158a53,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-91c650ea-b52c-4abb-826a-865f31e6fe3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-84a616a1-6d49-49d8-94fe-b35d9bec73fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-c675127f-0e66-485b-9ba4-de60018ef4d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-550966428-172.17.0.19-1595887365596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44579,DS-da0a1d91-898b-40c0-a703-caef2951c981,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-650b075e-fc86-4ff6-8922-07789de2e5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-6dcb4c6f-2503-4472-9fbe-f45fd95a2323,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-7183e983-de28-447c-88d4-546cef7ced6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-8993bf19-5213-431d-b82e-efebef158a53,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-91c650ea-b52c-4abb-826a-865f31e6fe3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-84a616a1-6d49-49d8-94fe-b35d9bec73fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-c675127f-0e66-485b-9ba4-de60018ef4d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409478776-172.17.0.19-1595887663328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33827,DS-c90c935a-2843-4454-a3eb-20273e49df07,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-0fb4ef2b-4ce1-48c6-a1d4-56c2f52efe79,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-50ff8cdb-3be3-44b8-82fb-3adbf9bbe72d,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-44855643-54f5-4a5e-bae2-1b3299a2ef26,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-658aea66-aa8b-4a2a-a034-35aa57b43ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-3dd5363d-5e3d-4903-a5c3-5ae7025d0a30,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-e5761eba-cae4-47d9-84ef-cd943cbc0d97,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-697efb50-2899-4348-9071-1880e122e9bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409478776-172.17.0.19-1595887663328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33827,DS-c90c935a-2843-4454-a3eb-20273e49df07,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-0fb4ef2b-4ce1-48c6-a1d4-56c2f52efe79,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-50ff8cdb-3be3-44b8-82fb-3adbf9bbe72d,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-44855643-54f5-4a5e-bae2-1b3299a2ef26,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-658aea66-aa8b-4a2a-a034-35aa57b43ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-3dd5363d-5e3d-4903-a5c3-5ae7025d0a30,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-e5761eba-cae4-47d9-84ef-cd943cbc0d97,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-697efb50-2899-4348-9071-1880e122e9bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2025377536-172.17.0.19-1595887730748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36530,DS-cfcd1dbf-b2ba-4351-ba12-a34cfefea4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39518,DS-290dcea7-1216-4019-892b-99f9f272894e,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-7e77d2df-2de8-4438-bc6e-19233cc43e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-da6779ee-4c85-4e47-965b-89e1abe3c836,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-d3a3ca17-43c0-4362-86f1-e8ef6c0688a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-f9515fd4-2975-4ff2-a9f8-64974268d2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-53fb8363-3589-4b20-bbba-f58547f3f05d,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-499aedfe-0aac-4eaf-bd10-a4958970fab0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2025377536-172.17.0.19-1595887730748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36530,DS-cfcd1dbf-b2ba-4351-ba12-a34cfefea4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39518,DS-290dcea7-1216-4019-892b-99f9f272894e,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-7e77d2df-2de8-4438-bc6e-19233cc43e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-da6779ee-4c85-4e47-965b-89e1abe3c836,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-d3a3ca17-43c0-4362-86f1-e8ef6c0688a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-f9515fd4-2975-4ff2-a9f8-64974268d2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-53fb8363-3589-4b20-bbba-f58547f3f05d,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-499aedfe-0aac-4eaf-bd10-a4958970fab0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221641384-172.17.0.19-1595888082832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37451,DS-a2dbd827-348b-48f2-975f-e841197a95d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-8bbe264f-4802-4e6b-8d45-dac6255cf3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-2abf750b-c0ff-4e99-b009-32f09ea0a0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-bfda4b33-5b2b-467d-b09c-c733d8f556ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-490f1a12-6985-45da-864c-aa0cf008c545,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-bc5de02f-a714-4bd2-b378-bcdefdb1a2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-a98ab76b-700b-45cb-b296-2f09fd200d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-60c30e47-5874-48df-b768-6356923ab098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221641384-172.17.0.19-1595888082832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37451,DS-a2dbd827-348b-48f2-975f-e841197a95d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-8bbe264f-4802-4e6b-8d45-dac6255cf3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-2abf750b-c0ff-4e99-b009-32f09ea0a0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-bfda4b33-5b2b-467d-b09c-c733d8f556ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-490f1a12-6985-45da-864c-aa0cf008c545,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-bc5de02f-a714-4bd2-b378-bcdefdb1a2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-a98ab76b-700b-45cb-b296-2f09fd200d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-60c30e47-5874-48df-b768-6356923ab098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5336
