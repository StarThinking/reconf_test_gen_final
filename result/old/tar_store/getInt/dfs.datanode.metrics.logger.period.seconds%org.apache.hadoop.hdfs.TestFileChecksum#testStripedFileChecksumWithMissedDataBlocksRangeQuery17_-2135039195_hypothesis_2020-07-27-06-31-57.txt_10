reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-287014549-172.17.0.5-1595831711528:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43380,DS-b0fff4ed-604b-44fd-a426-31019047d224,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-aecad32f-e179-4a33-8281-d19ff7238167,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-d2e30474-8e4b-4dcb-8083-1c87b4314c30,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-bf9810aa-d1e8-4022-b1a0-97b7cf91fe7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-d2533d55-d707-4a14-a4b1-ec94cdd3db25,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-a0c1540a-f9da-4f6a-8d8b-3b9ed2aea033,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-eb210171-ad11-40c1-9a80-2b1cb8038834,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-7cab9fa3-6e2e-4955-a9bd-bc79b97b7387,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-287014549-172.17.0.5-1595831711528:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43380,DS-b0fff4ed-604b-44fd-a426-31019047d224,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-aecad32f-e179-4a33-8281-d19ff7238167,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-d2e30474-8e4b-4dcb-8083-1c87b4314c30,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-bf9810aa-d1e8-4022-b1a0-97b7cf91fe7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-d2533d55-d707-4a14-a4b1-ec94cdd3db25,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-a0c1540a-f9da-4f6a-8d8b-3b9ed2aea033,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-eb210171-ad11-40c1-9a80-2b1cb8038834,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-7cab9fa3-6e2e-4955-a9bd-bc79b97b7387,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1669328599-172.17.0.5-1595832588710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37811,DS-48d30e69-4587-45e0-a522-1c4dba65ab9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-6e1c323e-f139-49fe-8df1-04e9dadc31e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-e0cb9c6b-fec7-4dcc-b8f1-7aefcffda40a,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-a7406e45-275b-42bc-952e-c8bfb42a12b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-b60aced3-820c-4c72-9e32-b9adb7b7b46e,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-3e141c86-d067-46cd-9a59-e16c3d099653,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-8ffa85fd-8b5f-444f-a508-878319dc03dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-e62a32b3-c817-48be-be06-0fe3268d6b8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1669328599-172.17.0.5-1595832588710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37811,DS-48d30e69-4587-45e0-a522-1c4dba65ab9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-6e1c323e-f139-49fe-8df1-04e9dadc31e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-e0cb9c6b-fec7-4dcc-b8f1-7aefcffda40a,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-a7406e45-275b-42bc-952e-c8bfb42a12b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-b60aced3-820c-4c72-9e32-b9adb7b7b46e,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-3e141c86-d067-46cd-9a59-e16c3d099653,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-8ffa85fd-8b5f-444f-a508-878319dc03dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-e62a32b3-c817-48be-be06-0fe3268d6b8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-728375189-172.17.0.5-1595833194809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46314,DS-8fc6c534-c633-4f61-a076-bbc690906701,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-8e95cfad-374d-4011-b8ce-f9b728a02d19,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-02f0fef7-0046-425d-9395-f57820b4ac8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-d8d2c923-9f30-490e-9fb9-d77a07dc4cae,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-2cdbdc91-4c5c-4fc1-9483-85ade226cc81,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-4ba204fe-fad0-4e18-bcf7-93405b101095,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-ad6bb543-fb8b-4c3c-b8cb-ee26302da2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-4e73fead-e0af-42b8-8cba-280ad5f5e808,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-728375189-172.17.0.5-1595833194809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46314,DS-8fc6c534-c633-4f61-a076-bbc690906701,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-8e95cfad-374d-4011-b8ce-f9b728a02d19,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-02f0fef7-0046-425d-9395-f57820b4ac8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-d8d2c923-9f30-490e-9fb9-d77a07dc4cae,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-2cdbdc91-4c5c-4fc1-9483-85ade226cc81,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-4ba204fe-fad0-4e18-bcf7-93405b101095,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-ad6bb543-fb8b-4c3c-b8cb-ee26302da2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-4e73fead-e0af-42b8-8cba-280ad5f5e808,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2023645482-172.17.0.5-1595833357906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35445,DS-776defc6-e59a-4d35-a130-1063e8686734,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-96817d86-7e0e-42dd-acc0-ce56922afa1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-1ad280f9-50a4-46e8-a349-8086da26cd20,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-abe72846-2518-439a-91be-33892f4d627d,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-96106354-e8b5-4c43-b785-82197fb9293b,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-2924e5b7-5837-498c-a0ea-3c9438640332,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-d5485eae-542f-4d56-963b-2346b79ac7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-80d98ab1-0d0f-4832-8279-c3dc3be38502,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2023645482-172.17.0.5-1595833357906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35445,DS-776defc6-e59a-4d35-a130-1063e8686734,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-96817d86-7e0e-42dd-acc0-ce56922afa1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-1ad280f9-50a4-46e8-a349-8086da26cd20,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-abe72846-2518-439a-91be-33892f4d627d,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-96106354-e8b5-4c43-b785-82197fb9293b,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-2924e5b7-5837-498c-a0ea-3c9438640332,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-d5485eae-542f-4d56-963b-2346b79ac7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-80d98ab1-0d0f-4832-8279-c3dc3be38502,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845916295-172.17.0.5-1595833520203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38097,DS-71bb2dd8-7fec-49d3-b874-09c63f7d5571,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-57d55c3b-c94a-4af5-a866-6ed0385d2a33,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-d276c7ae-c5c0-4b7d-b09f-8ccfd377e32e,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-262ee5f4-3211-4e5d-b845-0a2ad0847b70,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-847c480c-8861-42d4-a374-bb76a7aa67da,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-490400cf-5475-4f71-9f04-2668d67e1f97,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-4f5044af-dc65-47df-9d02-ecf4db5454f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-b789c4e3-b736-4692-bec2-8e104553a979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845916295-172.17.0.5-1595833520203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38097,DS-71bb2dd8-7fec-49d3-b874-09c63f7d5571,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-57d55c3b-c94a-4af5-a866-6ed0385d2a33,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-d276c7ae-c5c0-4b7d-b09f-8ccfd377e32e,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-262ee5f4-3211-4e5d-b845-0a2ad0847b70,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-847c480c-8861-42d4-a374-bb76a7aa67da,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-490400cf-5475-4f71-9f04-2668d67e1f97,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-4f5044af-dc65-47df-9d02-ecf4db5454f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-b789c4e3-b736-4692-bec2-8e104553a979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1760701980-172.17.0.5-1595833583656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39228,DS-23acc74a-4d90-414b-bd63-9bc87ace94f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-f3de8c4c-7db2-428f-8c89-1003c9ba08f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-c8f71980-ab04-4a62-bc35-340bd1c8c891,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-ab54c2c8-f6a4-411f-9174-bedb4ca17108,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-2d45c384-8bf5-486a-90fe-af5ba001f179,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-5cc478c0-784b-424d-8715-0160821ff39d,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-18cf9c6c-cd2c-4c0d-9d1b-7c36cb7e3a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-299985ca-f2ed-4678-96b4-fdd839f07fbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1760701980-172.17.0.5-1595833583656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39228,DS-23acc74a-4d90-414b-bd63-9bc87ace94f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-f3de8c4c-7db2-428f-8c89-1003c9ba08f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-c8f71980-ab04-4a62-bc35-340bd1c8c891,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-ab54c2c8-f6a4-411f-9174-bedb4ca17108,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-2d45c384-8bf5-486a-90fe-af5ba001f179,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-5cc478c0-784b-424d-8715-0160821ff39d,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-18cf9c6c-cd2c-4c0d-9d1b-7c36cb7e3a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-299985ca-f2ed-4678-96b4-fdd839f07fbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638231407-172.17.0.5-1595833621472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37926,DS-62508f72-3d3d-447a-99c9-8356643bd188,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-68fdb4c9-4611-4c73-8166-85d1bf0cbd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-1366b312-2107-4901-b7b4-28a001160ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-e98525b0-1502-470c-a7e9-ef6c094b5094,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-8e9868e5-937a-46c6-8157-f72c9bf7f8db,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-2fecedda-dfa7-4039-b041-46427478b801,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-d948e0a2-9519-44e0-9550-2775a7b5d5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-23b29e94-c282-4108-bcbb-92eb4e2ea591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638231407-172.17.0.5-1595833621472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37926,DS-62508f72-3d3d-447a-99c9-8356643bd188,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-68fdb4c9-4611-4c73-8166-85d1bf0cbd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-1366b312-2107-4901-b7b4-28a001160ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-e98525b0-1502-470c-a7e9-ef6c094b5094,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-8e9868e5-937a-46c6-8157-f72c9bf7f8db,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-2fecedda-dfa7-4039-b041-46427478b801,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-d948e0a2-9519-44e0-9550-2775a7b5d5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-23b29e94-c282-4108-bcbb-92eb4e2ea591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539665543-172.17.0.5-1595833982811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35325,DS-4bd16942-c7a1-4fc2-bc77-5d82aab20c32,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-f64bbc6c-efd1-4a35-b60c-bb19ed511403,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-6c7d24e0-cb69-490c-9e85-de468b2ff456,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-b2373892-e2e3-47cf-a2cc-0116324a69cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-2f6bec4e-a4ef-402a-9423-c5eff894aa1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-e7a29f68-8f17-4bdb-86e9-d660820f6a74,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-ccf58f28-1b43-4880-9668-e846fec98e81,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-e8275b45-71a3-4368-a8b2-9d594469de9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539665543-172.17.0.5-1595833982811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35325,DS-4bd16942-c7a1-4fc2-bc77-5d82aab20c32,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-f64bbc6c-efd1-4a35-b60c-bb19ed511403,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-6c7d24e0-cb69-490c-9e85-de468b2ff456,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-b2373892-e2e3-47cf-a2cc-0116324a69cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-2f6bec4e-a4ef-402a-9423-c5eff894aa1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-e7a29f68-8f17-4bdb-86e9-d660820f6a74,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-ccf58f28-1b43-4880-9668-e846fec98e81,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-e8275b45-71a3-4368-a8b2-9d594469de9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-692353748-172.17.0.5-1595834190087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37329,DS-ec4a2101-077f-4ab0-9e1a-8022e4244ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-5c02b061-bdfd-48a6-bb2c-e0c5c7eb86ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-d98ffb7f-f863-4e5e-a8fa-017c32e3d6df,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-6e39e921-fe8b-437e-8c31-ddfc25d45d66,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-ca8c65a6-b855-4881-90d9-a6fa5b42f254,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-32a1603c-77cd-4b28-bd95-8e114e83e760,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-2a95e3ca-86ec-4eef-bd5a-77b814382094,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-6ed3c348-4732-4274-aa75-b10bcc8cbdb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-692353748-172.17.0.5-1595834190087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37329,DS-ec4a2101-077f-4ab0-9e1a-8022e4244ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-5c02b061-bdfd-48a6-bb2c-e0c5c7eb86ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-d98ffb7f-f863-4e5e-a8fa-017c32e3d6df,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-6e39e921-fe8b-437e-8c31-ddfc25d45d66,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-ca8c65a6-b855-4881-90d9-a6fa5b42f254,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-32a1603c-77cd-4b28-bd95-8e114e83e760,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-2a95e3ca-86ec-4eef-bd5a-77b814382094,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-6ed3c348-4732-4274-aa75-b10bcc8cbdb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1542637200-172.17.0.5-1595834222947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40546,DS-5e43f435-c2f2-4390-bd3b-9301bc3a99f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-4b3c472b-1e5c-4839-bbda-20226c8b1efe,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-b159f235-3031-4ba8-8633-28728e826503,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-4ec49664-f189-4507-9239-4d30091b666c,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-9780b1f6-49a4-4b57-b095-a01ca364a508,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-c5a07525-24af-4960-82ee-909db2124535,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-f45793de-ea10-4936-9054-df23dc902c98,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-83d9e705-6771-4468-a8ac-94e2ce1e7de6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1542637200-172.17.0.5-1595834222947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40546,DS-5e43f435-c2f2-4390-bd3b-9301bc3a99f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-4b3c472b-1e5c-4839-bbda-20226c8b1efe,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-b159f235-3031-4ba8-8633-28728e826503,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-4ec49664-f189-4507-9239-4d30091b666c,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-9780b1f6-49a4-4b57-b095-a01ca364a508,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-c5a07525-24af-4960-82ee-909db2124535,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-f45793de-ea10-4936-9054-df23dc902c98,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-83d9e705-6771-4468-a8ac-94e2ce1e7de6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1041015366-172.17.0.5-1595834699951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43769,DS-eed28ecc-0da9-4452-869b-cce6be3efdef,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-a171c973-ac47-4582-8ee2-a55d5e5890c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-243449e2-60ae-4f74-bb2e-9fb4bd88a7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-05f4bea0-89dc-4a68-9383-d3a9739ac746,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-a4b64c4f-2ae3-4a67-9414-5bb7eacb197c,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-af826eef-a7a8-47e4-ba76-3f6dfa9f68ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-83af0021-4b77-4ac3-9d48-3b099f375577,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-7f536209-e928-42ca-be39-7153996cfec4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1041015366-172.17.0.5-1595834699951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43769,DS-eed28ecc-0da9-4452-869b-cce6be3efdef,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-a171c973-ac47-4582-8ee2-a55d5e5890c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-243449e2-60ae-4f74-bb2e-9fb4bd88a7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-05f4bea0-89dc-4a68-9383-d3a9739ac746,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-a4b64c4f-2ae3-4a67-9414-5bb7eacb197c,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-af826eef-a7a8-47e4-ba76-3f6dfa9f68ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-83af0021-4b77-4ac3-9d48-3b099f375577,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-7f536209-e928-42ca-be39-7153996cfec4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899785290-172.17.0.5-1595835054946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43986,DS-1728ae83-78c2-47c5-b7a3-bbd37ab426b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-eb05811f-9149-4778-85bc-b6a5289f1df4,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-c0d51d34-e415-41e2-9770-1c7f9ed15613,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-6b0d78d0-f8a8-4887-92f8-4cf9d8aa6b45,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-439bdbda-78c3-4074-9e4f-af717e6a5c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-edc7d031-4209-46c6-a566-e99e566d1eca,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-2bc26a8d-1500-49ce-89c8-8d5144011236,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-7cd7d60e-3c09-495f-8a80-02146454100e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899785290-172.17.0.5-1595835054946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43986,DS-1728ae83-78c2-47c5-b7a3-bbd37ab426b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-eb05811f-9149-4778-85bc-b6a5289f1df4,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-c0d51d34-e415-41e2-9770-1c7f9ed15613,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-6b0d78d0-f8a8-4887-92f8-4cf9d8aa6b45,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-439bdbda-78c3-4074-9e4f-af717e6a5c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-edc7d031-4209-46c6-a566-e99e566d1eca,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-2bc26a8d-1500-49ce-89c8-8d5144011236,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-7cd7d60e-3c09-495f-8a80-02146454100e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-505415712-172.17.0.5-1595835130451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43506,DS-31c15233-ce65-4102-aae3-5865f49a9b41,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-94e2d76b-4d1d-47a1-b67f-433be47b093a,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-1e13886e-9e95-429b-a477-37e076e0f9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-f0b4c9b0-5fa5-4303-bb85-b7110eee9796,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-4d555ef9-55c7-49fd-96ac-9de4e649dc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-122a73b6-c2ac-4599-8340-f0d4b3bc4142,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-be08dc2f-278e-49a0-8e09-d9ef64bbbc84,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-7356e70c-75a4-4b14-a45f-908c6706f965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-505415712-172.17.0.5-1595835130451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43506,DS-31c15233-ce65-4102-aae3-5865f49a9b41,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-94e2d76b-4d1d-47a1-b67f-433be47b093a,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-1e13886e-9e95-429b-a477-37e076e0f9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-f0b4c9b0-5fa5-4303-bb85-b7110eee9796,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-4d555ef9-55c7-49fd-96ac-9de4e649dc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-122a73b6-c2ac-4599-8340-f0d4b3bc4142,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-be08dc2f-278e-49a0-8e09-d9ef64bbbc84,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-7356e70c-75a4-4b14-a45f-908c6706f965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-815354334-172.17.0.5-1595835474180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38051,DS-9a419cd1-4698-4d47-9e4a-f8147161686d,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-33fa2e91-f827-412f-a0ad-98fd30331435,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-13f12185-1d11-4177-b108-aca64268cd43,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-65d7861d-915a-4a4f-9ba5-0206fe9c9fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-26f6f94d-6c75-4199-9e95-3c2064c0bb27,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-096fc469-e0cb-4734-8743-d3ed4fb63e22,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-5f3419c5-b16f-401b-92eb-0541db5ebd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-e7850ffc-9c81-4a9e-ae3f-b068fc0c974b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-815354334-172.17.0.5-1595835474180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38051,DS-9a419cd1-4698-4d47-9e4a-f8147161686d,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-33fa2e91-f827-412f-a0ad-98fd30331435,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-13f12185-1d11-4177-b108-aca64268cd43,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-65d7861d-915a-4a4f-9ba5-0206fe9c9fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-26f6f94d-6c75-4199-9e95-3c2064c0bb27,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-096fc469-e0cb-4734-8743-d3ed4fb63e22,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-5f3419c5-b16f-401b-92eb-0541db5ebd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-e7850ffc-9c81-4a9e-ae3f-b068fc0c974b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1847133458-172.17.0.5-1595835845861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43805,DS-624a7750-7297-4e99-bb96-caf1e746a530,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-814c1fca-edf2-4564-9989-79884103bac2,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-f0ef74b0-9ef0-4028-bf20-a957ffa97431,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-f1c592cf-d237-40ed-bf5f-238df81b9707,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-85d58f74-d03a-4344-a001-f9bac29fd68a,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-db4ee92a-d1b8-448c-9600-5e6b04d715da,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-2df0ff96-9ae8-426f-be67-a8f6ff1c9468,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-b0612337-f461-403b-9ce0-c4ea559d500b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1847133458-172.17.0.5-1595835845861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43805,DS-624a7750-7297-4e99-bb96-caf1e746a530,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-814c1fca-edf2-4564-9989-79884103bac2,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-f0ef74b0-9ef0-4028-bf20-a957ffa97431,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-f1c592cf-d237-40ed-bf5f-238df81b9707,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-85d58f74-d03a-4344-a001-f9bac29fd68a,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-db4ee92a-d1b8-448c-9600-5e6b04d715da,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-2df0ff96-9ae8-426f-be67-a8f6ff1c9468,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-b0612337-f461-403b-9ce0-c4ea559d500b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-101567370-172.17.0.5-1595835950723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45013,DS-92570526-3717-42a4-8fea-fe99cc26ca1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-36d3e341-0753-4e30-a9c8-62b7047e7d38,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-15de7412-97df-49f6-8c96-bd111313688d,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-eb765159-cd0c-4a37-9f6a-c74abe386397,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-448cd882-c3a9-402d-8b18-4150bf79bffe,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-71e90fe2-b2a7-4780-93c7-9586cddb6992,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-027e55a9-461c-4526-953f-9385138e000b,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-f5426624-0b50-4ded-81fc-374997efe0eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-101567370-172.17.0.5-1595835950723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45013,DS-92570526-3717-42a4-8fea-fe99cc26ca1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-36d3e341-0753-4e30-a9c8-62b7047e7d38,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-15de7412-97df-49f6-8c96-bd111313688d,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-eb765159-cd0c-4a37-9f6a-c74abe386397,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-448cd882-c3a9-402d-8b18-4150bf79bffe,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-71e90fe2-b2a7-4780-93c7-9586cddb6992,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-027e55a9-461c-4526-953f-9385138e000b,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-f5426624-0b50-4ded-81fc-374997efe0eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5014
