reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172163957-172.17.0.20-1595853147920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35657,DS-c1f032fc-0716-4a26-bcd4-14765d46cc68,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-a2d04429-d4a4-4f1a-894c-b13ac6572f35,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-2090b897-2b8e-404f-8daa-d912de978f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-9b29617c-6624-4f72-b45b-4f5d595744fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-e54f2d2a-e830-4d70-9455-15fac53c5605,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-58df4eab-654e-4c04-abda-6cb6ef0dbd56,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-576e4a5b-f5b3-48ee-95d5-bd3cba8446a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-5814f077-96cd-4a21-b83a-ec76698407e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172163957-172.17.0.20-1595853147920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35657,DS-c1f032fc-0716-4a26-bcd4-14765d46cc68,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-a2d04429-d4a4-4f1a-894c-b13ac6572f35,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-2090b897-2b8e-404f-8daa-d912de978f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-9b29617c-6624-4f72-b45b-4f5d595744fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-e54f2d2a-e830-4d70-9455-15fac53c5605,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-58df4eab-654e-4c04-abda-6cb6ef0dbd56,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-576e4a5b-f5b3-48ee-95d5-bd3cba8446a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-5814f077-96cd-4a21-b83a-ec76698407e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469619250-172.17.0.20-1595853372046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44393,DS-ae313198-dfb5-4c21-a775-dce2be1a6545,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-c4b7ec33-7f0f-4ed0-bcea-0f3d3d924060,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-64eafe2f-fe0d-42a9-8f9b-1d16a4817e99,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-492f84dc-b040-4129-86e7-07b93a393122,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-c9b5a6a3-6c86-4693-a06f-e3e22da7ff24,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-6d2d5204-d884-4f42-a8c1-7db224cf51d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-bfe6c896-12f2-43a7-95d0-8edae185a2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-a18af438-b5da-479a-a83d-feedb2053300,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469619250-172.17.0.20-1595853372046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44393,DS-ae313198-dfb5-4c21-a775-dce2be1a6545,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-c4b7ec33-7f0f-4ed0-bcea-0f3d3d924060,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-64eafe2f-fe0d-42a9-8f9b-1d16a4817e99,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-492f84dc-b040-4129-86e7-07b93a393122,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-c9b5a6a3-6c86-4693-a06f-e3e22da7ff24,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-6d2d5204-d884-4f42-a8c1-7db224cf51d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-bfe6c896-12f2-43a7-95d0-8edae185a2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-a18af438-b5da-479a-a83d-feedb2053300,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84203004-172.17.0.20-1595853840809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37003,DS-959a590e-8581-45f3-b751-3b93751c6e33,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-6ac86ad9-5c56-4a8a-bf64-641c3f269023,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-10a86e54-8ad2-4633-b6ae-542f124bbb26,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-b1e0167f-befa-4109-9d21-040d60b51bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-28696c4e-f5fa-461d-a69f-1272e3fdfca5,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-45bb1261-23ee-44db-b436-7255f93760cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-e69c076d-cc2e-48e0-b795-72bd60f3e1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-a3a46634-fae5-4f7d-93db-394201af315a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84203004-172.17.0.20-1595853840809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37003,DS-959a590e-8581-45f3-b751-3b93751c6e33,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-6ac86ad9-5c56-4a8a-bf64-641c3f269023,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-10a86e54-8ad2-4633-b6ae-542f124bbb26,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-b1e0167f-befa-4109-9d21-040d60b51bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-28696c4e-f5fa-461d-a69f-1272e3fdfca5,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-45bb1261-23ee-44db-b436-7255f93760cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-e69c076d-cc2e-48e0-b795-72bd60f3e1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-a3a46634-fae5-4f7d-93db-394201af315a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852157886-172.17.0.20-1595854234865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33682,DS-81e76cc0-693d-4eb7-b865-bb44a466a926,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-b805fe1e-9272-4ca4-b85c-5714f8c0790f,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-10dbe402-15b0-4d82-8219-98750ee1dfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-9f1ca49a-b844-4123-a99e-753d11a14693,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-ee8649cc-b323-4b92-80df-19e4f1e20899,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-8882fbf2-eb24-469f-842a-3f07125683a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-c51a8a13-7742-472a-b8a8-a062c8fa87d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-64f761c1-1f07-4190-ab47-5fb83c20fd86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852157886-172.17.0.20-1595854234865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33682,DS-81e76cc0-693d-4eb7-b865-bb44a466a926,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-b805fe1e-9272-4ca4-b85c-5714f8c0790f,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-10dbe402-15b0-4d82-8219-98750ee1dfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-9f1ca49a-b844-4123-a99e-753d11a14693,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-ee8649cc-b323-4b92-80df-19e4f1e20899,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-8882fbf2-eb24-469f-842a-3f07125683a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-c51a8a13-7742-472a-b8a8-a062c8fa87d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-64f761c1-1f07-4190-ab47-5fb83c20fd86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-50438666-172.17.0.20-1595854271934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41151,DS-fe742749-9454-4df4-b8cf-f3886786cede,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-8bfb687d-73ff-44e6-8c0f-d4483459c095,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-7c290926-571c-4080-9b90-2c6115b81ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-ba1ae5d9-d14e-4090-9b28-db32edaa545d,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-e3b5e919-c9f3-45a6-8c6a-d08e4e2257e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-5eb1423b-d241-4ed6-89e7-74a625738314,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-1c30d250-1af5-4b0a-b663-ecd899a7cca0,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-d1ca3b78-e18b-4464-bc34-121137ee1ee9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-50438666-172.17.0.20-1595854271934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41151,DS-fe742749-9454-4df4-b8cf-f3886786cede,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-8bfb687d-73ff-44e6-8c0f-d4483459c095,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-7c290926-571c-4080-9b90-2c6115b81ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-ba1ae5d9-d14e-4090-9b28-db32edaa545d,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-e3b5e919-c9f3-45a6-8c6a-d08e4e2257e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-5eb1423b-d241-4ed6-89e7-74a625738314,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-1c30d250-1af5-4b0a-b663-ecd899a7cca0,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-d1ca3b78-e18b-4464-bc34-121137ee1ee9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532698042-172.17.0.20-1595854305434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36813,DS-f0256968-d319-4d45-bdf9-67510498f354,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-1c5a3323-40f9-4e97-bcea-052b30cbdf14,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-73147e2c-c63b-47ed-bcb9-6daba335d238,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-91e81a8f-70ea-437d-b084-25930d836965,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-dd62e81d-2d57-411a-9e90-cdc283f0a64c,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-b40b8442-5f8a-4057-8af9-cd668ce0c190,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-428deac8-a23b-439a-8224-9180fcf2c1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-d9aeed5d-0052-4d63-b516-7a120de1bfe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532698042-172.17.0.20-1595854305434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36813,DS-f0256968-d319-4d45-bdf9-67510498f354,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-1c5a3323-40f9-4e97-bcea-052b30cbdf14,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-73147e2c-c63b-47ed-bcb9-6daba335d238,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-91e81a8f-70ea-437d-b084-25930d836965,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-dd62e81d-2d57-411a-9e90-cdc283f0a64c,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-b40b8442-5f8a-4057-8af9-cd668ce0c190,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-428deac8-a23b-439a-8224-9180fcf2c1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-d9aeed5d-0052-4d63-b516-7a120de1bfe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593939447-172.17.0.20-1595855016976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38071,DS-0ad0bba8-f69f-4a61-933a-3cdfa456a61d,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-683d402b-664b-4329-a10a-4054af9b943e,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-435dcf9d-0c0e-4c96-b7c9-65b43686de8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-3cbeda9b-b7b2-4076-9dcd-a625161b3ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-58388054-80e8-43d3-baaf-8c150cbfe224,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-1cc3f661-5f21-4653-bd14-cc72eac50312,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-e75b8fb1-f520-495e-9a2c-bfc38ba8516c,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-34f8abd3-e2e8-4c7e-8bba-37452e76c705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593939447-172.17.0.20-1595855016976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38071,DS-0ad0bba8-f69f-4a61-933a-3cdfa456a61d,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-683d402b-664b-4329-a10a-4054af9b943e,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-435dcf9d-0c0e-4c96-b7c9-65b43686de8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-3cbeda9b-b7b2-4076-9dcd-a625161b3ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-58388054-80e8-43d3-baaf-8c150cbfe224,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-1cc3f661-5f21-4653-bd14-cc72eac50312,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-e75b8fb1-f520-495e-9a2c-bfc38ba8516c,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-34f8abd3-e2e8-4c7e-8bba-37452e76c705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337169577-172.17.0.20-1595855275197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42536,DS-7cf749d6-0ae1-4e30-9cce-3225864cccac,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-5814daad-a843-457a-a0ec-b1f887ef78fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-c4f7efd3-febf-4faa-a8d5-3b44140163f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-33e496b8-5b07-4eba-89a5-79cb24e73962,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-e2791772-9a8f-410a-8c90-f7c8f36fcfc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-cfceeb55-41db-4e32-b3f0-4df4b6e7cef3,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-fe500b14-b2ef-41bd-8f55-aef42f0dcfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-d8820621-892a-4f27-9fa1-60a677a63e15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337169577-172.17.0.20-1595855275197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42536,DS-7cf749d6-0ae1-4e30-9cce-3225864cccac,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-5814daad-a843-457a-a0ec-b1f887ef78fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-c4f7efd3-febf-4faa-a8d5-3b44140163f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-33e496b8-5b07-4eba-89a5-79cb24e73962,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-e2791772-9a8f-410a-8c90-f7c8f36fcfc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-cfceeb55-41db-4e32-b3f0-4df4b6e7cef3,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-fe500b14-b2ef-41bd-8f55-aef42f0dcfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-d8820621-892a-4f27-9fa1-60a677a63e15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921852052-172.17.0.20-1595855556785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37359,DS-6767f9c3-f7da-4410-a0fd-4b672d9b234f,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-77341e13-d67e-4fba-ae30-eaab58bf0c36,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-8081c336-410c-4be2-b04d-8552dbd4474c,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-639f2e1e-b340-4682-9ce3-23256b9a9017,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-544e339d-dfe7-4a70-8d1a-305cf6b586db,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-5e174273-87be-418f-81ff-7ab6b26cc2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-dd91c591-7f6e-48f1-8137-90fc86d5b2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-57e65602-d57b-4841-9a36-23ba2a21c3bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921852052-172.17.0.20-1595855556785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37359,DS-6767f9c3-f7da-4410-a0fd-4b672d9b234f,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-77341e13-d67e-4fba-ae30-eaab58bf0c36,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-8081c336-410c-4be2-b04d-8552dbd4474c,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-639f2e1e-b340-4682-9ce3-23256b9a9017,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-544e339d-dfe7-4a70-8d1a-305cf6b586db,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-5e174273-87be-418f-81ff-7ab6b26cc2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-dd91c591-7f6e-48f1-8137-90fc86d5b2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-57e65602-d57b-4841-9a36-23ba2a21c3bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1544189208-172.17.0.20-1595855603618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42582,DS-52035f5d-551d-42ff-b0b0-0bcb99edff1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35127,DS-426204c9-54e3-47f8-b7c4-f2eff32db5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-71a9779b-8e8c-4256-b872-83421b29c9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-121f218a-b6d5-439b-841b-c9284b6826df,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-6fe91d7e-6179-4564-b4e9-73d4b4d0405c,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-19206806-84d6-4282-ba7a-539090a93234,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-87c47fdf-4604-4c51-9ca5-72301eb54b27,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-8e3bc0e9-9211-4ddd-a4a7-b47038a33928,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1544189208-172.17.0.20-1595855603618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42582,DS-52035f5d-551d-42ff-b0b0-0bcb99edff1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35127,DS-426204c9-54e3-47f8-b7c4-f2eff32db5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-71a9779b-8e8c-4256-b872-83421b29c9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-121f218a-b6d5-439b-841b-c9284b6826df,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-6fe91d7e-6179-4564-b4e9-73d4b4d0405c,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-19206806-84d6-4282-ba7a-539090a93234,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-87c47fdf-4604-4c51-9ca5-72301eb54b27,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-8e3bc0e9-9211-4ddd-a4a7-b47038a33928,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-465637969-172.17.0.20-1595856361463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37417,DS-c82cef94-f093-4680-9c57-12bc73c4304d,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-e6432fdc-6ca9-4e54-ad7c-b058c45ca321,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-4dd878a5-0c6a-4260-a424-133bab205778,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-390ee8d7-54de-4629-ad49-9ee9fc6583c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-983fa951-bdbd-43b7-a12b-1e5fb90a2c60,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-6717d1a3-3cfc-4a35-aeb3-f565b4fddf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-cbcedb00-80ce-4614-8189-ee006e6f2d00,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-d6215106-f08c-494a-a367-065ea0f57d83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-465637969-172.17.0.20-1595856361463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37417,DS-c82cef94-f093-4680-9c57-12bc73c4304d,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-e6432fdc-6ca9-4e54-ad7c-b058c45ca321,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-4dd878a5-0c6a-4260-a424-133bab205778,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-390ee8d7-54de-4629-ad49-9ee9fc6583c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-983fa951-bdbd-43b7-a12b-1e5fb90a2c60,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-6717d1a3-3cfc-4a35-aeb3-f565b4fddf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-cbcedb00-80ce-4614-8189-ee006e6f2d00,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-d6215106-f08c-494a-a367-065ea0f57d83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721243550-172.17.0.20-1595856570577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36631,DS-8a89177d-051c-4c21-994c-39bd56160bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-b6c8b856-5684-4c2a-9dfc-6d7972feee99,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-d10bfe4d-5d0c-4b17-9776-2c1dd26417e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-7f5917ea-f151-442b-b1be-b0fe4ccffbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-14ba7bcd-9d0d-4c2d-844a-fd7a50029f90,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-a70536e0-69f8-4a0c-9e8c-73c482da1236,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-816c930e-4760-4d74-b50c-b969eab1ff04,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-40cfedd6-76a6-43a2-bd7b-2b8a7c1d5335,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721243550-172.17.0.20-1595856570577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36631,DS-8a89177d-051c-4c21-994c-39bd56160bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-b6c8b856-5684-4c2a-9dfc-6d7972feee99,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-d10bfe4d-5d0c-4b17-9776-2c1dd26417e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-7f5917ea-f151-442b-b1be-b0fe4ccffbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-14ba7bcd-9d0d-4c2d-844a-fd7a50029f90,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-a70536e0-69f8-4a0c-9e8c-73c482da1236,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-816c930e-4760-4d74-b50c-b969eab1ff04,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-40cfedd6-76a6-43a2-bd7b-2b8a7c1d5335,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476917109-172.17.0.20-1595856874338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32804,DS-fa058a09-4042-42e7-b5d4-a2d246aa9b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-40d55ece-0802-493c-bdb1-b13fe661487d,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-28efebac-71a0-4325-8235-154a6f18b604,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-068c0861-0a6f-45c2-9125-2e283fdf492c,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-c71552be-f52e-4e6f-8ebb-99c914c62dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-40645c37-4110-482b-9a22-c58e42fc6129,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-bd57d6ff-f3ed-4ab7-a241-b179446343ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-4f061d32-9311-4a58-bb06-2c9ae444e920,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476917109-172.17.0.20-1595856874338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32804,DS-fa058a09-4042-42e7-b5d4-a2d246aa9b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-40d55ece-0802-493c-bdb1-b13fe661487d,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-28efebac-71a0-4325-8235-154a6f18b604,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-068c0861-0a6f-45c2-9125-2e283fdf492c,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-c71552be-f52e-4e6f-8ebb-99c914c62dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-40645c37-4110-482b-9a22-c58e42fc6129,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-bd57d6ff-f3ed-4ab7-a241-b179446343ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-4f061d32-9311-4a58-bb06-2c9ae444e920,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781411502-172.17.0.20-1595857002128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42625,DS-3a9661b6-5c5f-48ee-a86c-4463b735cb57,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-78cd84aa-68b8-4844-9cc0-2aa9fd81a5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-fa810ea8-66d0-43b9-9e84-f68cd20d57d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-f766ca51-afea-4414-bcce-9c4c443634a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-cd119800-31b7-44b7-93d3-8267362695d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-b09b9200-3eef-4536-8087-b76d4c881d20,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-52aed926-e657-4f1c-9d83-0c7e2df4f942,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-392ef632-d4e4-483e-addc-ddc41135f0e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781411502-172.17.0.20-1595857002128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42625,DS-3a9661b6-5c5f-48ee-a86c-4463b735cb57,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-78cd84aa-68b8-4844-9cc0-2aa9fd81a5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-fa810ea8-66d0-43b9-9e84-f68cd20d57d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-f766ca51-afea-4414-bcce-9c4c443634a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-cd119800-31b7-44b7-93d3-8267362695d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-b09b9200-3eef-4536-8087-b76d4c881d20,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-52aed926-e657-4f1c-9d83-0c7e2df4f942,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-392ef632-d4e4-483e-addc-ddc41135f0e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645796617-172.17.0.20-1595857671912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43801,DS-912b1ac1-3324-4d25-a7d4-ea4fd460ce23,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-ee82b294-8854-420d-acd9-9c1ffcb31a36,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-398c4982-b7cc-4b85-a24f-cac2452de0da,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-426de3d0-aaef-4939-b398-e9aac77c35eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-e1d562f7-d4a3-4432-bbf4-45f55d7ca5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-f062a27b-0ffe-4ea5-9d34-9603af04e7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-f422c650-04e9-4ead-8d72-52c136bda002,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-3e44e3c7-e55d-45ef-a7dc-4e9d72fbac22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645796617-172.17.0.20-1595857671912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43801,DS-912b1ac1-3324-4d25-a7d4-ea4fd460ce23,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-ee82b294-8854-420d-acd9-9c1ffcb31a36,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-398c4982-b7cc-4b85-a24f-cac2452de0da,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-426de3d0-aaef-4939-b398-e9aac77c35eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-e1d562f7-d4a3-4432-bbf4-45f55d7ca5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-f062a27b-0ffe-4ea5-9d34-9603af04e7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-f422c650-04e9-4ead-8d72-52c136bda002,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-3e44e3c7-e55d-45ef-a7dc-4e9d72fbac22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931012016-172.17.0.20-1595857755886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32841,DS-b4d44665-bca3-47ac-8507-5f772933cfae,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-efa5a56b-59fc-4c70-ad03-9aaf0a1beeea,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-fb6374f6-fb99-4687-84b2-1f84b090a226,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-0c955ca6-b838-4bfa-add9-b71ad32f6db7,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-8fb7e052-a089-41c6-9417-83e9689391e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-096af663-11d3-4dd8-9055-15e9c3532c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-17fc9708-0b39-4443-bdc0-23f8e22f247d,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-6d682c4b-dade-45fb-9d86-2a74837692bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931012016-172.17.0.20-1595857755886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32841,DS-b4d44665-bca3-47ac-8507-5f772933cfae,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-efa5a56b-59fc-4c70-ad03-9aaf0a1beeea,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-fb6374f6-fb99-4687-84b2-1f84b090a226,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-0c955ca6-b838-4bfa-add9-b71ad32f6db7,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-8fb7e052-a089-41c6-9417-83e9689391e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-096af663-11d3-4dd8-9055-15e9c3532c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-17fc9708-0b39-4443-bdc0-23f8e22f247d,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-6d682c4b-dade-45fb-9d86-2a74837692bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-318862821-172.17.0.20-1595857996017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33946,DS-4146b86f-86f1-4f82-aa95-9236c2480bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-fdd5c335-376e-49fe-b19a-021119c5fd17,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-25905d89-6178-4170-a3b6-d338d7c2784f,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-ae486735-19c3-4cec-9118-502db042a6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-7cf4e08d-7166-4dfb-badf-9fe944fd855f,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-1804e907-5dec-4dd3-9171-a321f656b316,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-440b18ee-eeeb-4249-8eac-e8c395f1e77d,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-d44f5741-9243-43c9-a037-49f33a59fc6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-318862821-172.17.0.20-1595857996017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33946,DS-4146b86f-86f1-4f82-aa95-9236c2480bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-fdd5c335-376e-49fe-b19a-021119c5fd17,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-25905d89-6178-4170-a3b6-d338d7c2784f,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-ae486735-19c3-4cec-9118-502db042a6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-7cf4e08d-7166-4dfb-badf-9fe944fd855f,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-1804e907-5dec-4dd3-9171-a321f656b316,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-440b18ee-eeeb-4249-8eac-e8c395f1e77d,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-d44f5741-9243-43c9-a037-49f33a59fc6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777336856-172.17.0.20-1595858074305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36321,DS-2ca864b2-d4e3-45b6-b469-a9897771948f,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-58f8fc63-a7f8-4ed8-90a5-7e2a681abc33,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-2d0a02b7-7dff-4939-879f-2c8c7664e025,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-68db28c3-8377-4dbd-8376-b89ec490d99d,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-b8bde543-3315-4202-beee-8445eed5303d,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-248e10a4-17ec-479e-a515-c0633c11f804,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-9a2c88fb-e716-4e37-9c5a-cb26855df32b,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-b1e1788f-32a2-44c3-9c7d-2505560f4e61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777336856-172.17.0.20-1595858074305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36321,DS-2ca864b2-d4e3-45b6-b469-a9897771948f,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-58f8fc63-a7f8-4ed8-90a5-7e2a681abc33,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-2d0a02b7-7dff-4939-879f-2c8c7664e025,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-68db28c3-8377-4dbd-8376-b89ec490d99d,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-b8bde543-3315-4202-beee-8445eed5303d,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-248e10a4-17ec-479e-a515-c0633c11f804,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-9a2c88fb-e716-4e37-9c5a-cb26855df32b,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-b1e1788f-32a2-44c3-9c7d-2505560f4e61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1081203022-172.17.0.20-1595858298016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45651,DS-9aed598a-854d-4924-9461-a37164f7d2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-91b827ba-cb0b-4f90-b44e-60e5dc71b253,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-115bc9ff-2b6e-4ca1-99f3-2806293fd557,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-c6ccabc1-5f1f-45c4-82db-9024f7510b68,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-ec5e5810-703d-4111-8cde-08ddc80bb9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-739e0751-bad4-455c-8fda-90db494d005a,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-7880f25c-3a91-4eae-be1c-e598f2c9c824,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-80c48627-99e2-4d1d-9a58-fbe0091e31bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1081203022-172.17.0.20-1595858298016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45651,DS-9aed598a-854d-4924-9461-a37164f7d2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-91b827ba-cb0b-4f90-b44e-60e5dc71b253,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-115bc9ff-2b6e-4ca1-99f3-2806293fd557,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-c6ccabc1-5f1f-45c4-82db-9024f7510b68,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-ec5e5810-703d-4111-8cde-08ddc80bb9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-739e0751-bad4-455c-8fda-90db494d005a,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-7880f25c-3a91-4eae-be1c-e598f2c9c824,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-80c48627-99e2-4d1d-9a58-fbe0091e31bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456669723-172.17.0.20-1595858794277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36936,DS-e2796990-397f-4dd6-ba6a-28fe0ae7c618,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-cfcf9f87-e695-4287-a16d-198f18f7af9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-47ec4b5c-f561-4f7d-b867-ccfc1f52b50d,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-178a8e48-1eaa-4148-8637-ba6f1ca42b84,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-ae7faf09-2395-49a3-b225-f34ee32a1bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-7f6838f8-b53c-420c-a6f9-bf3899386483,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-e89b15b3-c2be-40b3-91b7-e4610ecc2a35,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-fcf0e063-1871-4b8c-9358-6e12641d755b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456669723-172.17.0.20-1595858794277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36936,DS-e2796990-397f-4dd6-ba6a-28fe0ae7c618,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-cfcf9f87-e695-4287-a16d-198f18f7af9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-47ec4b5c-f561-4f7d-b867-ccfc1f52b50d,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-178a8e48-1eaa-4148-8637-ba6f1ca42b84,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-ae7faf09-2395-49a3-b225-f34ee32a1bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-7f6838f8-b53c-420c-a6f9-bf3899386483,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-e89b15b3-c2be-40b3-91b7-e4610ecc2a35,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-fcf0e063-1871-4b8c-9358-6e12641d755b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6353
