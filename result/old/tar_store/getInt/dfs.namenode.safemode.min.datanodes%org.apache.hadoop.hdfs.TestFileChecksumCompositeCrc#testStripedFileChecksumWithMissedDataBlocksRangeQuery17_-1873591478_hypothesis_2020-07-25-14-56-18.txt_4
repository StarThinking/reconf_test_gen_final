reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 4
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 4
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829781024-172.17.0.9-1595689357841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45970,DS-8ebecc1d-3a1e-4f8e-a371-ea4b3ec8ac3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-23a92de7-e5f7-4df5-affe-7660db624f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-6bbf399a-c9c6-4b42-aef2-3ac1830daa01,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-48972220-c8d4-4516-8ea2-7c7c6685ee0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42971,DS-efbd8afc-8a0f-41cb-ad67-4844f8e34aff,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-0ce92e7d-2444-42f8-bde4-ee2141a0fdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-b0bf5ee4-059a-47c6-9ee7-226158917bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-92cb93b6-758a-410f-8334-a2de8395ab5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829781024-172.17.0.9-1595689357841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45970,DS-8ebecc1d-3a1e-4f8e-a371-ea4b3ec8ac3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-23a92de7-e5f7-4df5-affe-7660db624f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-6bbf399a-c9c6-4b42-aef2-3ac1830daa01,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-48972220-c8d4-4516-8ea2-7c7c6685ee0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42971,DS-efbd8afc-8a0f-41cb-ad67-4844f8e34aff,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-0ce92e7d-2444-42f8-bde4-ee2141a0fdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-b0bf5ee4-059a-47c6-9ee7-226158917bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-92cb93b6-758a-410f-8334-a2de8395ab5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 4
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1876322166-172.17.0.9-1595690091681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39546,DS-274243c4-b3cd-4a83-8cdb-ca4098e9643a,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-dd6abf8d-76df-4ae0-83b4-8c60a816f0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-105e7c55-4b94-49b2-b294-8a4363ce2424,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-91affe14-8a5c-4f90-bbe7-4831889e42a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-79177eb3-7a30-46f7-8bd0-cbfe5a7a6aec,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-766e8286-d8b3-4ea5-bbd5-3e9eeb364a24,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-1c59d3d8-2efe-41d7-8ab9-52a342ed43fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-f36f0335-5f90-4cc9-b94e-05b439f134b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1876322166-172.17.0.9-1595690091681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39546,DS-274243c4-b3cd-4a83-8cdb-ca4098e9643a,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-dd6abf8d-76df-4ae0-83b4-8c60a816f0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-105e7c55-4b94-49b2-b294-8a4363ce2424,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-91affe14-8a5c-4f90-bbe7-4831889e42a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-79177eb3-7a30-46f7-8bd0-cbfe5a7a6aec,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-766e8286-d8b3-4ea5-bbd5-3e9eeb364a24,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-1c59d3d8-2efe-41d7-8ab9-52a342ed43fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-f36f0335-5f90-4cc9-b94e-05b439f134b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 4
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-799254576-172.17.0.9-1595690137559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43435,DS-c519583b-ab85-45de-9314-c91633bfc893,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-28e7087c-c1ae-4422-82e5-f6d700ac7c90,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-cdb2fe78-ad82-44c5-94bc-4c42d01c52db,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-dd30df90-4f36-43c6-b97c-f313b63996ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-02edb831-4caa-4775-8d7e-44bb87cbbf77,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-d0d18f2a-ba69-4d24-b2e6-0263c2552a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-226c02b3-6526-45b7-984e-af81acc43dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-bce733f1-0844-4df4-a33a-43625b7bcf88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-799254576-172.17.0.9-1595690137559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43435,DS-c519583b-ab85-45de-9314-c91633bfc893,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-28e7087c-c1ae-4422-82e5-f6d700ac7c90,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-cdb2fe78-ad82-44c5-94bc-4c42d01c52db,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-dd30df90-4f36-43c6-b97c-f313b63996ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-02edb831-4caa-4775-8d7e-44bb87cbbf77,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-d0d18f2a-ba69-4d24-b2e6-0263c2552a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-226c02b3-6526-45b7-984e-af81acc43dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-bce733f1-0844-4df4-a33a-43625b7bcf88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 4
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1769862619-172.17.0.9-1595690663165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36307,DS-6645de71-9eb4-40e7-830a-9b25f1e7b68b,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-93606e1f-acc3-4c49-93c3-89dd63adb7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-4b2c7fa8-0d93-47c4-9e99-0202a248504f,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-0f6df2ec-a788-444f-93b9-f9fcb6e1aab8,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-169a8541-8c6b-4763-ac93-5143f667044c,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-ed49425e-e2ed-4631-8e79-9e84a012a1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-793888ed-6cd2-43a5-a6ca-f44062e7c53c,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-59a0a7dd-b532-4f80-9f0c-c3f00c33a576,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1769862619-172.17.0.9-1595690663165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36307,DS-6645de71-9eb4-40e7-830a-9b25f1e7b68b,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-93606e1f-acc3-4c49-93c3-89dd63adb7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-4b2c7fa8-0d93-47c4-9e99-0202a248504f,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-0f6df2ec-a788-444f-93b9-f9fcb6e1aab8,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-169a8541-8c6b-4763-ac93-5143f667044c,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-ed49425e-e2ed-4631-8e79-9e84a012a1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-793888ed-6cd2-43a5-a6ca-f44062e7c53c,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-59a0a7dd-b532-4f80-9f0c-c3f00c33a576,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 4
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1628447393-172.17.0.9-1595690750201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40649,DS-1933841a-d5f8-4db7-9683-7a3a44bb2252,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-e07851fc-a2ee-4624-99de-7f10b8a2d9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-969e765f-e617-4bcf-8461-4cddf21bfdae,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-ccc89780-3141-4bcc-a280-9ab719860c37,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-3b263601-86e8-42b4-aa95-437badf99970,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-48f99831-2cba-442d-8fb8-c1c10c2ef949,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-decda730-b04c-4aaf-a938-212a8bdbc532,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-7faf13da-af80-45c7-9108-b52f3201046d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1628447393-172.17.0.9-1595690750201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40649,DS-1933841a-d5f8-4db7-9683-7a3a44bb2252,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-e07851fc-a2ee-4624-99de-7f10b8a2d9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-969e765f-e617-4bcf-8461-4cddf21bfdae,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-ccc89780-3141-4bcc-a280-9ab719860c37,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-3b263601-86e8-42b4-aa95-437badf99970,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-48f99831-2cba-442d-8fb8-c1c10c2ef949,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-decda730-b04c-4aaf-a938-212a8bdbc532,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-7faf13da-af80-45c7-9108-b52f3201046d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 4
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1504956261-172.17.0.9-1595691037911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41791,DS-d66dcc6c-4526-4f56-a3c1-d4be57701415,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-cb4f24ec-71ef-4eff-a536-c8071d5a936f,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-4ecb404c-cb83-4caa-87ba-71157fae18d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-a82940b3-c404-49fb-9b9c-281cfb09662c,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-c6e1ea7f-5d34-4504-97f0-45e2bd3174b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-eb138052-0862-4697-8e80-9fa87b89ca2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-a5493f8d-1727-4770-ad26-f2b9e9efb89a,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-cb4b6501-d017-44cd-af89-bfdd28af214b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1504956261-172.17.0.9-1595691037911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41791,DS-d66dcc6c-4526-4f56-a3c1-d4be57701415,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-cb4f24ec-71ef-4eff-a536-c8071d5a936f,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-4ecb404c-cb83-4caa-87ba-71157fae18d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-a82940b3-c404-49fb-9b9c-281cfb09662c,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-c6e1ea7f-5d34-4504-97f0-45e2bd3174b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-eb138052-0862-4697-8e80-9fa87b89ca2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-a5493f8d-1727-4770-ad26-f2b9e9efb89a,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-cb4b6501-d017-44cd-af89-bfdd28af214b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 4
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858400368-172.17.0.9-1595691119976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38980,DS-f18d5d57-9a00-4c1e-8345-8fbe024d6dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-e6523e18-6672-45f1-9aeb-b3508d180e30,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-10dd13f4-2981-430f-88fd-b44134c5f2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-17d9c246-c49c-4f44-a024-9c3fbe315676,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-606c755e-50a0-4c9d-845e-19a96dad7cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-d0ffed88-7dda-4679-b8bb-96391cb40726,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-5805fa4a-4536-48c1-9b28-6ca3cf0c6523,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-bc472088-8a21-4220-8415-0c51f17de19a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858400368-172.17.0.9-1595691119976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38980,DS-f18d5d57-9a00-4c1e-8345-8fbe024d6dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-e6523e18-6672-45f1-9aeb-b3508d180e30,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-10dd13f4-2981-430f-88fd-b44134c5f2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-17d9c246-c49c-4f44-a024-9c3fbe315676,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-606c755e-50a0-4c9d-845e-19a96dad7cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-d0ffed88-7dda-4679-b8bb-96391cb40726,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-5805fa4a-4536-48c1-9b28-6ca3cf0c6523,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-bc472088-8a21-4220-8415-0c51f17de19a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 4
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-312260668-172.17.0.9-1595691192970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46099,DS-7c223929-bd5d-427b-b37c-61f05fd5398b,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-61fbd862-1537-435b-ba2a-2672325c340b,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-8473e5f5-c360-44ec-a279-f87d1cd773f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-b5e18e5f-bc0e-4722-8cb2-e51b663ea4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-e7c4b366-2d69-41b7-961f-0e0fda668300,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-023d5122-4b3e-4488-b9b2-ff2e2ae807b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-18e953ca-eeb6-42b8-8f40-d0a65dc2ba63,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-1fe2bd59-3c6a-40f9-af96-3fc8eb76c02c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-312260668-172.17.0.9-1595691192970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46099,DS-7c223929-bd5d-427b-b37c-61f05fd5398b,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-61fbd862-1537-435b-ba2a-2672325c340b,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-8473e5f5-c360-44ec-a279-f87d1cd773f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-b5e18e5f-bc0e-4722-8cb2-e51b663ea4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-e7c4b366-2d69-41b7-961f-0e0fda668300,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-023d5122-4b3e-4488-b9b2-ff2e2ae807b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-18e953ca-eeb6-42b8-8f40-d0a65dc2ba63,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-1fe2bd59-3c6a-40f9-af96-3fc8eb76c02c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 4
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-812356628-172.17.0.9-1595691276899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39681,DS-3aa24688-a59b-4519-9677-eda2dcedf180,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-cbe297e5-3a83-43eb-b9b0-6e8e6e9101e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-5d0f14a8-9a72-4f87-81c2-e07140bff466,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-05998552-4a1d-4f94-848b-3e52e99d5fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-7e0838b1-c520-4e23-bc71-a5586c4ec034,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-56867b57-df63-44b9-8d62-9770a7d837ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-a1944cb9-0377-4f82-abd6-df65f9bbe76b,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-01835535-b156-4bb5-a82f-0be611e2e6c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-812356628-172.17.0.9-1595691276899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39681,DS-3aa24688-a59b-4519-9677-eda2dcedf180,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-cbe297e5-3a83-43eb-b9b0-6e8e6e9101e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-5d0f14a8-9a72-4f87-81c2-e07140bff466,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-05998552-4a1d-4f94-848b-3e52e99d5fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-7e0838b1-c520-4e23-bc71-a5586c4ec034,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-56867b57-df63-44b9-8d62-9770a7d837ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-a1944cb9-0377-4f82-abd6-df65f9bbe76b,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-01835535-b156-4bb5-a82f-0be611e2e6c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 4
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-716436434-172.17.0.9-1595691357596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46355,DS-02144b01-1335-479c-90e9-3b6b0ed19241,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-f9373dee-3fef-465b-99bf-48c3405c6138,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-e88bf85b-837d-42ea-b8a5-1d1d4f3de5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-f114fe82-abd8-44f1-b50e-f491caf53aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-9eeaefee-4551-4005-aaa3-0417789bd12f,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-f1ef7f6b-c102-473e-8c69-ba8ebcba66ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-3f33dd17-e307-4ee1-a64c-e35fa7f64123,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-7c9f0b27-32f3-4d4d-8fdd-67087b3560da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-716436434-172.17.0.9-1595691357596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46355,DS-02144b01-1335-479c-90e9-3b6b0ed19241,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-f9373dee-3fef-465b-99bf-48c3405c6138,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-e88bf85b-837d-42ea-b8a5-1d1d4f3de5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-f114fe82-abd8-44f1-b50e-f491caf53aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-9eeaefee-4551-4005-aaa3-0417789bd12f,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-f1ef7f6b-c102-473e-8c69-ba8ebcba66ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-3f33dd17-e307-4ee1-a64c-e35fa7f64123,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-7c9f0b27-32f3-4d4d-8fdd-67087b3560da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 4
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702091980-172.17.0.9-1595691582113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43770,DS-d9956691-284e-4ea2-afdb-26399394407d,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-f102d43b-e62f-4f49-b999-d0b9a4194520,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-40593be1-e4e2-4ad3-831d-c535e9228f86,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-5606d370-bde6-4d1e-9f4f-08ebc152e267,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-884299bb-3680-42eb-96a8-51dca8e40f14,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-8f102792-41ea-40ac-91f5-f68bf7c7c03b,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-642e096e-a41f-4890-ab26-fc9a0ab520bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-279461f6-4b4d-4d90-887a-e9a1ba0d90bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702091980-172.17.0.9-1595691582113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43770,DS-d9956691-284e-4ea2-afdb-26399394407d,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-f102d43b-e62f-4f49-b999-d0b9a4194520,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-40593be1-e4e2-4ad3-831d-c535e9228f86,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-5606d370-bde6-4d1e-9f4f-08ebc152e267,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-884299bb-3680-42eb-96a8-51dca8e40f14,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-8f102792-41ea-40ac-91f5-f68bf7c7c03b,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-642e096e-a41f-4890-ab26-fc9a0ab520bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-279461f6-4b4d-4d90-887a-e9a1ba0d90bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 4
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1669125361-172.17.0.9-1595692227141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38820,DS-7bf6cba2-ea88-49ba-b177-ac2ba16e7fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-6e6d676f-acad-4708-88a5-cf5659300328,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-5c16ff52-569a-416a-9851-dc9139c36863,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-c77a4478-75d2-4b6b-9565-8c22ea309d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-daf2708b-9b81-44af-9fd7-dbd5f65a6571,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-800d52db-e681-45bd-bf5f-aa560f17f51d,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-93dce489-d861-4b66-b860-ee48d077406c,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-3b417e8c-9673-4c77-897b-d33fd2a02599,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1669125361-172.17.0.9-1595692227141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38820,DS-7bf6cba2-ea88-49ba-b177-ac2ba16e7fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-6e6d676f-acad-4708-88a5-cf5659300328,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-5c16ff52-569a-416a-9851-dc9139c36863,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-c77a4478-75d2-4b6b-9565-8c22ea309d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-daf2708b-9b81-44af-9fd7-dbd5f65a6571,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-800d52db-e681-45bd-bf5f-aa560f17f51d,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-93dce489-d861-4b66-b860-ee48d077406c,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-3b417e8c-9673-4c77-897b-d33fd2a02599,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 4
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1234358808-172.17.0.9-1595692415527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32831,DS-28af1742-6e22-46d5-81b5-a73e1b4b26d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-6c581f76-6327-43a6-ab78-8d0157d1ce03,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-5185d124-6392-4c85-ba5a-7be2fc0dde20,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-a80d0b0c-8733-411f-8e5f-98f1c07faf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-b078b566-9015-44af-b203-e52b5ef75610,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-8115bb60-ad8e-4109-b6b3-d6a7c12a6d69,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-039f605c-4c58-4edf-aeb9-d63bfcfad06d,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-5e6d51cc-bcbf-48b9-9e0f-d1fd183c3b17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1234358808-172.17.0.9-1595692415527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32831,DS-28af1742-6e22-46d5-81b5-a73e1b4b26d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-6c581f76-6327-43a6-ab78-8d0157d1ce03,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-5185d124-6392-4c85-ba5a-7be2fc0dde20,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-a80d0b0c-8733-411f-8e5f-98f1c07faf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-b078b566-9015-44af-b203-e52b5ef75610,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-8115bb60-ad8e-4109-b6b3-d6a7c12a6d69,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-039f605c-4c58-4edf-aeb9-d63bfcfad06d,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-5e6d51cc-bcbf-48b9-9e0f-d1fd183c3b17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 4
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-433566718-172.17.0.9-1595692678264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38184,DS-d40b2e99-cb46-4e16-8c64-d2de91536772,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-a2c64def-0f36-4d3c-a5ed-74dc20c182f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-7f0d1279-59c4-42d5-9770-2350c8f34a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-75a445e0-bd80-49a0-bda9-5ea605eb41a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-930b96d2-c507-48c6-8dce-d596eaa26350,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-fb2406a8-7954-44a9-bba5-95426e6acfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-4787e454-8239-4106-9ea0-ab39ce9af77a,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-fec91807-5c0d-445d-88a6-d578eea742a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-433566718-172.17.0.9-1595692678264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38184,DS-d40b2e99-cb46-4e16-8c64-d2de91536772,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-a2c64def-0f36-4d3c-a5ed-74dc20c182f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-7f0d1279-59c4-42d5-9770-2350c8f34a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-75a445e0-bd80-49a0-bda9-5ea605eb41a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-930b96d2-c507-48c6-8dce-d596eaa26350,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-fb2406a8-7954-44a9-bba5-95426e6acfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-4787e454-8239-4106-9ea0-ab39ce9af77a,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-fec91807-5c0d-445d-88a6-d578eea742a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 4
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1895747285-172.17.0.9-1595693159701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42099,DS-92fe9422-498d-4172-ac3d-a0b79f235acd,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-4e6eada8-2f1d-4c83-b6d0-deb96e67a90a,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-ae4df040-673a-454b-b3d3-07e2f545e24f,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-84a148fd-e24f-4cbb-bd80-7b071ac176f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-a6db6c07-fce5-4f15-8a26-dc3c33aa1561,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-84a0f4d3-2e6c-4053-a6bc-b51f82873598,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-d803ad92-b732-4e61-b93d-525e5cb67a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-fcd3fb4d-fca6-4010-a573-68c00ace2113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1895747285-172.17.0.9-1595693159701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42099,DS-92fe9422-498d-4172-ac3d-a0b79f235acd,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-4e6eada8-2f1d-4c83-b6d0-deb96e67a90a,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-ae4df040-673a-454b-b3d3-07e2f545e24f,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-84a148fd-e24f-4cbb-bd80-7b071ac176f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-a6db6c07-fce5-4f15-8a26-dc3c33aa1561,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-84a0f4d3-2e6c-4053-a6bc-b51f82873598,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-d803ad92-b732-4e61-b93d-525e5cb67a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-fcd3fb4d-fca6-4010-a573-68c00ace2113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 4
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1304417459-172.17.0.9-1595693609413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34192,DS-15b814a7-5e70-43e7-af28-2aaae01ec548,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-a9161571-0921-41a6-9088-290f3d70129b,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-a9e162a1-cd99-434e-9647-676f163e5521,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-96f67360-0de9-41ec-a444-0bde98c43e94,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-c69842cc-3c34-4592-b28a-6db6a5059d28,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-9fa9cf29-ee30-45e8-8d09-0653d001ab87,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-68fa32d1-d59a-4277-8aba-f6ac44fe4d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-29e36cca-ceba-4521-84cf-53dbe07d9a45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1304417459-172.17.0.9-1595693609413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34192,DS-15b814a7-5e70-43e7-af28-2aaae01ec548,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-a9161571-0921-41a6-9088-290f3d70129b,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-a9e162a1-cd99-434e-9647-676f163e5521,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-96f67360-0de9-41ec-a444-0bde98c43e94,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-c69842cc-3c34-4592-b28a-6db6a5059d28,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-9fa9cf29-ee30-45e8-8d09-0653d001ab87,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-68fa32d1-d59a-4277-8aba-f6ac44fe4d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-29e36cca-ceba-4521-84cf-53dbe07d9a45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 4
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239323814-172.17.0.9-1595693703304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42195,DS-dd8d311e-83ba-49b4-ab31-1b8e1e78cd41,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-22b40895-81e1-4b3d-9a32-ec5b1eb11009,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-6725e973-3858-453a-88bf-7a744deecf59,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-f9165df1-c545-4386-b7b3-f1f96a0409ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-baacc9fe-f072-4153-90f6-f341d3380220,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-52d3a42f-98ec-432b-85fc-f3ef72cd0ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-c7d641c0-4f83-461c-8fd5-e3b6ad8bce9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-def7988a-7e57-462d-98c6-ff539954920d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239323814-172.17.0.9-1595693703304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42195,DS-dd8d311e-83ba-49b4-ab31-1b8e1e78cd41,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-22b40895-81e1-4b3d-9a32-ec5b1eb11009,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-6725e973-3858-453a-88bf-7a744deecf59,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-f9165df1-c545-4386-b7b3-f1f96a0409ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-baacc9fe-f072-4153-90f6-f341d3380220,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-52d3a42f-98ec-432b-85fc-f3ef72cd0ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-c7d641c0-4f83-461c-8fd5-e3b6ad8bce9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-def7988a-7e57-462d-98c6-ff539954920d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 4
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-886567961-172.17.0.9-1595694093478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44021,DS-382dc996-3cfe-4890-8784-ef483d84d57b,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-64457021-fdf0-4ff6-955e-f162a32cc134,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-3e662970-f8ad-4f58-975d-f1141f7a8d96,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-c5aac59e-4d16-46b9-bb9a-3d05cf9e9a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-c8c95640-136f-473a-9e19-bc23f940b543,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-ec7a2122-b97c-4d50-9dcf-fb40bad9020a,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-8737c9cc-4df6-4cbf-95cc-89e42ca53bec,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-d7bafb45-b187-4da4-90e1-9b41875535f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-886567961-172.17.0.9-1595694093478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44021,DS-382dc996-3cfe-4890-8784-ef483d84d57b,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-64457021-fdf0-4ff6-955e-f162a32cc134,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-3e662970-f8ad-4f58-975d-f1141f7a8d96,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-c5aac59e-4d16-46b9-bb9a-3d05cf9e9a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-c8c95640-136f-473a-9e19-bc23f940b543,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-ec7a2122-b97c-4d50-9dcf-fb40bad9020a,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-8737c9cc-4df6-4cbf-95cc-89e42ca53bec,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-d7bafb45-b187-4da4-90e1-9b41875535f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 4
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-306215249-172.17.0.9-1595695293484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33369,DS-392007cf-0c4a-480b-959f-fa5fb9962398,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-6aa46960-d6fc-493a-8ffc-770d7ca16d12,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-9daf4250-f883-4d89-ad73-93b0731abb87,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-5e32e477-a211-4fda-97ff-d1f35ce86853,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-7f04c2de-f2cd-450b-8b4d-6d87e9e93d85,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-4b58d1f2-c9ee-41ac-9846-45ab56c6b8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-8b9a667a-c5e0-4030-806d-edf335b919a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-c19fc33d-2baf-47c7-bd30-6dacebf09765,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-306215249-172.17.0.9-1595695293484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33369,DS-392007cf-0c4a-480b-959f-fa5fb9962398,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-6aa46960-d6fc-493a-8ffc-770d7ca16d12,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-9daf4250-f883-4d89-ad73-93b0731abb87,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-5e32e477-a211-4fda-97ff-d1f35ce86853,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-7f04c2de-f2cd-450b-8b4d-6d87e9e93d85,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-4b58d1f2-c9ee-41ac-9846-45ab56c6b8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-8b9a667a-c5e0-4030-806d-edf335b919a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-c19fc33d-2baf-47c7-bd30-6dacebf09765,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6713
