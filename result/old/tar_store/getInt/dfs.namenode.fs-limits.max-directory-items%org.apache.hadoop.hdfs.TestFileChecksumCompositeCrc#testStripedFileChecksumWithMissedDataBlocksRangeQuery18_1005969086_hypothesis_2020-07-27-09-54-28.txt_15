reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2122665178-172.17.0.18-1595843886594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43636,DS-35293bb0-a264-4f3b-9356-7f189f38bfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-484a767b-644a-43d0-be34-0a82e3d6e22e,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-7cec2de0-c832-4bae-bb22-1488d05b2454,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-a2108c37-077d-4528-aed4-3c091639d643,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-435b9d2a-e05c-4ca0-a2bb-f292ed911e41,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-60f61f7f-d85e-42ac-b21c-5a97aa00776f,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-695c5c53-ab3d-4397-bdfc-19826961b1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-1b49f05a-62a8-4d0b-a9eb-b6098bee1213,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2122665178-172.17.0.18-1595843886594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43636,DS-35293bb0-a264-4f3b-9356-7f189f38bfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-484a767b-644a-43d0-be34-0a82e3d6e22e,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-7cec2de0-c832-4bae-bb22-1488d05b2454,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-a2108c37-077d-4528-aed4-3c091639d643,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-435b9d2a-e05c-4ca0-a2bb-f292ed911e41,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-60f61f7f-d85e-42ac-b21c-5a97aa00776f,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-695c5c53-ab3d-4397-bdfc-19826961b1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-1b49f05a-62a8-4d0b-a9eb-b6098bee1213,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-946983837-172.17.0.18-1595843919415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38093,DS-85a7e717-200c-4f04-a058-134954249057,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-14ef3f58-a574-41b3-ae51-4ff60f933c04,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-64a9428f-9432-4246-abb1-74458e76846e,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-0d1939f7-c2ec-4d58-a507-5ccc230ac725,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-83974cfa-d143-411c-8738-19ff8f3daaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-6ff81cd9-753f-4754-b4f7-f65bf4c9c2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-6b82e30f-986c-43f8-a2ac-b0bdf274e28b,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-3d0b617c-5723-4db5-8f63-4a85f4bb6225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-946983837-172.17.0.18-1595843919415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38093,DS-85a7e717-200c-4f04-a058-134954249057,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-14ef3f58-a574-41b3-ae51-4ff60f933c04,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-64a9428f-9432-4246-abb1-74458e76846e,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-0d1939f7-c2ec-4d58-a507-5ccc230ac725,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-83974cfa-d143-411c-8738-19ff8f3daaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-6ff81cd9-753f-4754-b4f7-f65bf4c9c2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-6b82e30f-986c-43f8-a2ac-b0bdf274e28b,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-3d0b617c-5723-4db5-8f63-4a85f4bb6225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-336247682-172.17.0.18-1595844037251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42446,DS-74f12009-5a92-401d-94d6-ef7fd4cd4570,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-e649f094-533e-41c2-992e-8552d100443e,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-01273170-2b1d-4f08-897a-2c0e78b686be,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-3c17dd75-f9fc-463b-9781-94abcc73daef,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-42b87305-93e8-4162-a51a-ca6550d349e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-ce4f55c5-09f7-4bb9-b7bb-ca4280d7fb35,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-eaa5d0c8-8ac6-4d04-b60f-7d44749b10b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-a99bf9b7-dd77-41f2-b32c-6927135bd978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-336247682-172.17.0.18-1595844037251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42446,DS-74f12009-5a92-401d-94d6-ef7fd4cd4570,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-e649f094-533e-41c2-992e-8552d100443e,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-01273170-2b1d-4f08-897a-2c0e78b686be,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-3c17dd75-f9fc-463b-9781-94abcc73daef,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-42b87305-93e8-4162-a51a-ca6550d349e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-ce4f55c5-09f7-4bb9-b7bb-ca4280d7fb35,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-eaa5d0c8-8ac6-4d04-b60f-7d44749b10b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-a99bf9b7-dd77-41f2-b32c-6927135bd978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-336674727-172.17.0.18-1595844763498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41854,DS-c409d386-da4c-4f28-8aea-20fd27000fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-686ae400-c06f-4ccc-8d4a-0f8a008a90ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33865,DS-1d941025-58e4-448f-99b2-bb051076f6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-bfea1ca8-83ba-405c-905e-0194628e59a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-44d36ccb-ad24-4bbe-9297-aae5bdfeb66e,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-8d13d4c7-34bc-4bfd-b1b2-eeb590ad58b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-880620ff-991f-4061-a456-a95ace37bca3,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-ab720fde-3c87-4db6-abfd-ca8f1118c0bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-336674727-172.17.0.18-1595844763498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41854,DS-c409d386-da4c-4f28-8aea-20fd27000fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-686ae400-c06f-4ccc-8d4a-0f8a008a90ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33865,DS-1d941025-58e4-448f-99b2-bb051076f6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-bfea1ca8-83ba-405c-905e-0194628e59a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-44d36ccb-ad24-4bbe-9297-aae5bdfeb66e,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-8d13d4c7-34bc-4bfd-b1b2-eeb590ad58b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-880620ff-991f-4061-a456-a95ace37bca3,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-ab720fde-3c87-4db6-abfd-ca8f1118c0bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31008082-172.17.0.18-1595845565438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40182,DS-9030a14d-cd3e-420a-ad91-b45ea1c9849e,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-95738146-de1b-436f-ba10-1ff896c9b998,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-e9eb6ccd-f2b2-490a-afdd-94f0a55fb274,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-6238390d-c6c4-4343-95c3-e7bdff1bea52,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-5655f8ad-de29-4bba-a391-267bb03c1cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-62cfa957-4561-4206-82b9-092f8a875296,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-3b363665-b8a6-4bd1-b352-69d57e519880,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-0f87e04c-c86b-49dc-9774-e5d072cb7fd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31008082-172.17.0.18-1595845565438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40182,DS-9030a14d-cd3e-420a-ad91-b45ea1c9849e,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-95738146-de1b-436f-ba10-1ff896c9b998,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-e9eb6ccd-f2b2-490a-afdd-94f0a55fb274,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-6238390d-c6c4-4343-95c3-e7bdff1bea52,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-5655f8ad-de29-4bba-a391-267bb03c1cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-62cfa957-4561-4206-82b9-092f8a875296,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-3b363665-b8a6-4bd1-b352-69d57e519880,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-0f87e04c-c86b-49dc-9774-e5d072cb7fd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1275912599-172.17.0.18-1595845781188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38416,DS-0a3cafa2-0d5d-4e54-bdcf-402cda77d9df,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-840466f6-a2d2-4b24-a8b6-c75bce3d9249,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-2a2e06bd-de10-4e17-848f-627d6c131016,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-38ff1538-227f-4e2f-a2a4-a0c4f7e63831,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-c86a0730-958b-4808-93a1-b71bebfd4aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-f01e6abc-2fcd-411b-ab71-d4df486bae0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-eadef4c1-fbb1-4ab4-94ee-4e2e2306a312,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-01399e7f-a645-47b5-aeec-d4490a0de920,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1275912599-172.17.0.18-1595845781188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38416,DS-0a3cafa2-0d5d-4e54-bdcf-402cda77d9df,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-840466f6-a2d2-4b24-a8b6-c75bce3d9249,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-2a2e06bd-de10-4e17-848f-627d6c131016,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-38ff1538-227f-4e2f-a2a4-a0c4f7e63831,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-c86a0730-958b-4808-93a1-b71bebfd4aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-f01e6abc-2fcd-411b-ab71-d4df486bae0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-eadef4c1-fbb1-4ab4-94ee-4e2e2306a312,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-01399e7f-a645-47b5-aeec-d4490a0de920,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1173379264-172.17.0.18-1595846250920:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43207,DS-82d6b93c-456a-481a-8776-f6680c67fa41,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-514cc69f-9d4b-4377-8184-38af599c89bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-62ad1e96-3842-438c-80c6-fc273441ae93,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-57943990-9588-4402-98d5-400f73b66e28,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-973fca88-d4d7-477b-bc83-d844ebd359c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-a7dc18e3-e9f0-4d2d-a98d-aa5fde80a82d,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-a058d713-18ad-4e60-965d-3789253fa9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-f6b0a76f-eee2-493c-9e72-8eed83865bf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1173379264-172.17.0.18-1595846250920:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43207,DS-82d6b93c-456a-481a-8776-f6680c67fa41,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-514cc69f-9d4b-4377-8184-38af599c89bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-62ad1e96-3842-438c-80c6-fc273441ae93,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-57943990-9588-4402-98d5-400f73b66e28,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-973fca88-d4d7-477b-bc83-d844ebd359c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-a7dc18e3-e9f0-4d2d-a98d-aa5fde80a82d,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-a058d713-18ad-4e60-965d-3789253fa9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-f6b0a76f-eee2-493c-9e72-8eed83865bf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-876789246-172.17.0.18-1595846552055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33278,DS-a46b2397-fc99-4fd7-a365-27565140a0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-35c78e58-28d2-4b09-8749-bee6f7e3f214,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-358c5720-a2e8-4baf-9457-52dca51d94a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-b8159b51-718d-4d1e-9a45-0165ca1f76c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-a472423b-d5b0-4f9b-8a4a-22a02d45b9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-bb401f63-2d04-49e4-8868-ba2e7d625d12,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-36b42391-9e7c-4724-80cd-553364cd6b32,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-73ef9623-8557-415d-bf3c-ff81b00e4b58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-876789246-172.17.0.18-1595846552055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33278,DS-a46b2397-fc99-4fd7-a365-27565140a0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-35c78e58-28d2-4b09-8749-bee6f7e3f214,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-358c5720-a2e8-4baf-9457-52dca51d94a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-b8159b51-718d-4d1e-9a45-0165ca1f76c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-a472423b-d5b0-4f9b-8a4a-22a02d45b9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-bb401f63-2d04-49e4-8868-ba2e7d625d12,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-36b42391-9e7c-4724-80cd-553364cd6b32,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-73ef9623-8557-415d-bf3c-ff81b00e4b58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1072948582-172.17.0.18-1595846650726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44332,DS-73deced8-4ecc-4a41-81a9-0f6e1649db29,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-e3a2be60-fe0a-401f-9f0e-878586998a98,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-1a23e6e3-23a5-4081-bd25-a130e65621f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-2d71823a-456a-4ad1-adde-8b782dcdf05a,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-fcdc647f-3995-4ecd-93bc-53d11ada1299,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-4a1fde4b-41b6-4032-bc80-8f8c6449928a,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-7ad82ff4-24ea-43b9-b124-bb63d1774507,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-c38856a9-9043-4b53-b26f-89351f2f61fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1072948582-172.17.0.18-1595846650726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44332,DS-73deced8-4ecc-4a41-81a9-0f6e1649db29,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-e3a2be60-fe0a-401f-9f0e-878586998a98,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-1a23e6e3-23a5-4081-bd25-a130e65621f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-2d71823a-456a-4ad1-adde-8b782dcdf05a,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-fcdc647f-3995-4ecd-93bc-53d11ada1299,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-4a1fde4b-41b6-4032-bc80-8f8c6449928a,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-7ad82ff4-24ea-43b9-b124-bb63d1774507,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-c38856a9-9043-4b53-b26f-89351f2f61fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-299496421-172.17.0.18-1595846830565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44287,DS-f9419a3b-96d4-4cf1-b6de-fbf259116e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-044b159b-d1a2-4d70-a6d1-cd663cd889a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-79993b18-884d-4559-bb24-0abba3be3705,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-83b490d7-c445-4d19-adf8-e99bd2910304,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-f22defb3-62c2-4bc8-aedd-208513acddb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-fec25216-2efe-4f5a-ac6b-47cbab37e48c,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-7d2239ed-21a5-4e29-868d-60185c38887f,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-df1aa9b0-0179-4d62-b64e-eddfc5878d76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-299496421-172.17.0.18-1595846830565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44287,DS-f9419a3b-96d4-4cf1-b6de-fbf259116e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-044b159b-d1a2-4d70-a6d1-cd663cd889a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-79993b18-884d-4559-bb24-0abba3be3705,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-83b490d7-c445-4d19-adf8-e99bd2910304,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-f22defb3-62c2-4bc8-aedd-208513acddb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-fec25216-2efe-4f5a-ac6b-47cbab37e48c,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-7d2239ed-21a5-4e29-868d-60185c38887f,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-df1aa9b0-0179-4d62-b64e-eddfc5878d76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-573498409-172.17.0.18-1595846935184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45522,DS-7bc20dff-8d45-42cd-8f45-4b8512232156,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-b22a9572-9735-4fab-af09-427a62355d06,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-878a4fd4-b0c9-4897-84fe-cb35ef1d3b84,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-7e1bfd94-03f7-4971-8131-61652e51f1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-11b3085a-425b-4960-af7d-d30d839214ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-f583a8e6-0fb0-4942-ba46-85acec6a9971,DISK], DatanodeInfoWithStorage[127.0.0.1:39518,DS-54a6e458-f13b-486d-9d86-bc444d50392f,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-e8831ab4-9406-4e0a-b098-7724ed5850ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-573498409-172.17.0.18-1595846935184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45522,DS-7bc20dff-8d45-42cd-8f45-4b8512232156,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-b22a9572-9735-4fab-af09-427a62355d06,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-878a4fd4-b0c9-4897-84fe-cb35ef1d3b84,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-7e1bfd94-03f7-4971-8131-61652e51f1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-11b3085a-425b-4960-af7d-d30d839214ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-f583a8e6-0fb0-4942-ba46-85acec6a9971,DISK], DatanodeInfoWithStorage[127.0.0.1:39518,DS-54a6e458-f13b-486d-9d86-bc444d50392f,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-e8831ab4-9406-4e0a-b098-7724ed5850ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1923131454-172.17.0.18-1595847041736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35959,DS-4bc2a109-deb9-4891-b672-ba5779e433f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-4ff824ca-3f1a-48ca-89cb-a7c3ababd24b,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-a6601d2b-aebb-4517-914b-974bfd47cc87,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-9b3043d6-a3ab-40e7-8c14-580910ec5a13,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-eecb9f07-e400-4f06-8f6d-52fae523833a,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-31dce9be-953e-4225-9fb5-172699fc84e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-bda2e472-655e-4f1b-94a2-b4c0172fbffb,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-61b05e22-9fe5-4c66-a005-c3d28997b1fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1923131454-172.17.0.18-1595847041736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35959,DS-4bc2a109-deb9-4891-b672-ba5779e433f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-4ff824ca-3f1a-48ca-89cb-a7c3ababd24b,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-a6601d2b-aebb-4517-914b-974bfd47cc87,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-9b3043d6-a3ab-40e7-8c14-580910ec5a13,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-eecb9f07-e400-4f06-8f6d-52fae523833a,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-31dce9be-953e-4225-9fb5-172699fc84e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-bda2e472-655e-4f1b-94a2-b4c0172fbffb,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-61b05e22-9fe5-4c66-a005-c3d28997b1fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-169868178-172.17.0.18-1595847240198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43110,DS-b97b3031-730a-4181-913b-d9027ce2af6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-b933a563-ccd6-4997-a6cb-4f8f3a79e6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-7a83e71b-f8c3-4ea5-9eca-ebebe3c66c43,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-3c9f47fb-d59f-407a-9344-3490c2434642,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-5cd86ac4-69a2-4e51-a56d-da3b2d3e64f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-abc65056-42da-479c-8399-af7b399cd87a,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-c151ea33-0829-4646-9de9-506db911b965,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-c67926be-9109-48e9-8e5f-18e12a1abea8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-169868178-172.17.0.18-1595847240198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43110,DS-b97b3031-730a-4181-913b-d9027ce2af6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-b933a563-ccd6-4997-a6cb-4f8f3a79e6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-7a83e71b-f8c3-4ea5-9eca-ebebe3c66c43,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-3c9f47fb-d59f-407a-9344-3490c2434642,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-5cd86ac4-69a2-4e51-a56d-da3b2d3e64f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-abc65056-42da-479c-8399-af7b399cd87a,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-c151ea33-0829-4646-9de9-506db911b965,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-c67926be-9109-48e9-8e5f-18e12a1abea8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2138291027-172.17.0.18-1595847269137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37015,DS-80ff1947-7203-49f6-8342-b7445d231af9,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-094fa008-2e42-4f68-b408-2ec940c53476,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-583c123d-6d52-4ee1-888b-dee3f3b7095c,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-16310e71-88d6-4770-8633-6842906cf0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-52a950a9-0282-4518-b028-1670de6af765,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-ef78a0ef-b494-4446-b738-b777d90cd62d,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-afeaa15e-a9b2-4c94-abb3-bb9339bb998d,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-831d209f-9195-47dd-8935-8bee2750a105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2138291027-172.17.0.18-1595847269137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37015,DS-80ff1947-7203-49f6-8342-b7445d231af9,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-094fa008-2e42-4f68-b408-2ec940c53476,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-583c123d-6d52-4ee1-888b-dee3f3b7095c,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-16310e71-88d6-4770-8633-6842906cf0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-52a950a9-0282-4518-b028-1670de6af765,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-ef78a0ef-b494-4446-b738-b777d90cd62d,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-afeaa15e-a9b2-4c94-abb3-bb9339bb998d,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-831d209f-9195-47dd-8935-8bee2750a105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-243181440-172.17.0.18-1595847473727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41429,DS-978034da-f0c7-45ab-a302-8f555f8fc221,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-e50d0cb4-03c0-423c-b3b9-916e0774a7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-72d6a1fd-11af-43dd-8c6a-bc3ce818649d,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-fe7f0061-0941-4d20-aa43-7f50cd1512b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-527811a2-f7d9-4998-9728-593dabdeb665,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-d2a5c4a6-e15e-44d6-92ca-f71bf5f0dce2,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-a85c0e7a-8b7f-4b14-a1bb-7449b8fc4684,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-0ab8c386-dbf7-4b23-b5c3-eb0383c10050,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-243181440-172.17.0.18-1595847473727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41429,DS-978034da-f0c7-45ab-a302-8f555f8fc221,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-e50d0cb4-03c0-423c-b3b9-916e0774a7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-72d6a1fd-11af-43dd-8c6a-bc3ce818649d,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-fe7f0061-0941-4d20-aa43-7f50cd1512b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-527811a2-f7d9-4998-9728-593dabdeb665,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-d2a5c4a6-e15e-44d6-92ca-f71bf5f0dce2,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-a85c0e7a-8b7f-4b14-a1bb-7449b8fc4684,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-0ab8c386-dbf7-4b23-b5c3-eb0383c10050,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807833704-172.17.0.18-1595847827766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43916,DS-51d31e37-8b87-4cea-8f73-862693b53184,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-342734d8-dafb-4f5d-a936-283e95fcb81a,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-6ca31e69-cc78-400d-8b43-c19c904b86d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-fd571458-6f9f-4425-9b03-724f83a8371b,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-fc612208-f2b0-4afd-be40-1f65331df2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-2f7ebc6d-a445-4624-947f-0c17b104a7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-8efe32d6-dcd5-4b75-8d6a-5fc29ca0bb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-db8f1402-0ddd-4f9d-a656-f81e6501e4b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807833704-172.17.0.18-1595847827766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43916,DS-51d31e37-8b87-4cea-8f73-862693b53184,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-342734d8-dafb-4f5d-a936-283e95fcb81a,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-6ca31e69-cc78-400d-8b43-c19c904b86d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-fd571458-6f9f-4425-9b03-724f83a8371b,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-fc612208-f2b0-4afd-be40-1f65331df2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-2f7ebc6d-a445-4624-947f-0c17b104a7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-8efe32d6-dcd5-4b75-8d6a-5fc29ca0bb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-db8f1402-0ddd-4f9d-a656-f81e6501e4b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693765266-172.17.0.18-1595847897755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36128,DS-8b5a6253-7627-4a1d-afad-7f6ef137a308,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-92a6b801-2660-4c62-9d86-47e302144a64,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-5140a71d-e9c2-42f5-9c60-62eaf68bb8af,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-7e4702f9-0674-4dc4-b2cb-2f676c77f44e,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-ac1d36a8-b6c1-4875-b64b-f8d9b98ce1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-08d0e515-ab3b-4519-8a86-58d3b02d3823,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-ffb67f63-e1c7-44d0-9c86-10dfbd9f2e44,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-2df4f82f-1c59-4069-92f5-8d1099c1d559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693765266-172.17.0.18-1595847897755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36128,DS-8b5a6253-7627-4a1d-afad-7f6ef137a308,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-92a6b801-2660-4c62-9d86-47e302144a64,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-5140a71d-e9c2-42f5-9c60-62eaf68bb8af,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-7e4702f9-0674-4dc4-b2cb-2f676c77f44e,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-ac1d36a8-b6c1-4875-b64b-f8d9b98ce1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-08d0e515-ab3b-4519-8a86-58d3b02d3823,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-ffb67f63-e1c7-44d0-9c86-10dfbd9f2e44,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-2df4f82f-1c59-4069-92f5-8d1099c1d559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-51312946-172.17.0.18-1595848225825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35583,DS-30ee1697-9179-4835-8023-83087a728e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-a09a31cd-ae18-41ed-8ed9-0e6f765f4562,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-f4c4db34-4306-4eff-bc44-462c0115ba48,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-38ada9ea-7961-486c-8a06-09453ba61f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-e29af923-9769-4d7c-8616-85eca5c154e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-f6044b87-fc95-4d4e-a431-9f3d8746d36d,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-4c80ee80-0dd0-43be-aff0-a44f2b8a7993,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-5fc5a068-3a54-49ea-9eb0-f4f3a77c7542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-51312946-172.17.0.18-1595848225825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35583,DS-30ee1697-9179-4835-8023-83087a728e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-a09a31cd-ae18-41ed-8ed9-0e6f765f4562,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-f4c4db34-4306-4eff-bc44-462c0115ba48,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-38ada9ea-7961-486c-8a06-09453ba61f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-e29af923-9769-4d7c-8616-85eca5c154e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-f6044b87-fc95-4d4e-a431-9f3d8746d36d,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-4c80ee80-0dd0-43be-aff0-a44f2b8a7993,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-5fc5a068-3a54-49ea-9eb0-f4f3a77c7542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-744689435-172.17.0.18-1595848337010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37833,DS-c4fd9e9a-0a02-4cbe-bd29-cafa9e78e0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-7f34c106-f784-4f79-9404-32331d0b55cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41813,DS-921d4228-905c-4ccf-b42e-a2ed2753061c,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-6241f1ca-287c-4409-b160-a6a6f1381eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-4cb0ba5f-32f3-44e3-b251-a5cb74663720,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-87f64ea0-fd06-43fc-b022-7339e4134b90,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-f0586aff-dfce-4f39-9365-2c4ca6080b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-0a6cb839-6801-4dff-8574-f2e3a9c7618d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-744689435-172.17.0.18-1595848337010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37833,DS-c4fd9e9a-0a02-4cbe-bd29-cafa9e78e0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-7f34c106-f784-4f79-9404-32331d0b55cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41813,DS-921d4228-905c-4ccf-b42e-a2ed2753061c,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-6241f1ca-287c-4409-b160-a6a6f1381eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-4cb0ba5f-32f3-44e3-b251-a5cb74663720,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-87f64ea0-fd06-43fc-b022-7339e4134b90,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-f0586aff-dfce-4f39-9365-2c4ca6080b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-0a6cb839-6801-4dff-8574-f2e3a9c7618d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-44514358-172.17.0.18-1595848377261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37076,DS-068aaeca-ae7d-4457-9192-08b2b0c558ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-0edb07a2-c7e7-49a9-8106-232895f757c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-14a49c45-4de2-45a4-9bc9-960242ceed84,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-0059506d-183b-4296-9b3e-98d4567dd719,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-98dc7e4c-b708-4d29-ba6a-78bae146a68f,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-0baca201-6739-4e03-a0e2-646befd17ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-85959358-45ab-4d44-8ceb-a076f2dd2ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-56731252-cf35-43df-b99d-13f4b027e936,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-44514358-172.17.0.18-1595848377261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37076,DS-068aaeca-ae7d-4457-9192-08b2b0c558ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-0edb07a2-c7e7-49a9-8106-232895f757c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-14a49c45-4de2-45a4-9bc9-960242ceed84,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-0059506d-183b-4296-9b3e-98d4567dd719,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-98dc7e4c-b708-4d29-ba6a-78bae146a68f,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-0baca201-6739-4e03-a0e2-646befd17ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-85959358-45ab-4d44-8ceb-a076f2dd2ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-56731252-cf35-43df-b99d-13f4b027e936,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822882766-172.17.0.18-1595848759354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33835,DS-4df2da60-0dcb-4ce2-8bb8-b4b915549eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-61890230-5ef9-400e-b211-0d4b5661169f,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-b109b2cb-a4a3-40bd-bec5-21c846c72b05,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-ab46987f-7253-473c-a139-42bac222eec2,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-434d61d3-6b3c-4568-9c8d-e1ecec0f24d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-d4f9693f-cbbb-4788-851e-ead6546f60e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-1f629369-8cf3-4e84-a83e-20efa62eaaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-379c0d60-a2b7-430b-afb7-d7072576cf02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822882766-172.17.0.18-1595848759354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33835,DS-4df2da60-0dcb-4ce2-8bb8-b4b915549eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-61890230-5ef9-400e-b211-0d4b5661169f,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-b109b2cb-a4a3-40bd-bec5-21c846c72b05,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-ab46987f-7253-473c-a139-42bac222eec2,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-434d61d3-6b3c-4568-9c8d-e1ecec0f24d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-d4f9693f-cbbb-4788-851e-ead6546f60e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-1f629369-8cf3-4e84-a83e-20efa62eaaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-379c0d60-a2b7-430b-afb7-d7072576cf02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5214
