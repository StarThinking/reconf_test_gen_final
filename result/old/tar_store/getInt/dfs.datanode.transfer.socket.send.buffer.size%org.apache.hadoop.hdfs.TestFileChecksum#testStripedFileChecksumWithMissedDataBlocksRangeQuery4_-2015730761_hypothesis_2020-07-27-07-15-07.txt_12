reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606932406-172.17.0.14-1595834258385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32837,DS-ee8d3759-ca45-4395-9042-8c59b0d2fd06,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-b7d24147-c61f-4e6f-92dc-083030ee23b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-52ab28b7-3d63-45c8-b319-d764844a3a32,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-6e3791b5-d51c-4ab5-b264-bbab3e9359e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-bf50f57b-5b15-4369-a4a8-7a1342d66413,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-eba18cb5-1480-464d-a148-24d9b3fc92c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-3149410d-f9ab-445e-b561-78be3aae30de,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-79bf8492-7ff1-47c7-916e-cecac346e74c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606932406-172.17.0.14-1595834258385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32837,DS-ee8d3759-ca45-4395-9042-8c59b0d2fd06,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-b7d24147-c61f-4e6f-92dc-083030ee23b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-52ab28b7-3d63-45c8-b319-d764844a3a32,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-6e3791b5-d51c-4ab5-b264-bbab3e9359e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-bf50f57b-5b15-4369-a4a8-7a1342d66413,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-eba18cb5-1480-464d-a148-24d9b3fc92c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-3149410d-f9ab-445e-b561-78be3aae30de,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-79bf8492-7ff1-47c7-916e-cecac346e74c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1240295226-172.17.0.14-1595834403110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32983,DS-4b636e0e-afe5-4fe6-8939-4b33c8dd2caf,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-01f1e1e1-9d71-40af-8205-dfdec3a0db7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-542a30f3-542b-48ec-806c-3431d606660f,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-806f92f8-293f-44cb-8b50-0b049829e504,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-24fd95c3-bfc7-4090-b7a5-0924c00d5f01,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-93ac6eff-13b8-466b-8222-d3f9db26fcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-c9a30ef4-2f54-4651-9fbd-4cfa70f5e7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-2a84508f-d431-4409-942b-c9958b6a6998,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1240295226-172.17.0.14-1595834403110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32983,DS-4b636e0e-afe5-4fe6-8939-4b33c8dd2caf,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-01f1e1e1-9d71-40af-8205-dfdec3a0db7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-542a30f3-542b-48ec-806c-3431d606660f,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-806f92f8-293f-44cb-8b50-0b049829e504,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-24fd95c3-bfc7-4090-b7a5-0924c00d5f01,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-93ac6eff-13b8-466b-8222-d3f9db26fcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-c9a30ef4-2f54-4651-9fbd-4cfa70f5e7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-2a84508f-d431-4409-942b-c9958b6a6998,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021601172-172.17.0.14-1595834441441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33413,DS-0f5833fb-9c90-4ee6-8385-51bdcce47940,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-d8b77674-08ad-4999-a3ab-3d3ed4fa967f,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-2458bb42-f7c4-4514-9317-0669bfaa4f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-22dc3607-4dab-45c7-95c9-454f0a699341,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-bb06b6cd-9fe1-4c20-a776-7105710dc20e,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-1e084fe4-f73e-464a-b480-c28187858ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-af170861-68a4-4899-89c9-f12c68cd5cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-692a3a51-4fec-4103-b4ba-aac3f93567c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021601172-172.17.0.14-1595834441441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33413,DS-0f5833fb-9c90-4ee6-8385-51bdcce47940,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-d8b77674-08ad-4999-a3ab-3d3ed4fa967f,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-2458bb42-f7c4-4514-9317-0669bfaa4f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-22dc3607-4dab-45c7-95c9-454f0a699341,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-bb06b6cd-9fe1-4c20-a776-7105710dc20e,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-1e084fe4-f73e-464a-b480-c28187858ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-af170861-68a4-4899-89c9-f12c68cd5cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-692a3a51-4fec-4103-b4ba-aac3f93567c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811743741-172.17.0.14-1595834560346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43047,DS-8552f632-cf64-4d4f-ab4b-02394b95147e,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-b6607c88-41f1-4fa9-a5a7-7a3faa4a1037,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-9a5fe86c-8113-48c0-a278-3dd6c539b1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-98159da2-6d71-432a-8edd-fec24f8495f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-b170b015-0537-4c6e-aa0f-e39905a3e652,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-31ebe644-d452-47f2-a12f-66f17ec0ceac,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-60e6ebea-e727-4a91-ae41-7b7a8f2c3838,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-a340871b-8bb8-49af-9bbf-bc178cfe7b3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811743741-172.17.0.14-1595834560346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43047,DS-8552f632-cf64-4d4f-ab4b-02394b95147e,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-b6607c88-41f1-4fa9-a5a7-7a3faa4a1037,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-9a5fe86c-8113-48c0-a278-3dd6c539b1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-98159da2-6d71-432a-8edd-fec24f8495f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-b170b015-0537-4c6e-aa0f-e39905a3e652,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-31ebe644-d452-47f2-a12f-66f17ec0ceac,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-60e6ebea-e727-4a91-ae41-7b7a8f2c3838,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-a340871b-8bb8-49af-9bbf-bc178cfe7b3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1017043341-172.17.0.14-1595835117710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42249,DS-7affca76-458d-4c39-a8f4-111696ec8234,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-e3ee9c0c-4819-4ea0-8740-dee26e4234d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-10b6c083-a87f-4658-b8eb-d1c40b31ee34,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-e338fbad-16ab-4c7e-b100-16fcbbb4d0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-7aafff4c-4ad5-4396-86e2-ac0b8fbb06c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-536b4f16-dbbe-4dbe-80f4-010a5ba127e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-1ce0d3d1-9970-4af6-ba95-83f67c0299e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-20fce3b4-91b6-4e76-8f0a-97b7b0ff44c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1017043341-172.17.0.14-1595835117710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42249,DS-7affca76-458d-4c39-a8f4-111696ec8234,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-e3ee9c0c-4819-4ea0-8740-dee26e4234d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-10b6c083-a87f-4658-b8eb-d1c40b31ee34,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-e338fbad-16ab-4c7e-b100-16fcbbb4d0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-7aafff4c-4ad5-4396-86e2-ac0b8fbb06c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-536b4f16-dbbe-4dbe-80f4-010a5ba127e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-1ce0d3d1-9970-4af6-ba95-83f67c0299e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-20fce3b4-91b6-4e76-8f0a-97b7b0ff44c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085802758-172.17.0.14-1595835157228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44046,DS-b8356be4-2331-40ab-a0fd-930cefa4948c,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-a91d28ab-22ec-4659-9e04-75c5625cee75,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-529744cc-e1b9-4eac-a289-71b4e0eacceb,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-4a8d246f-beea-4746-8c1d-bd9b7ebce7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-48a57eb0-cc9e-4732-9ab2-f8ec82919d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-dd417d57-1705-4c9b-9abb-48536b4f6d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-591a61ab-370c-4c5f-8316-54ba687a75da,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-1db472b9-606f-471c-861e-7aa4b8f9131f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085802758-172.17.0.14-1595835157228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44046,DS-b8356be4-2331-40ab-a0fd-930cefa4948c,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-a91d28ab-22ec-4659-9e04-75c5625cee75,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-529744cc-e1b9-4eac-a289-71b4e0eacceb,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-4a8d246f-beea-4746-8c1d-bd9b7ebce7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-48a57eb0-cc9e-4732-9ab2-f8ec82919d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-dd417d57-1705-4c9b-9abb-48536b4f6d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-591a61ab-370c-4c5f-8316-54ba687a75da,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-1db472b9-606f-471c-861e-7aa4b8f9131f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241200107-172.17.0.14-1595835253899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43303,DS-c2fbb51d-ef23-400b-8ee5-3f03183345f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-412a5c1b-4f35-4096-8ebc-4af2bdc8ee96,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-2580c4e6-f185-4ef1-8744-6d641cc74ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-dfb47441-deef-4f64-9206-8c64648246c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-6e06ae94-7532-41fa-9e83-92f34b799461,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-1fba0c9f-f450-45ea-a9bd-d7c85d444195,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-d55e202f-a5c3-457b-9092-17a2e5f8b2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-8ac0e4d7-e094-4f4a-ae85-e2e88ca6123a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241200107-172.17.0.14-1595835253899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43303,DS-c2fbb51d-ef23-400b-8ee5-3f03183345f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-412a5c1b-4f35-4096-8ebc-4af2bdc8ee96,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-2580c4e6-f185-4ef1-8744-6d641cc74ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-dfb47441-deef-4f64-9206-8c64648246c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-6e06ae94-7532-41fa-9e83-92f34b799461,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-1fba0c9f-f450-45ea-a9bd-d7c85d444195,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-d55e202f-a5c3-457b-9092-17a2e5f8b2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-8ac0e4d7-e094-4f4a-ae85-e2e88ca6123a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1975012345-172.17.0.14-1595835771852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40554,DS-20a89a63-49d3-4d2a-9cea-249c6bc45320,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-1e36e648-717a-4c07-a3f6-481d07a3d5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-ef13604b-4e71-461a-927d-9ef83a0037f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-22022fd3-4e26-43ef-94f4-ea14dcfa38da,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-0ba1738b-bb52-429b-aa70-a146610ae0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-4cecde76-504b-4e1b-af83-983e4fb06132,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-2fc8ccb3-a79c-4900-9bdf-d39a77ba681a,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-4b55dfcc-2095-4ad0-9a86-85823e88ec8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1975012345-172.17.0.14-1595835771852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40554,DS-20a89a63-49d3-4d2a-9cea-249c6bc45320,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-1e36e648-717a-4c07-a3f6-481d07a3d5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-ef13604b-4e71-461a-927d-9ef83a0037f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-22022fd3-4e26-43ef-94f4-ea14dcfa38da,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-0ba1738b-bb52-429b-aa70-a146610ae0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-4cecde76-504b-4e1b-af83-983e4fb06132,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-2fc8ccb3-a79c-4900-9bdf-d39a77ba681a,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-4b55dfcc-2095-4ad0-9a86-85823e88ec8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457711612-172.17.0.14-1595836573413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36707,DS-cbe023fe-2133-4267-8be9-527839c7e9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-9abcb6a0-dd4a-48cd-b07f-1eedc0780adb,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-ec9b638c-7594-4670-9a07-660b1cba9ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-f0e68ede-ee51-4bdb-81cb-2e9af3ae654b,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-1557603c-d13f-40a8-9ecc-3ba2d5213058,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-abbcb540-7644-4170-9f1d-f29087b904b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-3d7041db-5016-4a44-9fa7-53673d05df9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-96ba1171-c115-49b2-a817-0731f482811c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457711612-172.17.0.14-1595836573413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36707,DS-cbe023fe-2133-4267-8be9-527839c7e9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-9abcb6a0-dd4a-48cd-b07f-1eedc0780adb,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-ec9b638c-7594-4670-9a07-660b1cba9ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-f0e68ede-ee51-4bdb-81cb-2e9af3ae654b,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-1557603c-d13f-40a8-9ecc-3ba2d5213058,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-abbcb540-7644-4170-9f1d-f29087b904b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-3d7041db-5016-4a44-9fa7-53673d05df9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-96ba1171-c115-49b2-a817-0731f482811c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712465843-172.17.0.14-1595837321096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46289,DS-252f0e05-6eb2-4b36-95eb-eb5fae597833,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-d39b8f45-04d1-4883-8437-1e041d703ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-0596965a-f81d-4c8d-a049-155ae581b38d,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-fcbba782-c64d-4fb2-bad1-2b42ae1bfda5,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-10369b63-d8a3-45a8-8d6a-9650073d95dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-6b950eea-bf19-4cf2-aab3-e1c8f697d838,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-e7182e3b-7666-4d94-9c7c-0db7ccb2e3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-3bf7034d-8269-4ba0-883d-36b4e5263d06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712465843-172.17.0.14-1595837321096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46289,DS-252f0e05-6eb2-4b36-95eb-eb5fae597833,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-d39b8f45-04d1-4883-8437-1e041d703ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-0596965a-f81d-4c8d-a049-155ae581b38d,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-fcbba782-c64d-4fb2-bad1-2b42ae1bfda5,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-10369b63-d8a3-45a8-8d6a-9650073d95dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-6b950eea-bf19-4cf2-aab3-e1c8f697d838,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-e7182e3b-7666-4d94-9c7c-0db7ccb2e3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-3bf7034d-8269-4ba0-883d-36b4e5263d06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1700630159-172.17.0.14-1595837355365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40023,DS-bb1596a9-7c65-419d-b6a4-cdfa15b6f447,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-98fc7283-6d74-440a-b4de-30de9429863a,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-0ae7ec74-3e05-4018-845b-dd27750809b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-93c4b859-58bb-4cb1-8be3-ea101cd3db72,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-138cf230-6dc6-432d-aaa5-f2c3367b2bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-16806b77-74e6-4d23-9c4d-510db53aec5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-c6018d36-ddce-4a5b-800b-66cb2543e0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-4c3bfcec-ead1-463f-a5c8-6c80608d9fc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1700630159-172.17.0.14-1595837355365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40023,DS-bb1596a9-7c65-419d-b6a4-cdfa15b6f447,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-98fc7283-6d74-440a-b4de-30de9429863a,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-0ae7ec74-3e05-4018-845b-dd27750809b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-93c4b859-58bb-4cb1-8be3-ea101cd3db72,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-138cf230-6dc6-432d-aaa5-f2c3367b2bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-16806b77-74e6-4d23-9c4d-510db53aec5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-c6018d36-ddce-4a5b-800b-66cb2543e0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-4c3bfcec-ead1-463f-a5c8-6c80608d9fc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1274814679-172.17.0.14-1595837646966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43507,DS-bfb370a4-c7eb-4653-8d59-4dea7b5c9bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-56e403ef-162c-4c95-9689-a3e22f412f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-7940a561-aa35-452c-a4e1-4701e63c0692,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-05197df1-9140-48eb-a30a-552338dce4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-799333f5-c798-4129-9060-a807c40c5932,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-cb218fc3-6b13-4408-9bb7-66de8b967d47,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-3b985a6b-b630-47ce-a6f7-34cf9174e8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-342e92c0-0b55-4c1f-b7a0-a52b74bcb93f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1274814679-172.17.0.14-1595837646966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43507,DS-bfb370a4-c7eb-4653-8d59-4dea7b5c9bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-56e403ef-162c-4c95-9689-a3e22f412f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-7940a561-aa35-452c-a4e1-4701e63c0692,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-05197df1-9140-48eb-a30a-552338dce4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-799333f5-c798-4129-9060-a807c40c5932,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-cb218fc3-6b13-4408-9bb7-66de8b967d47,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-3b985a6b-b630-47ce-a6f7-34cf9174e8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-342e92c0-0b55-4c1f-b7a0-a52b74bcb93f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-306421626-172.17.0.14-1595837969192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45256,DS-c549a930-6f4f-4aa5-9904-ad7ca28db76d,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-70198aa5-b7dc-4b5e-a433-f951e9488a40,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-006aae26-ad52-4825-85a8-f2434f426a42,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-81e9ede3-cd01-4e21-9d9c-b7f1062c23d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-9e46221f-358e-43bb-b08c-24e88ed58312,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-b32472f7-9017-445d-a363-cb5149183e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-516bbad2-8a98-4b10-87a8-07552fcbfd79,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-7db6793b-70f4-4c17-a0a0-21b4aac15e01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-306421626-172.17.0.14-1595837969192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45256,DS-c549a930-6f4f-4aa5-9904-ad7ca28db76d,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-70198aa5-b7dc-4b5e-a433-f951e9488a40,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-006aae26-ad52-4825-85a8-f2434f426a42,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-81e9ede3-cd01-4e21-9d9c-b7f1062c23d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-9e46221f-358e-43bb-b08c-24e88ed58312,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-b32472f7-9017-445d-a363-cb5149183e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-516bbad2-8a98-4b10-87a8-07552fcbfd79,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-7db6793b-70f4-4c17-a0a0-21b4aac15e01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505131846-172.17.0.14-1595838129484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38890,DS-1d69f5a4-1a2b-4f9b-8328-06c7356d6cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-85c28731-f226-4d68-a2f9-7d7f7ef755d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-a2dd0a05-cab6-4ef6-9ef8-3d159a03a4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-540cb875-95c6-4d61-8cd4-4190de6be003,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-215f6406-558e-4dcb-972a-a1fdbfcf76f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-77079451-937b-4ca5-8c87-a22dc53903a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-754f7815-e2cf-409f-bcf1-0ac7135e70c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-ed7e2930-5be0-49f2-8f0b-d6cd77123721,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505131846-172.17.0.14-1595838129484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38890,DS-1d69f5a4-1a2b-4f9b-8328-06c7356d6cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-85c28731-f226-4d68-a2f9-7d7f7ef755d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-a2dd0a05-cab6-4ef6-9ef8-3d159a03a4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-540cb875-95c6-4d61-8cd4-4190de6be003,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-215f6406-558e-4dcb-972a-a1fdbfcf76f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-77079451-937b-4ca5-8c87-a22dc53903a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-754f7815-e2cf-409f-bcf1-0ac7135e70c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-ed7e2930-5be0-49f2-8f0b-d6cd77123721,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767831928-172.17.0.14-1595838490820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45777,DS-152b753c-6536-4bc4-ba7c-eb5f839e027b,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-22240ea2-0d41-420f-b6c1-2be6a65b7ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-effc9a0a-4639-4e32-92ad-a03af2dbb87d,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-eca0fccb-23b8-41aa-a8a4-29f0931f415f,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-a1d09f8e-9d02-4fae-a260-6e2ff0dab1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-844dc72e-ea54-4834-ba92-2f2fbf091dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-c240c555-e9cc-4db1-ae88-ab9179c4b5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-7679b465-2fe5-4520-8484-0cdb30bd3e6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767831928-172.17.0.14-1595838490820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45777,DS-152b753c-6536-4bc4-ba7c-eb5f839e027b,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-22240ea2-0d41-420f-b6c1-2be6a65b7ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-effc9a0a-4639-4e32-92ad-a03af2dbb87d,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-eca0fccb-23b8-41aa-a8a4-29f0931f415f,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-a1d09f8e-9d02-4fae-a260-6e2ff0dab1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-844dc72e-ea54-4834-ba92-2f2fbf091dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-c240c555-e9cc-4db1-ae88-ab9179c4b5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-7679b465-2fe5-4520-8484-0cdb30bd3e6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028127348-172.17.0.14-1595838806883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42569,DS-08bc8937-c00a-4d4e-9fe3-39d779aacaee,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-a2797fbd-df06-4e48-a54a-56374ac48d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-16928bf5-1041-471b-834d-7ba3dec3ef67,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-5fca806c-5305-4f41-acfc-7c4611c57903,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-e7454037-98e2-497b-9a63-9f403faae0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-116a69f6-fc5b-4b13-a60e-1ff61c971cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-7130517a-3653-4235-a933-57631f3c4e48,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-a2c683d9-5c7e-4bd9-abf4-843aaa04f66d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028127348-172.17.0.14-1595838806883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42569,DS-08bc8937-c00a-4d4e-9fe3-39d779aacaee,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-a2797fbd-df06-4e48-a54a-56374ac48d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-16928bf5-1041-471b-834d-7ba3dec3ef67,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-5fca806c-5305-4f41-acfc-7c4611c57903,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-e7454037-98e2-497b-9a63-9f403faae0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-116a69f6-fc5b-4b13-a60e-1ff61c971cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-7130517a-3653-4235-a933-57631f3c4e48,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-a2c683d9-5c7e-4bd9-abf4-843aaa04f66d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981919942-172.17.0.14-1595838876990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39120,DS-c345dd9c-3c87-484f-b09f-96797c27327d,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-346d3c32-4ea1-42a6-b13f-df5a24211931,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-1a3e1403-b9a3-4d23-8211-1a3fb9897ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-0854aa60-fd0e-4462-829a-517d2d3d292b,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-0026d585-a53b-423e-a9e1-1a951df8c9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-285054ab-749a-4c00-94b8-3368fd464c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-6a614ab4-b753-4e5f-8b17-722782861829,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-74e0975b-5686-49da-9446-23bb9a94e275,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981919942-172.17.0.14-1595838876990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39120,DS-c345dd9c-3c87-484f-b09f-96797c27327d,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-346d3c32-4ea1-42a6-b13f-df5a24211931,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-1a3e1403-b9a3-4d23-8211-1a3fb9897ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-0854aa60-fd0e-4462-829a-517d2d3d292b,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-0026d585-a53b-423e-a9e1-1a951df8c9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-285054ab-749a-4c00-94b8-3368fd464c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-6a614ab4-b753-4e5f-8b17-722782861829,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-74e0975b-5686-49da-9446-23bb9a94e275,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5106
