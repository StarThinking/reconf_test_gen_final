reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430045904-172.17.0.12-1595480711640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34399,DS-76f286e3-9a90-481d-b6f7-fe9016c57c65,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-d19949e7-d23d-4d49-9cf2-8845dc40b95c,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-ac9792dd-c714-4087-9ca3-df4e9514b12f,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-9fb6f3f9-b1f4-486c-b7bd-e47d92f716b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-4d0bfb28-66a5-4f41-9d9d-997eb4a0211d,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-3c471031-67ef-461d-b4aa-22c688421e46,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-94d54508-7159-4335-96ae-877d9a27e634,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-27c546be-2256-4954-ba8c-a807eedbfb90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430045904-172.17.0.12-1595480711640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34399,DS-76f286e3-9a90-481d-b6f7-fe9016c57c65,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-d19949e7-d23d-4d49-9cf2-8845dc40b95c,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-ac9792dd-c714-4087-9ca3-df4e9514b12f,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-9fb6f3f9-b1f4-486c-b7bd-e47d92f716b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-4d0bfb28-66a5-4f41-9d9d-997eb4a0211d,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-3c471031-67ef-461d-b4aa-22c688421e46,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-94d54508-7159-4335-96ae-877d9a27e634,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-27c546be-2256-4954-ba8c-a807eedbfb90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-534363273-172.17.0.12-1595480749953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39737,DS-08be1015-b4ff-426a-b2dc-83157e7d5a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-0bcd034a-2215-4a46-aeb3-791f73bd622a,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-d266575d-b359-4645-b0d3-69fa0948cb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-2a3a6159-b764-4c5c-b8ec-fa806cfcf7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-6a8dc49b-16a5-447b-aa56-f581c017cb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-94a9ac2a-c39b-4632-bcb2-269a641bdcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-cd8625e7-b854-4820-803b-55b800d6fcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-d99b0d76-b651-428d-bda1-fe592de914ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-534363273-172.17.0.12-1595480749953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39737,DS-08be1015-b4ff-426a-b2dc-83157e7d5a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-0bcd034a-2215-4a46-aeb3-791f73bd622a,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-d266575d-b359-4645-b0d3-69fa0948cb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-2a3a6159-b764-4c5c-b8ec-fa806cfcf7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-6a8dc49b-16a5-447b-aa56-f581c017cb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-94a9ac2a-c39b-4632-bcb2-269a641bdcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-cd8625e7-b854-4820-803b-55b800d6fcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-d99b0d76-b651-428d-bda1-fe592de914ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2006176857-172.17.0.12-1595481093302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46097,DS-9d1d895f-b05f-4c40-aef0-33053157d1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-89424356-2d6e-45f1-a97b-d7f338787124,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-04fe8196-07ae-4622-962e-55b00e95ecb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-70ec3df6-6077-47a5-aaf9-5f4245f14a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-8d194a3f-0cb2-4b7a-8c45-cf327c764015,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-4d144e93-bb65-4ad6-906e-3bf4b53654fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-68c13e0e-a464-4f59-87ec-b64de0b3aafc,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-edc05368-a42d-4c7e-8280-d92aa4b403cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2006176857-172.17.0.12-1595481093302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46097,DS-9d1d895f-b05f-4c40-aef0-33053157d1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-89424356-2d6e-45f1-a97b-d7f338787124,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-04fe8196-07ae-4622-962e-55b00e95ecb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-70ec3df6-6077-47a5-aaf9-5f4245f14a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-8d194a3f-0cb2-4b7a-8c45-cf327c764015,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-4d144e93-bb65-4ad6-906e-3bf4b53654fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-68c13e0e-a464-4f59-87ec-b64de0b3aafc,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-edc05368-a42d-4c7e-8280-d92aa4b403cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340536776-172.17.0.12-1595481523458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44233,DS-7cc089ab-7f45-461d-98b7-d58b8e53b568,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-fdd41791-bb09-4f21-8a16-e37020513048,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-031aed15-39f9-4faa-9009-569259f828ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-5862e536-2396-4fb4-880c-637396785b47,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-cc2c3c8d-9c20-486c-8435-a844aa496250,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-1b1914eb-ca74-4403-9c41-39a8ed4069e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-5ec936d0-ce77-4863-9b28-d3cde5d6c2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-e8fe07fe-6255-43a1-8c37-acf9cb76cdf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340536776-172.17.0.12-1595481523458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44233,DS-7cc089ab-7f45-461d-98b7-d58b8e53b568,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-fdd41791-bb09-4f21-8a16-e37020513048,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-031aed15-39f9-4faa-9009-569259f828ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-5862e536-2396-4fb4-880c-637396785b47,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-cc2c3c8d-9c20-486c-8435-a844aa496250,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-1b1914eb-ca74-4403-9c41-39a8ed4069e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-5ec936d0-ce77-4863-9b28-d3cde5d6c2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-e8fe07fe-6255-43a1-8c37-acf9cb76cdf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1523203142-172.17.0.12-1595483375146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34397,DS-bd7ecc2e-8130-4815-b257-a962f0ab6520,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-7c8c1864-e99c-412b-b6bc-a1c41d00a5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-4eb22cf6-b039-4c8d-8648-095bd3508a21,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-55f55a52-ed84-4b47-ae1d-1f3984e476f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-e3539f8e-9f6b-447e-a519-a1aa34c479e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-8fdd80bc-a174-47c2-bb6e-d9530ea2766d,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-ecf11177-0c00-457e-865b-ac5b1f299fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-fbb4d8dc-b140-44e9-a8bb-61e1206dec9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1523203142-172.17.0.12-1595483375146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34397,DS-bd7ecc2e-8130-4815-b257-a962f0ab6520,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-7c8c1864-e99c-412b-b6bc-a1c41d00a5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-4eb22cf6-b039-4c8d-8648-095bd3508a21,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-55f55a52-ed84-4b47-ae1d-1f3984e476f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-e3539f8e-9f6b-447e-a519-a1aa34c479e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-8fdd80bc-a174-47c2-bb6e-d9530ea2766d,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-ecf11177-0c00-457e-865b-ac5b1f299fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-fbb4d8dc-b140-44e9-a8bb-61e1206dec9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117459943-172.17.0.12-1595483669416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46317,DS-56d15bd2-7b6f-4444-beeb-4d0e53cb51be,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-a5021582-5730-45a4-923a-f79e49634dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-b194b199-36e4-4a70-ae6d-5d077f9769ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-621569ab-6349-4b96-b66d-ac4aab5b3a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-fdfed9da-ef74-4aab-96fb-ed215716b67d,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-214bdc07-acd1-4498-9529-2553dc23d593,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-22dbce2e-910e-41c3-b83c-afa8a6338cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-12c58242-2ccf-4c8f-9591-74ecedba575b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117459943-172.17.0.12-1595483669416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46317,DS-56d15bd2-7b6f-4444-beeb-4d0e53cb51be,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-a5021582-5730-45a4-923a-f79e49634dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-b194b199-36e4-4a70-ae6d-5d077f9769ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-621569ab-6349-4b96-b66d-ac4aab5b3a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-fdfed9da-ef74-4aab-96fb-ed215716b67d,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-214bdc07-acd1-4498-9529-2553dc23d593,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-22dbce2e-910e-41c3-b83c-afa8a6338cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-12c58242-2ccf-4c8f-9591-74ecedba575b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624366474-172.17.0.12-1595483712141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43725,DS-b5dc2f02-625f-4856-b262-d848578f53da,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-613b6b39-d970-483d-93eb-bc514bfd897c,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-1b5d59ff-6fd9-4c96-a00a-f5d242cb6c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-13c504e9-a3bd-4761-aa19-68b80e0bff01,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-c40dec4d-f99b-4d63-a745-1df3993ff2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-c5155d1b-b433-4310-994a-b7ecd679b653,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-df789a80-a169-41fe-8932-515e4d4620c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-8f272055-cb4c-44c6-86b9-b277e051bb88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624366474-172.17.0.12-1595483712141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43725,DS-b5dc2f02-625f-4856-b262-d848578f53da,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-613b6b39-d970-483d-93eb-bc514bfd897c,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-1b5d59ff-6fd9-4c96-a00a-f5d242cb6c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-13c504e9-a3bd-4761-aa19-68b80e0bff01,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-c40dec4d-f99b-4d63-a745-1df3993ff2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-c5155d1b-b433-4310-994a-b7ecd679b653,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-df789a80-a169-41fe-8932-515e4d4620c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-8f272055-cb4c-44c6-86b9-b277e051bb88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395616407-172.17.0.12-1595483896897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36740,DS-0aaf9003-36ca-4031-a031-0f4a3b488015,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-7c5f60d0-f647-4a7d-898f-889e096b7ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-9fefa576-1c40-4d57-8789-dea47d404923,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-c1583f53-cf14-43cf-b260-3691b889c859,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-86dc1993-46f8-4c6f-b95a-ef386c4d6810,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-7cf2c2cd-2232-420e-b2ae-aafecc49e5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-8b95e02b-8410-4077-865c-85d435a20b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-a4f6295b-2b7c-4d05-bc8c-2d1024058595,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395616407-172.17.0.12-1595483896897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36740,DS-0aaf9003-36ca-4031-a031-0f4a3b488015,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-7c5f60d0-f647-4a7d-898f-889e096b7ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-9fefa576-1c40-4d57-8789-dea47d404923,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-c1583f53-cf14-43cf-b260-3691b889c859,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-86dc1993-46f8-4c6f-b95a-ef386c4d6810,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-7cf2c2cd-2232-420e-b2ae-aafecc49e5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-8b95e02b-8410-4077-865c-85d435a20b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-a4f6295b-2b7c-4d05-bc8c-2d1024058595,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103350983-172.17.0.12-1595484873329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38694,DS-071f91a2-5483-482c-a76c-40e441063f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-07710dac-73ea-43a2-b8d2-79ea78a06a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-f5325f45-d421-4333-9dce-5bcc95295937,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-200e75ce-2747-480a-8853-c01fb6edcea5,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-b14abd3e-4ef0-4eee-82d7-953a28a7380a,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-de3b07be-f4c1-4b60-a62a-9591769f0252,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-a87f7d44-fc99-4565-91ac-f6a742555ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-61416abc-717d-447a-9af9-dbd4421280bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103350983-172.17.0.12-1595484873329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38694,DS-071f91a2-5483-482c-a76c-40e441063f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-07710dac-73ea-43a2-b8d2-79ea78a06a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-f5325f45-d421-4333-9dce-5bcc95295937,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-200e75ce-2747-480a-8853-c01fb6edcea5,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-b14abd3e-4ef0-4eee-82d7-953a28a7380a,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-de3b07be-f4c1-4b60-a62a-9591769f0252,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-a87f7d44-fc99-4565-91ac-f6a742555ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-61416abc-717d-447a-9af9-dbd4421280bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39806890-172.17.0.12-1595485201263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45307,DS-8006617e-c2a4-4600-8066-c49b079ef4de,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-3789beab-5b0a-42a7-a4c2-2ee26fc71f03,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-71664c4f-ce68-4583-8e21-5ad83e7ffb54,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-4977196d-6760-416e-b2ca-445fc8f4935f,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-a0e5839e-bd65-408c-86d9-6a118a1b565d,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-4ec30ff3-58cc-495e-a4c7-0269530b9b48,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-f8ab2d0b-1b29-4a20-a0a1-e605b1a342bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-895b2ac6-0b11-4145-8ac8-3b3be77f0980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39806890-172.17.0.12-1595485201263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45307,DS-8006617e-c2a4-4600-8066-c49b079ef4de,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-3789beab-5b0a-42a7-a4c2-2ee26fc71f03,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-71664c4f-ce68-4583-8e21-5ad83e7ffb54,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-4977196d-6760-416e-b2ca-445fc8f4935f,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-a0e5839e-bd65-408c-86d9-6a118a1b565d,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-4ec30ff3-58cc-495e-a4c7-0269530b9b48,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-f8ab2d0b-1b29-4a20-a0a1-e605b1a342bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-895b2ac6-0b11-4145-8ac8-3b3be77f0980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1125799085-172.17.0.12-1595485643576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34167,DS-084f3711-b4bf-46b6-9bdc-e39dcadf9e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-ccead397-d8f3-48f2-80f0-75188fcca175,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-3e267ac7-cb37-4e7a-b2d5-4eaf55e2e52b,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-da4646ae-00ce-4ae5-b45e-f94ec416fcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-32541de7-9514-408d-9ae7-589c19564307,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-0f4f2b7d-3f45-480a-a8c7-5db3a5d8c7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-2a0b37f1-5cb6-4f12-ad8a-cffb43c0fb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-aee117eb-900e-41b8-ba55-df41b891d4aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1125799085-172.17.0.12-1595485643576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34167,DS-084f3711-b4bf-46b6-9bdc-e39dcadf9e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-ccead397-d8f3-48f2-80f0-75188fcca175,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-3e267ac7-cb37-4e7a-b2d5-4eaf55e2e52b,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-da4646ae-00ce-4ae5-b45e-f94ec416fcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-32541de7-9514-408d-9ae7-589c19564307,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-0f4f2b7d-3f45-480a-a8c7-5db3a5d8c7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-2a0b37f1-5cb6-4f12-ad8a-cffb43c0fb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-aee117eb-900e-41b8-ba55-df41b891d4aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892074510-172.17.0.12-1595485782953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33177,DS-fcd6e642-ea0b-43e6-a14c-1dbe466caec5,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-7b319e26-d35f-4517-bb2e-2188d344c82d,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-6ddb3003-9a0f-4b28-bc59-8a581acfc9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-46ea4029-182f-46d1-8b69-7e80527f42b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-e67f3472-d553-4450-bf95-3be4b364221a,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-cab5334c-82ea-426e-b555-a10424f8a113,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-ae7779ee-e23f-4372-a81c-ef5f42f176c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-f9a4f108-c1a3-42d5-be8f-8c3861a265b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892074510-172.17.0.12-1595485782953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33177,DS-fcd6e642-ea0b-43e6-a14c-1dbe466caec5,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-7b319e26-d35f-4517-bb2e-2188d344c82d,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-6ddb3003-9a0f-4b28-bc59-8a581acfc9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-46ea4029-182f-46d1-8b69-7e80527f42b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-e67f3472-d553-4450-bf95-3be4b364221a,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-cab5334c-82ea-426e-b555-a10424f8a113,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-ae7779ee-e23f-4372-a81c-ef5f42f176c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-f9a4f108-c1a3-42d5-be8f-8c3861a265b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-372112488-172.17.0.12-1595485822582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33798,DS-fc9f024a-827d-45d4-8578-fcc52a03d389,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-f3055449-4071-4384-ac41-300886a56bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-294302f2-e0fa-4049-a460-ece364f642b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-9f7699f0-6d92-4fbb-88cc-7cdb14915e75,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-7fa4e750-f152-41c3-a9c7-fa76739b6b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-47c84f34-0c6a-4dad-b157-e11fb01b8887,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-99d5d614-72d1-411d-a93e-a84d36613c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-92488257-89be-466d-be0a-b6f11024cdb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-372112488-172.17.0.12-1595485822582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33798,DS-fc9f024a-827d-45d4-8578-fcc52a03d389,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-f3055449-4071-4384-ac41-300886a56bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-294302f2-e0fa-4049-a460-ece364f642b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-9f7699f0-6d92-4fbb-88cc-7cdb14915e75,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-7fa4e750-f152-41c3-a9c7-fa76739b6b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-47c84f34-0c6a-4dad-b157-e11fb01b8887,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-99d5d614-72d1-411d-a93e-a84d36613c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-92488257-89be-466d-be0a-b6f11024cdb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1558244132-172.17.0.12-1595485913934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34062,DS-e581fc67-b7c8-4a76-a789-d77da7f88870,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-4d7c48fb-b0e0-4a3d-aa86-1d85466eff6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-a24a72c2-97a0-489e-8a41-04beb7b558a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-df6b259a-dfb7-45d9-85ea-c302a6aa96d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-c506b5f2-22cc-4d1f-9cc7-2acfd40ad539,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-040696d8-75f5-4688-8ea2-71303b9fb9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-e54b6af0-cb33-43ff-b499-8e5a3fd801ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37862,DS-f26d0bfb-7963-4244-8481-6a6aee6052f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1558244132-172.17.0.12-1595485913934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34062,DS-e581fc67-b7c8-4a76-a789-d77da7f88870,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-4d7c48fb-b0e0-4a3d-aa86-1d85466eff6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-a24a72c2-97a0-489e-8a41-04beb7b558a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-df6b259a-dfb7-45d9-85ea-c302a6aa96d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-c506b5f2-22cc-4d1f-9cc7-2acfd40ad539,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-040696d8-75f5-4688-8ea2-71303b9fb9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-e54b6af0-cb33-43ff-b499-8e5a3fd801ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37862,DS-f26d0bfb-7963-4244-8481-6a6aee6052f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781319312-172.17.0.12-1595486476175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39230,DS-9b768725-c171-48b2-afef-d877c83c9461,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-0568a2c8-9af0-4673-9d81-b8288691753a,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-3d661465-3790-4ac2-bfc4-96cd0193413f,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-6ff22ca0-65df-4131-8145-24509da3776c,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-cd2a8ae1-b2d0-4528-a6eb-2ad011bb91a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-dbf898cf-1e1b-453e-bf2b-a1f59ae3a0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-48f440f9-94dd-487b-9594-c6dadff27d91,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-c6e34851-d818-43c7-8b54-7cb3a20fa979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781319312-172.17.0.12-1595486476175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39230,DS-9b768725-c171-48b2-afef-d877c83c9461,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-0568a2c8-9af0-4673-9d81-b8288691753a,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-3d661465-3790-4ac2-bfc4-96cd0193413f,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-6ff22ca0-65df-4131-8145-24509da3776c,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-cd2a8ae1-b2d0-4528-a6eb-2ad011bb91a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-dbf898cf-1e1b-453e-bf2b-a1f59ae3a0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-48f440f9-94dd-487b-9594-c6dadff27d91,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-c6e34851-d818-43c7-8b54-7cb3a20fa979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-824603845-172.17.0.12-1595486697201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34649,DS-fc1e59b5-7b0f-4f3a-8e2b-5e7e72cc1557,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-63695692-edc2-48e8-b2c6-ad2717dd7f36,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-c466d009-723c-4e1b-9cdb-e69ab625495f,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-d31bbf76-575c-4907-bbd0-4d38dfb9f3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-6b0227ad-f9e7-4390-a626-55136933e178,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-2f8a483c-2a78-48ad-b38a-124aaaa78e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-7d13f96f-3935-4701-bc01-7f505abfd16c,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-774b953d-17ec-4757-9e96-34711fb0b416,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-824603845-172.17.0.12-1595486697201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34649,DS-fc1e59b5-7b0f-4f3a-8e2b-5e7e72cc1557,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-63695692-edc2-48e8-b2c6-ad2717dd7f36,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-c466d009-723c-4e1b-9cdb-e69ab625495f,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-d31bbf76-575c-4907-bbd0-4d38dfb9f3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-6b0227ad-f9e7-4390-a626-55136933e178,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-2f8a483c-2a78-48ad-b38a-124aaaa78e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-7d13f96f-3935-4701-bc01-7f505abfd16c,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-774b953d-17ec-4757-9e96-34711fb0b416,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6717
