reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-191492111-172.17.0.3-1595562977709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33112,DS-8f837334-9dd1-4fa2-8bf4-08dcd8aa7840,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-1ba8ffbc-c1f7-46e2-9e04-f78d4459b3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-75559999-1018-426c-83d7-65dfe6791282,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-16e498eb-d01b-4390-add3-26dedd023623,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-3b274413-5f31-47c6-b27b-ee8c8f4f9bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-136ea237-53fa-45e6-a313-c02fa9b039be,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-122f2437-afec-4793-88d6-ff5b8b97b47f,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-d8a54ef5-6d3d-4d60-897e-b0783ca3fc8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-191492111-172.17.0.3-1595562977709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33112,DS-8f837334-9dd1-4fa2-8bf4-08dcd8aa7840,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-1ba8ffbc-c1f7-46e2-9e04-f78d4459b3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-75559999-1018-426c-83d7-65dfe6791282,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-16e498eb-d01b-4390-add3-26dedd023623,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-3b274413-5f31-47c6-b27b-ee8c8f4f9bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-136ea237-53fa-45e6-a313-c02fa9b039be,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-122f2437-afec-4793-88d6-ff5b8b97b47f,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-d8a54ef5-6d3d-4d60-897e-b0783ca3fc8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1770448719-172.17.0.3-1595563200381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33752,DS-f3659dee-530a-4865-a87d-447d0836f340,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-5019de43-1777-45f3-91db-f7f458b6560c,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-8417b952-34b5-4363-ba22-5c831419ef49,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-1c3668c9-a881-4f43-9a1d-29e9542989c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-53b3296e-1f58-426c-a4e0-030e02fd93bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-c5915924-7eb8-43c0-a3f2-84ac09dad8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-1dd3fe0f-f420-4d4d-affb-bb2b3cfed17b,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-73e46b8b-185f-4f4a-8866-a418f661237b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1770448719-172.17.0.3-1595563200381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33752,DS-f3659dee-530a-4865-a87d-447d0836f340,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-5019de43-1777-45f3-91db-f7f458b6560c,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-8417b952-34b5-4363-ba22-5c831419ef49,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-1c3668c9-a881-4f43-9a1d-29e9542989c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-53b3296e-1f58-426c-a4e0-030e02fd93bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-c5915924-7eb8-43c0-a3f2-84ac09dad8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-1dd3fe0f-f420-4d4d-affb-bb2b3cfed17b,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-73e46b8b-185f-4f4a-8866-a418f661237b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-602024314-172.17.0.3-1595563474562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42796,DS-fb970ba8-4954-49a0-8f77-3d9ef7babaee,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-32ef2693-4a4a-403c-acfc-6552bee645ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-60d9109e-fdde-4ac0-8124-44bd26ae4454,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-600a650b-5461-4e55-a049-33697249d700,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-13a69347-0f90-4d97-b85d-8678eb404fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-69b30899-bc02-4623-a9d3-95f83dbe268f,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-ed1f5e41-cf6b-42df-a63a-a64f88b632f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-89271411-faae-4b80-96b5-b7a375ac4f90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-602024314-172.17.0.3-1595563474562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42796,DS-fb970ba8-4954-49a0-8f77-3d9ef7babaee,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-32ef2693-4a4a-403c-acfc-6552bee645ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-60d9109e-fdde-4ac0-8124-44bd26ae4454,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-600a650b-5461-4e55-a049-33697249d700,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-13a69347-0f90-4d97-b85d-8678eb404fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-69b30899-bc02-4623-a9d3-95f83dbe268f,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-ed1f5e41-cf6b-42df-a63a-a64f88b632f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-89271411-faae-4b80-96b5-b7a375ac4f90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2135145843-172.17.0.3-1595563534865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37507,DS-1a3c9dca-e249-4877-a635-8ec343014537,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-4f3e913e-cbba-4fc5-9873-c9ca02e0c4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-64a9a382-5ee4-4654-af50-ccc387c56a96,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-41abc2c7-257d-4e21-b996-7f3efab2a8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-e353b4d0-0207-475a-99d2-9571ed893cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-d0e50063-00ad-43b0-8a1e-e170640058af,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-0e2ce09a-e657-4b08-ab25-60f46b295166,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-72ceefef-5487-4869-8f84-9fde6edcbf98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2135145843-172.17.0.3-1595563534865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37507,DS-1a3c9dca-e249-4877-a635-8ec343014537,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-4f3e913e-cbba-4fc5-9873-c9ca02e0c4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-64a9a382-5ee4-4654-af50-ccc387c56a96,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-41abc2c7-257d-4e21-b996-7f3efab2a8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-e353b4d0-0207-475a-99d2-9571ed893cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-d0e50063-00ad-43b0-8a1e-e170640058af,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-0e2ce09a-e657-4b08-ab25-60f46b295166,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-72ceefef-5487-4869-8f84-9fde6edcbf98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-718910201-172.17.0.3-1595563601110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41254,DS-404480d7-7b48-4d8e-9e68-0fbecec14039,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-50ddeb5f-d108-448b-b61c-30dd4b50209c,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-14a44e11-f865-483f-89a4-c1e7f86b53f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-69d93b76-4f29-487f-9724-36de4630905c,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-909d391b-23d6-451a-92d7-9bf72080d2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-34452ea4-2414-4254-bfe8-d5f538c4f639,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-ed4d3ad8-f516-4370-b4db-c892ae81a410,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-7beeef1e-9ede-4868-8379-8b85aa514a96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-718910201-172.17.0.3-1595563601110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41254,DS-404480d7-7b48-4d8e-9e68-0fbecec14039,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-50ddeb5f-d108-448b-b61c-30dd4b50209c,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-14a44e11-f865-483f-89a4-c1e7f86b53f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-69d93b76-4f29-487f-9724-36de4630905c,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-909d391b-23d6-451a-92d7-9bf72080d2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-34452ea4-2414-4254-bfe8-d5f538c4f639,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-ed4d3ad8-f516-4370-b4db-c892ae81a410,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-7beeef1e-9ede-4868-8379-8b85aa514a96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1082356765-172.17.0.3-1595563635866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34565,DS-09eefeee-5495-496f-95b3-3f8179a787ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-d7c1fc06-899a-4885-9a75-2f8118fbf9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-12084e8c-6df3-49ad-808b-67ecf5174f74,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-8c4bdb69-a600-49b6-a3d6-b7bc28dc0e09,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-cc725475-90c7-43a0-b62f-b6eae315a02b,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-68387c41-226a-4525-89a8-3f744a7c3718,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-f81744b6-ceee-4aa1-974d-e43fed13c165,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-df3f7278-210d-473e-9804-e14a94accc23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1082356765-172.17.0.3-1595563635866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34565,DS-09eefeee-5495-496f-95b3-3f8179a787ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-d7c1fc06-899a-4885-9a75-2f8118fbf9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-12084e8c-6df3-49ad-808b-67ecf5174f74,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-8c4bdb69-a600-49b6-a3d6-b7bc28dc0e09,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-cc725475-90c7-43a0-b62f-b6eae315a02b,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-68387c41-226a-4525-89a8-3f744a7c3718,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-f81744b6-ceee-4aa1-974d-e43fed13c165,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-df3f7278-210d-473e-9804-e14a94accc23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1061236326-172.17.0.3-1595563787781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39918,DS-91c97973-ac5f-48aa-b4c6-57c77cb8cd31,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-9df21377-0dd8-4cf7-818e-ca50acc87206,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-6fcc9661-4ec2-4ddb-9e0d-791500d7af08,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-5dbd5588-dd0b-4679-bbfc-8b6f0e250e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-b6af8a8f-26a2-4946-a0a6-7201dc0ad826,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-56080912-44ac-48ee-a912-4da275c633b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-8787f105-56db-48a7-8a93-fe6647d546f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-e5f705b2-f56f-42da-8ed1-cb9a007ba582,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1061236326-172.17.0.3-1595563787781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39918,DS-91c97973-ac5f-48aa-b4c6-57c77cb8cd31,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-9df21377-0dd8-4cf7-818e-ca50acc87206,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-6fcc9661-4ec2-4ddb-9e0d-791500d7af08,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-5dbd5588-dd0b-4679-bbfc-8b6f0e250e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-b6af8a8f-26a2-4946-a0a6-7201dc0ad826,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-56080912-44ac-48ee-a912-4da275c633b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-8787f105-56db-48a7-8a93-fe6647d546f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-e5f705b2-f56f-42da-8ed1-cb9a007ba582,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1573762914-172.17.0.3-1595563882157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38836,DS-3cdcb0b6-d8c8-4553-9eb2-0c1df884dd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-be63ad13-df60-4151-970f-3f12e773b1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-67580091-656c-4a66-8f34-732337edccfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-1c8c650d-c64b-4417-8355-6f11de4e5734,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-162e51f2-f27e-4b03-921a-42dfcf3a77f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-abecac44-1deb-4f54-96d4-cdd4215a4439,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-f0cf329e-a88b-4908-a62c-85b10c188d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-b7964e13-0358-40ff-b739-3fe4bac6d077,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1573762914-172.17.0.3-1595563882157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38836,DS-3cdcb0b6-d8c8-4553-9eb2-0c1df884dd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-be63ad13-df60-4151-970f-3f12e773b1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-67580091-656c-4a66-8f34-732337edccfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-1c8c650d-c64b-4417-8355-6f11de4e5734,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-162e51f2-f27e-4b03-921a-42dfcf3a77f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-abecac44-1deb-4f54-96d4-cdd4215a4439,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-f0cf329e-a88b-4908-a62c-85b10c188d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-b7964e13-0358-40ff-b739-3fe4bac6d077,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-873500367-172.17.0.3-1595564443172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41327,DS-58b36af2-dadd-431a-aa9f-640493b3a4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-a84f37ab-42d2-458b-9eb4-44be893e9b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-0093e70e-9d04-4e26-905d-3ee4f4a3a25a,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-c1304beb-74b2-4143-b9c1-d210ef0e4084,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-95af7db2-7b33-4714-b4dc-a914702f204d,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-6b947ab2-87b2-4a3b-bded-d0bf609d2af2,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-98c6ac96-30e4-44c8-a246-3d0ab8c8fa27,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-9ac00775-c043-481a-9a8a-eb26e02d7366,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-873500367-172.17.0.3-1595564443172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41327,DS-58b36af2-dadd-431a-aa9f-640493b3a4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-a84f37ab-42d2-458b-9eb4-44be893e9b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-0093e70e-9d04-4e26-905d-3ee4f4a3a25a,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-c1304beb-74b2-4143-b9c1-d210ef0e4084,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-95af7db2-7b33-4714-b4dc-a914702f204d,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-6b947ab2-87b2-4a3b-bded-d0bf609d2af2,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-98c6ac96-30e4-44c8-a246-3d0ab8c8fa27,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-9ac00775-c043-481a-9a8a-eb26e02d7366,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365719992-172.17.0.3-1595564602790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37228,DS-f10afeb1-c28b-4aa0-9bc2-6aa596730650,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-fd9f53d0-841f-40f4-aae9-2ef6a15ffbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-b428bd73-6bc7-40c7-a990-da79b4af6a29,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-115d23b4-cb03-4aa8-8758-bba7b405018b,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-a9c37c8c-d00a-4144-8b9a-a991dc1b84a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-9746731e-e36a-4516-8717-6461083306cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-d2dd8a03-f8c0-4b8e-80b1-54682c1e2853,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-1f06c093-1af0-4a1c-9291-725a740a929d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365719992-172.17.0.3-1595564602790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37228,DS-f10afeb1-c28b-4aa0-9bc2-6aa596730650,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-fd9f53d0-841f-40f4-aae9-2ef6a15ffbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-b428bd73-6bc7-40c7-a990-da79b4af6a29,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-115d23b4-cb03-4aa8-8758-bba7b405018b,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-a9c37c8c-d00a-4144-8b9a-a991dc1b84a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-9746731e-e36a-4516-8717-6461083306cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-d2dd8a03-f8c0-4b8e-80b1-54682c1e2853,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-1f06c093-1af0-4a1c-9291-725a740a929d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1922391416-172.17.0.3-1595564936792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43256,DS-f96c2de7-c373-44ed-9343-53f3c42b8395,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-15b124fb-afce-435e-a0d2-eda631e702e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-f4f82e58-7be3-49f7-8f4f-a4ac16b2a845,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-7e51cccf-d583-4213-a2a3-e60bb8d564d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-56af8244-0f67-4fb1-bbde-a288bb073f68,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-609a87c9-ac16-407f-8984-b0b13e44ce1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-120429ca-7426-44f1-ac28-ecdb3215d660,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-09a15939-308f-4f7e-b149-28c2deb45d7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1922391416-172.17.0.3-1595564936792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43256,DS-f96c2de7-c373-44ed-9343-53f3c42b8395,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-15b124fb-afce-435e-a0d2-eda631e702e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-f4f82e58-7be3-49f7-8f4f-a4ac16b2a845,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-7e51cccf-d583-4213-a2a3-e60bb8d564d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-56af8244-0f67-4fb1-bbde-a288bb073f68,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-609a87c9-ac16-407f-8984-b0b13e44ce1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-120429ca-7426-44f1-ac28-ecdb3215d660,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-09a15939-308f-4f7e-b149-28c2deb45d7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2020589786-172.17.0.3-1595564968200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34648,DS-6b4bb31d-f8ed-4823-a0bd-aa171ec89c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-1c7d090a-7301-4afe-9b16-4aba254b1353,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-0b270728-87ef-4693-843d-5acbac52ca2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-42c2cff8-cad5-4551-90c3-4f9667e2e973,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-03a16731-1717-4452-8381-a5cf34d42ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-dddb1f16-85ae-4937-a7fb-41488efa3a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-8abc2dd3-5e13-4df8-8ce5-28a9a1bc6dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46100,DS-a6ec2c62-585e-4c86-8289-8da2ae590e69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2020589786-172.17.0.3-1595564968200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34648,DS-6b4bb31d-f8ed-4823-a0bd-aa171ec89c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-1c7d090a-7301-4afe-9b16-4aba254b1353,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-0b270728-87ef-4693-843d-5acbac52ca2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-42c2cff8-cad5-4551-90c3-4f9667e2e973,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-03a16731-1717-4452-8381-a5cf34d42ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-dddb1f16-85ae-4937-a7fb-41488efa3a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-8abc2dd3-5e13-4df8-8ce5-28a9a1bc6dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46100,DS-a6ec2c62-585e-4c86-8289-8da2ae590e69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-873121105-172.17.0.3-1595565099604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42259,DS-bc0cf93e-2d87-424c-8749-9c7a578f8d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-2b695ad6-52a4-4af0-a8a3-489026357474,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-53e2236c-e6b1-447c-a942-341b5ea1a12a,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-8797328f-727e-415d-b432-590378e83dff,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-9775c2aa-0340-4737-874f-e3bff4923803,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-954c527f-5518-459a-a97e-0d2c8cc907e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-f81ce560-ca8f-4b65-9dc5-3c293094205b,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-d7ce5905-beb5-4af9-af7d-f6f882227b58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-873121105-172.17.0.3-1595565099604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42259,DS-bc0cf93e-2d87-424c-8749-9c7a578f8d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-2b695ad6-52a4-4af0-a8a3-489026357474,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-53e2236c-e6b1-447c-a942-341b5ea1a12a,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-8797328f-727e-415d-b432-590378e83dff,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-9775c2aa-0340-4737-874f-e3bff4923803,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-954c527f-5518-459a-a97e-0d2c8cc907e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-f81ce560-ca8f-4b65-9dc5-3c293094205b,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-d7ce5905-beb5-4af9-af7d-f6f882227b58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1020257719-172.17.0.3-1595565130838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42796,DS-bbff776b-212d-4e30-b57f-0ced5ca1b33f,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-e3c6a4ce-4ffe-42b7-895c-f30ad507a861,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-cc50e373-2e8c-4520-a293-04a52a207ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-f969f5f4-d82c-42e3-bfdd-ecc789c9e74c,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-8e3f08b1-b3c0-49a0-bf06-3e317dd20e20,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-ef609a8d-ec4d-4b7d-be70-05c4d3b26ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-29072d2e-803e-41ad-9a11-02809b46cc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-5ac0cdb5-28d2-4e92-8e38-37671049efdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1020257719-172.17.0.3-1595565130838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42796,DS-bbff776b-212d-4e30-b57f-0ced5ca1b33f,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-e3c6a4ce-4ffe-42b7-895c-f30ad507a861,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-cc50e373-2e8c-4520-a293-04a52a207ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-f969f5f4-d82c-42e3-bfdd-ecc789c9e74c,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-8e3f08b1-b3c0-49a0-bf06-3e317dd20e20,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-ef609a8d-ec4d-4b7d-be70-05c4d3b26ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-29072d2e-803e-41ad-9a11-02809b46cc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-5ac0cdb5-28d2-4e92-8e38-37671049efdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-419067498-172.17.0.3-1595565196027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41133,DS-45b0e3c0-1a88-40b0-8ab5-5cd7cb5e6549,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-d2a85d98-68b6-42bc-9e92-1b7bf17d7295,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-50c94599-e6ea-406a-ba37-9a77e5318fea,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-5c9f8ace-8beb-41ba-9b6c-2a453e31e65c,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-9f214969-bdee-4325-9cba-e817ebb218cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-441d6aa7-5d1d-4e97-97e1-7fdd18828398,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-19ae0407-6dd7-4671-9f74-a12ecaa73d93,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-a0277a7d-d1aa-4b32-92df-130bc59294b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-419067498-172.17.0.3-1595565196027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41133,DS-45b0e3c0-1a88-40b0-8ab5-5cd7cb5e6549,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-d2a85d98-68b6-42bc-9e92-1b7bf17d7295,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-50c94599-e6ea-406a-ba37-9a77e5318fea,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-5c9f8ace-8beb-41ba-9b6c-2a453e31e65c,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-9f214969-bdee-4325-9cba-e817ebb218cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-441d6aa7-5d1d-4e97-97e1-7fdd18828398,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-19ae0407-6dd7-4671-9f74-a12ecaa73d93,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-a0277a7d-d1aa-4b32-92df-130bc59294b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-839699773-172.17.0.3-1595565600174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43206,DS-46f811ef-4be2-4c7e-8f1d-8636cb7ca615,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-2c6282c5-6378-452f-85d4-3bac70b78736,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-62b73ae7-4716-4f56-9a6d-3503e1f43592,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-39af4c23-93b7-49c6-a94a-cc319a398c88,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-6bd5bc10-5753-4640-b0d2-eaf70daddd29,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-026a80fa-63cb-4d5e-8e2a-04baffbfebc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-ed629237-90f5-439e-93a9-388070d50bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-b8d6f88c-7fa5-4501-b9d0-b39aaf296f58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-839699773-172.17.0.3-1595565600174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43206,DS-46f811ef-4be2-4c7e-8f1d-8636cb7ca615,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-2c6282c5-6378-452f-85d4-3bac70b78736,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-62b73ae7-4716-4f56-9a6d-3503e1f43592,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-39af4c23-93b7-49c6-a94a-cc319a398c88,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-6bd5bc10-5753-4640-b0d2-eaf70daddd29,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-026a80fa-63cb-4d5e-8e2a-04baffbfebc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-ed629237-90f5-439e-93a9-388070d50bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-b8d6f88c-7fa5-4501-b9d0-b39aaf296f58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1991886925-172.17.0.3-1595565637889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36119,DS-c9c7b54c-80e0-41f2-b016-05f53f573e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-9bdd23ec-c40b-4e00-989f-af31c75a9faa,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-9917dfce-b427-4215-a40d-d0e698f3a510,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-15fa0fe5-2767-402b-b5e8-2d03efbe5c96,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-8dc96bf2-dfee-4377-9da9-d9fe65eeb67a,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-36f35063-21ad-4d97-aa05-8d59d6ff7904,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-119bde72-e213-42f4-a5a6-b94554671f74,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-4bc92a67-78f2-4a90-8b55-59b994e97e8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1991886925-172.17.0.3-1595565637889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36119,DS-c9c7b54c-80e0-41f2-b016-05f53f573e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-9bdd23ec-c40b-4e00-989f-af31c75a9faa,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-9917dfce-b427-4215-a40d-d0e698f3a510,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-15fa0fe5-2767-402b-b5e8-2d03efbe5c96,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-8dc96bf2-dfee-4377-9da9-d9fe65eeb67a,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-36f35063-21ad-4d97-aa05-8d59d6ff7904,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-119bde72-e213-42f4-a5a6-b94554671f74,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-4bc92a67-78f2-4a90-8b55-59b994e97e8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1658539977-172.17.0.3-1595566044362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35283,DS-0395eec6-8fb5-4719-8525-b4525f4fadce,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-6a2fba4b-4868-4652-bebd-172d0e43e663,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-645491d1-e0ee-45d1-a31b-3494aa6b13af,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-c504ee49-d8ce-44f1-b490-a80ee80379bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-cea4fbfc-2a7f-4a97-bd8b-ffe441dc4ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-cecc82d3-b1fb-4ee3-8f3b-b1312d6b144f,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-0416009f-d99f-4215-9a58-496a809e058b,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-6f23fb01-34bb-4dcc-ab9e-1a1d08514d54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1658539977-172.17.0.3-1595566044362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35283,DS-0395eec6-8fb5-4719-8525-b4525f4fadce,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-6a2fba4b-4868-4652-bebd-172d0e43e663,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-645491d1-e0ee-45d1-a31b-3494aa6b13af,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-c504ee49-d8ce-44f1-b490-a80ee80379bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-cea4fbfc-2a7f-4a97-bd8b-ffe441dc4ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-cecc82d3-b1fb-4ee3-8f3b-b1312d6b144f,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-0416009f-d99f-4215-9a58-496a809e058b,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-6f23fb01-34bb-4dcc-ab9e-1a1d08514d54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-632340652-172.17.0.3-1595566737015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45506,DS-688ab954-2663-4f52-b2aa-f7c857ea28d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-5e8d60c1-27e7-44b8-ad3a-16105cfc670d,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-3ee689b5-354b-41c0-880c-ff4b1fa93ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-7b007690-6c3c-4abb-922e-2a1f4c88cbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-dd4da706-6ddf-46ad-974d-1b65597a1065,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-e7c21620-cb19-48b1-9993-b27fe84ab130,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-8343c643-aaf9-464e-a2a5-ea9e140fe093,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-04396d88-06c2-418a-8863-270b69c9e885,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-632340652-172.17.0.3-1595566737015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45506,DS-688ab954-2663-4f52-b2aa-f7c857ea28d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-5e8d60c1-27e7-44b8-ad3a-16105cfc670d,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-3ee689b5-354b-41c0-880c-ff4b1fa93ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-7b007690-6c3c-4abb-922e-2a1f4c88cbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-dd4da706-6ddf-46ad-974d-1b65597a1065,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-e7c21620-cb19-48b1-9993-b27fe84ab130,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-8343c643-aaf9-464e-a2a5-ea9e140fe093,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-04396d88-06c2-418a-8863-270b69c9e885,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-351466240-172.17.0.3-1595567014227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34045,DS-cbb45073-859d-4509-b178-b10e7948b856,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-8d1b02c6-e570-4d0b-8e2a-39624599029d,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-01d7442d-492c-4b9d-bf73-08ea3b283b84,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-99cb61fe-2e54-4823-a0a5-08fbd083956d,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-481763dd-90ba-4cbf-8fa3-4c6019b0369f,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-47ef259e-5e03-41c9-885b-0bcc59854e46,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-3c3a5a6c-9504-4bad-a47c-0d150686298c,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-a18562a6-d4ff-4760-b6d7-0c8e0b2fc5c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-351466240-172.17.0.3-1595567014227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34045,DS-cbb45073-859d-4509-b178-b10e7948b856,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-8d1b02c6-e570-4d0b-8e2a-39624599029d,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-01d7442d-492c-4b9d-bf73-08ea3b283b84,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-99cb61fe-2e54-4823-a0a5-08fbd083956d,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-481763dd-90ba-4cbf-8fa3-4c6019b0369f,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-47ef259e-5e03-41c9-885b-0bcc59854e46,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-3c3a5a6c-9504-4bad-a47c-0d150686298c,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-a18562a6-d4ff-4760-b6d7-0c8e0b2fc5c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239822938-172.17.0.3-1595567113307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36156,DS-d1a1843a-ba3f-4d71-afbe-12be0e6ee885,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-3f1ef51d-cb54-4eb2-a412-cbb069836018,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-811cab09-6edc-42cf-a89d-2750d4fb7fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-1de1cf65-7a08-4e5d-805f-a0d590bb2764,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-f4bc9a50-d0e8-4070-84f4-a838725ea96c,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-11ac508c-8873-4734-8410-502d3184e482,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-3f53db90-faef-410a-bdda-c2926bcbf3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-99139ed4-77e5-4f7d-ae83-cbef6d29ec54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239822938-172.17.0.3-1595567113307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36156,DS-d1a1843a-ba3f-4d71-afbe-12be0e6ee885,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-3f1ef51d-cb54-4eb2-a412-cbb069836018,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-811cab09-6edc-42cf-a89d-2750d4fb7fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-1de1cf65-7a08-4e5d-805f-a0d590bb2764,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-f4bc9a50-d0e8-4070-84f4-a838725ea96c,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-11ac508c-8873-4734-8410-502d3184e482,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-3f53db90-faef-410a-bdda-c2926bcbf3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-99139ed4-77e5-4f7d-ae83-cbef6d29ec54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 4700
