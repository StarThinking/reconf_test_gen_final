reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621639969-172.17.0.18-1595481358842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42536,DS-da108382-2eaa-4b33-b5da-535706bf16ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-fd8da992-4f48-44b5-a729-3e61be18e9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-9a3147e8-af69-4208-96d7-e2e7811bddca,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-ef9cbe91-d1c9-4ef9-9f2d-70caabaa6ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-85bf5869-73a6-4d32-869e-3dd2f4bbabd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-00fcda00-be7d-4ac7-83d5-df863ef849d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-c4941b7f-7fce-4b08-bb17-75cfaf4c2c47,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-802ae92a-21e6-4898-9b72-cd98524d31c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621639969-172.17.0.18-1595481358842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42536,DS-da108382-2eaa-4b33-b5da-535706bf16ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-fd8da992-4f48-44b5-a729-3e61be18e9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-9a3147e8-af69-4208-96d7-e2e7811bddca,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-ef9cbe91-d1c9-4ef9-9f2d-70caabaa6ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-85bf5869-73a6-4d32-869e-3dd2f4bbabd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-00fcda00-be7d-4ac7-83d5-df863ef849d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-c4941b7f-7fce-4b08-bb17-75cfaf4c2c47,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-802ae92a-21e6-4898-9b72-cd98524d31c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1124883460-172.17.0.18-1595482067013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34535,DS-6b5ec944-7758-4f5f-b9cb-898b95f819b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-dc14725f-61ba-48e8-bf29-8f1c73040c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-ab8dd4c4-3551-4284-9424-7d95c6fdb426,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-213434fb-3759-4327-95f6-956ab673c6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-a25ee5d9-7723-4530-b18b-bffa5120c114,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-276f3b8d-8ba5-4fb2-a790-dd29db2b97b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-ebbffec9-aedc-4120-bd9a-e79cd060df39,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-556c8869-fe37-46ed-b500-f3c0f01273d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1124883460-172.17.0.18-1595482067013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34535,DS-6b5ec944-7758-4f5f-b9cb-898b95f819b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-dc14725f-61ba-48e8-bf29-8f1c73040c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-ab8dd4c4-3551-4284-9424-7d95c6fdb426,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-213434fb-3759-4327-95f6-956ab673c6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-a25ee5d9-7723-4530-b18b-bffa5120c114,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-276f3b8d-8ba5-4fb2-a790-dd29db2b97b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-ebbffec9-aedc-4120-bd9a-e79cd060df39,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-556c8869-fe37-46ed-b500-f3c0f01273d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352352411-172.17.0.18-1595482097709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46474,DS-4e0cf3e7-6f0c-465f-926d-dc4efd6b7782,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-580c4efa-e3e7-4463-aad7-da4c0d0ae938,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-9be032e8-3fcd-44f7-bbab-d7ed6ad72cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-10e738d6-ece5-4f02-b7b1-1549e09523af,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-b8015bf7-5615-40ba-a269-667b514533ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-278585fd-d715-436d-90b7-3172184b22ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-4f90eda3-0d4a-45ac-a8da-06464237673a,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-1fac6330-1d43-4c61-a1b9-da651c004332,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352352411-172.17.0.18-1595482097709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46474,DS-4e0cf3e7-6f0c-465f-926d-dc4efd6b7782,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-580c4efa-e3e7-4463-aad7-da4c0d0ae938,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-9be032e8-3fcd-44f7-bbab-d7ed6ad72cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-10e738d6-ece5-4f02-b7b1-1549e09523af,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-b8015bf7-5615-40ba-a269-667b514533ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-278585fd-d715-436d-90b7-3172184b22ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-4f90eda3-0d4a-45ac-a8da-06464237673a,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-1fac6330-1d43-4c61-a1b9-da651c004332,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-211413541-172.17.0.18-1595482175222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33466,DS-c74d3192-fb9b-44b0-b4a5-c0fdd8d7cfbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-bd4dd3b9-086d-4021-9867-eafa2283b204,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-710349bd-61ac-4b33-a3e0-60a45b3a5ece,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-6e0d9ef6-fb93-49e6-882e-0a3fe0709601,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-214e196a-60c4-4c99-a20a-8146dd52ddf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-dab3a664-89f6-42dd-a694-6a065fc782dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-c01ab1b3-7f28-4474-8b59-5c554adb0809,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-aec912ed-4dd2-40af-90f1-ed949e5618a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-211413541-172.17.0.18-1595482175222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33466,DS-c74d3192-fb9b-44b0-b4a5-c0fdd8d7cfbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-bd4dd3b9-086d-4021-9867-eafa2283b204,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-710349bd-61ac-4b33-a3e0-60a45b3a5ece,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-6e0d9ef6-fb93-49e6-882e-0a3fe0709601,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-214e196a-60c4-4c99-a20a-8146dd52ddf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-dab3a664-89f6-42dd-a694-6a065fc782dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-c01ab1b3-7f28-4474-8b59-5c554adb0809,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-aec912ed-4dd2-40af-90f1-ed949e5618a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2136360461-172.17.0.18-1595482503272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45703,DS-46704edf-3b78-435e-8c22-b4397ca6c768,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-31e07084-4a6c-4b02-9b64-8c9744573fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-67ce521a-6b68-44a3-ab18-ed67f604d699,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-30324d3f-7a36-4150-b518-8b0cc28455a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-fd8e10e7-56bf-4b28-bafb-d3a0d1af3694,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-26246582-2785-49a5-b7b8-c6237fb085ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-7f388184-448d-4518-8aaa-f9e251c88eec,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-068858b5-a9f8-4f3a-8384-178b11ddc4ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2136360461-172.17.0.18-1595482503272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45703,DS-46704edf-3b78-435e-8c22-b4397ca6c768,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-31e07084-4a6c-4b02-9b64-8c9744573fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-67ce521a-6b68-44a3-ab18-ed67f604d699,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-30324d3f-7a36-4150-b518-8b0cc28455a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-fd8e10e7-56bf-4b28-bafb-d3a0d1af3694,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-26246582-2785-49a5-b7b8-c6237fb085ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-7f388184-448d-4518-8aaa-f9e251c88eec,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-068858b5-a9f8-4f3a-8384-178b11ddc4ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581707811-172.17.0.18-1595482612789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46378,DS-ef607553-ac39-41a2-8b33-807a1be26f54,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-b0653a6a-2186-47ad-89ed-6cfc797b7d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-1ac5c817-6be5-452f-90e8-15987ef9f1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-4e45eafd-306b-4867-b245-d28751b888b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-b7efd270-5a56-44f3-aba2-8213cf06cd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-ff8ffb0c-cae3-454e-a6bf-8330926dd223,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-292db16f-27ac-47dc-8168-58f1911dd5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-a3ea8f68-32c2-4af6-a150-ce5b1662bb14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581707811-172.17.0.18-1595482612789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46378,DS-ef607553-ac39-41a2-8b33-807a1be26f54,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-b0653a6a-2186-47ad-89ed-6cfc797b7d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-1ac5c817-6be5-452f-90e8-15987ef9f1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-4e45eafd-306b-4867-b245-d28751b888b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-b7efd270-5a56-44f3-aba2-8213cf06cd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-ff8ffb0c-cae3-454e-a6bf-8330926dd223,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-292db16f-27ac-47dc-8168-58f1911dd5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-a3ea8f68-32c2-4af6-a150-ce5b1662bb14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2029234426-172.17.0.18-1595482764478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44651,DS-1b001671-156d-4866-a221-e36b706a1e18,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-8f23a8f1-7955-414b-a847-9dfd4d163cda,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-60ffe860-bdf6-4c42-b3c9-e456a7f348a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-0d408379-8ff1-4721-964f-f93a6369b49b,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-5aadbc3f-edec-424e-b1e1-d2bfe90a5f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-467c557d-0d42-4092-8b8d-6d630de5a9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-c845be9c-a756-46f5-b8b7-ce6d45e03685,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-326b6866-d0f2-46d6-ba7c-76dc4f42eaba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2029234426-172.17.0.18-1595482764478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44651,DS-1b001671-156d-4866-a221-e36b706a1e18,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-8f23a8f1-7955-414b-a847-9dfd4d163cda,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-60ffe860-bdf6-4c42-b3c9-e456a7f348a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-0d408379-8ff1-4721-964f-f93a6369b49b,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-5aadbc3f-edec-424e-b1e1-d2bfe90a5f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-467c557d-0d42-4092-8b8d-6d630de5a9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-c845be9c-a756-46f5-b8b7-ce6d45e03685,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-326b6866-d0f2-46d6-ba7c-76dc4f42eaba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438244686-172.17.0.18-1595482914342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33554,DS-87d79e0f-0870-46d5-9e53-2b7488803e10,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-e4146bd9-6b00-43b2-97d9-4a3c1945580b,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-5e0dbcfb-da9c-43a2-ab72-5928d32c99cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-4e58b148-e587-4c88-9935-6cd3973bb007,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-27aa338d-6fa0-4511-b0d7-8ac5bba26733,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-1af94355-8c80-4846-bf86-9a62029d7292,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-d7bbc2cc-433f-47f6-81cc-6b25d204d380,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-42f34fa2-391e-4c5e-9184-bdded41574a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438244686-172.17.0.18-1595482914342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33554,DS-87d79e0f-0870-46d5-9e53-2b7488803e10,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-e4146bd9-6b00-43b2-97d9-4a3c1945580b,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-5e0dbcfb-da9c-43a2-ab72-5928d32c99cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-4e58b148-e587-4c88-9935-6cd3973bb007,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-27aa338d-6fa0-4511-b0d7-8ac5bba26733,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-1af94355-8c80-4846-bf86-9a62029d7292,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-d7bbc2cc-433f-47f6-81cc-6b25d204d380,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-42f34fa2-391e-4c5e-9184-bdded41574a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1135852855-172.17.0.18-1595483125940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32980,DS-a7152f37-6f3b-4c70-a1b2-dcf24739b1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-b8c79a62-0849-4786-bd79-2cd039769415,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-7a4c3b6e-884c-4fc2-af39-887d8c8bfdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-69b2510f-f487-49df-be6a-24f32bff86dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-a57dd763-1ac4-4847-9cb3-d4df61a9ad03,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-957a49fd-06db-45cf-9eb6-3bfbfe88ff57,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-27447e92-b012-44dd-b7c1-b242997d6ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-b80b4956-224f-408b-937e-6477d3df6824,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1135852855-172.17.0.18-1595483125940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32980,DS-a7152f37-6f3b-4c70-a1b2-dcf24739b1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-b8c79a62-0849-4786-bd79-2cd039769415,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-7a4c3b6e-884c-4fc2-af39-887d8c8bfdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-69b2510f-f487-49df-be6a-24f32bff86dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-a57dd763-1ac4-4847-9cb3-d4df61a9ad03,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-957a49fd-06db-45cf-9eb6-3bfbfe88ff57,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-27447e92-b012-44dd-b7c1-b242997d6ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-b80b4956-224f-408b-937e-6477d3df6824,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-174878214-172.17.0.18-1595483271159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41131,DS-f52b79c1-8930-4076-9bb0-61d367ebe0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-43ce785a-7355-41de-b21c-ffd7bf8301a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-04f37215-a3e6-4bfc-baa9-739477776944,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-4d28adbd-f451-4980-862f-2615d51b4a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-e88f7616-68e9-4ccc-9c59-1bca3ba8f037,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-8be44893-73c6-4b3b-b3f3-b1d31e98fc27,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-f0a4b5c1-917b-4cd6-bc77-999e49ac002e,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-c2190e82-aac2-4728-9a26-a1a5d956b62b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-174878214-172.17.0.18-1595483271159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41131,DS-f52b79c1-8930-4076-9bb0-61d367ebe0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-43ce785a-7355-41de-b21c-ffd7bf8301a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-04f37215-a3e6-4bfc-baa9-739477776944,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-4d28adbd-f451-4980-862f-2615d51b4a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-e88f7616-68e9-4ccc-9c59-1bca3ba8f037,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-8be44893-73c6-4b3b-b3f3-b1d31e98fc27,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-f0a4b5c1-917b-4cd6-bc77-999e49ac002e,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-c2190e82-aac2-4728-9a26-a1a5d956b62b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1985086916-172.17.0.18-1595483377895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43059,DS-7d8ac8f0-32cd-4d16-8ad8-37aaca7c8672,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-e2415cf5-e342-4d64-a080-121da8943199,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-5b51e9fa-c34a-4b30-bcae-bd327e3a608f,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-16fc8b3c-ef1b-437c-9a61-c680bc6ec8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-4436cbaa-2c01-47c0-8d37-356cbc6ed10b,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-21b905c4-5247-4c59-8b50-c2aaf94f4e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-5f75081b-8c5a-4cc4-b00c-da32294a6af6,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-cd4f2331-e379-48ee-8412-629a675b9e54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1985086916-172.17.0.18-1595483377895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43059,DS-7d8ac8f0-32cd-4d16-8ad8-37aaca7c8672,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-e2415cf5-e342-4d64-a080-121da8943199,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-5b51e9fa-c34a-4b30-bcae-bd327e3a608f,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-16fc8b3c-ef1b-437c-9a61-c680bc6ec8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-4436cbaa-2c01-47c0-8d37-356cbc6ed10b,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-21b905c4-5247-4c59-8b50-c2aaf94f4e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-5f75081b-8c5a-4cc4-b00c-da32294a6af6,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-cd4f2331-e379-48ee-8412-629a675b9e54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1669114252-172.17.0.18-1595483966983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39608,DS-0907db74-3d8a-48e6-988a-1cb53702463a,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-188bb13d-0ea3-4598-be6a-1658003c8171,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-ccdca24e-7858-4341-b5f4-c7cf59c8f3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-c2cee6f5-598b-4ae5-92e5-7b3151e0115a,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-036f9cd2-af64-4665-a453-80a56df3fa95,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-e77d6e55-1e0e-4c4b-95a4-79ed1b48b8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-48b164e9-895b-415e-bc4a-bd65d95d2439,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-b184a1df-1cfa-4ee4-9b93-6e101fb48298,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1669114252-172.17.0.18-1595483966983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39608,DS-0907db74-3d8a-48e6-988a-1cb53702463a,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-188bb13d-0ea3-4598-be6a-1658003c8171,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-ccdca24e-7858-4341-b5f4-c7cf59c8f3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-c2cee6f5-598b-4ae5-92e5-7b3151e0115a,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-036f9cd2-af64-4665-a453-80a56df3fa95,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-e77d6e55-1e0e-4c4b-95a4-79ed1b48b8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-48b164e9-895b-415e-bc4a-bd65d95d2439,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-b184a1df-1cfa-4ee4-9b93-6e101fb48298,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904909774-172.17.0.18-1595484598334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33909,DS-0f2a8722-6d6c-4a37-b3d2-d17d81cb5978,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-f74a42dd-ee46-4c84-8131-3362383ae844,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-34ebce78-425a-4001-a210-9320a38234f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-02da2d6c-b904-4c4d-b2c7-95a0a5cb25e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-ece58d42-46a6-46b6-b950-f19ae6749551,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-2fd25fb3-a98f-4284-ae09-8f3520b5d0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-e19469b1-f463-4a3c-b0f5-1514dcb3968a,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-375af1bc-b1ac-45f5-9f9f-6f0a39f27e64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904909774-172.17.0.18-1595484598334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33909,DS-0f2a8722-6d6c-4a37-b3d2-d17d81cb5978,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-f74a42dd-ee46-4c84-8131-3362383ae844,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-34ebce78-425a-4001-a210-9320a38234f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-02da2d6c-b904-4c4d-b2c7-95a0a5cb25e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-ece58d42-46a6-46b6-b950-f19ae6749551,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-2fd25fb3-a98f-4284-ae09-8f3520b5d0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-e19469b1-f463-4a3c-b0f5-1514dcb3968a,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-375af1bc-b1ac-45f5-9f9f-6f0a39f27e64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1203936630-172.17.0.18-1595484754354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39684,DS-d2f6b080-2bc6-4271-b5af-2334fb43b3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-caa29cb3-a507-4277-8be7-f94feb104c20,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-15a0d250-3b6d-4652-8849-b0869fe79486,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-5f3aadf9-578a-41d1-9d7a-d6de3c7dac01,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-82714f22-ae48-499a-b028-6795006cc225,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-1faf7df9-6a8b-4631-9f9f-35a7749f4d76,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-f1d8e020-bb39-4490-a018-3f01aade1676,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-b602e702-2d16-4025-9f63-92f3fd0a285b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1203936630-172.17.0.18-1595484754354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39684,DS-d2f6b080-2bc6-4271-b5af-2334fb43b3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-caa29cb3-a507-4277-8be7-f94feb104c20,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-15a0d250-3b6d-4652-8849-b0869fe79486,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-5f3aadf9-578a-41d1-9d7a-d6de3c7dac01,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-82714f22-ae48-499a-b028-6795006cc225,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-1faf7df9-6a8b-4631-9f9f-35a7749f4d76,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-f1d8e020-bb39-4490-a018-3f01aade1676,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-b602e702-2d16-4025-9f63-92f3fd0a285b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1208694313-172.17.0.18-1595484935700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38282,DS-4b5c2a2f-293b-421e-b93c-b5f9b6dde413,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-ff5bb8b5-6da2-4970-bd3e-ef74eb2c6246,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-d00a54bb-cebe-4a5b-8170-5736d2c8abdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-aaae4727-369c-406e-b1ea-32c46a7596c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-7a3e367a-a01f-4319-85cc-8dd3b77934b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-444ec466-8c32-4c98-a885-92df54398b32,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-587a9b38-6df7-483a-afdd-5ea122e36e36,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-7ed54586-91de-4cb2-b5d8-d3d3c854656c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1208694313-172.17.0.18-1595484935700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38282,DS-4b5c2a2f-293b-421e-b93c-b5f9b6dde413,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-ff5bb8b5-6da2-4970-bd3e-ef74eb2c6246,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-d00a54bb-cebe-4a5b-8170-5736d2c8abdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-aaae4727-369c-406e-b1ea-32c46a7596c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-7a3e367a-a01f-4319-85cc-8dd3b77934b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-444ec466-8c32-4c98-a885-92df54398b32,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-587a9b38-6df7-483a-afdd-5ea122e36e36,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-7ed54586-91de-4cb2-b5d8-d3d3c854656c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-288900895-172.17.0.18-1595485043046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42367,DS-4d5215a0-504a-4070-82fa-153cc25bb0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-db94c17b-73e7-45ae-8825-d03e7ea8a786,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-a3f32387-a892-479c-9da9-d4dc17a74930,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-da10017b-d464-41e0-9d99-e57448efccc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-e737c589-b573-43e0-9c40-fd3ca0dae656,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-6e3821be-e15c-4d79-814f-5c8b5bb5d0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-fc47b5c0-76ed-4f29-8c66-80264d889980,DISK], DatanodeInfoWithStorage[127.0.0.1:37774,DS-69f4c505-d4ba-4bfe-ad8a-0ec197493bce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-288900895-172.17.0.18-1595485043046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42367,DS-4d5215a0-504a-4070-82fa-153cc25bb0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-db94c17b-73e7-45ae-8825-d03e7ea8a786,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-a3f32387-a892-479c-9da9-d4dc17a74930,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-da10017b-d464-41e0-9d99-e57448efccc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-e737c589-b573-43e0-9c40-fd3ca0dae656,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-6e3821be-e15c-4d79-814f-5c8b5bb5d0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-fc47b5c0-76ed-4f29-8c66-80264d889980,DISK], DatanodeInfoWithStorage[127.0.0.1:37774,DS-69f4c505-d4ba-4bfe-ad8a-0ec197493bce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635562426-172.17.0.18-1595485156917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36807,DS-985f84b2-0181-46ba-a697-f3dc0cadf998,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-9863092e-32d1-4018-96a8-9aa2e637b4af,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-68ac386f-d621-44ff-93e3-bf0f104658fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-13a22b36-2ea1-47c0-bec1-3bc965cfba80,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-1e58dc4d-1152-4263-8394-8bc98490e300,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-75b043fd-439e-4fd7-9ac8-c2ed66757e67,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-931a87c2-b6aa-418c-9139-4b7f3a2b1dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-38eee02d-a564-4c7d-a719-a2d68de36e95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635562426-172.17.0.18-1595485156917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36807,DS-985f84b2-0181-46ba-a697-f3dc0cadf998,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-9863092e-32d1-4018-96a8-9aa2e637b4af,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-68ac386f-d621-44ff-93e3-bf0f104658fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-13a22b36-2ea1-47c0-bec1-3bc965cfba80,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-1e58dc4d-1152-4263-8394-8bc98490e300,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-75b043fd-439e-4fd7-9ac8-c2ed66757e67,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-931a87c2-b6aa-418c-9139-4b7f3a2b1dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-38eee02d-a564-4c7d-a719-a2d68de36e95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-454850873-172.17.0.18-1595485627550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37974,DS-3f25b7dc-82bf-45a7-8a46-3c4c09062877,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-33961aaa-27af-4dd8-8157-51845d5efc20,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-f7a3b1af-4179-4156-b3f1-bd9be6e11bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-8ac807a2-19f3-4579-b0e8-4cb8bbc33192,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-f7a4eb20-83d1-4854-8d75-889f7e156fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-a34d9b2f-f70c-4f00-a15b-9dad37b97a17,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-d1027cb0-824a-43fc-9370-b9153bb5b5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-83218ad5-e672-482b-90c5-8a2a1d440d24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-454850873-172.17.0.18-1595485627550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37974,DS-3f25b7dc-82bf-45a7-8a46-3c4c09062877,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-33961aaa-27af-4dd8-8157-51845d5efc20,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-f7a3b1af-4179-4156-b3f1-bd9be6e11bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-8ac807a2-19f3-4579-b0e8-4cb8bbc33192,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-f7a4eb20-83d1-4854-8d75-889f7e156fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-a34d9b2f-f70c-4f00-a15b-9dad37b97a17,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-d1027cb0-824a-43fc-9370-b9153bb5b5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-83218ad5-e672-482b-90c5-8a2a1d440d24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1603120590-172.17.0.18-1595485691106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33505,DS-f163570d-01ce-45d0-a468-c0ec3a9500f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-cf3293e6-9d95-480a-b934-c5af9cecadf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-c69024b0-b2cc-4302-9390-a85dbc2146b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-268a66c7-823b-48d2-a42a-133527f33461,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-2c89bbca-8953-4f20-bd25-85e93862971a,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-d9334ddc-85cc-48fc-89bc-1852a26128d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-f78c7994-8438-49f3-8e93-adcf69271f64,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-7687fbc9-6ad2-40bb-a89e-1b225fca8684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1603120590-172.17.0.18-1595485691106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33505,DS-f163570d-01ce-45d0-a468-c0ec3a9500f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-cf3293e6-9d95-480a-b934-c5af9cecadf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-c69024b0-b2cc-4302-9390-a85dbc2146b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-268a66c7-823b-48d2-a42a-133527f33461,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-2c89bbca-8953-4f20-bd25-85e93862971a,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-d9334ddc-85cc-48fc-89bc-1852a26128d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-f78c7994-8438-49f3-8e93-adcf69271f64,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-7687fbc9-6ad2-40bb-a89e-1b225fca8684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-926591599-172.17.0.18-1595485831271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36755,DS-74a9462d-07df-498f-baa8-39061ebfd234,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-926537bb-f614-4107-8881-73a3da4f6f61,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-0c61ee05-0afd-4306-8f88-399cabb8cd45,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-a1b443c0-120e-4428-ad94-4e8de169dc22,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-a44367c8-24b7-4c8d-b316-907a12a93740,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-b099e20f-4cdd-4377-85ef-d9d1aa5fdca8,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-c08088a5-54e6-4997-a940-b461e5b2aeff,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-13be6ba3-fdf8-43ff-aba1-1536f53c449e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-926591599-172.17.0.18-1595485831271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36755,DS-74a9462d-07df-498f-baa8-39061ebfd234,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-926537bb-f614-4107-8881-73a3da4f6f61,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-0c61ee05-0afd-4306-8f88-399cabb8cd45,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-a1b443c0-120e-4428-ad94-4e8de169dc22,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-a44367c8-24b7-4c8d-b316-907a12a93740,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-b099e20f-4cdd-4377-85ef-d9d1aa5fdca8,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-c08088a5-54e6-4997-a940-b461e5b2aeff,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-13be6ba3-fdf8-43ff-aba1-1536f53c449e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-202679524-172.17.0.18-1595486101037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45935,DS-928981e6-84ff-4084-8e31-691bdaf4aaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-d0835327-d340-44d7-941f-787adcac61a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-63fca2db-4e59-4ab8-8831-bb2532fcf62e,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-f67ba06d-614a-46c9-8455-7c530a460cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-cbda3deb-4d5c-4f26-ac25-127187c84ede,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-43a18c5b-6d75-441a-9dce-60da917cd2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-c683008a-f37c-49c1-b5bf-c528ca8dcf43,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-ad007a3b-a764-4cca-8236-d1124b1ab6b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-202679524-172.17.0.18-1595486101037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45935,DS-928981e6-84ff-4084-8e31-691bdaf4aaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-d0835327-d340-44d7-941f-787adcac61a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-63fca2db-4e59-4ab8-8831-bb2532fcf62e,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-f67ba06d-614a-46c9-8455-7c530a460cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-cbda3deb-4d5c-4f26-ac25-127187c84ede,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-43a18c5b-6d75-441a-9dce-60da917cd2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-c683008a-f37c-49c1-b5bf-c528ca8dcf43,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-ad007a3b-a764-4cca-8236-d1124b1ab6b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-837743602-172.17.0.18-1595486347636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43214,DS-ec759877-da9b-422d-b7ed-f94707aac9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-c7cb6083-5e51-4d3b-b104-bb9cf6164491,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-23bce4a0-dbb3-4dff-89e6-edbab63730b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-9b2e2100-bffd-4020-92d2-71cd42517b68,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-0dabbefb-c8c6-4507-bf02-c2622d78f555,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-37fafd92-911d-4dd4-bfff-e3f836be08b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-b5e7d945-e8f4-403e-b140-5b08632bf870,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-e959fab2-0e9b-4196-8481-eb10b91ad092,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-837743602-172.17.0.18-1595486347636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43214,DS-ec759877-da9b-422d-b7ed-f94707aac9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-c7cb6083-5e51-4d3b-b104-bb9cf6164491,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-23bce4a0-dbb3-4dff-89e6-edbab63730b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-9b2e2100-bffd-4020-92d2-71cd42517b68,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-0dabbefb-c8c6-4507-bf02-c2622d78f555,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-37fafd92-911d-4dd4-bfff-e3f836be08b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-b5e7d945-e8f4-403e-b140-5b08632bf870,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-e959fab2-0e9b-4196-8481-eb10b91ad092,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5350
