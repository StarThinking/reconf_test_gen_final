reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063730919-172.17.0.12-1595801318265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43503,DS-a03d7dcb-7334-46b7-b328-d84da4a32a59,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-5ac2390e-defe-4d04-aab6-256816420faa,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-9df52d45-56c2-48f2-bcc7-0898d0e32c51,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-a54e57ab-3502-4014-9134-20e70670d89c,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-4b95466e-9e21-480e-8b1f-86aa37c7391a,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-c1825fbd-c989-405f-90de-7ee9582206d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-a84f55f3-f0a4-40b4-8b40-d0e4907b0a28,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-38b7b523-cd13-4693-bdbf-9e6d8e5f1275,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063730919-172.17.0.12-1595801318265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43503,DS-a03d7dcb-7334-46b7-b328-d84da4a32a59,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-5ac2390e-defe-4d04-aab6-256816420faa,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-9df52d45-56c2-48f2-bcc7-0898d0e32c51,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-a54e57ab-3502-4014-9134-20e70670d89c,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-4b95466e-9e21-480e-8b1f-86aa37c7391a,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-c1825fbd-c989-405f-90de-7ee9582206d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-a84f55f3-f0a4-40b4-8b40-d0e4907b0a28,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-38b7b523-cd13-4693-bdbf-9e6d8e5f1275,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-895666392-172.17.0.12-1595801530909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44958,DS-18641b5d-e913-4d58-b25e-a775e7845990,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-435c9a5e-64d5-47af-9741-5cc157ac398a,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-ff9c8da4-f7ea-421f-be37-0579d4e999dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-14eed9de-45e9-47ac-8409-8078ec7182ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-2f2a3a8f-66bb-4dd3-965c-10cb199d0cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-bc5020be-7cef-4af0-a204-8242d0168f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-c5fe6913-599a-4b3b-8b4b-0153ec1c9e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-7ef87a18-e759-4860-9a14-62733448eff3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-895666392-172.17.0.12-1595801530909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44958,DS-18641b5d-e913-4d58-b25e-a775e7845990,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-435c9a5e-64d5-47af-9741-5cc157ac398a,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-ff9c8da4-f7ea-421f-be37-0579d4e999dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-14eed9de-45e9-47ac-8409-8078ec7182ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-2f2a3a8f-66bb-4dd3-965c-10cb199d0cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-bc5020be-7cef-4af0-a204-8242d0168f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-c5fe6913-599a-4b3b-8b4b-0153ec1c9e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-7ef87a18-e759-4860-9a14-62733448eff3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1289118802-172.17.0.12-1595802427219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33337,DS-6132f8cd-e113-4293-9650-cd6bb2b804a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-e51f0dab-fd6f-4800-8a2d-a7d1f56dc8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-3bf9d9b8-edfc-4dfa-911f-42f7db52eacd,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-dff0e4ac-634b-4606-b084-7f94cb51e0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-b713932a-b92d-42b4-8cd0-1031288c22c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-34212b03-68fd-452f-aff6-a3360b993e79,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-872f10f4-d902-45af-b5c7-c212cb37d8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-b4a6261f-39a8-411e-a6fa-0657fa67eaa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1289118802-172.17.0.12-1595802427219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33337,DS-6132f8cd-e113-4293-9650-cd6bb2b804a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-e51f0dab-fd6f-4800-8a2d-a7d1f56dc8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-3bf9d9b8-edfc-4dfa-911f-42f7db52eacd,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-dff0e4ac-634b-4606-b084-7f94cb51e0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-b713932a-b92d-42b4-8cd0-1031288c22c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-34212b03-68fd-452f-aff6-a3360b993e79,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-872f10f4-d902-45af-b5c7-c212cb37d8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-b4a6261f-39a8-411e-a6fa-0657fa67eaa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199744678-172.17.0.12-1595802461618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39524,DS-ef8a9d82-831c-4474-92c2-f1de57349522,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-1f8b5047-2aba-485a-b9c4-d972ffc89a01,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-0045ef4f-cb1a-474f-bce2-1764c81ec541,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-b87860cb-1f5e-4ba7-98b5-356f22b6b5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-62749e7d-6090-4596-bf9a-5076c8bac596,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-e95df845-7d86-4f77-89a5-c0ede5d0223d,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-88a800bc-1915-4df9-83be-340d9b679a24,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-9dab6b01-06fb-4009-a1bf-602894f60919,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199744678-172.17.0.12-1595802461618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39524,DS-ef8a9d82-831c-4474-92c2-f1de57349522,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-1f8b5047-2aba-485a-b9c4-d972ffc89a01,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-0045ef4f-cb1a-474f-bce2-1764c81ec541,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-b87860cb-1f5e-4ba7-98b5-356f22b6b5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-62749e7d-6090-4596-bf9a-5076c8bac596,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-e95df845-7d86-4f77-89a5-c0ede5d0223d,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-88a800bc-1915-4df9-83be-340d9b679a24,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-9dab6b01-06fb-4009-a1bf-602894f60919,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826935628-172.17.0.12-1595802637725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38781,DS-e2ccf678-ced1-4e2d-bd91-ccaffcaea393,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-edfda328-08c6-40d0-891f-f7f82f824ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-9458c1a2-6c4d-424c-a47e-6a8ba85022c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-6da165f5-f6e6-4fbd-8ffc-82e985bd078c,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-fbe78392-da33-4d8a-916e-a14260f0980d,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-dec6f751-a09c-41b9-9898-6882fa30de99,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-e2540a3e-d8f5-4524-a4e3-1bdbbf0a7794,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-591d00fb-770d-4788-8b2c-4993bc9f44a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826935628-172.17.0.12-1595802637725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38781,DS-e2ccf678-ced1-4e2d-bd91-ccaffcaea393,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-edfda328-08c6-40d0-891f-f7f82f824ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-9458c1a2-6c4d-424c-a47e-6a8ba85022c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-6da165f5-f6e6-4fbd-8ffc-82e985bd078c,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-fbe78392-da33-4d8a-916e-a14260f0980d,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-dec6f751-a09c-41b9-9898-6882fa30de99,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-e2540a3e-d8f5-4524-a4e3-1bdbbf0a7794,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-591d00fb-770d-4788-8b2c-4993bc9f44a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864196282-172.17.0.12-1595803382379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44219,DS-9577e5fa-c4f6-44d4-9365-7e8d98e60d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-1fb1fcda-c4f4-4190-9140-9029dcb7ee0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-78fde5ec-c7f2-4261-b8e2-8f11a848e041,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-f48aa5aa-320e-4df9-bd9e-8ba7769d2f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-e6cfbb41-c29d-4ab0-9cd1-8262b529327d,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-acee1b89-2875-494a-a64b-d1e5a7cb5610,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-4c6afb2e-9fb4-4b92-9a2c-cc38cda2c7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-78ee4457-1c61-4247-9edf-42ef9ac5aa88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864196282-172.17.0.12-1595803382379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44219,DS-9577e5fa-c4f6-44d4-9365-7e8d98e60d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-1fb1fcda-c4f4-4190-9140-9029dcb7ee0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-78fde5ec-c7f2-4261-b8e2-8f11a848e041,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-f48aa5aa-320e-4df9-bd9e-8ba7769d2f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-e6cfbb41-c29d-4ab0-9cd1-8262b529327d,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-acee1b89-2875-494a-a64b-d1e5a7cb5610,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-4c6afb2e-9fb4-4b92-9a2c-cc38cda2c7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-78ee4457-1c61-4247-9edf-42ef9ac5aa88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-529582240-172.17.0.12-1595803484955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33558,DS-1fbd97c0-44bd-4378-bd99-015eb2bb7c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-455c2622-8534-4c53-b61a-166e36de1d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-a16cd5a3-834f-4bbb-994e-ac3c7c5b9cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-dfb7d627-d0b3-48f1-9f5a-a0711de4750c,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-08ac279a-623f-4303-b0fa-621d448543fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-0956b993-8dd8-4eb9-b15e-0b0c0c53dec8,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-8c499869-17cf-4350-b9d1-db43e94f1ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-2e376955-554f-4d7a-919e-2ed816194ac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-529582240-172.17.0.12-1595803484955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33558,DS-1fbd97c0-44bd-4378-bd99-015eb2bb7c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-455c2622-8534-4c53-b61a-166e36de1d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-a16cd5a3-834f-4bbb-994e-ac3c7c5b9cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-dfb7d627-d0b3-48f1-9f5a-a0711de4750c,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-08ac279a-623f-4303-b0fa-621d448543fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-0956b993-8dd8-4eb9-b15e-0b0c0c53dec8,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-8c499869-17cf-4350-b9d1-db43e94f1ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-2e376955-554f-4d7a-919e-2ed816194ac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-657748425-172.17.0.12-1595803879379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37133,DS-7e861d3a-bf68-43d7-80b1-d458e35eadba,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-bfcd3b2f-b856-4bc8-ac42-1138ae4bccfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-e285f920-fbba-452c-8b4f-a87d2f48461d,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-b18fbdea-8019-46cf-b41f-a480f26e6ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-0e0e5b7a-e5a8-4dc3-bd8f-d3b7c0936edb,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-795db040-965e-4d4f-a1e8-c295e5080183,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-ac087bef-7b82-41fe-8b84-3803e6425433,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-b3ee533e-7961-4c20-9271-de59d684ed2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-657748425-172.17.0.12-1595803879379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37133,DS-7e861d3a-bf68-43d7-80b1-d458e35eadba,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-bfcd3b2f-b856-4bc8-ac42-1138ae4bccfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-e285f920-fbba-452c-8b4f-a87d2f48461d,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-b18fbdea-8019-46cf-b41f-a480f26e6ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-0e0e5b7a-e5a8-4dc3-bd8f-d3b7c0936edb,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-795db040-965e-4d4f-a1e8-c295e5080183,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-ac087bef-7b82-41fe-8b84-3803e6425433,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-b3ee533e-7961-4c20-9271-de59d684ed2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1795578993-172.17.0.12-1595803961017:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38601,DS-7052ffc0-c46b-4f9d-9799-45b6e60ed3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-399c5be1-f78c-43d8-b09b-49195320e58b,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-87ffaba4-4fea-4e88-ac56-a3b84bcab114,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-b3531ac6-b264-45c3-8960-5bf2c9d0cde4,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-3fc33ca1-d471-46bf-bc29-b60f7326548e,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-7aa55cd8-4e5a-44f3-93aa-61afac7ec5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-2f057180-c920-4fa4-9a3e-f3d4c66a57ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-42a7c42b-7547-4f95-91f8-6b290b18e103,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1795578993-172.17.0.12-1595803961017:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38601,DS-7052ffc0-c46b-4f9d-9799-45b6e60ed3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-399c5be1-f78c-43d8-b09b-49195320e58b,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-87ffaba4-4fea-4e88-ac56-a3b84bcab114,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-b3531ac6-b264-45c3-8960-5bf2c9d0cde4,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-3fc33ca1-d471-46bf-bc29-b60f7326548e,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-7aa55cd8-4e5a-44f3-93aa-61afac7ec5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-2f057180-c920-4fa4-9a3e-f3d4c66a57ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-42a7c42b-7547-4f95-91f8-6b290b18e103,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1798154836-172.17.0.12-1595804353437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45417,DS-f671c67b-cb5b-4cf3-8dfb-baac8e145941,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-10c91d58-8cea-4f55-82d6-0cff0251fc53,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-0f053ac3-bdca-475f-a05c-8c66c92c28c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-ca11045f-a7d2-43b2-8cad-c396e0b7011b,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-56156b68-3966-4048-9905-a4c658bdda21,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-dddc59eb-da00-4c8d-b5b3-2fbc4e6545f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-b269ad7f-ca95-4744-991f-fcf3686ff56d,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-54e7d435-22fe-47d5-a362-3d2894b4b508,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1798154836-172.17.0.12-1595804353437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45417,DS-f671c67b-cb5b-4cf3-8dfb-baac8e145941,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-10c91d58-8cea-4f55-82d6-0cff0251fc53,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-0f053ac3-bdca-475f-a05c-8c66c92c28c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-ca11045f-a7d2-43b2-8cad-c396e0b7011b,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-56156b68-3966-4048-9905-a4c658bdda21,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-dddc59eb-da00-4c8d-b5b3-2fbc4e6545f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-b269ad7f-ca95-4744-991f-fcf3686ff56d,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-54e7d435-22fe-47d5-a362-3d2894b4b508,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1138298766-172.17.0.12-1595804636497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42542,DS-aeaaddbd-d70c-43dd-8bf3-1458a5935953,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-fb2b959e-d50e-4215-a6b1-66398bb1e99b,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-e523fa19-e29b-43ac-a4ea-42b3ed0d66af,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-4352a7f1-2cf2-472f-bf00-2ac2f12dc9db,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-6c979ec3-8129-44ea-8678-b79810e58afc,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-67d46a3c-dfad-4c06-ac5e-4218abc4f05c,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-37b5a9a6-d5a5-4fc4-bb16-c5984d620241,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-7c460630-9a19-41fc-8c22-93dfede5818f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1138298766-172.17.0.12-1595804636497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42542,DS-aeaaddbd-d70c-43dd-8bf3-1458a5935953,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-fb2b959e-d50e-4215-a6b1-66398bb1e99b,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-e523fa19-e29b-43ac-a4ea-42b3ed0d66af,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-4352a7f1-2cf2-472f-bf00-2ac2f12dc9db,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-6c979ec3-8129-44ea-8678-b79810e58afc,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-67d46a3c-dfad-4c06-ac5e-4218abc4f05c,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-37b5a9a6-d5a5-4fc4-bb16-c5984d620241,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-7c460630-9a19-41fc-8c22-93dfede5818f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234080158-172.17.0.12-1595805374537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33483,DS-f6f7f617-c17b-4858-93dc-afa73c800b42,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-90850746-2178-407d-b0d0-db15bc90b0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-684bbb90-60c2-4ad0-bdc3-a78a629d6080,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-207da07e-0e2c-42c7-a9a7-46dba1526472,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-d415611b-523d-455f-a4c5-4e1b6481e516,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-77226b7f-f41e-4e4e-b1d0-c73d0b02765e,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-336b3c9b-7e22-4f95-bbbc-c0c5158dc143,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-ee6d5034-78c1-4dd9-963a-f377295f2d2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234080158-172.17.0.12-1595805374537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33483,DS-f6f7f617-c17b-4858-93dc-afa73c800b42,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-90850746-2178-407d-b0d0-db15bc90b0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-684bbb90-60c2-4ad0-bdc3-a78a629d6080,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-207da07e-0e2c-42c7-a9a7-46dba1526472,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-d415611b-523d-455f-a4c5-4e1b6481e516,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-77226b7f-f41e-4e4e-b1d0-c73d0b02765e,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-336b3c9b-7e22-4f95-bbbc-c0c5158dc143,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-ee6d5034-78c1-4dd9-963a-f377295f2d2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1413440897-172.17.0.12-1595805510072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35667,DS-599e45cf-f07f-4248-806d-4e51dd2b4896,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-a5d93964-040b-4206-88c9-f1b93a1895ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-8fc5ddd1-24e6-4a18-b551-28ef46f65d21,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-78dafd8e-3747-4058-bcd4-6b2fa871e651,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-9cbcba30-02ca-41d0-81b7-89cdf62b61dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-b4121ab4-e3b9-4348-be67-aac79afc297f,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-cfcc027d-5479-446e-9c86-862f9ffbe1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-2b8e7353-cfe8-47cb-b05d-d911aca99a03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1413440897-172.17.0.12-1595805510072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35667,DS-599e45cf-f07f-4248-806d-4e51dd2b4896,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-a5d93964-040b-4206-88c9-f1b93a1895ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-8fc5ddd1-24e6-4a18-b551-28ef46f65d21,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-78dafd8e-3747-4058-bcd4-6b2fa871e651,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-9cbcba30-02ca-41d0-81b7-89cdf62b61dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-b4121ab4-e3b9-4348-be67-aac79afc297f,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-cfcc027d-5479-446e-9c86-862f9ffbe1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-2b8e7353-cfe8-47cb-b05d-d911aca99a03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1740945002-172.17.0.12-1595805709551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41892,DS-db038b14-80d8-4673-b633-2a9c65d294dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-18605952-a21b-4f47-90ea-7e6c230109a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-e4e1345d-cb81-4ec5-9546-c5a0a64a1d04,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-4b8eabe8-f699-48d5-a1a1-a27f1a32ece5,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-2caf3966-f1fb-4c6f-b0f5-e0fb6cad4e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-5b405bc8-93f1-4a88-8409-162ace07d67b,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-03d2d0a3-0ed0-491f-924e-b00fa81150ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-7dd04e5f-1328-4d84-bf4d-b0461e6d29cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1740945002-172.17.0.12-1595805709551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41892,DS-db038b14-80d8-4673-b633-2a9c65d294dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-18605952-a21b-4f47-90ea-7e6c230109a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-e4e1345d-cb81-4ec5-9546-c5a0a64a1d04,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-4b8eabe8-f699-48d5-a1a1-a27f1a32ece5,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-2caf3966-f1fb-4c6f-b0f5-e0fb6cad4e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-5b405bc8-93f1-4a88-8409-162ace07d67b,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-03d2d0a3-0ed0-491f-924e-b00fa81150ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-7dd04e5f-1328-4d84-bf4d-b0461e6d29cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5292
