reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1928040468-172.17.0.12-1596030106320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45991,DS-3b69c83b-93a7-41fb-9a3b-0a52d350a131,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-b8e3b5a6-380d-4f4b-8961-592d256c4721,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-1195799a-b153-480b-a59e-e12d87ffa804,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-e8e3efdd-a7db-460b-a51e-044efe1d690a,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-e09568ac-e591-4256-ab0a-b54f0554d5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-3c026ecf-ad48-49b4-9d96-d0ba68c66b59,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-00e719bb-cac8-4a22-97a2-e206db5afe9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-b7eace32-bfdd-4e06-8813-471b724657a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1928040468-172.17.0.12-1596030106320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45991,DS-3b69c83b-93a7-41fb-9a3b-0a52d350a131,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-b8e3b5a6-380d-4f4b-8961-592d256c4721,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-1195799a-b153-480b-a59e-e12d87ffa804,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-e8e3efdd-a7db-460b-a51e-044efe1d690a,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-e09568ac-e591-4256-ab0a-b54f0554d5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-3c026ecf-ad48-49b4-9d96-d0ba68c66b59,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-00e719bb-cac8-4a22-97a2-e206db5afe9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-b7eace32-bfdd-4e06-8813-471b724657a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545898912-172.17.0.12-1596030138251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39831,DS-591b9fc9-dd2f-4826-bc82-c9ac38ef5396,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-3211e06d-455c-4d48-b700-f659c3813c64,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-1d2c3a26-5c87-4696-8638-fc149d2abdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-c461851c-e830-4107-95a8-33269f2a8372,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-0b8f8d20-75bd-4ebf-bdcf-b6d467e805e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-9be2ac4b-fa28-44de-89eb-78a50beeade0,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-44e16213-a758-4b11-828c-9d39cc6fd8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-cbebb0bf-abf4-4a68-afd1-3ea46eace5d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545898912-172.17.0.12-1596030138251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39831,DS-591b9fc9-dd2f-4826-bc82-c9ac38ef5396,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-3211e06d-455c-4d48-b700-f659c3813c64,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-1d2c3a26-5c87-4696-8638-fc149d2abdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-c461851c-e830-4107-95a8-33269f2a8372,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-0b8f8d20-75bd-4ebf-bdcf-b6d467e805e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-9be2ac4b-fa28-44de-89eb-78a50beeade0,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-44e16213-a758-4b11-828c-9d39cc6fd8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-cbebb0bf-abf4-4a68-afd1-3ea46eace5d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887087245-172.17.0.12-1596030232943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39010,DS-ac511839-c6bb-48d7-9311-6284acf80099,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-36d05ce0-7239-4f32-ba0a-cb892ad95589,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-ef3295d4-ae93-4149-a5dc-7306e294c5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-ab981f3d-6d51-44ff-8b45-ef8fc1c983c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-49eb6c8f-e97d-41e9-bfb6-b06786a255a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-1bf2f7c1-32d9-4209-9a17-aea5857ac70d,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-0085718c-2983-4c4c-a0cb-6d0a15f67dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-931ffd62-f879-444d-bc5d-980eee696deb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887087245-172.17.0.12-1596030232943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39010,DS-ac511839-c6bb-48d7-9311-6284acf80099,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-36d05ce0-7239-4f32-ba0a-cb892ad95589,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-ef3295d4-ae93-4149-a5dc-7306e294c5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-ab981f3d-6d51-44ff-8b45-ef8fc1c983c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-49eb6c8f-e97d-41e9-bfb6-b06786a255a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-1bf2f7c1-32d9-4209-9a17-aea5857ac70d,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-0085718c-2983-4c4c-a0cb-6d0a15f67dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-931ffd62-f879-444d-bc5d-980eee696deb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1648591383-172.17.0.12-1596030311913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43138,DS-61166b28-5703-4823-8340-cac749c50e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-4b3d4a84-a574-4cf7-9438-16c9d380a92d,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-f1e642f1-33e7-4ddb-afab-569af255d2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-b30bd5f6-1c1d-4c90-9290-95d7f67abcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-1d9fa64d-b467-482f-b1a1-5b1d589a411f,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-f93d52ac-95f1-4970-9dff-fca1281da1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-7ed0fcc3-e1bf-4fc0-92cc-53332d0f79fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-913a70f8-fec4-450a-9531-282aa145075e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1648591383-172.17.0.12-1596030311913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43138,DS-61166b28-5703-4823-8340-cac749c50e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-4b3d4a84-a574-4cf7-9438-16c9d380a92d,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-f1e642f1-33e7-4ddb-afab-569af255d2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-b30bd5f6-1c1d-4c90-9290-95d7f67abcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-1d9fa64d-b467-482f-b1a1-5b1d589a411f,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-f93d52ac-95f1-4970-9dff-fca1281da1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-7ed0fcc3-e1bf-4fc0-92cc-53332d0f79fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-913a70f8-fec4-450a-9531-282aa145075e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249884069-172.17.0.12-1596030358977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45848,DS-41c9ac8c-2e55-4b80-b8d0-782330dcfed9,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-c8f13281-631b-409c-b56c-fba7b029b5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-1228e0e1-8615-4cf1-a2a0-3537e372a09f,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-93efb100-d3b8-444b-a0d6-e165468f2398,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-9fba097f-ea4f-44ad-a670-689daa5aaa79,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-39e1fb01-7eaa-4ea4-b1c6-350aa7514bce,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-eeeffbd4-89d4-4cea-94b4-029c40f8eb05,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-d90bfdb6-ea2a-423d-b205-86f92e1b2b0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249884069-172.17.0.12-1596030358977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45848,DS-41c9ac8c-2e55-4b80-b8d0-782330dcfed9,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-c8f13281-631b-409c-b56c-fba7b029b5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-1228e0e1-8615-4cf1-a2a0-3537e372a09f,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-93efb100-d3b8-444b-a0d6-e165468f2398,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-9fba097f-ea4f-44ad-a670-689daa5aaa79,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-39e1fb01-7eaa-4ea4-b1c6-350aa7514bce,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-eeeffbd4-89d4-4cea-94b4-029c40f8eb05,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-d90bfdb6-ea2a-423d-b205-86f92e1b2b0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237411378-172.17.0.12-1596030390777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36552,DS-a208ca20-df0b-4349-910a-58a901cbfe94,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-c9964d2c-bfd9-494d-a92f-8d78a8071138,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-feaba4d8-e3e0-4403-b4d2-db94e94db30a,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-d7a55314-a1a6-41b1-a411-ad1eb52b372e,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-e7d5ec22-b7c7-4c93-add4-285e9d0ee270,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-2778b543-8e27-4559-9fab-69e327181c26,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-603b2ae9-238a-4f18-bfba-42b24a2460aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-c7d471d1-0f93-4f1e-92a0-a60f5d791d69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237411378-172.17.0.12-1596030390777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36552,DS-a208ca20-df0b-4349-910a-58a901cbfe94,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-c9964d2c-bfd9-494d-a92f-8d78a8071138,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-feaba4d8-e3e0-4403-b4d2-db94e94db30a,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-d7a55314-a1a6-41b1-a411-ad1eb52b372e,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-e7d5ec22-b7c7-4c93-add4-285e9d0ee270,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-2778b543-8e27-4559-9fab-69e327181c26,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-603b2ae9-238a-4f18-bfba-42b24a2460aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-c7d471d1-0f93-4f1e-92a0-a60f5d791d69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707483193-172.17.0.12-1596030438869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42682,DS-6ff47d3a-ebe8-43a6-9a4e-6ea46a7359d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-ffc4ce79-f1a2-4e14-aa91-6577b0b73431,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-a95ab9d4-b2a1-4ab5-9107-bd2326886358,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-a6733cbd-c5aa-438b-b0da-a38a913f46fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-385c2a10-bda8-4730-b8ec-88936b9f0ade,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-880d4b97-8510-4e3f-89e2-3123a48e68f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-b66cd182-4137-4340-8a25-633bb0b289bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-df48a515-018c-41f4-ae43-63718c1c08ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707483193-172.17.0.12-1596030438869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42682,DS-6ff47d3a-ebe8-43a6-9a4e-6ea46a7359d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-ffc4ce79-f1a2-4e14-aa91-6577b0b73431,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-a95ab9d4-b2a1-4ab5-9107-bd2326886358,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-a6733cbd-c5aa-438b-b0da-a38a913f46fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-385c2a10-bda8-4730-b8ec-88936b9f0ade,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-880d4b97-8510-4e3f-89e2-3123a48e68f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-b66cd182-4137-4340-8a25-633bb0b289bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-df48a515-018c-41f4-ae43-63718c1c08ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774206278-172.17.0.12-1596030502820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38090,DS-74a1bbf1-e429-4324-bcd8-e1757370e777,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-462e8eef-0f8d-46c2-842d-c3661cf72dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-c627abab-5291-4050-b576-907a068b3c56,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-961a1ab2-e2d3-4b12-a0ee-db2797f6bd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-cfa28606-b46d-45af-9f09-d28fbb31cee6,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-de80d132-59fa-4fe5-80bf-efc654e17eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-81b99a84-2c67-4799-a3c7-18b59e018717,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-f5b5417a-513c-48d2-80b5-476ecaa98e57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774206278-172.17.0.12-1596030502820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38090,DS-74a1bbf1-e429-4324-bcd8-e1757370e777,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-462e8eef-0f8d-46c2-842d-c3661cf72dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-c627abab-5291-4050-b576-907a068b3c56,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-961a1ab2-e2d3-4b12-a0ee-db2797f6bd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-cfa28606-b46d-45af-9f09-d28fbb31cee6,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-de80d132-59fa-4fe5-80bf-efc654e17eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-81b99a84-2c67-4799-a3c7-18b59e018717,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-f5b5417a-513c-48d2-80b5-476ecaa98e57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665209470-172.17.0.12-1596030582321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41387,DS-2fa140f7-b695-4d0e-9b00-ec8f47c57ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-5f04b725-5796-4de3-830c-86046dd46f40,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-68a99078-ab6c-4fc4-93e7-154266ebb42f,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-842f40fd-d24a-4389-abe0-a54a0ecb5b53,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-e47dc294-db1d-4eb6-bd26-cbce09e8bbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-60b6386e-f66b-4c27-877a-3d958e8482c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-2bd92990-948b-4e74-93db-da0212c22d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-03e5f02f-3646-4fb7-ab53-5b706e267d4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665209470-172.17.0.12-1596030582321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41387,DS-2fa140f7-b695-4d0e-9b00-ec8f47c57ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-5f04b725-5796-4de3-830c-86046dd46f40,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-68a99078-ab6c-4fc4-93e7-154266ebb42f,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-842f40fd-d24a-4389-abe0-a54a0ecb5b53,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-e47dc294-db1d-4eb6-bd26-cbce09e8bbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-60b6386e-f66b-4c27-877a-3d958e8482c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-2bd92990-948b-4e74-93db-da0212c22d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-03e5f02f-3646-4fb7-ab53-5b706e267d4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958933053-172.17.0.12-1596030787652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42435,DS-84bbf0c4-cba8-499f-8e3a-07dc71dcd430,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-660ea199-cc76-4087-a3fe-63e019662f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-90a7981d-372c-494d-9889-7a04e30f49ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-9e085866-cd6f-41d3-a4df-009b21b2c987,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-79f8712a-cf4b-4b39-9087-781e6b6a6786,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-19539dd7-7367-409a-8df7-ebea52202ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-c421ff1e-fd4a-4008-8cc2-2ee52115fba9,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-d8def6f7-d2fc-4bdd-86d7-87683db7a69f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958933053-172.17.0.12-1596030787652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42435,DS-84bbf0c4-cba8-499f-8e3a-07dc71dcd430,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-660ea199-cc76-4087-a3fe-63e019662f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-90a7981d-372c-494d-9889-7a04e30f49ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-9e085866-cd6f-41d3-a4df-009b21b2c987,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-79f8712a-cf4b-4b39-9087-781e6b6a6786,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-19539dd7-7367-409a-8df7-ebea52202ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-c421ff1e-fd4a-4008-8cc2-2ee52115fba9,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-d8def6f7-d2fc-4bdd-86d7-87683db7a69f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716069740-172.17.0.12-1596030913869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46492,DS-e0167cfa-c9a5-490d-b1ec-e6b6e8517c74,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-2ef2bb46-4e0f-44ba-be7c-fc300238dc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-b0fb460c-a5f6-46dd-a462-30aa3d85721e,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-154b5d67-722c-4450-a30a-93447edb55f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-2fe127ab-fdab-4fb9-9c18-c34a3fa54162,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-111dbda2-2d51-42d3-a742-fcc7ef9a5598,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-f5a177ce-3ee4-4957-914e-8d6ae6bf9be2,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-583fd82d-d9f1-4cf0-add8-c8667aad0b27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716069740-172.17.0.12-1596030913869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46492,DS-e0167cfa-c9a5-490d-b1ec-e6b6e8517c74,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-2ef2bb46-4e0f-44ba-be7c-fc300238dc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-b0fb460c-a5f6-46dd-a462-30aa3d85721e,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-154b5d67-722c-4450-a30a-93447edb55f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-2fe127ab-fdab-4fb9-9c18-c34a3fa54162,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-111dbda2-2d51-42d3-a742-fcc7ef9a5598,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-f5a177ce-3ee4-4957-914e-8d6ae6bf9be2,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-583fd82d-d9f1-4cf0-add8-c8667aad0b27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166293401-172.17.0.12-1596030929746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44035,DS-18c02a53-097a-4a81-84a2-8c40a8361210,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-c422dbe5-5bcc-49d3-aa83-7803941374ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-a2abee97-315d-4b97-9f2c-b2feb8226119,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-99c86b42-e555-417a-8d00-b8d75f88c16d,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-a54ec97e-420b-4317-8876-b41f4e8a92d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-c90c72e4-f5e2-4cbc-9b03-743175b27e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-685de0b4-9a83-40a4-9740-9176eb63ba1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-b79d3afd-0a13-468e-a169-3c42b374757b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166293401-172.17.0.12-1596030929746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44035,DS-18c02a53-097a-4a81-84a2-8c40a8361210,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-c422dbe5-5bcc-49d3-aa83-7803941374ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-a2abee97-315d-4b97-9f2c-b2feb8226119,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-99c86b42-e555-417a-8d00-b8d75f88c16d,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-a54ec97e-420b-4317-8876-b41f4e8a92d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-c90c72e4-f5e2-4cbc-9b03-743175b27e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-685de0b4-9a83-40a4-9740-9176eb63ba1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-b79d3afd-0a13-468e-a169-3c42b374757b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838954797-172.17.0.12-1596030945656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43332,DS-bdf5cf04-4eb1-4b65-9655-f58c779d10e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-cdad25fc-46d1-4da2-b693-9a682bb5d193,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-ff91af17-0c05-4875-b258-7c82a6393be0,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-c3b612e0-bb9f-404a-aa94-e9955c48d151,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-e829b2c7-1185-4eda-a820-cbe9021f2bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-a860d361-7620-464c-a3b2-8d569b36175f,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-e2f3e5aa-e802-4e69-b58a-e06335119f07,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-8b09211f-fb7b-4090-bd52-fa8e40301c6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838954797-172.17.0.12-1596030945656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43332,DS-bdf5cf04-4eb1-4b65-9655-f58c779d10e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-cdad25fc-46d1-4da2-b693-9a682bb5d193,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-ff91af17-0c05-4875-b258-7c82a6393be0,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-c3b612e0-bb9f-404a-aa94-e9955c48d151,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-e829b2c7-1185-4eda-a820-cbe9021f2bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-a860d361-7620-464c-a3b2-8d569b36175f,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-e2f3e5aa-e802-4e69-b58a-e06335119f07,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-8b09211f-fb7b-4090-bd52-fa8e40301c6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-301514689-172.17.0.12-1596031072048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34618,DS-0b89d672-d210-462a-8987-d119c075ab06,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-73ee07be-342b-4d72-8442-7394b0b473eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-0c50bc1a-9120-488d-8a1b-37aaa735a1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-ef3420e7-29f0-4cb2-9686-6e7d22aec26e,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-750f35dc-5ea5-4850-8582-4c523fc77dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-d7ece6be-76df-4678-b3a4-cecc23d8a15d,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-b5cc52bf-dde2-42af-8315-6ff8d56d898e,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-598f3a1f-76b2-4093-9703-c109f376bb9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-301514689-172.17.0.12-1596031072048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34618,DS-0b89d672-d210-462a-8987-d119c075ab06,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-73ee07be-342b-4d72-8442-7394b0b473eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-0c50bc1a-9120-488d-8a1b-37aaa735a1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-ef3420e7-29f0-4cb2-9686-6e7d22aec26e,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-750f35dc-5ea5-4850-8582-4c523fc77dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-d7ece6be-76df-4678-b3a4-cecc23d8a15d,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-b5cc52bf-dde2-42af-8315-6ff8d56d898e,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-598f3a1f-76b2-4093-9703-c109f376bb9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926934018-172.17.0.12-1596031103811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42734,DS-4da169eb-3a67-46c8-88e0-fab30924233c,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-4a8ac44d-4bd9-4a45-83bc-2f2d554a7b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-e2facffe-de43-48f3-936c-c9751875a073,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-14a9bea4-abe9-4368-a584-e9bef3cc2b78,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-afdb8f30-2554-4d37-ad80-5e1dc2e28695,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-fbb06964-9f46-4a6b-a639-3421c9ae9c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-cdac2402-daed-4451-a82c-2409743267cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-3891f83f-ffc6-424b-beb3-a130c32f7031,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926934018-172.17.0.12-1596031103811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42734,DS-4da169eb-3a67-46c8-88e0-fab30924233c,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-4a8ac44d-4bd9-4a45-83bc-2f2d554a7b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-e2facffe-de43-48f3-936c-c9751875a073,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-14a9bea4-abe9-4368-a584-e9bef3cc2b78,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-afdb8f30-2554-4d37-ad80-5e1dc2e28695,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-fbb06964-9f46-4a6b-a639-3421c9ae9c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-cdac2402-daed-4451-a82c-2409743267cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-3891f83f-ffc6-424b-beb3-a130c32f7031,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963559351-172.17.0.12-1596031167765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35722,DS-989350b7-7bc3-487f-8b4c-328f0013dfc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-302ac9f4-6289-40e4-88f4-fb1773d25722,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-e62be88a-2ff2-4842-9334-ea2ff4c63156,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-a589211f-3af2-4404-9506-ec0bb742b4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-96600d4f-929f-4db0-afd2-8d6bdac1bf03,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-62613400-c5c9-4d60-bd3a-a95b4e825c02,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-8326be53-73e4-4f1e-a2f7-92bb237d3d54,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-6f2aec88-5a43-425d-8e82-2642f60bfd19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963559351-172.17.0.12-1596031167765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35722,DS-989350b7-7bc3-487f-8b4c-328f0013dfc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-302ac9f4-6289-40e4-88f4-fb1773d25722,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-e62be88a-2ff2-4842-9334-ea2ff4c63156,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-a589211f-3af2-4404-9506-ec0bb742b4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-96600d4f-929f-4db0-afd2-8d6bdac1bf03,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-62613400-c5c9-4d60-bd3a-a95b4e825c02,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-8326be53-73e4-4f1e-a2f7-92bb237d3d54,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-6f2aec88-5a43-425d-8e82-2642f60bfd19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112635942-172.17.0.12-1596031215246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34144,DS-fd0f6458-afc2-496f-8ebc-61bc74ded141,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-5dff73f8-485a-4871-81bf-07561ce7e420,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-04c80318-28c9-400a-bacb-7a330cd7d0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-7916b065-4e93-4ca9-9940-4f2b753d18fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-3c8b8ba4-6814-400a-a0c7-7f72cc45b329,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-c367c138-1fca-4d5a-812e-81eb04cde55c,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-11ac8c60-6098-4433-984f-4fe73d49a595,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-dd5d9c61-5047-454c-b97e-22344466898a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112635942-172.17.0.12-1596031215246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34144,DS-fd0f6458-afc2-496f-8ebc-61bc74ded141,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-5dff73f8-485a-4871-81bf-07561ce7e420,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-04c80318-28c9-400a-bacb-7a330cd7d0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-7916b065-4e93-4ca9-9940-4f2b753d18fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-3c8b8ba4-6814-400a-a0c7-7f72cc45b329,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-c367c138-1fca-4d5a-812e-81eb04cde55c,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-11ac8c60-6098-4433-984f-4fe73d49a595,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-dd5d9c61-5047-454c-b97e-22344466898a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1648281789-172.17.0.12-1596031231627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44906,DS-f9226598-3811-45e0-8386-990528f04efc,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-14c56d52-e39b-48ff-8d10-3cfac8f25069,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-9c8280c5-449b-41d1-8113-53686d651c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-197fc032-e1a4-4fe8-9b27-821a1afe7b08,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-345b37ef-3d26-4c7f-b3bf-51a59b276bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-90ac21f4-0363-4268-940e-c222ae3d4299,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-d8f9be1d-b5cc-4398-b496-234694c601c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-e1524d01-d0b6-4d8c-bb93-ba0cd49eb41b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1648281789-172.17.0.12-1596031231627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44906,DS-f9226598-3811-45e0-8386-990528f04efc,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-14c56d52-e39b-48ff-8d10-3cfac8f25069,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-9c8280c5-449b-41d1-8113-53686d651c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-197fc032-e1a4-4fe8-9b27-821a1afe7b08,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-345b37ef-3d26-4c7f-b3bf-51a59b276bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-90ac21f4-0363-4268-940e-c222ae3d4299,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-d8f9be1d-b5cc-4398-b496-234694c601c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-e1524d01-d0b6-4d8c-bb93-ba0cd49eb41b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031136608-172.17.0.12-1596031359386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35433,DS-31a25c12-3219-4889-9a2f-e664427436f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-97e8b466-6a9e-40b2-b1e5-7f044ab8df22,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-b4b32896-f066-4e2b-b8e8-c56fb6c36f42,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-6c301c84-4ac1-4a67-b919-4a0a747439a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-9e220b68-1dfb-4850-85e1-336771f87044,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-cd805c66-ff39-499f-b24d-a3f0200ef866,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-45a94855-a304-41ff-821c-d6b074808394,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-dab5babe-a314-4307-af63-29b571e0d20d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031136608-172.17.0.12-1596031359386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35433,DS-31a25c12-3219-4889-9a2f-e664427436f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-97e8b466-6a9e-40b2-b1e5-7f044ab8df22,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-b4b32896-f066-4e2b-b8e8-c56fb6c36f42,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-6c301c84-4ac1-4a67-b919-4a0a747439a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-9e220b68-1dfb-4850-85e1-336771f87044,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-cd805c66-ff39-499f-b24d-a3f0200ef866,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-45a94855-a304-41ff-821c-d6b074808394,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-dab5babe-a314-4307-af63-29b571e0d20d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-317450624-172.17.0.12-1596031453519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45555,DS-ef3448ee-7de4-4b39-8190-30f188e2d2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-6b38fe72-c0da-4413-b3c0-cb20cb7ec128,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-8d6935ae-80f2-480e-abd8-23dd48dd9c66,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-434ec253-4f2c-4c3f-b25f-8f6852bfc289,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-faed6454-6eab-4fad-aa57-fced99a420a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-6c26ae6e-b109-48b0-8f34-1c3a56f277b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-64a13a03-199c-4449-94a0-48b81f9b7b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-a34611bd-7ac7-46a4-91a9-6ec1b16155c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-317450624-172.17.0.12-1596031453519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45555,DS-ef3448ee-7de4-4b39-8190-30f188e2d2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-6b38fe72-c0da-4413-b3c0-cb20cb7ec128,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-8d6935ae-80f2-480e-abd8-23dd48dd9c66,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-434ec253-4f2c-4c3f-b25f-8f6852bfc289,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-faed6454-6eab-4fad-aa57-fced99a420a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-6c26ae6e-b109-48b0-8f34-1c3a56f277b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-64a13a03-199c-4449-94a0-48b81f9b7b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-a34611bd-7ac7-46a4-91a9-6ec1b16155c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804450460-172.17.0.12-1596031469716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38540,DS-1cc20619-d9c2-4ba5-ad1f-8a0b3f7d3be0,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-b08ca2f8-2408-4e4a-adb5-b4c2937a162c,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-c74a1b6b-c80f-4513-aca5-27b6e7ca710e,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-514fb17d-ffe7-40b1-bc09-75757011aa3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-a9da2b51-efe2-4d11-b3a6-3ab4895fcef0,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-2ca189ee-6027-45a1-96c6-69752755803d,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-1a765543-2b1f-4e30-b174-8f1d093f32a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-a2d70d38-fd14-498b-bf90-cc40c85dee73,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804450460-172.17.0.12-1596031469716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38540,DS-1cc20619-d9c2-4ba5-ad1f-8a0b3f7d3be0,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-b08ca2f8-2408-4e4a-adb5-b4c2937a162c,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-c74a1b6b-c80f-4513-aca5-27b6e7ca710e,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-514fb17d-ffe7-40b1-bc09-75757011aa3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-a9da2b51-efe2-4d11-b3a6-3ab4895fcef0,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-2ca189ee-6027-45a1-96c6-69752755803d,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-1a765543-2b1f-4e30-b174-8f1d093f32a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-a2d70d38-fd14-498b-bf90-cc40c85dee73,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121445417-172.17.0.12-1596031533339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42380,DS-796c9110-211e-48e0-a250-7304f1e631a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-e4bd1650-55e4-4d2e-a2cb-758a3452d64a,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-86c9381b-eab2-4789-8d3f-19a804530d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-731e0123-38fa-4bca-ad6d-a890d900664d,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-36b1b127-5319-44ce-8a2b-bf7b12b4ae0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-c083d746-4b7c-4ea7-b056-9ce66bf2ff5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-24e80e6f-6228-443c-8196-09bab7cae8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-4620185f-f4f7-49ba-840c-e5b9c4f6751c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121445417-172.17.0.12-1596031533339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42380,DS-796c9110-211e-48e0-a250-7304f1e631a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-e4bd1650-55e4-4d2e-a2cb-758a3452d64a,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-86c9381b-eab2-4789-8d3f-19a804530d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-731e0123-38fa-4bca-ad6d-a890d900664d,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-36b1b127-5319-44ce-8a2b-bf7b12b4ae0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-c083d746-4b7c-4ea7-b056-9ce66bf2ff5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-24e80e6f-6228-443c-8196-09bab7cae8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-4620185f-f4f7-49ba-840c-e5b9c4f6751c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396062422-172.17.0.12-1596031612107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45971,DS-fd991ba8-7e37-44f1-8d99-11c14007630a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-e216f54e-fed3-4be1-b49a-ae9eb8622e44,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-0fb9dae9-8226-47ea-afc0-0dcd6fdef940,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-e040283f-c384-4fc9-a500-b02a6ae74bff,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-d2454bc9-6d8d-469e-a79c-3e8ee42860a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-5d5dd576-d2f4-4df4-a305-bade989339ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-02196734-5dbd-44ee-8867-d53fe84f526f,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-faa0af54-3737-4b7a-99dc-6c62084b303f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396062422-172.17.0.12-1596031612107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45971,DS-fd991ba8-7e37-44f1-8d99-11c14007630a,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-e216f54e-fed3-4be1-b49a-ae9eb8622e44,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-0fb9dae9-8226-47ea-afc0-0dcd6fdef940,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-e040283f-c384-4fc9-a500-b02a6ae74bff,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-d2454bc9-6d8d-469e-a79c-3e8ee42860a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-5d5dd576-d2f4-4df4-a305-bade989339ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-02196734-5dbd-44ee-8867-d53fe84f526f,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-faa0af54-3737-4b7a-99dc-6c62084b303f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134440312-172.17.0.12-1596031627942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40900,DS-8a070baa-b370-4e85-a2e4-402268d7d3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-eb6072cc-f865-4f1e-b3c1-976a61fea217,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-4a4bb13c-fc0d-4ce1-ba18-9ef76120d439,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-dc702720-6dbc-41b4-8449-715287c7e357,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-5726cf52-622c-4973-872a-5c1270c54a58,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-cbb11159-080b-4e88-9edf-8aec025eb491,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-7aa7708a-f149-495d-bedf-9832896270d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-a6d312c4-55bf-470a-aede-9bfa56c260c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134440312-172.17.0.12-1596031627942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40900,DS-8a070baa-b370-4e85-a2e4-402268d7d3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-eb6072cc-f865-4f1e-b3c1-976a61fea217,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-4a4bb13c-fc0d-4ce1-ba18-9ef76120d439,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-dc702720-6dbc-41b4-8449-715287c7e357,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-5726cf52-622c-4973-872a-5c1270c54a58,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-cbb11159-080b-4e88-9edf-8aec025eb491,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-7aa7708a-f149-495d-bedf-9832896270d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-a6d312c4-55bf-470a-aede-9bfa56c260c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019734189-172.17.0.12-1596031738832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43527,DS-21301dad-3a6d-449f-a4a5-2441f339db38,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-b92d9b07-2b41-4f5c-b607-de6adf84c1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-091b4ab6-b1a2-4e8f-988f-79446b619b43,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-845637ef-6509-4329-9c51-7a4ccd626a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-5b93e6a8-7383-4893-9f37-0d8f4537ac65,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-f15d5780-dcec-4332-aa2b-e7a7a900fe38,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-2a508884-9c2c-40dd-aca0-655065b2d1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-f385f8ac-991f-4430-895d-3f1934a9911c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019734189-172.17.0.12-1596031738832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43527,DS-21301dad-3a6d-449f-a4a5-2441f339db38,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-b92d9b07-2b41-4f5c-b607-de6adf84c1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-091b4ab6-b1a2-4e8f-988f-79446b619b43,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-845637ef-6509-4329-9c51-7a4ccd626a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-5b93e6a8-7383-4893-9f37-0d8f4537ac65,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-f15d5780-dcec-4332-aa2b-e7a7a900fe38,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-2a508884-9c2c-40dd-aca0-655065b2d1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-f385f8ac-991f-4430-895d-3f1934a9911c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124090861-172.17.0.12-1596031802099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45762,DS-4b2ddfb2-35d6-4479-80ee-785b31630390,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-a88c9d6c-d62e-450a-ba50-3b7d02acbfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-3c1905aa-758d-47f3-b92c-1e8302351218,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-059f80ac-9f85-4f57-bd50-7be7523227aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-966d2e1c-008c-4919-b340-b358b7281196,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-32723cfe-2101-4bbe-8d7d-b29056f00f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-a9c08042-da05-4925-847c-1b074bb70665,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-e7b9521a-b566-4923-ae86-305fe06760fa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124090861-172.17.0.12-1596031802099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45762,DS-4b2ddfb2-35d6-4479-80ee-785b31630390,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-a88c9d6c-d62e-450a-ba50-3b7d02acbfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-3c1905aa-758d-47f3-b92c-1e8302351218,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-059f80ac-9f85-4f57-bd50-7be7523227aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-966d2e1c-008c-4919-b340-b358b7281196,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-32723cfe-2101-4bbe-8d7d-b29056f00f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-a9c08042-da05-4925-847c-1b074bb70665,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-e7b9521a-b566-4923-ae86-305fe06760fa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747964529-172.17.0.12-1596031833632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41059,DS-862d15ab-6f67-4e9d-8e94-ff60681cfb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-84b83b66-6deb-40eb-a427-05af27454131,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-a78616fd-88f1-4642-87b8-fbbe5a55cfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-ad60c662-4262-4494-aeb9-15edf42d358b,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-128a5d56-37d7-4658-877a-20ee2bb1e821,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-37bbca32-c4ea-4c5c-909b-a3044a60ef71,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-34cc2d87-7ecc-4a8a-944f-3fd89b27ffdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-4941691b-0c3f-483e-a534-888f09e5a684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747964529-172.17.0.12-1596031833632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41059,DS-862d15ab-6f67-4e9d-8e94-ff60681cfb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-84b83b66-6deb-40eb-a427-05af27454131,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-a78616fd-88f1-4642-87b8-fbbe5a55cfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-ad60c662-4262-4494-aeb9-15edf42d358b,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-128a5d56-37d7-4658-877a-20ee2bb1e821,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-37bbca32-c4ea-4c5c-909b-a3044a60ef71,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-34cc2d87-7ecc-4a8a-944f-3fd89b27ffdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-4941691b-0c3f-483e-a534-888f09e5a684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1665785342-172.17.0.12-1596031865473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46092,DS-76c01523-9d09-46d5-97f8-7d114de294ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-ea737e8c-ffb0-4a19-bb28-6816fed9bdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-6ef7ef94-e1d6-414d-8164-72bd614dd307,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-e877fece-be97-4316-85a8-ab4b8d2bb315,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-ebdf0be6-ce5d-4d69-bc51-55b0a7470762,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-2d531df8-2f8c-418e-a3ba-85e5a7f0ecf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-27fffbb2-59ec-4be6-98f9-e5cfa718fcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-7f49d5a9-1b1e-4d2d-85dd-8a55b741684e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1665785342-172.17.0.12-1596031865473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46092,DS-76c01523-9d09-46d5-97f8-7d114de294ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-ea737e8c-ffb0-4a19-bb28-6816fed9bdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-6ef7ef94-e1d6-414d-8164-72bd614dd307,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-e877fece-be97-4316-85a8-ab4b8d2bb315,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-ebdf0be6-ce5d-4d69-bc51-55b0a7470762,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-2d531df8-2f8c-418e-a3ba-85e5a7f0ecf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-27fffbb2-59ec-4be6-98f9-e5cfa718fcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-7f49d5a9-1b1e-4d2d-85dd-8a55b741684e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995427462-172.17.0.12-1596031897339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40648,DS-dde062f5-aab7-4c3d-a144-37d719de3036,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-ef47f44d-7200-4c26-8381-249578e2000d,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-b2924a42-3c66-4863-b7fd-e7b3cc570dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-df258be1-3dc3-4b96-9232-4851ea1eea73,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-1f83013b-b7b1-48b7-850f-953255e3c3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-2ce628f8-3672-499c-96ac-7f3baf16e820,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-2d685cd0-5893-46a5-a09e-a7750e62e71d,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-4469d375-5fa8-4dd5-9939-df5bdbde1a77,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995427462-172.17.0.12-1596031897339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40648,DS-dde062f5-aab7-4c3d-a144-37d719de3036,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-ef47f44d-7200-4c26-8381-249578e2000d,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-b2924a42-3c66-4863-b7fd-e7b3cc570dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-df258be1-3dc3-4b96-9232-4851ea1eea73,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-1f83013b-b7b1-48b7-850f-953255e3c3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-2ce628f8-3672-499c-96ac-7f3baf16e820,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-2d685cd0-5893-46a5-a09e-a7750e62e71d,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-4469d375-5fa8-4dd5-9939-df5bdbde1a77,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113884351-172.17.0.12-1596031944698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34003,DS-230117ab-1074-42ff-b0d4-0166cd71adec,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-5d4d8938-f0f2-4660-a739-bbb3282d92b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-b0c8df62-fa65-4a55-91f3-77170e6ee6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-84aaf870-1c5d-44ae-a5fb-66616325e09e,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-45cbc2fb-3668-4f10-813c-c5ea8351b837,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-3ec74270-118d-45d7-b974-eb44caa45827,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-fa51f45e-1e8d-4777-bdf5-1ac454169307,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-bc2a4990-34de-4f7f-9563-7067610cf98d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113884351-172.17.0.12-1596031944698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34003,DS-230117ab-1074-42ff-b0d4-0166cd71adec,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-5d4d8938-f0f2-4660-a739-bbb3282d92b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-b0c8df62-fa65-4a55-91f3-77170e6ee6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-84aaf870-1c5d-44ae-a5fb-66616325e09e,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-45cbc2fb-3668-4f10-813c-c5ea8351b837,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-3ec74270-118d-45d7-b974-eb44caa45827,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-fa51f45e-1e8d-4777-bdf5-1ac454169307,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-bc2a4990-34de-4f7f-9563-7067610cf98d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1431415233-172.17.0.12-1596031992233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33663,DS-11519918-151f-456b-acb6-0da4e3a23045,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-170dcd28-eea5-4ea7-87c2-2ef08fbb45fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-720a9c24-cb2a-4456-8667-581e4f94a9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-bd2fcb8f-e298-45fc-84d4-eeb132b48ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-d6173ced-3e85-461d-926d-4cb7e01dfb58,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-7278d565-c219-4dcf-ac82-cb9ad352312c,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-9b89f1d5-5b63-432e-8b61-59f8f1de6c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-7588683c-b1ef-45ec-a9f1-865deb1e2b62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1431415233-172.17.0.12-1596031992233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33663,DS-11519918-151f-456b-acb6-0da4e3a23045,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-170dcd28-eea5-4ea7-87c2-2ef08fbb45fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-720a9c24-cb2a-4456-8667-581e4f94a9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-bd2fcb8f-e298-45fc-84d4-eeb132b48ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-d6173ced-3e85-461d-926d-4cb7e01dfb58,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-7278d565-c219-4dcf-ac82-cb9ad352312c,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-9b89f1d5-5b63-432e-8b61-59f8f1de6c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-7588683c-b1ef-45ec-a9f1-865deb1e2b62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365670440-172.17.0.12-1596032071303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37744,DS-60aa6d92-a52a-4e14-a1b4-6860fbe3f607,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-b27cc6b8-3edb-4024-adcf-d04aa5617585,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-c01e44d1-f05d-4674-b8ed-6d33792cad03,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-781bf5e8-24de-4655-95a2-f367c3759c93,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-4c1be668-b1f3-49a3-b716-f9341bebf677,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-da772bd4-c840-4328-9ea8-ba3fb2ab4ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-1a3a381f-df05-4238-8740-20abcd28ac64,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-d29f41d2-8f49-4e20-a58e-d24e318a116b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365670440-172.17.0.12-1596032071303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37744,DS-60aa6d92-a52a-4e14-a1b4-6860fbe3f607,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-b27cc6b8-3edb-4024-adcf-d04aa5617585,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-c01e44d1-f05d-4674-b8ed-6d33792cad03,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-781bf5e8-24de-4655-95a2-f367c3759c93,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-4c1be668-b1f3-49a3-b716-f9341bebf677,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-da772bd4-c840-4328-9ea8-ba3fb2ab4ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-1a3a381f-df05-4238-8740-20abcd28ac64,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-d29f41d2-8f49-4e20-a58e-d24e318a116b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045692556-172.17.0.12-1596032197522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41268,DS-f3710fa5-d7a4-4b45-90bf-a0b6ab21ec6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-7ebf4b77-e484-4740-b03d-05379874763d,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-d96e7e82-78e3-4fbb-aee7-602bcf478740,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-19893df1-f13d-44b8-92bb-23cb2a759bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-2b2c32f9-dc5d-460a-a376-af2b5f12687e,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-279f4eca-8774-4360-aa01-1ce664d0b7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-8a0b564d-67a9-4b6d-a8cc-75ce462a060f,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-6f7236bb-102a-499c-85a2-4218c36e573a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045692556-172.17.0.12-1596032197522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41268,DS-f3710fa5-d7a4-4b45-90bf-a0b6ab21ec6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-7ebf4b77-e484-4740-b03d-05379874763d,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-d96e7e82-78e3-4fbb-aee7-602bcf478740,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-19893df1-f13d-44b8-92bb-23cb2a759bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-2b2c32f9-dc5d-460a-a376-af2b5f12687e,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-279f4eca-8774-4360-aa01-1ce664d0b7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-8a0b564d-67a9-4b6d-a8cc-75ce462a060f,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-6f7236bb-102a-499c-85a2-4218c36e573a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302790165-172.17.0.12-1596032277024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37038,DS-7e2e0fb9-e9fa-449e-9e75-c2cbf2437c30,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-a298c732-9b2d-48b3-9d42-e61c2931c75f,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-ece880d7-96c6-4a88-acdd-f9d0aac6cd76,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-7eba43fc-4f0e-416b-80b1-f9e82bc2e71e,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-2f2db85d-77b4-4942-8924-c2baa32799ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-30da5252-f64c-44ed-948c-9f7fc71dbab7,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-38576745-627d-4801-8d89-5dd38ad693ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-8b2b438d-0082-4aa3-a659-7588bcd9b2e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302790165-172.17.0.12-1596032277024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37038,DS-7e2e0fb9-e9fa-449e-9e75-c2cbf2437c30,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-a298c732-9b2d-48b3-9d42-e61c2931c75f,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-ece880d7-96c6-4a88-acdd-f9d0aac6cd76,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-7eba43fc-4f0e-416b-80b1-f9e82bc2e71e,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-2f2db85d-77b4-4942-8924-c2baa32799ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-30da5252-f64c-44ed-948c-9f7fc71dbab7,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-38576745-627d-4801-8d89-5dd38ad693ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-8b2b438d-0082-4aa3-a659-7588bcd9b2e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 2398
