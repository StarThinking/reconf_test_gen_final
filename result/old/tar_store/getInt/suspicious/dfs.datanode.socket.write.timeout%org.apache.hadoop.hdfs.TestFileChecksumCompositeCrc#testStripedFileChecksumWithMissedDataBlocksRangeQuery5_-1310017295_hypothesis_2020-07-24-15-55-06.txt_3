reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035444032-172.17.0.3-1595606233462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33064,DS-4a2fe876-e551-4c40-b423-12fa734bffe8,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-84143eeb-7a98-4890-8e35-1a339e4597af,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-404d583b-0717-4e26-abeb-9592a283732a,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-6b6074a7-a980-4a4f-b289-1342287ad00d,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-7ddc6dbe-9212-443d-88e8-bbf315febe0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-7baee0a5-a614-4a52-ade5-8e701dfffad4,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-b59a0b8c-3c86-4af5-8083-30880967f75f,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-64d7baec-e083-4632-8f15-716bc824f41d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035444032-172.17.0.3-1595606233462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33064,DS-4a2fe876-e551-4c40-b423-12fa734bffe8,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-84143eeb-7a98-4890-8e35-1a339e4597af,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-404d583b-0717-4e26-abeb-9592a283732a,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-6b6074a7-a980-4a4f-b289-1342287ad00d,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-7ddc6dbe-9212-443d-88e8-bbf315febe0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-7baee0a5-a614-4a52-ade5-8e701dfffad4,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-b59a0b8c-3c86-4af5-8083-30880967f75f,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-64d7baec-e083-4632-8f15-716bc824f41d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-320587771-172.17.0.3-1595606273030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40733,DS-9e04ce48-45ee-4aea-aedc-95cefb45bdae,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-85d79a01-511f-401a-ba8f-459bfd039c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-9957bec5-0c9f-45a8-9b2b-3e6ed99a1d96,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-a331ea12-f2dd-4019-8f63-24d16a0d7c00,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-30c58f8e-326a-47d1-9963-db75911e52d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-a2af33f5-0ed9-4db6-be0d-7d97253a2cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-49cac239-36aa-4a5a-8646-9ca30c94d073,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-4e5b54d4-84b6-4b6c-a741-b13c024c9815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-320587771-172.17.0.3-1595606273030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40733,DS-9e04ce48-45ee-4aea-aedc-95cefb45bdae,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-85d79a01-511f-401a-ba8f-459bfd039c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-9957bec5-0c9f-45a8-9b2b-3e6ed99a1d96,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-a331ea12-f2dd-4019-8f63-24d16a0d7c00,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-30c58f8e-326a-47d1-9963-db75911e52d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-a2af33f5-0ed9-4db6-be0d-7d97253a2cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-49cac239-36aa-4a5a-8646-9ca30c94d073,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-4e5b54d4-84b6-4b6c-a741-b13c024c9815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-158708831-172.17.0.3-1595606424522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35570,DS-b0a5df7b-f546-4fc0-bcc6-6a3f9f6abbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-225e4514-9b45-4a1c-a061-5fcedf925323,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-6b5b7453-269a-40d8-a7ac-e3196961e587,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-09c84909-40ee-4ff3-891d-34fcec744ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-9858128b-5caf-4dd5-ae8e-2de3db6b913f,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-cbfa638e-6f61-4e92-8def-7f3a3db53be8,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-e94169f0-4137-4a2d-8dd2-77f8a14f29fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-4b5e4eff-7810-421d-97aa-f337d3ac3a02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-158708831-172.17.0.3-1595606424522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35570,DS-b0a5df7b-f546-4fc0-bcc6-6a3f9f6abbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-225e4514-9b45-4a1c-a061-5fcedf925323,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-6b5b7453-269a-40d8-a7ac-e3196961e587,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-09c84909-40ee-4ff3-891d-34fcec744ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-9858128b-5caf-4dd5-ae8e-2de3db6b913f,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-cbfa638e-6f61-4e92-8def-7f3a3db53be8,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-e94169f0-4137-4a2d-8dd2-77f8a14f29fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-4b5e4eff-7810-421d-97aa-f337d3ac3a02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1574779073-172.17.0.3-1595606533068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35802,DS-24240af8-3931-4c9a-ba20-3986bb3566e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-fa8c9f91-7317-4053-921c-bdcbac2ed5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-c8b3fb8a-b0a0-47c3-a0f9-965b3fc58d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-cf66abf3-b9f8-491d-88a7-80a098338089,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-24eec767-dc60-41af-9c49-177baf5f8554,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-fc9924eb-9cbe-4c37-889c-dbeba8db70df,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-68de1ca0-6780-43af-972b-79eac849a85d,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-6d988d9e-f1ed-4ed3-a269-86aa967c2d83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1574779073-172.17.0.3-1595606533068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35802,DS-24240af8-3931-4c9a-ba20-3986bb3566e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-fa8c9f91-7317-4053-921c-bdcbac2ed5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-c8b3fb8a-b0a0-47c3-a0f9-965b3fc58d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-cf66abf3-b9f8-491d-88a7-80a098338089,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-24eec767-dc60-41af-9c49-177baf5f8554,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-fc9924eb-9cbe-4c37-889c-dbeba8db70df,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-68de1ca0-6780-43af-972b-79eac849a85d,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-6d988d9e-f1ed-4ed3-a269-86aa967c2d83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328355900-172.17.0.3-1595606780293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37181,DS-94d531af-9b46-473d-b528-6fa56673eb30,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-bfba00fc-007c-45fc-ae9a-4894f7f6f287,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-98502af8-bef8-4ed5-a55d-f9b97f6c94fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-bb7a87f6-15a5-4255-bb0e-8f73703c796a,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-739e2234-4df5-4cc7-ac88-a4e5a5a3b22f,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-df53931f-baf8-4e1c-910e-485c2b521069,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-062947df-c2b9-46e2-8685-6a3a9b208bae,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-d69f31b2-9b3a-4868-a843-29a92937db8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328355900-172.17.0.3-1595606780293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37181,DS-94d531af-9b46-473d-b528-6fa56673eb30,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-bfba00fc-007c-45fc-ae9a-4894f7f6f287,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-98502af8-bef8-4ed5-a55d-f9b97f6c94fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-bb7a87f6-15a5-4255-bb0e-8f73703c796a,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-739e2234-4df5-4cc7-ac88-a4e5a5a3b22f,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-df53931f-baf8-4e1c-910e-485c2b521069,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-062947df-c2b9-46e2-8685-6a3a9b208bae,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-d69f31b2-9b3a-4868-a843-29a92937db8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076820775-172.17.0.3-1595607409336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42325,DS-facd64b7-149e-4ca0-a149-5644b9e46bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-b2a53411-4540-4ffc-ac5c-f8b6f8870415,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-1cb751b1-9a25-40c1-8495-203a8be2bc59,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-4a3bfac5-90b1-4d75-aa14-3198869ad5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-3dedfc1d-f2cc-4507-8e24-33342eb55572,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-28b04764-c1bb-4ad2-9e97-8e578dac6b94,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-3d283265-b614-40e2-b5fa-8e057615479c,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-393d9a99-d9bf-4abb-b021-068a79d63b5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076820775-172.17.0.3-1595607409336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42325,DS-facd64b7-149e-4ca0-a149-5644b9e46bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-b2a53411-4540-4ffc-ac5c-f8b6f8870415,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-1cb751b1-9a25-40c1-8495-203a8be2bc59,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-4a3bfac5-90b1-4d75-aa14-3198869ad5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-3dedfc1d-f2cc-4507-8e24-33342eb55572,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-28b04764-c1bb-4ad2-9e97-8e578dac6b94,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-3d283265-b614-40e2-b5fa-8e057615479c,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-393d9a99-d9bf-4abb-b021-068a79d63b5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41449624-172.17.0.3-1595607445604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44728,DS-0c636d6e-2ca7-44f8-9a6e-c70041672e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-9cb90d24-ece5-427f-bfeb-03caa8da29c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-b8084300-f04e-4c07-8c66-ff3be356671f,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-eaf464f0-021a-452f-8c6c-3b989025b1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-82ca1dfb-638e-4a61-99ca-c2a236166f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-53fc2c3a-3800-41b2-a843-3a131d78ae8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-5280fcca-73cb-4c79-a3d8-df85165aebef,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-b10ac917-1810-42f0-bc42-75015a054dc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41449624-172.17.0.3-1595607445604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44728,DS-0c636d6e-2ca7-44f8-9a6e-c70041672e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-9cb90d24-ece5-427f-bfeb-03caa8da29c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-b8084300-f04e-4c07-8c66-ff3be356671f,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-eaf464f0-021a-452f-8c6c-3b989025b1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-82ca1dfb-638e-4a61-99ca-c2a236166f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-53fc2c3a-3800-41b2-a843-3a131d78ae8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-5280fcca-73cb-4c79-a3d8-df85165aebef,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-b10ac917-1810-42f0-bc42-75015a054dc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-180928609-172.17.0.3-1595607549594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36795,DS-75725f1f-f321-4b42-887e-799e0a5550df,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-09ac350a-f0cf-42e4-9e7c-079b558f0f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-e36a2475-f2a2-4b88-8ad8-0cc80950177a,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-26e3586b-00d5-4ad1-8737-3a8ca40e5603,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-87aab973-02ba-41b6-858f-6223996be3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-d63e940c-74cb-4025-9686-0dfa21043c22,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-a99c4cec-f476-4e08-981d-bbbe486e9bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-51373521-07fc-4c8c-940f-e1ad12c4858b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-180928609-172.17.0.3-1595607549594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36795,DS-75725f1f-f321-4b42-887e-799e0a5550df,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-09ac350a-f0cf-42e4-9e7c-079b558f0f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-e36a2475-f2a2-4b88-8ad8-0cc80950177a,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-26e3586b-00d5-4ad1-8737-3a8ca40e5603,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-87aab973-02ba-41b6-858f-6223996be3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-d63e940c-74cb-4025-9686-0dfa21043c22,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-a99c4cec-f476-4e08-981d-bbbe486e9bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-51373521-07fc-4c8c-940f-e1ad12c4858b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777534888-172.17.0.3-1595607931294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38694,DS-22ed024a-5a62-4d36-bd87-e25656783fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-ef16b8e8-8bc9-43e4-984e-3085c1d1cb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-91c4cfe5-8f3f-4334-a020-2f4f524589b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-66551ef4-69b9-4ef9-801e-fb47d64df7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-9aa55689-1e53-444e-826a-65a8aaad8f12,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-630ab417-ff4c-4dc2-aa8d-2bf126d1a52c,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-16c5a04c-6618-46a7-af28-1986e26599fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-c6ddc2bf-b02f-4ac9-be9f-51cd165e68ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777534888-172.17.0.3-1595607931294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38694,DS-22ed024a-5a62-4d36-bd87-e25656783fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-ef16b8e8-8bc9-43e4-984e-3085c1d1cb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-91c4cfe5-8f3f-4334-a020-2f4f524589b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-66551ef4-69b9-4ef9-801e-fb47d64df7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-9aa55689-1e53-444e-826a-65a8aaad8f12,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-630ab417-ff4c-4dc2-aa8d-2bf126d1a52c,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-16c5a04c-6618-46a7-af28-1986e26599fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-c6ddc2bf-b02f-4ac9-be9f-51cd165e68ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-927657111-172.17.0.3-1595608161664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46883,DS-6bc9136e-bd42-477b-905f-3155b8de852f,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-3991be5b-a82a-4dd3-8280-891a848ea141,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-b8baa137-7355-43f6-9817-b2c0b7d28b18,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-48fa0d4e-5fed-4e74-962b-b86ea259e055,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-70e7a164-abe2-469e-96ce-87cbdd78818f,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-2b5d4480-735d-4c9b-ac21-0ef1ab153775,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-7979f9fc-fd75-4d26-abe1-f32de774fb93,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-bbe284d3-292a-4a03-9378-3b718904ea2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-927657111-172.17.0.3-1595608161664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46883,DS-6bc9136e-bd42-477b-905f-3155b8de852f,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-3991be5b-a82a-4dd3-8280-891a848ea141,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-b8baa137-7355-43f6-9817-b2c0b7d28b18,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-48fa0d4e-5fed-4e74-962b-b86ea259e055,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-70e7a164-abe2-469e-96ce-87cbdd78818f,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-2b5d4480-735d-4c9b-ac21-0ef1ab153775,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-7979f9fc-fd75-4d26-abe1-f32de774fb93,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-bbe284d3-292a-4a03-9378-3b718904ea2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278525264-172.17.0.3-1595608246571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34149,DS-e8431c8c-2b27-4da3-868b-96fbdc7a1949,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-0830cd70-a960-437c-8fe3-1997001941f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-7f8095e5-ace6-45a0-9b08-f0666e6e15ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-c52a8acd-b8ac-4e55-8243-f02e90822b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-c89b5464-168c-4d87-93f9-3697b116e37d,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-e7a9e312-7ae2-45ea-9686-4a88f5bbdff6,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-68e73aad-ad71-4146-b149-32e48b5167af,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-690359e0-6009-4486-be3c-af927644c851,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278525264-172.17.0.3-1595608246571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34149,DS-e8431c8c-2b27-4da3-868b-96fbdc7a1949,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-0830cd70-a960-437c-8fe3-1997001941f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-7f8095e5-ace6-45a0-9b08-f0666e6e15ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-c52a8acd-b8ac-4e55-8243-f02e90822b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-c89b5464-168c-4d87-93f9-3697b116e37d,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-e7a9e312-7ae2-45ea-9686-4a88f5bbdff6,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-68e73aad-ad71-4146-b149-32e48b5167af,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-690359e0-6009-4486-be3c-af927644c851,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-65814740-172.17.0.3-1595608489322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43746,DS-a482fa32-413b-4ad4-aaa7-a81d1699bd87,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-09207cb2-8f9a-4271-9f71-2149d4392cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-3025b103-b13a-4643-ab46-984d78f563d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-43696ebb-ada2-408c-a252-842f2997633e,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-b2f5e386-2681-4471-82fa-fd900cd8dbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-767e4498-e8f5-4d93-9f16-72932e87fcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-1aa1f48b-bfc6-458b-a32b-f10790fe28e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-3a4b7bf8-822f-43b9-898a-c3437bbf3312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-65814740-172.17.0.3-1595608489322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43746,DS-a482fa32-413b-4ad4-aaa7-a81d1699bd87,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-09207cb2-8f9a-4271-9f71-2149d4392cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-3025b103-b13a-4643-ab46-984d78f563d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-43696ebb-ada2-408c-a252-842f2997633e,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-b2f5e386-2681-4471-82fa-fd900cd8dbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-767e4498-e8f5-4d93-9f16-72932e87fcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-1aa1f48b-bfc6-458b-a32b-f10790fe28e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-3a4b7bf8-822f-43b9-898a-c3437bbf3312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860685085-172.17.0.3-1595608590123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38003,DS-22a579fd-394c-4f3f-b31f-bba37185f0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-831e5fc8-8395-4729-a681-0e095a247e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-7d54e60c-637a-4367-a0f1-4235b1d4c6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-41ef2e28-a7c1-4ef1-9e9f-b2025f5f2547,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-9a566b7f-2b6a-4355-8161-c06056de7184,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-a34ba5a1-83df-4cab-b743-e24af5371d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-b98157bd-6e18-4444-ba22-ddb8034c98b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-fc45a9a0-fc48-4c64-a0fc-38b63e7d4066,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860685085-172.17.0.3-1595608590123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38003,DS-22a579fd-394c-4f3f-b31f-bba37185f0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-831e5fc8-8395-4729-a681-0e095a247e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-7d54e60c-637a-4367-a0f1-4235b1d4c6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-41ef2e28-a7c1-4ef1-9e9f-b2025f5f2547,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-9a566b7f-2b6a-4355-8161-c06056de7184,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-a34ba5a1-83df-4cab-b743-e24af5371d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-b98157bd-6e18-4444-ba22-ddb8034c98b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-fc45a9a0-fc48-4c64-a0fc-38b63e7d4066,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381690640-172.17.0.3-1595608833716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36879,DS-092bc951-2b27-425d-952c-15c53a085a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-7b732250-25bb-4b50-83a0-13fabfd904e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-217601d2-e83d-4ace-8ec7-1ffe73242e51,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-8e201936-3aef-428f-894c-e753c76a3780,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-8a64da51-b530-4400-b27e-82437c897304,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-b08d30b9-1a18-4620-9063-a2d2e32d8e77,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-6e64feae-ffe9-4570-8fef-bf2c231056ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-1d7d3067-c21f-4b8e-b1bf-cebfaad34f19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381690640-172.17.0.3-1595608833716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36879,DS-092bc951-2b27-425d-952c-15c53a085a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-7b732250-25bb-4b50-83a0-13fabfd904e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-217601d2-e83d-4ace-8ec7-1ffe73242e51,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-8e201936-3aef-428f-894c-e753c76a3780,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-8a64da51-b530-4400-b27e-82437c897304,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-b08d30b9-1a18-4620-9063-a2d2e32d8e77,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-6e64feae-ffe9-4570-8fef-bf2c231056ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-1d7d3067-c21f-4b8e-b1bf-cebfaad34f19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-879874624-172.17.0.3-1595609168673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33446,DS-03478359-15d1-47c2-aac8-43d7fd39e3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-82f3186a-1252-41f6-ac18-b6385a1a2de7,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-1f91face-9b9f-4dfe-a2df-d3a3c1b0056e,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-8a61a1f5-2b04-4333-96b2-6bb0912fb04c,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-d26c409e-320d-4bf1-bfdb-cef642755c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-3087b2fc-bcff-47ca-9f1d-516d550c2b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-3f30ec62-16d3-4a5c-811b-6cf0ba3fbcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-ffa994ed-4623-49c7-a045-8c875cd7fe68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-879874624-172.17.0.3-1595609168673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33446,DS-03478359-15d1-47c2-aac8-43d7fd39e3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-82f3186a-1252-41f6-ac18-b6385a1a2de7,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-1f91face-9b9f-4dfe-a2df-d3a3c1b0056e,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-8a61a1f5-2b04-4333-96b2-6bb0912fb04c,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-d26c409e-320d-4bf1-bfdb-cef642755c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-3087b2fc-bcff-47ca-9f1d-516d550c2b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-3f30ec62-16d3-4a5c-811b-6cf0ba3fbcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-ffa994ed-4623-49c7-a045-8c875cd7fe68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245341068-172.17.0.3-1595609276979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43947,DS-7206d930-688b-4a20-a971-50bf636b32bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-70912f8a-39c6-4f9d-8334-114e3671f147,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-0a9b38d0-9366-4b0a-b8e4-915fede93557,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-d2c596a8-f995-4963-9b69-928ba4556b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-8cc6f1d7-b85b-441e-bffa-6b9524735b56,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-1ac2ffd9-751f-449d-81b9-f61710983ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-790f7a08-0aaf-4bde-b765-47a879d4e0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-9e03a316-4655-4f35-8896-004d6123cf67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245341068-172.17.0.3-1595609276979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43947,DS-7206d930-688b-4a20-a971-50bf636b32bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-70912f8a-39c6-4f9d-8334-114e3671f147,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-0a9b38d0-9366-4b0a-b8e4-915fede93557,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-d2c596a8-f995-4963-9b69-928ba4556b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-8cc6f1d7-b85b-441e-bffa-6b9524735b56,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-1ac2ffd9-751f-449d-81b9-f61710983ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-790f7a08-0aaf-4bde-b765-47a879d4e0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-9e03a316-4655-4f35-8896-004d6123cf67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216162014-172.17.0.3-1595609628817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38295,DS-e4127472-1fab-4096-87e0-c18b783740f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-3cf06ad0-d3f2-4d21-9adf-4dc20e07fca1,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-3a020bc8-df21-440d-806d-bb89eef6bb48,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-4584e72f-b6bf-445f-b2df-eb2e5e79b8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-e0445f05-bd07-469f-a943-c8f4f3947f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-260a53d4-b5bc-4169-ae16-f1f2fd78d02e,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-fafd6e76-e64c-4800-b490-cfe9554b770f,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-0ba4f8c1-3833-4d33-8f27-28cf2cac60b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216162014-172.17.0.3-1595609628817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38295,DS-e4127472-1fab-4096-87e0-c18b783740f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-3cf06ad0-d3f2-4d21-9adf-4dc20e07fca1,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-3a020bc8-df21-440d-806d-bb89eef6bb48,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-4584e72f-b6bf-445f-b2df-eb2e5e79b8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-e0445f05-bd07-469f-a943-c8f4f3947f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-260a53d4-b5bc-4169-ae16-f1f2fd78d02e,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-fafd6e76-e64c-4800-b490-cfe9554b770f,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-0ba4f8c1-3833-4d33-8f27-28cf2cac60b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-973491277-172.17.0.3-1595610965944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43667,DS-fa2c7611-db87-4be2-9410-4390ad86e237,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-4e7b2bab-30b6-413b-a3bb-2113c63ad559,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-c81e423b-a200-4bee-bd5c-b52679bd617a,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-841eb264-cd71-43b5-a29a-274f994b3b62,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-2cebdc68-97e3-4e07-90b1-fcd9d6db04ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-cc224e28-ea0f-40a5-b875-28be10cd9ade,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-cd3c3888-47a1-47dd-adda-e206e9a7e529,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-040d0e05-517f-464d-9d59-edcbf64112a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-973491277-172.17.0.3-1595610965944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43667,DS-fa2c7611-db87-4be2-9410-4390ad86e237,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-4e7b2bab-30b6-413b-a3bb-2113c63ad559,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-c81e423b-a200-4bee-bd5c-b52679bd617a,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-841eb264-cd71-43b5-a29a-274f994b3b62,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-2cebdc68-97e3-4e07-90b1-fcd9d6db04ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-cc224e28-ea0f-40a5-b875-28be10cd9ade,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-cd3c3888-47a1-47dd-adda-e206e9a7e529,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-040d0e05-517f-464d-9d59-edcbf64112a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5639
