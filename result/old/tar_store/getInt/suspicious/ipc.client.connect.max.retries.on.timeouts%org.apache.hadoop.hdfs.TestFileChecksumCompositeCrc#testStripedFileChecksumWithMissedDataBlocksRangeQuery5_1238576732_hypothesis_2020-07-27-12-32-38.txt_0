reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107936475-172.17.0.12-1595854027999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34881,DS-6e05d387-cfcd-4eb7-8246-c9a92807c8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-c606647f-bf29-4090-b8b5-c448ee245b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-6924a219-b51b-4a13-a39e-6e792df4bf6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-666c8cd2-9b09-4a98-80ab-e3725eff3a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-761a99e6-e0f9-4d08-a00a-0bc6881a3f27,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-4cf5a56f-1bcb-4626-988f-5d0038ce3486,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-e929772f-4f12-4217-8251-14a6b11763a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-ffd6586b-5b42-4d54-87e3-24448121870a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107936475-172.17.0.12-1595854027999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34881,DS-6e05d387-cfcd-4eb7-8246-c9a92807c8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-c606647f-bf29-4090-b8b5-c448ee245b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-6924a219-b51b-4a13-a39e-6e792df4bf6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-666c8cd2-9b09-4a98-80ab-e3725eff3a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-761a99e6-e0f9-4d08-a00a-0bc6881a3f27,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-4cf5a56f-1bcb-4626-988f-5d0038ce3486,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-e929772f-4f12-4217-8251-14a6b11763a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-ffd6586b-5b42-4d54-87e3-24448121870a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107373853-172.17.0.12-1595854214426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43018,DS-31548756-c7bd-4fa7-b3c9-70daa5268f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-6de9da49-1933-41c3-acd5-aada1013145d,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-94b45446-497e-46da-9e0e-285ebc9d673f,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-32008237-dd8e-4b44-aeea-82500c760f50,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-f8fffbca-dca8-455f-b6bc-129251616721,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-a13d227f-84bc-45d8-bd15-af5af1015583,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-d37143a7-c569-463a-aeb5-4a7416c62c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-bd634c69-dfa0-479e-991b-868e1a1e3240,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107373853-172.17.0.12-1595854214426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43018,DS-31548756-c7bd-4fa7-b3c9-70daa5268f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-6de9da49-1933-41c3-acd5-aada1013145d,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-94b45446-497e-46da-9e0e-285ebc9d673f,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-32008237-dd8e-4b44-aeea-82500c760f50,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-f8fffbca-dca8-455f-b6bc-129251616721,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-a13d227f-84bc-45d8-bd15-af5af1015583,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-d37143a7-c569-463a-aeb5-4a7416c62c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-bd634c69-dfa0-479e-991b-868e1a1e3240,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214930390-172.17.0.12-1595854260861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33610,DS-4b6676dc-9a30-482d-a0bd-c66a3c7198f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-eee6000a-d5c1-477e-a734-99aa75d68fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-85534ef7-9798-4e29-9735-4dc15f88b86a,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-72fc03f6-dcc9-406d-9dba-ecd508699428,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-df88e795-4f7a-4a27-8c40-c12627babe35,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-4d211e32-520c-42fa-bf99-010b05e2af23,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-c71a8354-c111-4f14-b6aa-235dad32c2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-fd8036b7-fcb7-45c0-b016-8f88b90de426,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214930390-172.17.0.12-1595854260861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33610,DS-4b6676dc-9a30-482d-a0bd-c66a3c7198f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-eee6000a-d5c1-477e-a734-99aa75d68fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-85534ef7-9798-4e29-9735-4dc15f88b86a,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-72fc03f6-dcc9-406d-9dba-ecd508699428,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-df88e795-4f7a-4a27-8c40-c12627babe35,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-4d211e32-520c-42fa-bf99-010b05e2af23,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-c71a8354-c111-4f14-b6aa-235dad32c2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-fd8036b7-fcb7-45c0-b016-8f88b90de426,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596962699-172.17.0.12-1595854933281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44239,DS-e06ea98f-b667-4810-b563-a84ccec9a86f,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-0cf3fb27-4763-4577-8f7e-6faa9d1dcfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-527f64c2-2b66-4747-9903-d01e9727d002,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-41e5851c-08e9-4e76-8002-7042720f5832,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-9eea0c0d-5f3f-4fa7-bb33-6e37a9a63b65,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-607dfeb2-44bf-44dd-9221-2a43c80a4d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-63f41900-5c72-4f1a-959a-92a9d80db0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-8595a464-603d-4208-b117-b92631980fe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596962699-172.17.0.12-1595854933281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44239,DS-e06ea98f-b667-4810-b563-a84ccec9a86f,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-0cf3fb27-4763-4577-8f7e-6faa9d1dcfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-527f64c2-2b66-4747-9903-d01e9727d002,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-41e5851c-08e9-4e76-8002-7042720f5832,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-9eea0c0d-5f3f-4fa7-bb33-6e37a9a63b65,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-607dfeb2-44bf-44dd-9221-2a43c80a4d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-63f41900-5c72-4f1a-959a-92a9d80db0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-8595a464-603d-4208-b117-b92631980fe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884857074-172.17.0.12-1595855718539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34185,DS-3deef7b1-31c2-4401-9334-d86b3f74ffa3,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-eeccf988-246a-4b94-839c-b734f8406a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-821af0c8-181b-4bc7-8e6d-9e1bd62e3705,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-e427b09a-a651-43b5-9307-69ec4cace22c,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-8597aaf3-eae4-4621-b9b9-1a95c83315b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-59d5c1d9-1beb-488c-adb7-250a3699e668,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-e36163a7-fc2b-4419-8706-573b69068fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-7e06cbd8-8316-4bab-b933-852b74b3aeb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884857074-172.17.0.12-1595855718539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34185,DS-3deef7b1-31c2-4401-9334-d86b3f74ffa3,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-eeccf988-246a-4b94-839c-b734f8406a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-821af0c8-181b-4bc7-8e6d-9e1bd62e3705,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-e427b09a-a651-43b5-9307-69ec4cace22c,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-8597aaf3-eae4-4621-b9b9-1a95c83315b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-59d5c1d9-1beb-488c-adb7-250a3699e668,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-e36163a7-fc2b-4419-8706-573b69068fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-7e06cbd8-8316-4bab-b933-852b74b3aeb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1526581339-172.17.0.12-1595855867200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38356,DS-36e0f8bc-bba3-4c0e-8855-c0ee5e8d0f98,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-cfbed8d7-0688-4616-afc2-d8a2a90ba994,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-56c3809a-b274-403c-ae01-26b2539b43b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-c1045759-5cb5-4e40-ade9-87ae5f491fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-9f7a3a14-7dc7-4b38-94c7-39047ab59b17,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-6fbbae48-f378-452c-9fb3-25f467ebaeea,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-3fec4c84-d37a-4dea-bc7e-614ee7184400,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-7b9fb9c7-ca9d-4457-ab21-6071829aa3f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1526581339-172.17.0.12-1595855867200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38356,DS-36e0f8bc-bba3-4c0e-8855-c0ee5e8d0f98,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-cfbed8d7-0688-4616-afc2-d8a2a90ba994,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-56c3809a-b274-403c-ae01-26b2539b43b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-c1045759-5cb5-4e40-ade9-87ae5f491fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-9f7a3a14-7dc7-4b38-94c7-39047ab59b17,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-6fbbae48-f378-452c-9fb3-25f467ebaeea,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-3fec4c84-d37a-4dea-bc7e-614ee7184400,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-7b9fb9c7-ca9d-4457-ab21-6071829aa3f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223063401-172.17.0.12-1595855902332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39225,DS-0eab41c0-a54c-4210-94d8-40d0e0b04d58,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-9b4cb72f-4083-4eeb-b237-02eb068c9c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-fb9bdb17-012d-4cb5-bd0d-272d29bb47ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-9e175258-45d1-4583-93a3-5c43af53f13b,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-6f18babc-ab1b-493c-97e4-3d9f8dd26697,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-0948d8d6-c5c3-4cb3-8e4a-0a38e6547fef,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-2e19eda4-fc2d-438b-888c-5c1bd09d430e,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-726723d9-d945-40d4-b54f-e68034f7b1db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223063401-172.17.0.12-1595855902332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39225,DS-0eab41c0-a54c-4210-94d8-40d0e0b04d58,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-9b4cb72f-4083-4eeb-b237-02eb068c9c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-fb9bdb17-012d-4cb5-bd0d-272d29bb47ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-9e175258-45d1-4583-93a3-5c43af53f13b,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-6f18babc-ab1b-493c-97e4-3d9f8dd26697,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-0948d8d6-c5c3-4cb3-8e4a-0a38e6547fef,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-2e19eda4-fc2d-438b-888c-5c1bd09d430e,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-726723d9-d945-40d4-b54f-e68034f7b1db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1287179571-172.17.0.12-1595855942686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44828,DS-f13c4294-5141-4c98-a9ab-36f481f4ec7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-20062d24-0d6d-45a2-acff-004fbd505db2,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-35455c7b-706e-4699-9d34-c9ebbb28be53,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-891affc9-aac3-424c-b918-eca7181da135,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-2355186a-7bfb-4025-93fc-682e7eb70f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-37dbe14c-6407-4d54-a92d-81467b1d0a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-b62dc188-a35f-4051-a13a-77e3db41a055,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-4654353c-ea2c-4ada-ad4b-52d341413aa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1287179571-172.17.0.12-1595855942686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44828,DS-f13c4294-5141-4c98-a9ab-36f481f4ec7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-20062d24-0d6d-45a2-acff-004fbd505db2,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-35455c7b-706e-4699-9d34-c9ebbb28be53,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-891affc9-aac3-424c-b918-eca7181da135,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-2355186a-7bfb-4025-93fc-682e7eb70f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-37dbe14c-6407-4d54-a92d-81467b1d0a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-b62dc188-a35f-4051-a13a-77e3db41a055,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-4654353c-ea2c-4ada-ad4b-52d341413aa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089928839-172.17.0.12-1595856091769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46072,DS-0e642063-75e3-459a-a278-3da2da921406,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-07ae4d80-09a9-4db1-8da3-e8bec068618c,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-5b53848d-46e1-46de-9ff3-9ca461afe3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-14e0fc19-a18b-4b74-aa99-ce8515db69fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-d8bb3fa4-f992-462e-a345-1c7a8c393347,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-1c8690a1-8129-471c-b8b8-86a2377a6c61,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-e7c83a1e-a23a-40a6-b238-de0872329daf,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-475e48a2-87d7-4f9a-98d6-1b05b9a21cca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089928839-172.17.0.12-1595856091769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46072,DS-0e642063-75e3-459a-a278-3da2da921406,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-07ae4d80-09a9-4db1-8da3-e8bec068618c,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-5b53848d-46e1-46de-9ff3-9ca461afe3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-14e0fc19-a18b-4b74-aa99-ce8515db69fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-d8bb3fa4-f992-462e-a345-1c7a8c393347,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-1c8690a1-8129-471c-b8b8-86a2377a6c61,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-e7c83a1e-a23a-40a6-b238-de0872329daf,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-475e48a2-87d7-4f9a-98d6-1b05b9a21cca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245588424-172.17.0.12-1595856131692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34170,DS-5f5ac7c6-9c21-4ded-ba0d-f0314df396b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-7b485941-b81d-4999-b45e-ffe04160a2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-4e889709-61de-4d7e-9043-483eea3eff8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-7ead9100-a616-4b3d-80e0-5fef335dfa89,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-ac7aa4f9-b859-47a0-9344-0f62e2dfaa9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-f0971ff4-4f32-423c-8beb-60dfd84d84b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-48be588a-f496-4b3d-9bf6-4df3e54033ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-212d5568-8a4c-4076-ad38-3f68c2ad8461,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245588424-172.17.0.12-1595856131692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34170,DS-5f5ac7c6-9c21-4ded-ba0d-f0314df396b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-7b485941-b81d-4999-b45e-ffe04160a2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-4e889709-61de-4d7e-9043-483eea3eff8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-7ead9100-a616-4b3d-80e0-5fef335dfa89,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-ac7aa4f9-b859-47a0-9344-0f62e2dfaa9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-f0971ff4-4f32-423c-8beb-60dfd84d84b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-48be588a-f496-4b3d-9bf6-4df3e54033ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-212d5568-8a4c-4076-ad38-3f68c2ad8461,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-191122031-172.17.0.12-1595857098155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33565,DS-21e4d509-ac16-45fa-bdde-aa1744df354e,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-653d2868-80bd-49d2-9f79-b587be011ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-2ff909bf-55fa-48b5-9b14-2917a6b5d18f,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-a35aa1ec-0ef8-4768-b929-4fb63ac106fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-a364994c-d83a-457c-937e-7e008fda4ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-325ee2a0-0759-469f-a351-cbc4c4cddd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-bff19ff5-6259-4fd4-856b-c033cc7331e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-0c826df7-6eac-404c-8bdd-4cf5ecebe1b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-191122031-172.17.0.12-1595857098155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33565,DS-21e4d509-ac16-45fa-bdde-aa1744df354e,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-653d2868-80bd-49d2-9f79-b587be011ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-2ff909bf-55fa-48b5-9b14-2917a6b5d18f,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-a35aa1ec-0ef8-4768-b929-4fb63ac106fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-a364994c-d83a-457c-937e-7e008fda4ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-325ee2a0-0759-469f-a351-cbc4c4cddd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-bff19ff5-6259-4fd4-856b-c033cc7331e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-0c826df7-6eac-404c-8bdd-4cf5ecebe1b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408612981-172.17.0.12-1595857193288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39645,DS-742bd2b1-5697-4111-bad6-2028bad5d8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-79f0f3bf-88a0-4bfd-966a-28b76022a0af,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-e1abf2be-5db8-4963-acd6-6983e429ffba,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-f73eb490-aeea-431a-8d41-d9838c08796b,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-1fb2f8bf-76a6-4f44-9a8d-03b075992f16,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-7d840601-259e-40c3-8340-ed5931b65777,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-6cbd6653-7e8d-4199-ae39-6f5a24eb0cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-0785c442-8b81-4dd3-9148-28d2bdac295d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408612981-172.17.0.12-1595857193288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39645,DS-742bd2b1-5697-4111-bad6-2028bad5d8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-79f0f3bf-88a0-4bfd-966a-28b76022a0af,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-e1abf2be-5db8-4963-acd6-6983e429ffba,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-f73eb490-aeea-431a-8d41-d9838c08796b,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-1fb2f8bf-76a6-4f44-9a8d-03b075992f16,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-7d840601-259e-40c3-8340-ed5931b65777,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-6cbd6653-7e8d-4199-ae39-6f5a24eb0cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-0785c442-8b81-4dd3-9148-28d2bdac295d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-223197182-172.17.0.12-1595857229793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44210,DS-b0c50eb4-3925-4328-ad41-2f7045c6a9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-85a4bb54-2ce2-4f2f-9f30-c0b3bb0eb54e,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-7d4a0cff-190c-4c68-bd43-78d59307f152,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-6e993527-cff3-4744-9772-f5d4d40cfa27,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-3eaf32b3-f520-4eb4-961c-16a293018e12,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-980d543e-1c26-44c1-832a-62a7c76d92b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-e84f6699-6f7b-4ef0-8c03-6b7b00f21d31,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-8876c493-e25a-4e7f-bc9a-27ad2a7afb8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-223197182-172.17.0.12-1595857229793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44210,DS-b0c50eb4-3925-4328-ad41-2f7045c6a9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-85a4bb54-2ce2-4f2f-9f30-c0b3bb0eb54e,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-7d4a0cff-190c-4c68-bd43-78d59307f152,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-6e993527-cff3-4744-9772-f5d4d40cfa27,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-3eaf32b3-f520-4eb4-961c-16a293018e12,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-980d543e-1c26-44c1-832a-62a7c76d92b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-e84f6699-6f7b-4ef0-8c03-6b7b00f21d31,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-8876c493-e25a-4e7f-bc9a-27ad2a7afb8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057014408-172.17.0.12-1595857268408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41348,DS-352847b1-3ca5-431a-aa05-8156b4d14cce,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-2bcf1d79-0b6c-43aa-b575-17d13043dacb,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-e30c5406-8694-43ce-a7cf-51b5bddbe46b,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-023b4bd0-a187-454c-8785-135bb4614ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-9e5c652c-496c-4e45-ba8a-e612e17bed92,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-e0fc4f47-9dc4-45d3-a160-602983d28385,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-995015a3-0d87-454d-b7ef-b42f06088841,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-f1421bcb-aeac-4c5d-9094-e90789b9d386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057014408-172.17.0.12-1595857268408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41348,DS-352847b1-3ca5-431a-aa05-8156b4d14cce,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-2bcf1d79-0b6c-43aa-b575-17d13043dacb,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-e30c5406-8694-43ce-a7cf-51b5bddbe46b,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-023b4bd0-a187-454c-8785-135bb4614ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-9e5c652c-496c-4e45-ba8a-e612e17bed92,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-e0fc4f47-9dc4-45d3-a160-602983d28385,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-995015a3-0d87-454d-b7ef-b42f06088841,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-f1421bcb-aeac-4c5d-9094-e90789b9d386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851814298-172.17.0.12-1595857497881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34680,DS-1e66709c-559e-4a51-b9a5-f47226959638,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-4d7dd382-ee11-4eb0-bf9d-6b72d6d7fb61,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-88cc8e4f-3e45-48fa-a4e8-6d291c320ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-10bc95e3-7621-4fe9-b925-ef920596a809,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-e8de0a9a-00d2-42c2-93e8-597f1c0ce72b,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-91bef26f-dfa3-4283-910b-d39f2ef14f66,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-593b4ae8-66d7-4f91-94b3-225ca7ed83bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-4252481c-2c58-4d16-88b9-a324745d8828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851814298-172.17.0.12-1595857497881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34680,DS-1e66709c-559e-4a51-b9a5-f47226959638,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-4d7dd382-ee11-4eb0-bf9d-6b72d6d7fb61,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-88cc8e4f-3e45-48fa-a4e8-6d291c320ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-10bc95e3-7621-4fe9-b925-ef920596a809,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-e8de0a9a-00d2-42c2-93e8-597f1c0ce72b,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-91bef26f-dfa3-4283-910b-d39f2ef14f66,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-593b4ae8-66d7-4f91-94b3-225ca7ed83bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-4252481c-2c58-4d16-88b9-a324745d8828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-462144492-172.17.0.12-1595857690951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41825,DS-99b7ea24-1ee6-4873-bac5-b297318b5786,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-61ec445e-9f5b-46f3-864f-2406dd1bec8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-ff0d76d8-b13b-43f5-99c0-7ee2b17243b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-dd485d4f-6d96-412d-96a8-26c96115df8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-d2e98af9-a757-446b-ad7d-84ef2a65f98a,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-a57dcb9e-90c3-48fe-a88c-e00b17a7707e,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-597933aa-856e-4086-a9c3-9647fac825d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-56777b1a-8cd2-41e4-a1f5-9de2d6901c62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-462144492-172.17.0.12-1595857690951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41825,DS-99b7ea24-1ee6-4873-bac5-b297318b5786,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-61ec445e-9f5b-46f3-864f-2406dd1bec8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-ff0d76d8-b13b-43f5-99c0-7ee2b17243b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-dd485d4f-6d96-412d-96a8-26c96115df8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-d2e98af9-a757-446b-ad7d-84ef2a65f98a,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-a57dcb9e-90c3-48fe-a88c-e00b17a7707e,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-597933aa-856e-4086-a9c3-9647fac825d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-56777b1a-8cd2-41e4-a1f5-9de2d6901c62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960184596-172.17.0.12-1595857848775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36869,DS-b45f7abc-ff79-431a-9a8f-a8187e1171f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-a5f64701-a7ff-45c3-92e5-259c33847dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-f48152fb-2145-4ea2-9802-f36452977e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-57e32e32-e91c-497e-bd6c-d17eb278bd94,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-9628e063-74d8-41f4-a200-fbe8f67155fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-e3bc891f-b6e7-414d-87f1-08fce1749b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-74a508d7-f83d-4e02-b2ea-86d8b49885c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-e0ee65b1-1b93-49c2-83d3-c78e8b1f2053,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960184596-172.17.0.12-1595857848775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36869,DS-b45f7abc-ff79-431a-9a8f-a8187e1171f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-a5f64701-a7ff-45c3-92e5-259c33847dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-f48152fb-2145-4ea2-9802-f36452977e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-57e32e32-e91c-497e-bd6c-d17eb278bd94,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-9628e063-74d8-41f4-a200-fbe8f67155fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-e3bc891f-b6e7-414d-87f1-08fce1749b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-74a508d7-f83d-4e02-b2ea-86d8b49885c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-e0ee65b1-1b93-49c2-83d3-c78e8b1f2053,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1389629404-172.17.0.12-1595857975102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36745,DS-446f581a-8991-47bc-af5d-44807668529d,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-e9af43eb-3082-4ca2-8ae9-7a59993d95aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-b2be1001-e2da-4fe9-beda-a0468930c849,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-eb5cba45-9ade-475a-9f4c-799807c57481,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-72cbff83-b39b-4077-8112-905bcb7585da,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-a853dd27-4ee3-4207-a5fa-f93d89ec612e,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-510a88fa-81d1-4834-8f3b-c660b7aef5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-c631ae3e-5d18-4bee-9fd8-f3cdc9b2d787,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1389629404-172.17.0.12-1595857975102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36745,DS-446f581a-8991-47bc-af5d-44807668529d,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-e9af43eb-3082-4ca2-8ae9-7a59993d95aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-b2be1001-e2da-4fe9-beda-a0468930c849,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-eb5cba45-9ade-475a-9f4c-799807c57481,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-72cbff83-b39b-4077-8112-905bcb7585da,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-a853dd27-4ee3-4207-a5fa-f93d89ec612e,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-510a88fa-81d1-4834-8f3b-c660b7aef5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-c631ae3e-5d18-4bee-9fd8-f3cdc9b2d787,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519463548-172.17.0.12-1595858083174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38752,DS-d44ea7c0-19b9-4ab5-b7aa-cdfdabd1acbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-4f699626-0e88-410c-82c6-6ef1ee4b3293,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-951101b8-95ba-4867-93be-556d64d7e4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-603db490-6cd6-41c5-b526-ff6ade578b89,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-4a38a1a4-b2ab-4414-bda5-4892c1da42e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-a8916a1a-20ff-4e2e-b944-bb1d23a4b8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-f49dba32-0fb1-4bdf-ba50-275ba64a8065,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-aa166ea3-9087-4b35-808f-2d63973b5783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519463548-172.17.0.12-1595858083174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38752,DS-d44ea7c0-19b9-4ab5-b7aa-cdfdabd1acbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-4f699626-0e88-410c-82c6-6ef1ee4b3293,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-951101b8-95ba-4867-93be-556d64d7e4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-603db490-6cd6-41c5-b526-ff6ade578b89,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-4a38a1a4-b2ab-4414-bda5-4892c1da42e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-a8916a1a-20ff-4e2e-b944-bb1d23a4b8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-f49dba32-0fb1-4bdf-ba50-275ba64a8065,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-aa166ea3-9087-4b35-808f-2d63973b5783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-749870498-172.17.0.12-1595858301715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43207,DS-d532b41b-4a16-4391-ad80-92a79b6c66b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-8234e724-f20e-4f35-983b-48f099a45689,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-7ba327c0-2f45-4b4c-8cf4-c52a407a0656,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-cc452e11-78b3-452b-bda0-8fa32eb62d87,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-94570554-9a75-4555-9ff3-eaf25bebaa53,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-02ac125c-7fc2-4ef1-b229-510b16631b05,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-aa17d1c7-bff8-4399-90ad-89f55a6fb804,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-123f5fc6-6a72-47da-b9ad-7544e4fc512b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-749870498-172.17.0.12-1595858301715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43207,DS-d532b41b-4a16-4391-ad80-92a79b6c66b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-8234e724-f20e-4f35-983b-48f099a45689,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-7ba327c0-2f45-4b4c-8cf4-c52a407a0656,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-cc452e11-78b3-452b-bda0-8fa32eb62d87,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-94570554-9a75-4555-9ff3-eaf25bebaa53,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-02ac125c-7fc2-4ef1-b229-510b16631b05,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-aa17d1c7-bff8-4399-90ad-89f55a6fb804,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-123f5fc6-6a72-47da-b9ad-7544e4fc512b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72882885-172.17.0.12-1595858637604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37248,DS-c0df65a9-0592-4914-8c55-fb829d017264,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-998076ad-bca1-4115-8961-4e88c06de899,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-dadddc80-99c8-4b99-8cfa-7ee1d8f46c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-8043074e-808c-441f-b37f-b7877be4c27b,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-07577612-48a6-43ba-9018-9f4ae53ce375,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-dd1130b8-0586-409d-a1fa-e0fffa064f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-1e26c4d1-ffcb-4253-86b5-f2d8f2a71dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-26c13088-d23e-41d7-8331-3af0716aded6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72882885-172.17.0.12-1595858637604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37248,DS-c0df65a9-0592-4914-8c55-fb829d017264,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-998076ad-bca1-4115-8961-4e88c06de899,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-dadddc80-99c8-4b99-8cfa-7ee1d8f46c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-8043074e-808c-441f-b37f-b7877be4c27b,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-07577612-48a6-43ba-9018-9f4ae53ce375,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-dd1130b8-0586-409d-a1fa-e0fffa064f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-1e26c4d1-ffcb-4253-86b5-f2d8f2a71dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-26c13088-d23e-41d7-8331-3af0716aded6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5585
