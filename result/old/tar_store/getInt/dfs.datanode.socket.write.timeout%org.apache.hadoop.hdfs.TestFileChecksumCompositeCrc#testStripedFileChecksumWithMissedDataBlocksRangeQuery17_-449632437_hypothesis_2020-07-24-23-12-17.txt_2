reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1762697945-172.17.0.15-1595632680114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37123,DS-1bc48103-50d2-4c54-991e-79d630e97153,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-4152becd-de85-4bf7-9ff1-f9d50f6eff7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-6128a7dc-14b7-485b-841b-7f93f4a260bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-5cbe8987-15cc-42e2-b241-dcdda65c03b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-8839aea8-9d46-4cb4-b57e-868048ad3e63,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-4e8fd1f4-cfe7-4f8f-9ba8-7aaf6c60cf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-9da3b8d3-ce82-417d-9bec-6c99f1d02dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-dfe73d1d-2f0a-4fae-87c1-64dca3223459,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1762697945-172.17.0.15-1595632680114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37123,DS-1bc48103-50d2-4c54-991e-79d630e97153,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-4152becd-de85-4bf7-9ff1-f9d50f6eff7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-6128a7dc-14b7-485b-841b-7f93f4a260bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-5cbe8987-15cc-42e2-b241-dcdda65c03b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-8839aea8-9d46-4cb4-b57e-868048ad3e63,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-4e8fd1f4-cfe7-4f8f-9ba8-7aaf6c60cf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-9da3b8d3-ce82-417d-9bec-6c99f1d02dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-dfe73d1d-2f0a-4fae-87c1-64dca3223459,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1291052985-172.17.0.15-1595633014163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37525,DS-a112fbf0-70a6-4c8d-a2f3-8aebe4a5e1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-21d8a11d-57b7-43a4-a49a-84c904c3bc28,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-ffb2628f-78ef-4ab1-abc8-d01bf47ab1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-044b955c-6168-4d53-a011-9621e7446801,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-8058a933-2b7a-433f-9089-eb8d1d5a1adf,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-b26d9ac7-b021-4f3d-9804-2a6eb88e8d86,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-0035f395-950b-404a-982f-cd4ac797b547,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-e5efc943-ee15-4a3a-aeee-6770e0cb811b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1291052985-172.17.0.15-1595633014163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37525,DS-a112fbf0-70a6-4c8d-a2f3-8aebe4a5e1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-21d8a11d-57b7-43a4-a49a-84c904c3bc28,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-ffb2628f-78ef-4ab1-abc8-d01bf47ab1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-044b955c-6168-4d53-a011-9621e7446801,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-8058a933-2b7a-433f-9089-eb8d1d5a1adf,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-b26d9ac7-b021-4f3d-9804-2a6eb88e8d86,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-0035f395-950b-404a-982f-cd4ac797b547,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-e5efc943-ee15-4a3a-aeee-6770e0cb811b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1923176735-172.17.0.15-1595633230647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33611,DS-13ea10bf-a792-497e-a2ce-49b33404c1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-fc1fd6ff-939e-4031-9867-4f9c0ff74b58,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-bce4ca1e-a51a-424f-80d8-30c065a89be6,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-ab3684ff-562f-47ec-9d1f-ac3ad9406ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-d152da80-9523-461f-bd5e-55845d0a08fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-e7d22453-8f4e-47b4-ba0b-803bce55627f,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-1a400883-af6f-4380-b19d-6f1328fdf335,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-fbc49647-b948-4fa2-bfbc-7b38eeebc779,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1923176735-172.17.0.15-1595633230647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33611,DS-13ea10bf-a792-497e-a2ce-49b33404c1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-fc1fd6ff-939e-4031-9867-4f9c0ff74b58,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-bce4ca1e-a51a-424f-80d8-30c065a89be6,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-ab3684ff-562f-47ec-9d1f-ac3ad9406ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-d152da80-9523-461f-bd5e-55845d0a08fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-e7d22453-8f4e-47b4-ba0b-803bce55627f,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-1a400883-af6f-4380-b19d-6f1328fdf335,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-fbc49647-b948-4fa2-bfbc-7b38eeebc779,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-650363613-172.17.0.15-1595633678529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36355,DS-bb303ffc-80c4-4255-b0a4-e4a96c97d850,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-202c9e95-2770-4c1e-a1a9-0eccf37d8337,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-695da846-181d-4397-98e0-1772dda83b26,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-0c93030a-f92c-490b-a65f-4da4ccaba804,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-74650542-14e5-435d-88d3-f148afd5c6df,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-035b3bf7-8bde-4390-8262-fb6899b748a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-7addf115-0c27-4ba9-93e9-4378bc2fe1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-b82b09ef-5b78-40b5-8853-f27c964b7a95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-650363613-172.17.0.15-1595633678529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36355,DS-bb303ffc-80c4-4255-b0a4-e4a96c97d850,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-202c9e95-2770-4c1e-a1a9-0eccf37d8337,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-695da846-181d-4397-98e0-1772dda83b26,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-0c93030a-f92c-490b-a65f-4da4ccaba804,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-74650542-14e5-435d-88d3-f148afd5c6df,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-035b3bf7-8bde-4390-8262-fb6899b748a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-7addf115-0c27-4ba9-93e9-4378bc2fe1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-b82b09ef-5b78-40b5-8853-f27c964b7a95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-855391533-172.17.0.15-1595633837713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38788,DS-ef486619-b648-4a6f-be51-c75dc0df3749,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-e06faf0c-a58e-4ae2-9cf7-f696c0b89ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-b636f608-4ffd-4f55-a783-0a7682ed496f,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-7ae7b117-6ce7-46a6-bb79-194d1d1266ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-9c7a251e-b8dc-45ad-96c4-4d4df4491ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-a52def75-65e1-4697-9158-666195dd6e13,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-873c78bf-1ccd-46e7-9812-3a277bc0c14a,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-3349da39-7331-4861-b39d-992e8f23b7b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-855391533-172.17.0.15-1595633837713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38788,DS-ef486619-b648-4a6f-be51-c75dc0df3749,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-e06faf0c-a58e-4ae2-9cf7-f696c0b89ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-b636f608-4ffd-4f55-a783-0a7682ed496f,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-7ae7b117-6ce7-46a6-bb79-194d1d1266ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-9c7a251e-b8dc-45ad-96c4-4d4df4491ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-a52def75-65e1-4697-9158-666195dd6e13,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-873c78bf-1ccd-46e7-9812-3a277bc0c14a,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-3349da39-7331-4861-b39d-992e8f23b7b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1351285574-172.17.0.15-1595634054288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38448,DS-82efb70d-10d5-47e0-bb26-af21bd75ac24,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-7bf1e113-02b0-4ad5-9400-95211e21006b,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-eb2f728a-d371-4586-8649-cbf59a2637e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-32bfd467-4002-4c67-adff-21883299734c,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-0e7ed5b6-3cf7-4af9-9956-f5202fb9fbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-f0ee05ec-abaa-49ec-bc0e-413712a67b81,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-1a6e4e2f-e5ce-4df3-992c-2a5376d2604c,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-891e5904-3b5f-47d5-ab70-2ce63a26a566,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1351285574-172.17.0.15-1595634054288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38448,DS-82efb70d-10d5-47e0-bb26-af21bd75ac24,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-7bf1e113-02b0-4ad5-9400-95211e21006b,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-eb2f728a-d371-4586-8649-cbf59a2637e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-32bfd467-4002-4c67-adff-21883299734c,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-0e7ed5b6-3cf7-4af9-9956-f5202fb9fbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-f0ee05ec-abaa-49ec-bc0e-413712a67b81,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-1a6e4e2f-e5ce-4df3-992c-2a5376d2604c,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-891e5904-3b5f-47d5-ab70-2ce63a26a566,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1847260086-172.17.0.15-1595634258698:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36276,DS-c4223eb1-abd9-48ff-923d-827b00a80413,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-d1a4c52c-9edb-4051-ad3a-62ea1213c450,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-9d2ee010-9f34-4a04-af3e-f350c0ef8404,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-46e99287-5b3e-4bd5-8f0e-67907338e770,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-7d3a2c10-c617-4b73-a207-12002605f005,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-fe5968c7-064b-475c-976e-91a802585704,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-67ff2341-8a7b-4741-8b33-40194bb6496e,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-f973b936-d6d6-4ed0-8c47-d3cbf7fefb56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1847260086-172.17.0.15-1595634258698:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36276,DS-c4223eb1-abd9-48ff-923d-827b00a80413,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-d1a4c52c-9edb-4051-ad3a-62ea1213c450,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-9d2ee010-9f34-4a04-af3e-f350c0ef8404,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-46e99287-5b3e-4bd5-8f0e-67907338e770,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-7d3a2c10-c617-4b73-a207-12002605f005,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-fe5968c7-064b-475c-976e-91a802585704,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-67ff2341-8a7b-4741-8b33-40194bb6496e,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-f973b936-d6d6-4ed0-8c47-d3cbf7fefb56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1093680342-172.17.0.15-1595634300663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36411,DS-88efa79b-e9c2-454e-bdab-607d22d4ee36,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-b2ccdae1-42d0-45c1-972f-d98a00359539,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-f3b767e0-65ab-43fd-b2c6-1ec81bf402eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-dda05cee-aca3-413f-82ee-484b6907eb27,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-f53f71a2-48ba-4993-b7d3-75da3c15d1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-c1002600-12d9-47fc-9b3f-fa960b6b9fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-dcf73f51-bced-4cc5-99dd-404b8f59f562,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-088040eb-a6c3-44d5-abce-d4cfddb3b2bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1093680342-172.17.0.15-1595634300663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36411,DS-88efa79b-e9c2-454e-bdab-607d22d4ee36,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-b2ccdae1-42d0-45c1-972f-d98a00359539,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-f3b767e0-65ab-43fd-b2c6-1ec81bf402eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-dda05cee-aca3-413f-82ee-484b6907eb27,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-f53f71a2-48ba-4993-b7d3-75da3c15d1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-c1002600-12d9-47fc-9b3f-fa960b6b9fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-dcf73f51-bced-4cc5-99dd-404b8f59f562,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-088040eb-a6c3-44d5-abce-d4cfddb3b2bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-772445949-172.17.0.15-1595634368117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42643,DS-26efa2b8-ec3d-4c86-806b-4f508cf1e010,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-6ffa7515-e7df-41ac-9910-9b0594782b22,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-2ee06db1-9574-4697-9d76-7269543e4b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-fa0aa507-6251-4920-b8b0-5b5c9a061bff,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-3b0c0102-9bea-42ac-aa9d-9b00d335e893,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-269a0cf7-7a3f-4d85-ad46-d6af59b7724f,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-42c4a643-fe6e-4bda-8775-49e339b59a98,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-0add753b-2e9d-45cf-b8f2-d63da487a652,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-772445949-172.17.0.15-1595634368117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42643,DS-26efa2b8-ec3d-4c86-806b-4f508cf1e010,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-6ffa7515-e7df-41ac-9910-9b0594782b22,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-2ee06db1-9574-4697-9d76-7269543e4b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-fa0aa507-6251-4920-b8b0-5b5c9a061bff,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-3b0c0102-9bea-42ac-aa9d-9b00d335e893,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-269a0cf7-7a3f-4d85-ad46-d6af59b7724f,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-42c4a643-fe6e-4bda-8775-49e339b59a98,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-0add753b-2e9d-45cf-b8f2-d63da487a652,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-785302252-172.17.0.15-1595635077643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43819,DS-9b7e6846-7e6a-4c10-8ebd-4fd384290134,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-2760f9dc-9028-49a6-9b47-0b6c4ac03226,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-a39407be-70d8-4bd2-b78d-b072a7c897f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-d6f92d28-7517-4937-94a8-e5b4c4d994f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-bba8c2d5-d827-4ea5-bcf1-e824dcced6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-d6dbc407-90a0-4f58-ab25-cd297af159d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-3fc41544-b92c-4172-9a07-b06c88fa0d33,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-fdf62f3a-f990-46da-bf07-9606a7308901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-785302252-172.17.0.15-1595635077643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43819,DS-9b7e6846-7e6a-4c10-8ebd-4fd384290134,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-2760f9dc-9028-49a6-9b47-0b6c4ac03226,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-a39407be-70d8-4bd2-b78d-b072a7c897f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-d6f92d28-7517-4937-94a8-e5b4c4d994f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-bba8c2d5-d827-4ea5-bcf1-e824dcced6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-d6dbc407-90a0-4f58-ab25-cd297af159d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-3fc41544-b92c-4172-9a07-b06c88fa0d33,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-fdf62f3a-f990-46da-bf07-9606a7308901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1855611200-172.17.0.15-1595635190437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34205,DS-824fe1a5-8c34-48aa-b9b8-ba5a561447bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-4229dda4-2134-40e1-a7fe-880ca24707c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-8ea6cf53-de8b-40c8-a83b-967c66618cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-cdf2b6ed-2c9a-4915-a728-0d765b082ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-9af9ba7d-bbed-4794-8dd4-2fd8ced062c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-2454f8aa-d8b6-4192-a656-dbbf0aa90cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-e9bcfb77-6cc1-4840-a5cb-4b8614e5a04b,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-571a3c7f-71f3-45b2-a829-03f239deee76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1855611200-172.17.0.15-1595635190437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34205,DS-824fe1a5-8c34-48aa-b9b8-ba5a561447bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-4229dda4-2134-40e1-a7fe-880ca24707c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-8ea6cf53-de8b-40c8-a83b-967c66618cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-cdf2b6ed-2c9a-4915-a728-0d765b082ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-9af9ba7d-bbed-4794-8dd4-2fd8ced062c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-2454f8aa-d8b6-4192-a656-dbbf0aa90cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-e9bcfb77-6cc1-4840-a5cb-4b8614e5a04b,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-571a3c7f-71f3-45b2-a829-03f239deee76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-878657548-172.17.0.15-1595635293554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35960,DS-11fb50e0-f4da-43b6-a6ff-7a8b6f515131,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-5e99e1cf-44fa-421b-b5c7-3abf5a61fe36,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-1597d2ca-c00a-4f47-af01-932cd3f44762,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-e6f896a6-5205-488e-a0f1-aa98dc001e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-c93cb52f-8442-4b15-8c2d-bdd093d393f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-780659fb-b223-4f8c-a2ac-792b5591e36f,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-82bf0dfc-d96f-4698-9aeb-b4ea47e5bde2,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-f6b932ab-876d-4d1b-948e-a6bb249a4f0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-878657548-172.17.0.15-1595635293554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35960,DS-11fb50e0-f4da-43b6-a6ff-7a8b6f515131,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-5e99e1cf-44fa-421b-b5c7-3abf5a61fe36,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-1597d2ca-c00a-4f47-af01-932cd3f44762,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-e6f896a6-5205-488e-a0f1-aa98dc001e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-c93cb52f-8442-4b15-8c2d-bdd093d393f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-780659fb-b223-4f8c-a2ac-792b5591e36f,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-82bf0dfc-d96f-4698-9aeb-b4ea47e5bde2,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-f6b932ab-876d-4d1b-948e-a6bb249a4f0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1027969239-172.17.0.15-1595635405158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43251,DS-40e465a2-f8c5-49b7-a040-feae1ac343a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-62e83014-d41b-4ce3-9835-3a4fc904a843,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-039c2a6c-a77a-493a-9d24-ab44d5f9f92e,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-347d4add-1850-4c2d-8cc9-4399ea473507,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-2a4c0df0-d5f4-4d69-9883-788dc032bb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-68d2f635-ddac-4cad-9b43-158252d79969,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-87be3e05-8d55-4490-a66b-33463ace2412,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-65470fd1-3b4b-486d-b5f0-dd65f9f9d8ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1027969239-172.17.0.15-1595635405158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43251,DS-40e465a2-f8c5-49b7-a040-feae1ac343a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-62e83014-d41b-4ce3-9835-3a4fc904a843,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-039c2a6c-a77a-493a-9d24-ab44d5f9f92e,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-347d4add-1850-4c2d-8cc9-4399ea473507,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-2a4c0df0-d5f4-4d69-9883-788dc032bb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-68d2f635-ddac-4cad-9b43-158252d79969,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-87be3e05-8d55-4490-a66b-33463ace2412,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-65470fd1-3b4b-486d-b5f0-dd65f9f9d8ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1319948943-172.17.0.15-1595635644673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46401,DS-bfced18a-2ba6-4b3d-890e-34f0203014c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-d446d8e7-3c51-48e1-9dba-5f74a5813f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-69850052-4719-4ca1-b0b0-6b5d0fe7863a,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-a3a449db-c605-40dd-bf4b-fdaf1f55eb56,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-f0a8c529-713c-4289-bd20-e1194f34ea0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-4d28c75d-bd48-4a14-8871-94bdac0bbd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-2b1da001-9c6b-4b84-8e65-c3c647c4e7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-c1a91b90-661c-4263-999d-0f08bffc6a81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1319948943-172.17.0.15-1595635644673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46401,DS-bfced18a-2ba6-4b3d-890e-34f0203014c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-d446d8e7-3c51-48e1-9dba-5f74a5813f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-69850052-4719-4ca1-b0b0-6b5d0fe7863a,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-a3a449db-c605-40dd-bf4b-fdaf1f55eb56,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-f0a8c529-713c-4289-bd20-e1194f34ea0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-4d28c75d-bd48-4a14-8871-94bdac0bbd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-2b1da001-9c6b-4b84-8e65-c3c647c4e7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-c1a91b90-661c-4263-999d-0f08bffc6a81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-605445066-172.17.0.15-1595635900584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45499,DS-f100ae47-20b7-4a17-b2d2-43e8eecb3b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-f22e871c-629f-47c1-b20a-dfa8e21c3e33,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-13318dcf-046c-4222-b243-c7512cfa14b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-961e404b-38ac-4475-9921-09c91a895f65,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-6878e7d1-7f37-40a9-ba68-6a476087d3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-a4fe9144-7573-4794-b7e3-591a36264ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-8826f37b-5da7-4382-ac10-b9c0fcbe49bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-715bdc47-2e47-46c9-a127-d6ef851300fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-605445066-172.17.0.15-1595635900584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45499,DS-f100ae47-20b7-4a17-b2d2-43e8eecb3b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-f22e871c-629f-47c1-b20a-dfa8e21c3e33,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-13318dcf-046c-4222-b243-c7512cfa14b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-961e404b-38ac-4475-9921-09c91a895f65,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-6878e7d1-7f37-40a9-ba68-6a476087d3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-a4fe9144-7573-4794-b7e3-591a36264ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-8826f37b-5da7-4382-ac10-b9c0fcbe49bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-715bdc47-2e47-46c9-a127-d6ef851300fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2084088459-172.17.0.15-1595636114724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38994,DS-2e3144ce-414a-4482-9fbe-a28b70ce5a06,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-278064d4-2092-42f9-980e-00fb3a0693f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-2a627afd-c4e4-4754-81de-a19d00016a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-69403a52-bd91-4357-aecd-0eb2f172cdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-6471a2cc-04f1-47e9-9917-781591c68fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-285caaba-2f1a-482f-948b-9e558837f7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-372b69dc-5aac-4dda-8250-0c104e2ae194,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-5b145410-9af5-4b15-86b7-6fe7c3e7694c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2084088459-172.17.0.15-1595636114724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38994,DS-2e3144ce-414a-4482-9fbe-a28b70ce5a06,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-278064d4-2092-42f9-980e-00fb3a0693f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-2a627afd-c4e4-4754-81de-a19d00016a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-69403a52-bd91-4357-aecd-0eb2f172cdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-6471a2cc-04f1-47e9-9917-781591c68fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-285caaba-2f1a-482f-948b-9e558837f7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-372b69dc-5aac-4dda-8250-0c104e2ae194,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-5b145410-9af5-4b15-86b7-6fe7c3e7694c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1265174364-172.17.0.15-1595636149023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33985,DS-57203337-f80f-42cc-96fb-49efa6ee931e,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-964c427f-2235-4b72-bbdd-534182764801,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-f73d4ac0-5a13-4697-bc2f-e44433611b94,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-c72c1226-8f64-400a-af3c-a0fdd8e137e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-bee3e9b3-04c0-4aa0-b3ba-10be2dc9fcee,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-a64f7f82-48c9-4d34-8dbb-441c2736aba2,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-b60246a6-2d69-4044-8fa0-dfabaf0cb263,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-bae63511-aac5-42ae-a903-c4d1009c98d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1265174364-172.17.0.15-1595636149023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33985,DS-57203337-f80f-42cc-96fb-49efa6ee931e,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-964c427f-2235-4b72-bbdd-534182764801,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-f73d4ac0-5a13-4697-bc2f-e44433611b94,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-c72c1226-8f64-400a-af3c-a0fdd8e137e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-bee3e9b3-04c0-4aa0-b3ba-10be2dc9fcee,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-a64f7f82-48c9-4d34-8dbb-441c2736aba2,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-b60246a6-2d69-4044-8fa0-dfabaf0cb263,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-bae63511-aac5-42ae-a903-c4d1009c98d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342492818-172.17.0.15-1595636185186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45500,DS-b214b23b-4597-4e73-99b1-6d90e37bdc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-5fe1def1-2795-4c96-a9dd-83974a118e07,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-7e424848-19bf-4525-b8a6-529f38f1588d,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-f08200e9-831c-482d-b132-d9b2d273f0be,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-7086a698-edf3-4c57-99d9-631e9a7b4c74,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-d8e7a0a8-d908-40f7-b2ff-d1e3aee32e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-12833321-3b29-452f-a6c0-3cd0785eced5,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-bbfd40b4-df2d-46cd-a33f-f91535552acf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342492818-172.17.0.15-1595636185186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45500,DS-b214b23b-4597-4e73-99b1-6d90e37bdc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-5fe1def1-2795-4c96-a9dd-83974a118e07,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-7e424848-19bf-4525-b8a6-529f38f1588d,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-f08200e9-831c-482d-b132-d9b2d273f0be,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-7086a698-edf3-4c57-99d9-631e9a7b4c74,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-d8e7a0a8-d908-40f7-b2ff-d1e3aee32e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-12833321-3b29-452f-a6c0-3cd0785eced5,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-bbfd40b4-df2d-46cd-a33f-f91535552acf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-204620558-172.17.0.15-1595636262476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40547,DS-b767fa3f-d04e-4308-8b89-bf4b2537170f,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-546d400e-bc4c-462b-af98-54d96a40e82f,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-753663f3-91e4-432c-9066-21827db58431,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-53dac135-d60e-4e7e-b5ea-1da9c6c3ed7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-68b0751b-94cf-414c-bddb-97671b15f71e,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-a8383b04-627c-45ad-b8f3-c1ef7a986dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-f4b4b5b7-4b23-46e2-ac7f-e4dd069c3675,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-24716a7d-7f93-4101-8c7f-1a44b5faf0ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-204620558-172.17.0.15-1595636262476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40547,DS-b767fa3f-d04e-4308-8b89-bf4b2537170f,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-546d400e-bc4c-462b-af98-54d96a40e82f,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-753663f3-91e4-432c-9066-21827db58431,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-53dac135-d60e-4e7e-b5ea-1da9c6c3ed7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-68b0751b-94cf-414c-bddb-97671b15f71e,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-a8383b04-627c-45ad-b8f3-c1ef7a986dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-f4b4b5b7-4b23-46e2-ac7f-e4dd069c3675,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-24716a7d-7f93-4101-8c7f-1a44b5faf0ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1063117431-172.17.0.15-1595636751784:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42907,DS-fec6065e-1eee-4374-8835-9e705eadd144,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-73025d42-4e0f-4745-92b7-090b2842d1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-48323dd5-5a39-46fd-bdd6-1756fd613de1,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-44dcf9ad-0e57-4d11-a693-554ac30d1d59,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-9219a87e-55c9-448b-a49b-9734b407f407,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-b08eaa55-49c1-4eaa-bcaa-40ab47be812b,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-58a76717-0b4b-4eec-8a10-e5c608631da5,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-351410d4-2d40-4ef6-9e9c-6bc0ecfdb2f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1063117431-172.17.0.15-1595636751784:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42907,DS-fec6065e-1eee-4374-8835-9e705eadd144,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-73025d42-4e0f-4745-92b7-090b2842d1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-48323dd5-5a39-46fd-bdd6-1756fd613de1,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-44dcf9ad-0e57-4d11-a693-554ac30d1d59,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-9219a87e-55c9-448b-a49b-9734b407f407,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-b08eaa55-49c1-4eaa-bcaa-40ab47be812b,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-58a76717-0b4b-4eec-8a10-e5c608631da5,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-351410d4-2d40-4ef6-9e9c-6bc0ecfdb2f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1732420607-172.17.0.15-1595636894624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36841,DS-c877d4d6-d797-4da7-9fc5-8fe3a4fcc843,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-fb3156df-16d5-4d96-81ff-a808493a1dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-c665674f-8635-4334-8e09-31942b6c1243,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-aaef3f4d-1a30-4af4-b855-a70c8a0ebf53,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-d29fa8ba-f8d8-469a-8eb5-b51feccad1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-e551cb0a-f449-4052-a24a-688a289f577e,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-b1c7d1c9-b3bc-403a-a66e-27105160cd43,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-c500557b-fdee-4728-9021-fecee82dc182,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1732420607-172.17.0.15-1595636894624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36841,DS-c877d4d6-d797-4da7-9fc5-8fe3a4fcc843,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-fb3156df-16d5-4d96-81ff-a808493a1dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-c665674f-8635-4334-8e09-31942b6c1243,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-aaef3f4d-1a30-4af4-b855-a70c8a0ebf53,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-d29fa8ba-f8d8-469a-8eb5-b51feccad1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-e551cb0a-f449-4052-a24a-688a289f577e,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-b1c7d1c9-b3bc-403a-a66e-27105160cd43,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-c500557b-fdee-4728-9021-fecee82dc182,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1965507655-172.17.0.15-1595637034335:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40585,DS-82f222e4-4d66-4364-8dcb-25055e79233a,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-a4147f3d-3217-4d4f-90b9-286e0ecb1e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-89b49743-d446-40cf-9b91-e83a50fe9337,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-e7b1ff2e-e0ac-41ab-bec9-a9fddb70b1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-4e5f07d2-eb03-4648-be73-d51e624ce2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-67baec68-5ccd-41d8-ad1a-bb85eaf65ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-0fe5e015-f087-42cf-945e-adf0c3c68fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-c6c21349-3d8c-4ce3-a735-56816ae1cac9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1965507655-172.17.0.15-1595637034335:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40585,DS-82f222e4-4d66-4364-8dcb-25055e79233a,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-a4147f3d-3217-4d4f-90b9-286e0ecb1e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-89b49743-d446-40cf-9b91-e83a50fe9337,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-e7b1ff2e-e0ac-41ab-bec9-a9fddb70b1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-4e5f07d2-eb03-4648-be73-d51e624ce2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-67baec68-5ccd-41d8-ad1a-bb85eaf65ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-0fe5e015-f087-42cf-945e-adf0c3c68fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-c6c21349-3d8c-4ce3-a735-56816ae1cac9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-746098255-172.17.0.15-1595637763953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36699,DS-8af6f169-1181-4c7b-924d-7967d6e261ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-d3de98d7-670e-4692-8869-d24c32e34f88,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-fc017646-af1c-4fb1-b5c7-52c2796b0252,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-69b5b602-48a5-47b1-8cfb-30981e8d706d,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-86bc4f1b-4881-4dc7-8a86-8185e563b34c,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-dcf6803c-2a34-4f8f-871e-312d9a5b2da7,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-6491034b-b215-4f4e-8875-191fca37f57f,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-08e3c584-995f-430c-a7a5-c2c0ea22d626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-746098255-172.17.0.15-1595637763953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36699,DS-8af6f169-1181-4c7b-924d-7967d6e261ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-d3de98d7-670e-4692-8869-d24c32e34f88,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-fc017646-af1c-4fb1-b5c7-52c2796b0252,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-69b5b602-48a5-47b1-8cfb-30981e8d706d,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-86bc4f1b-4881-4dc7-8a86-8185e563b34c,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-dcf6803c-2a34-4f8f-871e-312d9a5b2da7,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-6491034b-b215-4f4e-8875-191fca37f57f,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-08e3c584-995f-430c-a7a5-c2c0ea22d626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5475
