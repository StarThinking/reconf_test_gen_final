reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-314575092-172.17.0.16-1595666367189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35972,DS-2149d693-339c-49ff-8c1c-8da10810d7de,DISK], DatanodeInfoWithStorage[127.0.0.1:39518,DS-808a95dc-5782-419a-9026-97e43ddfcdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-4c3a2c40-166b-41a9-86cb-9c55b4dd7174,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-c7d16bb9-0dc3-47d8-b5d7-fbc25cef0ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-ffabf3db-6e7e-4203-bb79-a52e25e673ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-542e5c22-9111-4d20-9cd7-b2c1f5c3ed37,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-3ca394da-10a4-40e6-88bc-7862237a1776,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-92af5160-1d33-4a0d-a520-c47adda18948,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-314575092-172.17.0.16-1595666367189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35972,DS-2149d693-339c-49ff-8c1c-8da10810d7de,DISK], DatanodeInfoWithStorage[127.0.0.1:39518,DS-808a95dc-5782-419a-9026-97e43ddfcdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-4c3a2c40-166b-41a9-86cb-9c55b4dd7174,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-c7d16bb9-0dc3-47d8-b5d7-fbc25cef0ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-ffabf3db-6e7e-4203-bb79-a52e25e673ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-542e5c22-9111-4d20-9cd7-b2c1f5c3ed37,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-3ca394da-10a4-40e6-88bc-7862237a1776,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-92af5160-1d33-4a0d-a520-c47adda18948,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1935660720-172.17.0.16-1595667465203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46206,DS-2050fd30-7ea5-4f14-8301-764b83ee96cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-59edd2cf-bcb8-493a-ad8d-a012ddc61d92,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-47be7bd0-3d98-4178-a57e-1fd308e2c9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-498109a6-0293-4cf0-8a93-8d1d61d96a62,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-51ddf2c3-3c76-4183-8db2-c89e7e856b02,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-4ceab460-219d-40a6-837c-ce38c2d7289b,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-0cf46bd2-3981-4dbd-9ec0-36585ae83777,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-6d4521b6-b848-4ae6-a2ec-ec9dbd82573b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1935660720-172.17.0.16-1595667465203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46206,DS-2050fd30-7ea5-4f14-8301-764b83ee96cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-59edd2cf-bcb8-493a-ad8d-a012ddc61d92,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-47be7bd0-3d98-4178-a57e-1fd308e2c9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-498109a6-0293-4cf0-8a93-8d1d61d96a62,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-51ddf2c3-3c76-4183-8db2-c89e7e856b02,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-4ceab460-219d-40a6-837c-ce38c2d7289b,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-0cf46bd2-3981-4dbd-9ec0-36585ae83777,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-6d4521b6-b848-4ae6-a2ec-ec9dbd82573b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1267856965-172.17.0.16-1595667512456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34234,DS-67a07c92-2abf-4d94-9b29-7d6519d0dee7,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-99c16a09-7a07-4bce-9628-ae1d384051e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-3bdbd768-86ae-4995-8273-512207a10fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:37930,DS-41806023-6c20-4188-9d7e-a2ebaa838726,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-5a36e97f-d073-49dc-a483-422bb52abb86,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-91e85813-5804-489d-bcbb-f9afd8c52a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-aa58d8aa-21ef-47e4-8721-0632ebcfdd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-158d2226-0422-4aa7-97f9-9ffc80628815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1267856965-172.17.0.16-1595667512456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34234,DS-67a07c92-2abf-4d94-9b29-7d6519d0dee7,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-99c16a09-7a07-4bce-9628-ae1d384051e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-3bdbd768-86ae-4995-8273-512207a10fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:37930,DS-41806023-6c20-4188-9d7e-a2ebaa838726,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-5a36e97f-d073-49dc-a483-422bb52abb86,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-91e85813-5804-489d-bcbb-f9afd8c52a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-aa58d8aa-21ef-47e4-8721-0632ebcfdd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-158d2226-0422-4aa7-97f9-9ffc80628815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1975820027-172.17.0.16-1595668102287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43709,DS-eefc0762-4713-4c6b-9337-1f053ffa74a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-e0d73c3d-a1f1-478e-889e-93c51a09d507,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-875e73e5-c232-4629-8720-c1cfc2fc14c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-5e5dd0af-c154-4847-8adb-a1b04ae49600,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-f731d737-7e23-4a49-b3da-964fa74f2d89,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-690d87cb-31a7-4f56-af74-c30511e644a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-a96085c6-406a-4228-b9a8-4f2693a822ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-248f6205-3eb3-441f-a7b2-7cc44097b3fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1975820027-172.17.0.16-1595668102287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43709,DS-eefc0762-4713-4c6b-9337-1f053ffa74a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-e0d73c3d-a1f1-478e-889e-93c51a09d507,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-875e73e5-c232-4629-8720-c1cfc2fc14c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-5e5dd0af-c154-4847-8adb-a1b04ae49600,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-f731d737-7e23-4a49-b3da-964fa74f2d89,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-690d87cb-31a7-4f56-af74-c30511e644a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-a96085c6-406a-4228-b9a8-4f2693a822ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-248f6205-3eb3-441f-a7b2-7cc44097b3fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1506299750-172.17.0.16-1595668521628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45405,DS-5c24d1ec-ed42-430b-940a-0bb5a79c4a65,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-02dbd958-0c14-47b0-8e3f-14a65435169a,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-ae2cfbef-5a11-4aaa-9e1a-5450a6bde68c,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-2a532f2a-809b-46b1-ae5b-837f687127e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-2b55d333-a7ad-400b-98b0-5e38aa664135,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-a0d56f2a-f2a9-424b-8444-46e2ce7b823f,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-31d7d63e-80ba-4827-b1c7-8f4fffabbe4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-085fbd86-3c11-4790-b52b-2294c5b2917c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1506299750-172.17.0.16-1595668521628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45405,DS-5c24d1ec-ed42-430b-940a-0bb5a79c4a65,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-02dbd958-0c14-47b0-8e3f-14a65435169a,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-ae2cfbef-5a11-4aaa-9e1a-5450a6bde68c,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-2a532f2a-809b-46b1-ae5b-837f687127e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-2b55d333-a7ad-400b-98b0-5e38aa664135,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-a0d56f2a-f2a9-424b-8444-46e2ce7b823f,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-31d7d63e-80ba-4827-b1c7-8f4fffabbe4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-085fbd86-3c11-4790-b52b-2294c5b2917c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043667904-172.17.0.16-1595668635276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40452,DS-63bf47c7-a3b4-48b2-a25b-76983562ec1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-b9fd0bad-5a0d-4c71-a6e5-d2fc02e922c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-ed1cdcf4-4fd3-4698-80af-179916c0b9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-7d60f2d0-31f4-4c1f-bb04-084f1c44fd89,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-2f68b05a-bae9-4182-814a-1ac348f8c1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-d53f6151-e648-49c8-ad0f-1212824014d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-f9cb4bce-2c4d-435e-894d-04598b992a83,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-13f6c76b-3b68-4387-ae96-14b6fdb89ff3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043667904-172.17.0.16-1595668635276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40452,DS-63bf47c7-a3b4-48b2-a25b-76983562ec1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-b9fd0bad-5a0d-4c71-a6e5-d2fc02e922c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-ed1cdcf4-4fd3-4698-80af-179916c0b9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-7d60f2d0-31f4-4c1f-bb04-084f1c44fd89,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-2f68b05a-bae9-4182-814a-1ac348f8c1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-d53f6151-e648-49c8-ad0f-1212824014d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-f9cb4bce-2c4d-435e-894d-04598b992a83,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-13f6c76b-3b68-4387-ae96-14b6fdb89ff3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1537059990-172.17.0.16-1595670629384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35082,DS-8f743e4c-d6ff-4f71-b40e-40d9780051ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-6ffd5c3e-ef60-4114-96cb-cf57a50e9335,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-bace6f2e-af44-4304-befd-1dedfc7187c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-2fbeec97-0667-47dd-8631-49e5c0f15b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-403167a4-b038-43d6-a075-f14c6ae05dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-c9d1790d-64a0-43e4-8240-3efe6c2a773a,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-b7821363-f81a-47b8-a361-fd59de37e42b,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-6c51753e-df29-454f-a5f0-4d0cebc47760,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1537059990-172.17.0.16-1595670629384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35082,DS-8f743e4c-d6ff-4f71-b40e-40d9780051ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-6ffd5c3e-ef60-4114-96cb-cf57a50e9335,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-bace6f2e-af44-4304-befd-1dedfc7187c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-2fbeec97-0667-47dd-8631-49e5c0f15b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-403167a4-b038-43d6-a075-f14c6ae05dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-c9d1790d-64a0-43e4-8240-3efe6c2a773a,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-b7821363-f81a-47b8-a361-fd59de37e42b,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-6c51753e-df29-454f-a5f0-4d0cebc47760,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2012395048-172.17.0.16-1595671086031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46566,DS-66d08c76-a1ef-449c-b220-23dd4d019cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-07811242-0b08-49c6-9d01-bdebf7280f10,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-fa9a7277-783c-471d-a1f2-16b7072cc071,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-1584ae7e-d4bf-4cca-b768-1c0e115b2c22,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-496fc844-610c-40fe-861d-6401a02dfa09,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-054bedd8-40de-4312-bead-d96c373fbb66,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-929386c3-0c6d-42c7-b2e0-5301da0dc942,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-f362a4f0-d5c0-46b5-8900-d386fb5f3ccd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2012395048-172.17.0.16-1595671086031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46566,DS-66d08c76-a1ef-449c-b220-23dd4d019cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-07811242-0b08-49c6-9d01-bdebf7280f10,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-fa9a7277-783c-471d-a1f2-16b7072cc071,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-1584ae7e-d4bf-4cca-b768-1c0e115b2c22,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-496fc844-610c-40fe-861d-6401a02dfa09,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-054bedd8-40de-4312-bead-d96c373fbb66,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-929386c3-0c6d-42c7-b2e0-5301da0dc942,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-f362a4f0-d5c0-46b5-8900-d386fb5f3ccd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1280769168-172.17.0.16-1595671401489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39415,DS-85e27a29-173f-4aa7-b1eb-8ceec2352165,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-7d63e6bb-722b-4376-a579-d26f2ee229b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-1e674934-0fae-4dfd-bb83-74e8cc87cf9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-952aa1aa-8175-401d-ba7d-d28dd488002d,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-dd1b21ee-4405-4ff7-bf53-f5b6ee58f54e,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-aadb7380-367a-40d7-9b3a-7968e89d53ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-abab6442-7b6d-4592-afef-3d6da5827396,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-2d1d26f3-3c92-4d62-92b2-6538c1354a1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1280769168-172.17.0.16-1595671401489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39415,DS-85e27a29-173f-4aa7-b1eb-8ceec2352165,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-7d63e6bb-722b-4376-a579-d26f2ee229b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-1e674934-0fae-4dfd-bb83-74e8cc87cf9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-952aa1aa-8175-401d-ba7d-d28dd488002d,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-dd1b21ee-4405-4ff7-bf53-f5b6ee58f54e,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-aadb7380-367a-40d7-9b3a-7968e89d53ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-abab6442-7b6d-4592-afef-3d6da5827396,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-2d1d26f3-3c92-4d62-92b2-6538c1354a1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371869122-172.17.0.16-1595671571782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33377,DS-2279218a-e7a3-4325-913a-8647a8006d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-5c757bee-76c8-498f-b61a-18ce5e194ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-e5cc7a1f-23ea-4127-801e-ac5945ce0691,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-e638f40a-3a63-42f8-9d93-d293564854c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-a96eff3d-178b-4932-b41b-c7aefc91f3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-5cbc668a-0665-475f-a4e3-ef2c21198618,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-5e752d26-3ac8-4bd1-910d-cc602cbf6463,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-2acb2bab-55a1-4add-8ff2-62199f546515,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371869122-172.17.0.16-1595671571782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33377,DS-2279218a-e7a3-4325-913a-8647a8006d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-5c757bee-76c8-498f-b61a-18ce5e194ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-e5cc7a1f-23ea-4127-801e-ac5945ce0691,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-e638f40a-3a63-42f8-9d93-d293564854c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-a96eff3d-178b-4932-b41b-c7aefc91f3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-5cbc668a-0665-475f-a4e3-ef2c21198618,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-5e752d26-3ac8-4bd1-910d-cc602cbf6463,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-2acb2bab-55a1-4add-8ff2-62199f546515,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1326690995-172.17.0.16-1595671756602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46840,DS-152a6c7f-ffe9-471d-8cbb-c1ffb7d527c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-8868dc4a-e32b-42fb-b6ca-f307ba727481,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-b679033c-1e7b-45a6-bda4-cdba0aee5e37,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-74cd9a1e-0248-4c19-9705-c226246cf492,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-87bb7946-0396-4139-b084-02606ffd8db4,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-6234b8c0-13fb-4c27-ae20-abc5a909d97b,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-190ff80a-746a-41c8-9015-04d7522fbb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-b37a30a5-4207-4225-b54c-fe2d193a47a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1326690995-172.17.0.16-1595671756602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46840,DS-152a6c7f-ffe9-471d-8cbb-c1ffb7d527c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-8868dc4a-e32b-42fb-b6ca-f307ba727481,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-b679033c-1e7b-45a6-bda4-cdba0aee5e37,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-74cd9a1e-0248-4c19-9705-c226246cf492,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-87bb7946-0396-4139-b084-02606ffd8db4,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-6234b8c0-13fb-4c27-ae20-abc5a909d97b,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-190ff80a-746a-41c8-9015-04d7522fbb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-b37a30a5-4207-4225-b54c-fe2d193a47a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5700
