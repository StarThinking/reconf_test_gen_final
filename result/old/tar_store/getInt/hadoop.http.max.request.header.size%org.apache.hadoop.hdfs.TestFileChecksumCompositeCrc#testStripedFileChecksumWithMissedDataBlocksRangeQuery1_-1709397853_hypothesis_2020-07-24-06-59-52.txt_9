reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-965669984-172.17.0.11-1595574052485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40828,DS-c6e864d0-4f73-4485-90c9-95286753708d,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-23f2522e-9223-4a6c-b314-83d7234f33b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-7c6e4862-8709-4c08-804d-ff83ba1f1809,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-5707b8ca-062a-4438-90ad-2f1c6056fb58,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-dc767faa-edfe-4766-a89e-6ea71ec5726d,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-2982c9a7-d9e3-43fd-b447-2ea19f61edaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-9b1c8dec-b30c-4a09-b26e-b2bb758dfd47,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-6276c97c-4c08-4b0b-bac1-802d0ba08ad8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-965669984-172.17.0.11-1595574052485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40828,DS-c6e864d0-4f73-4485-90c9-95286753708d,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-23f2522e-9223-4a6c-b314-83d7234f33b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-7c6e4862-8709-4c08-804d-ff83ba1f1809,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-5707b8ca-062a-4438-90ad-2f1c6056fb58,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-dc767faa-edfe-4766-a89e-6ea71ec5726d,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-2982c9a7-d9e3-43fd-b447-2ea19f61edaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-9b1c8dec-b30c-4a09-b26e-b2bb758dfd47,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-6276c97c-4c08-4b0b-bac1-802d0ba08ad8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956928479-172.17.0.11-1595575487742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34379,DS-6b976143-e71c-4374-91b0-57db8cd7fcac,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-e3681c3e-c87f-412f-9421-585a30963d86,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-4366d66c-a711-4224-8809-f9cbf4b5fe6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-b8b275f6-7df7-47bb-b809-d2252e9e55f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-971b8623-ff0b-479f-bd1a-9f0b2b44bece,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-fc382172-9228-4f5c-9409-8085950e6006,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-46a4ce5e-ce55-46df-8b14-3f511ba6a1de,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-e50e8f2f-5fe6-4e0c-a382-1a20d40a72a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956928479-172.17.0.11-1595575487742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34379,DS-6b976143-e71c-4374-91b0-57db8cd7fcac,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-e3681c3e-c87f-412f-9421-585a30963d86,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-4366d66c-a711-4224-8809-f9cbf4b5fe6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-b8b275f6-7df7-47bb-b809-d2252e9e55f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-971b8623-ff0b-479f-bd1a-9f0b2b44bece,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-fc382172-9228-4f5c-9409-8085950e6006,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-46a4ce5e-ce55-46df-8b14-3f511ba6a1de,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-e50e8f2f-5fe6-4e0c-a382-1a20d40a72a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500309872-172.17.0.11-1595576460846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44458,DS-51c720d1-2ece-4175-9fde-8a56c00d579c,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-011e5d89-2c25-4700-ac70-03afa99211dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-f00d4719-2df2-4706-918b-ea89cbe873ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-54fac325-f205-4a40-bb28-6e202853bc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-ee25a754-ba53-4ada-99d8-dcf123a96557,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-4a9c7acb-e0d9-4f37-90f9-f1bd6c088d67,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-3b589247-cc52-4ce0-a993-0726ae04786a,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-fd4a3e16-dabc-4888-a781-cbe79bed0382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500309872-172.17.0.11-1595576460846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44458,DS-51c720d1-2ece-4175-9fde-8a56c00d579c,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-011e5d89-2c25-4700-ac70-03afa99211dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-f00d4719-2df2-4706-918b-ea89cbe873ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-54fac325-f205-4a40-bb28-6e202853bc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-ee25a754-ba53-4ada-99d8-dcf123a96557,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-4a9c7acb-e0d9-4f37-90f9-f1bd6c088d67,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-3b589247-cc52-4ce0-a993-0726ae04786a,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-fd4a3e16-dabc-4888-a781-cbe79bed0382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761122617-172.17.0.11-1595576496075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39455,DS-712c64f2-b4d0-4a00-9fd8-91024b2c6334,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-e2872cea-8fb9-433c-850a-17e001d36d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-4fc479df-e5b5-4590-aa5e-b31b8c809feb,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-5e63ca71-9060-451c-9bc9-3c1d3285f1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-88b984de-82b5-4b58-ab23-a24927281d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-cd777290-c408-4343-a5b4-92b74a111ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-98e397ee-fc5b-4aea-bd30-397a42fe6594,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-9d0cb12a-146e-419c-9439-fa547033cda6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761122617-172.17.0.11-1595576496075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39455,DS-712c64f2-b4d0-4a00-9fd8-91024b2c6334,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-e2872cea-8fb9-433c-850a-17e001d36d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-4fc479df-e5b5-4590-aa5e-b31b8c809feb,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-5e63ca71-9060-451c-9bc9-3c1d3285f1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-88b984de-82b5-4b58-ab23-a24927281d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-cd777290-c408-4343-a5b4-92b74a111ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-98e397ee-fc5b-4aea-bd30-397a42fe6594,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-9d0cb12a-146e-419c-9439-fa547033cda6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21901774-172.17.0.11-1595576703126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40916,DS-9c527b53-a992-425f-aa58-9c13bab597bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-21013e7c-74ed-4de7-a9ae-16c798853b45,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-4089bd7c-86d3-4411-91ea-50cda2137a70,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-08d460a0-9db9-4881-ba2e-e2977429e51c,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-9de3b1a2-105e-456d-ad10-5521eba33171,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-7d188d7e-db76-4e6c-ba19-13202242ea55,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-5be52761-0ed9-42b5-bd98-7d98e483470f,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-7885469e-a7bd-44bc-b3be-0713acd95ab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21901774-172.17.0.11-1595576703126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40916,DS-9c527b53-a992-425f-aa58-9c13bab597bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-21013e7c-74ed-4de7-a9ae-16c798853b45,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-4089bd7c-86d3-4411-91ea-50cda2137a70,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-08d460a0-9db9-4881-ba2e-e2977429e51c,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-9de3b1a2-105e-456d-ad10-5521eba33171,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-7d188d7e-db76-4e6c-ba19-13202242ea55,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-5be52761-0ed9-42b5-bd98-7d98e483470f,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-7885469e-a7bd-44bc-b3be-0713acd95ab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518383594-172.17.0.11-1595576861402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45540,DS-fba4aa97-6ae8-4d3d-a7fa-4bd66e0a0e33,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-d5f4e030-60bd-4942-8431-00bda944eb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-cc2c7e2b-3a27-4fff-8b88-fda502ff1f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-3e32dff7-6a85-4ffa-bf7a-470d8005ac6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-114a83dd-75e1-4308-8593-0e510a19dc01,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-189ef565-e288-42f4-aee9-811d150c0f37,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-874b2f2b-c26f-409e-9730-aa495f61c370,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-1e41f89d-4348-4f27-abeb-df664785c85b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518383594-172.17.0.11-1595576861402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45540,DS-fba4aa97-6ae8-4d3d-a7fa-4bd66e0a0e33,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-d5f4e030-60bd-4942-8431-00bda944eb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-cc2c7e2b-3a27-4fff-8b88-fda502ff1f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-3e32dff7-6a85-4ffa-bf7a-470d8005ac6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-114a83dd-75e1-4308-8593-0e510a19dc01,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-189ef565-e288-42f4-aee9-811d150c0f37,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-874b2f2b-c26f-409e-9730-aa495f61c370,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-1e41f89d-4348-4f27-abeb-df664785c85b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908459457-172.17.0.11-1595577182028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37938,DS-bf506856-6600-40de-8b5c-6549f2543208,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-6ececdc0-b3e6-4c74-a075-0792bdf25bac,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-65c4bab3-a0a8-449c-8caf-5c34ecd40895,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-cc08887d-eb3b-4fcc-ad24-c83b2a552b83,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-2e6cd484-7995-414b-8983-1a9b4d8cbf46,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-913308b4-af4f-4a3b-9771-eb9d5b30f1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-09eddab9-929e-4a56-b2b1-2b8b179b7189,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-72f4feda-9a4c-4ef5-9e8a-e54eb3894078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908459457-172.17.0.11-1595577182028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37938,DS-bf506856-6600-40de-8b5c-6549f2543208,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-6ececdc0-b3e6-4c74-a075-0792bdf25bac,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-65c4bab3-a0a8-449c-8caf-5c34ecd40895,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-cc08887d-eb3b-4fcc-ad24-c83b2a552b83,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-2e6cd484-7995-414b-8983-1a9b4d8cbf46,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-913308b4-af4f-4a3b-9771-eb9d5b30f1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-09eddab9-929e-4a56-b2b1-2b8b179b7189,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-72f4feda-9a4c-4ef5-9e8a-e54eb3894078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638180308-172.17.0.11-1595577349932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38965,DS-1ed85390-e4db-49fb-8d3e-19440791f634,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-e6d7d761-3b27-4ea0-8576-c52a64be347e,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-75d118f6-8ba4-4f20-9984-e6743d8599b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-04045a40-b324-4f6a-b0d9-1d2a3e33a45e,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-051c87da-8486-41ae-b5d9-ca37009a69a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-8c3b5ec9-4f96-4e13-8164-cd4ea0595487,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-7f025409-ce90-4f86-97e8-2ed2225a9274,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-2e0682c1-b85a-4e41-9034-8065e48b7552,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638180308-172.17.0.11-1595577349932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38965,DS-1ed85390-e4db-49fb-8d3e-19440791f634,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-e6d7d761-3b27-4ea0-8576-c52a64be347e,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-75d118f6-8ba4-4f20-9984-e6743d8599b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-04045a40-b324-4f6a-b0d9-1d2a3e33a45e,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-051c87da-8486-41ae-b5d9-ca37009a69a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-8c3b5ec9-4f96-4e13-8164-cd4ea0595487,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-7f025409-ce90-4f86-97e8-2ed2225a9274,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-2e0682c1-b85a-4e41-9034-8065e48b7552,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835137539-172.17.0.11-1595577610990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39982,DS-2435a7d1-a1c6-4861-87d0-dc0cfa0479a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-281a7690-c810-44dc-8278-e8719e85b7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-104e4bcb-2368-436a-8479-74b6ae38042f,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-290cf550-8813-4707-a537-2be01325415e,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-9bdda9f3-6a81-4a61-a927-c770427ca597,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-759aea77-7119-4a68-8391-b858a0910762,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-2e409bd5-c666-42e0-a0d9-7bd125544b99,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-33dcc684-1855-46c9-a495-9f43fe4f294c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835137539-172.17.0.11-1595577610990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39982,DS-2435a7d1-a1c6-4861-87d0-dc0cfa0479a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-281a7690-c810-44dc-8278-e8719e85b7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-104e4bcb-2368-436a-8479-74b6ae38042f,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-290cf550-8813-4707-a537-2be01325415e,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-9bdda9f3-6a81-4a61-a927-c770427ca597,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-759aea77-7119-4a68-8391-b858a0910762,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-2e409bd5-c666-42e0-a0d9-7bd125544b99,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-33dcc684-1855-46c9-a495-9f43fe4f294c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1912401986-172.17.0.11-1595577834547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46092,DS-a262c4d4-3115-46d4-b727-e5e995489f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43379,DS-0431bf61-5550-41e4-aa19-934fc7ad5a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-fa2d6f48-9980-4a94-b3eb-065c8d046b29,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-d7f5d450-c7be-492a-9e00-1203171a9a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-3c504000-9765-4ff6-b7ba-afce8cc6f82d,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-2494ff21-7fd2-4f8a-a289-ee8ac8dc7507,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-97d35942-d0eb-4b1b-b82b-653bf25d01b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-4f94c484-ce15-4440-8aef-92725ac19116,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1912401986-172.17.0.11-1595577834547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46092,DS-a262c4d4-3115-46d4-b727-e5e995489f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43379,DS-0431bf61-5550-41e4-aa19-934fc7ad5a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-fa2d6f48-9980-4a94-b3eb-065c8d046b29,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-d7f5d450-c7be-492a-9e00-1203171a9a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-3c504000-9765-4ff6-b7ba-afce8cc6f82d,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-2494ff21-7fd2-4f8a-a289-ee8ac8dc7507,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-97d35942-d0eb-4b1b-b82b-653bf25d01b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-4f94c484-ce15-4440-8aef-92725ac19116,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-678448703-172.17.0.11-1595577921611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44151,DS-072eb71f-aefb-4ddd-a572-57e89a359449,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-8a6f397b-0782-416f-ad34-89cd94d19b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-ec9d62de-b7d4-403c-a4ac-c6f5a6a9c7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-79516dab-042b-44c7-8a82-3fe6b7f38349,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-996e74a4-b7e4-4ae3-9f04-1cdf21ae2599,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-af000001-16ee-4432-8104-544bcee37207,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-9be27f0f-4dcc-480f-885c-c3dc40db9552,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-35e28273-da77-4c14-b693-82d755d0d828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-678448703-172.17.0.11-1595577921611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44151,DS-072eb71f-aefb-4ddd-a572-57e89a359449,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-8a6f397b-0782-416f-ad34-89cd94d19b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-ec9d62de-b7d4-403c-a4ac-c6f5a6a9c7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-79516dab-042b-44c7-8a82-3fe6b7f38349,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-996e74a4-b7e4-4ae3-9f04-1cdf21ae2599,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-af000001-16ee-4432-8104-544bcee37207,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-9be27f0f-4dcc-480f-885c-c3dc40db9552,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-35e28273-da77-4c14-b693-82d755d0d828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383280489-172.17.0.11-1595578685516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44827,DS-ea47e70b-3753-40a9-94f5-da5950036203,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-8e409657-0507-4acc-b9a4-b0dca15955b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-84d8e5b5-dfc1-448f-9b7f-c692cefcdf93,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-0ce085bc-9a96-413f-9938-98cbb7397836,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-1e62a308-cfe4-4efa-9061-958a9fbabdef,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-c86f2b68-ef95-4303-b958-38679dbfcf76,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-aac1d049-26ab-45e2-b4e8-37cfa782397b,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-786ee999-1f68-440a-8954-0369b285a95a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383280489-172.17.0.11-1595578685516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44827,DS-ea47e70b-3753-40a9-94f5-da5950036203,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-8e409657-0507-4acc-b9a4-b0dca15955b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-84d8e5b5-dfc1-448f-9b7f-c692cefcdf93,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-0ce085bc-9a96-413f-9938-98cbb7397836,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-1e62a308-cfe4-4efa-9061-958a9fbabdef,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-c86f2b68-ef95-4303-b958-38679dbfcf76,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-aac1d049-26ab-45e2-b4e8-37cfa782397b,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-786ee999-1f68-440a-8954-0369b285a95a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-433116768-172.17.0.11-1595578770361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36907,DS-120e3d4e-3908-4bbe-ae32-19dfd013fc11,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-f01e7efa-ab5e-4dd2-9ac5-b17640a3c45a,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-ad95206d-0133-44da-8ee7-d6e3000aa070,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-85882629-595a-4a55-82b3-a1b3c87eba5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-522d5da3-82df-4cfe-ace7-3b7a936ff439,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-80ca87df-11d5-418d-970c-1a029b4aad51,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-2f07e8a6-da9b-4093-930b-a4cbe5768796,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-0df7d7e4-6fa2-4611-8759-f604155cdbc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-433116768-172.17.0.11-1595578770361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36907,DS-120e3d4e-3908-4bbe-ae32-19dfd013fc11,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-f01e7efa-ab5e-4dd2-9ac5-b17640a3c45a,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-ad95206d-0133-44da-8ee7-d6e3000aa070,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-85882629-595a-4a55-82b3-a1b3c87eba5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-522d5da3-82df-4cfe-ace7-3b7a936ff439,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-80ca87df-11d5-418d-970c-1a029b4aad51,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-2f07e8a6-da9b-4093-930b-a4cbe5768796,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-0df7d7e4-6fa2-4611-8759-f604155cdbc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1989846850-172.17.0.11-1595578854831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34406,DS-d5421867-63fd-4e41-9b10-3ed2227ba6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-655de9e4-afa0-45f5-a586-c44dd4b04dab,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-42cceacc-bf12-4cae-a052-ab4e99e97f64,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-83aa61e3-e097-48c6-9638-838ac0a9d505,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-350446db-40d8-4b4e-9733-a47013313d58,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-d1f89751-7662-45b2-be73-72f7ee7d9fee,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-b5c1aa07-371b-48b6-887b-d1faa8fbaa5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-51fb42df-c64a-4358-b2c9-3fc9be3adfc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1989846850-172.17.0.11-1595578854831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34406,DS-d5421867-63fd-4e41-9b10-3ed2227ba6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-655de9e4-afa0-45f5-a586-c44dd4b04dab,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-42cceacc-bf12-4cae-a052-ab4e99e97f64,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-83aa61e3-e097-48c6-9638-838ac0a9d505,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-350446db-40d8-4b4e-9733-a47013313d58,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-d1f89751-7662-45b2-be73-72f7ee7d9fee,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-b5c1aa07-371b-48b6-887b-d1faa8fbaa5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-51fb42df-c64a-4358-b2c9-3fc9be3adfc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520808988-172.17.0.11-1595579018593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35840,DS-97c9f6e9-5079-4a9d-903d-5b094b16a9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-43f18a1b-a8f6-47fb-a0d6-1ffdf6a6fd72,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-e2825913-b0c5-4711-993b-6faad69fc229,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-b67a4b9f-1630-4ea7-9255-81b46591c425,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-44d0b72a-cbdb-4372-b2c1-4621f010fa98,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-1aabdb49-c77a-40f6-ba15-2a79f935e1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-517b244d-238a-42cc-9da6-43cb3c5dafb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-12dc0415-9f3a-46e0-ac28-b9c48891b5de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520808988-172.17.0.11-1595579018593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35840,DS-97c9f6e9-5079-4a9d-903d-5b094b16a9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-43f18a1b-a8f6-47fb-a0d6-1ffdf6a6fd72,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-e2825913-b0c5-4711-993b-6faad69fc229,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-b67a4b9f-1630-4ea7-9255-81b46591c425,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-44d0b72a-cbdb-4372-b2c1-4621f010fa98,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-1aabdb49-c77a-40f6-ba15-2a79f935e1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-517b244d-238a-42cc-9da6-43cb3c5dafb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-12dc0415-9f3a-46e0-ac28-b9c48891b5de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5835
