reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1828940894-172.17.0.16-1595710057828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43284,DS-7d540778-d7a9-43a5-b97c-67be502287d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35866,DS-c05be2d1-24ef-46c5-a115-25924e37df34,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-98d94e19-792c-4c0c-9a20-f509de86e7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-f82bdd2d-8a72-4273-b3c1-c82951e61aec,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-f831b9aa-26d6-4b16-abf7-1226195f6e10,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-e3c1c76c-67db-4226-b025-f2e49b7f3056,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-8cb15dae-73eb-4b23-ace6-b16a48ec8798,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-4e916804-3167-44da-abc8-f41d0fba38f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1828940894-172.17.0.16-1595710057828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43284,DS-7d540778-d7a9-43a5-b97c-67be502287d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35866,DS-c05be2d1-24ef-46c5-a115-25924e37df34,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-98d94e19-792c-4c0c-9a20-f509de86e7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-f82bdd2d-8a72-4273-b3c1-c82951e61aec,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-f831b9aa-26d6-4b16-abf7-1226195f6e10,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-e3c1c76c-67db-4226-b025-f2e49b7f3056,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-8cb15dae-73eb-4b23-ace6-b16a48ec8798,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-4e916804-3167-44da-abc8-f41d0fba38f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612282219-172.17.0.16-1595710138320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41320,DS-2df43fd6-ebf1-403c-9794-c1f20f77a78e,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-431f889e-70df-4ba7-9ca9-64cf380ba524,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-8787ebab-7161-4d71-8d8c-d30f8105f272,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-876d5644-6093-4938-87cf-5a6cbc0ea3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-fd8d0ce7-b1c0-42d6-b644-be28288b6ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-a75f34a8-9877-4fdd-b9b6-ee518365b6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-fad93b1d-5a12-4eef-b443-bc3f9c103fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-438c4d97-5eb4-4acb-8fb8-1ae30a7af5fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612282219-172.17.0.16-1595710138320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41320,DS-2df43fd6-ebf1-403c-9794-c1f20f77a78e,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-431f889e-70df-4ba7-9ca9-64cf380ba524,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-8787ebab-7161-4d71-8d8c-d30f8105f272,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-876d5644-6093-4938-87cf-5a6cbc0ea3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-fd8d0ce7-b1c0-42d6-b644-be28288b6ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-a75f34a8-9877-4fdd-b9b6-ee518365b6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-fad93b1d-5a12-4eef-b443-bc3f9c103fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-438c4d97-5eb4-4acb-8fb8-1ae30a7af5fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-340780679-172.17.0.16-1595710179369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45248,DS-22794fa7-6972-4567-840d-3aca0d3ba6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-64294852-8229-4316-8651-e675cacc5d78,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-750ce0e0-a6df-4481-bc28-04efcb4d8805,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-ed1b8491-2e12-473b-8a5e-91bf59580a80,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-8ba2ce48-53cb-47a4-aa7f-e0502dda6389,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-5decd8fb-efc9-4000-b075-03698800524e,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-0108b0bb-9039-4d02-b4d4-9261b341f7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-6e603d0e-efae-43b4-ab48-0829302a423f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-340780679-172.17.0.16-1595710179369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45248,DS-22794fa7-6972-4567-840d-3aca0d3ba6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-64294852-8229-4316-8651-e675cacc5d78,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-750ce0e0-a6df-4481-bc28-04efcb4d8805,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-ed1b8491-2e12-473b-8a5e-91bf59580a80,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-8ba2ce48-53cb-47a4-aa7f-e0502dda6389,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-5decd8fb-efc9-4000-b075-03698800524e,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-0108b0bb-9039-4d02-b4d4-9261b341f7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-6e603d0e-efae-43b4-ab48-0829302a423f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1435560323-172.17.0.16-1595710318994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46074,DS-e6ca4b25-7501-4d70-86e7-3a5f672af54f,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-c8c9faf5-facf-49a7-aa85-0cc8cd68f4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-6da9b6e9-79af-4d34-861d-bb7933ed104a,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-11718f46-a735-40a2-a745-e5ff6db6e46a,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-5d99c90e-750d-436e-a8a2-04117dbe8112,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-bac4ff0b-b41d-4c59-8286-a8140097017d,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-a8f4b9a0-68ac-4c2c-9c11-4cafba53f94a,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-91532b39-89cb-4aa6-8d5f-cf3ad5c6ad10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1435560323-172.17.0.16-1595710318994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46074,DS-e6ca4b25-7501-4d70-86e7-3a5f672af54f,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-c8c9faf5-facf-49a7-aa85-0cc8cd68f4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-6da9b6e9-79af-4d34-861d-bb7933ed104a,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-11718f46-a735-40a2-a745-e5ff6db6e46a,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-5d99c90e-750d-436e-a8a2-04117dbe8112,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-bac4ff0b-b41d-4c59-8286-a8140097017d,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-a8f4b9a0-68ac-4c2c-9c11-4cafba53f94a,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-91532b39-89cb-4aa6-8d5f-cf3ad5c6ad10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994752817-172.17.0.16-1595710512726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39473,DS-a9fd45bf-fe25-48a7-8e01-81b138567539,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-87e74327-9765-44c8-9c82-985d2394adfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-3d39378a-3a5d-4b2c-8052-7300d64d0c50,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-c917f964-c7c1-45d9-9400-8152e9b9f05e,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-a342b333-af6c-4717-833b-365752761875,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-aa060fbd-b157-4525-b93a-4a8e9dd4d24f,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-bd4993ee-0ba3-451d-9449-2ccbef31c997,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-1d7dd936-e08c-4f2d-8cd0-1c93772c9be8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994752817-172.17.0.16-1595710512726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39473,DS-a9fd45bf-fe25-48a7-8e01-81b138567539,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-87e74327-9765-44c8-9c82-985d2394adfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-3d39378a-3a5d-4b2c-8052-7300d64d0c50,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-c917f964-c7c1-45d9-9400-8152e9b9f05e,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-a342b333-af6c-4717-833b-365752761875,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-aa060fbd-b157-4525-b93a-4a8e9dd4d24f,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-bd4993ee-0ba3-451d-9449-2ccbef31c997,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-1d7dd936-e08c-4f2d-8cd0-1c93772c9be8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963121277-172.17.0.16-1595711027009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41948,DS-44de9a6a-42fa-41ff-9ffc-4ba79547abdc,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-1e39fc67-88a5-4385-84ba-177823e2089c,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-5200d06e-d917-45e2-a28d-e7d691732550,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-fbd5d587-1929-41b7-ab35-71e9f0750d94,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-c67bda8b-8950-4d43-9395-92f38ff28824,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-1b5d3887-06a0-4617-a223-92f7ca65c3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-2b67b2db-dab5-4945-a7e2-49e1883a0103,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-0c78654d-b6c1-4802-8a2d-f9749d4c76f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963121277-172.17.0.16-1595711027009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41948,DS-44de9a6a-42fa-41ff-9ffc-4ba79547abdc,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-1e39fc67-88a5-4385-84ba-177823e2089c,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-5200d06e-d917-45e2-a28d-e7d691732550,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-fbd5d587-1929-41b7-ab35-71e9f0750d94,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-c67bda8b-8950-4d43-9395-92f38ff28824,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-1b5d3887-06a0-4617-a223-92f7ca65c3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-2b67b2db-dab5-4945-a7e2-49e1883a0103,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-0c78654d-b6c1-4802-8a2d-f9749d4c76f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2117509467-172.17.0.16-1595711100576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37751,DS-925db9f8-07f6-4a1e-ab52-33fad7d27e96,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-e36fe07d-7bd3-40fc-b710-379ccdfc2f78,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-a818cdc2-bc35-4868-9a49-296f2c4b7356,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-e8fe6ebd-a1e9-4af2-993f-c2375f2340b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-cdfb7365-76a3-4550-a37a-ed93872e28d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-33181aa4-4cbb-4af0-8443-ba106920891f,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-f518a4bc-bd01-4859-b018-74f2971d1796,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-7db1534d-da21-4516-87a0-648f8e6b01bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2117509467-172.17.0.16-1595711100576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37751,DS-925db9f8-07f6-4a1e-ab52-33fad7d27e96,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-e36fe07d-7bd3-40fc-b710-379ccdfc2f78,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-a818cdc2-bc35-4868-9a49-296f2c4b7356,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-e8fe6ebd-a1e9-4af2-993f-c2375f2340b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-cdfb7365-76a3-4550-a37a-ed93872e28d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-33181aa4-4cbb-4af0-8443-ba106920891f,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-f518a4bc-bd01-4859-b018-74f2971d1796,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-7db1534d-da21-4516-87a0-648f8e6b01bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1277933636-172.17.0.16-1595711389375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46090,DS-08f09c8c-30db-4737-afca-8ed568d1ba69,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-a20f73db-20a2-496f-8b7b-11dc1184752e,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-648d512e-5106-46b2-8261-7685dd5f8c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-0828db8f-fe24-4945-a6dd-3dde4ce06dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-c2047029-d387-4883-8567-3bdec1304dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-cca45239-12fa-45bc-8b4d-72c8942728c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-584c6848-e108-4852-969f-251b143ff777,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-ab3a727c-04d2-4047-8cd9-57e8bf4eb7e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1277933636-172.17.0.16-1595711389375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46090,DS-08f09c8c-30db-4737-afca-8ed568d1ba69,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-a20f73db-20a2-496f-8b7b-11dc1184752e,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-648d512e-5106-46b2-8261-7685dd5f8c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-0828db8f-fe24-4945-a6dd-3dde4ce06dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-c2047029-d387-4883-8567-3bdec1304dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-cca45239-12fa-45bc-8b4d-72c8942728c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-584c6848-e108-4852-969f-251b143ff777,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-ab3a727c-04d2-4047-8cd9-57e8bf4eb7e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257795672-172.17.0.16-1595711632291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44168,DS-90dcd92b-d52e-4409-b415-fd7d79f97741,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-f636504f-bbec-4052-85d3-387a741d161e,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-687cc47b-7f57-4f02-a2d6-7a8be385aa08,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-091ae8c8-25e5-4b0a-83b1-509b8351da6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-93b46763-309e-4e12-934e-834f8ae81235,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-b96d5b56-9daf-4a11-b747-ecfc713c2e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-a8536ced-3d0c-4a83-999c-ce6ea0c24b60,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-e6dee2e0-ebd9-4bef-99c7-2cf491a0b682,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257795672-172.17.0.16-1595711632291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44168,DS-90dcd92b-d52e-4409-b415-fd7d79f97741,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-f636504f-bbec-4052-85d3-387a741d161e,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-687cc47b-7f57-4f02-a2d6-7a8be385aa08,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-091ae8c8-25e5-4b0a-83b1-509b8351da6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-93b46763-309e-4e12-934e-834f8ae81235,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-b96d5b56-9daf-4a11-b747-ecfc713c2e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-a8536ced-3d0c-4a83-999c-ce6ea0c24b60,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-e6dee2e0-ebd9-4bef-99c7-2cf491a0b682,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977574183-172.17.0.16-1595711849242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41851,DS-a1592b5a-f43a-47a3-840a-cbdc0486f4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-83103848-f7d8-4b57-85cf-73002e0b54cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-8e902278-ca59-489a-adad-97dfd560fe3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-98903a0b-dcda-44b4-bf0a-e93fcdbb9c04,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-8d6b4705-76cf-4516-b306-0cdb671bc5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-4133cf76-ed59-4604-8fd5-11a8dec62be2,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-774622dd-825d-4331-83ab-9928dc4af426,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-daea68b9-08a0-46b6-ae92-bdc8aed73cbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977574183-172.17.0.16-1595711849242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41851,DS-a1592b5a-f43a-47a3-840a-cbdc0486f4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-83103848-f7d8-4b57-85cf-73002e0b54cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-8e902278-ca59-489a-adad-97dfd560fe3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-98903a0b-dcda-44b4-bf0a-e93fcdbb9c04,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-8d6b4705-76cf-4516-b306-0cdb671bc5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-4133cf76-ed59-4604-8fd5-11a8dec62be2,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-774622dd-825d-4331-83ab-9928dc4af426,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-daea68b9-08a0-46b6-ae92-bdc8aed73cbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864696622-172.17.0.16-1595712549421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39379,DS-b34e32ab-8d21-4134-b404-ea2d866fa9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-61879c7e-b29e-402c-806f-660e8157205e,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-f591c439-e089-4cc9-9e83-4d68b0f21c57,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-8b1e53de-5f06-4f88-951f-95d1613e13f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-4d83a1d3-7bda-45ef-a9e4-8588ed2182b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-58d4b38f-bf6b-46a1-a7ae-fce88a147a51,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-e86765fa-4f5d-4fdc-a87d-47ab099bd94e,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-67f599f1-c20c-4e7a-ba73-f7c7d5316933,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864696622-172.17.0.16-1595712549421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39379,DS-b34e32ab-8d21-4134-b404-ea2d866fa9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-61879c7e-b29e-402c-806f-660e8157205e,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-f591c439-e089-4cc9-9e83-4d68b0f21c57,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-8b1e53de-5f06-4f88-951f-95d1613e13f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-4d83a1d3-7bda-45ef-a9e4-8588ed2182b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-58d4b38f-bf6b-46a1-a7ae-fce88a147a51,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-e86765fa-4f5d-4fdc-a87d-47ab099bd94e,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-67f599f1-c20c-4e7a-ba73-f7c7d5316933,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186044687-172.17.0.16-1595712618265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44517,DS-5b30075b-ad46-4ccf-8775-dc398d2685cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-43e465f3-e081-4853-9b77-1b979bcb9045,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-1b230247-c989-49c1-a018-20fd5263e361,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-a4c96a9a-9674-43ec-bdd5-55e7e558b5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-747ae0fd-007b-4852-830b-dc63eaefbd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-6c187709-7865-4af7-881e-6db7fb11499a,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-540f5cc6-4662-4ec8-8aac-37ed715aed4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-65f87505-d186-4a4d-bea3-efaae4b58967,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186044687-172.17.0.16-1595712618265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44517,DS-5b30075b-ad46-4ccf-8775-dc398d2685cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-43e465f3-e081-4853-9b77-1b979bcb9045,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-1b230247-c989-49c1-a018-20fd5263e361,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-a4c96a9a-9674-43ec-bdd5-55e7e558b5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-747ae0fd-007b-4852-830b-dc63eaefbd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-6c187709-7865-4af7-881e-6db7fb11499a,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-540f5cc6-4662-4ec8-8aac-37ed715aed4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-65f87505-d186-4a4d-bea3-efaae4b58967,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-429483876-172.17.0.16-1595712742755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45651,DS-02073fed-64f6-4b8a-a878-c9b527f6cfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-9b4d916e-d1de-45d4-9186-1f49738ac7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-09010657-e665-44aa-80c0-b7edd3f31f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-ad61d5cc-6010-45e1-9c8a-e68a7c3ff21a,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-4292c8ac-dc58-42d6-9d95-c851fbfe7b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-c1c0cafe-a23e-4610-8cf0-1830dbc96537,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-aae16d72-49d4-4970-b15d-cecae59e7048,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-20ad958a-b4cc-49b8-8487-f25082da7ea6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-429483876-172.17.0.16-1595712742755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45651,DS-02073fed-64f6-4b8a-a878-c9b527f6cfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-9b4d916e-d1de-45d4-9186-1f49738ac7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-09010657-e665-44aa-80c0-b7edd3f31f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-ad61d5cc-6010-45e1-9c8a-e68a7c3ff21a,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-4292c8ac-dc58-42d6-9d95-c851fbfe7b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-c1c0cafe-a23e-4610-8cf0-1830dbc96537,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-aae16d72-49d4-4970-b15d-cecae59e7048,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-20ad958a-b4cc-49b8-8487-f25082da7ea6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-769197322-172.17.0.16-1595713275113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33361,DS-d6890ee8-6f7f-4b90-b20d-97e101cb96e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-d1a72319-3d71-48d2-9606-06138a06c6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-f8551702-cdfe-401c-a4c1-ac5fdac4a72c,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-03535716-ad7b-4649-8a51-c75e74bada67,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-14e0d997-cea7-43ff-ae65-33ab5bb39c96,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-00ecc784-cfd0-4bf6-b13c-2cbc56b35c94,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-7b835660-0005-4a48-98e3-763721a06079,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-25c6f203-755e-48c4-aebf-178d81fc5d51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-769197322-172.17.0.16-1595713275113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33361,DS-d6890ee8-6f7f-4b90-b20d-97e101cb96e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-d1a72319-3d71-48d2-9606-06138a06c6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-f8551702-cdfe-401c-a4c1-ac5fdac4a72c,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-03535716-ad7b-4649-8a51-c75e74bada67,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-14e0d997-cea7-43ff-ae65-33ab5bb39c96,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-00ecc784-cfd0-4bf6-b13c-2cbc56b35c94,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-7b835660-0005-4a48-98e3-763721a06079,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-25c6f203-755e-48c4-aebf-178d81fc5d51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105755737-172.17.0.16-1595713314848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45478,DS-58e24ef0-3d1c-4980-93dc-77a0ca99506b,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-d7ae9d4e-f4c8-4b50-aa5e-083ab1595a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-66484030-e909-419c-83c9-1e04b11b5c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-78baae7f-9995-4a79-be73-d3f17ea1683b,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-6bba490e-4f99-46c7-bc74-bc7fab7774db,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-2f89a58e-3b5a-4c61-a790-6ba79966387b,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-0a65fe7f-2ac3-451e-a571-c90189036ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-88bcb6db-7f72-43bc-bcba-ea4c962317d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105755737-172.17.0.16-1595713314848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45478,DS-58e24ef0-3d1c-4980-93dc-77a0ca99506b,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-d7ae9d4e-f4c8-4b50-aa5e-083ab1595a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-66484030-e909-419c-83c9-1e04b11b5c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-78baae7f-9995-4a79-be73-d3f17ea1683b,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-6bba490e-4f99-46c7-bc74-bc7fab7774db,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-2f89a58e-3b5a-4c61-a790-6ba79966387b,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-0a65fe7f-2ac3-451e-a571-c90189036ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-88bcb6db-7f72-43bc-bcba-ea4c962317d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408498516-172.17.0.16-1595713615970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35848,DS-274edfa4-5225-4eba-8322-d96670bd6681,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-ff24f9ba-5135-4960-a2d5-b0091fa497e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-9a0b624b-ef8a-4dd8-ae68-2f18bf4552e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-f63c8b46-bd20-4970-b787-eee0663b5b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-4e8989cf-8afd-4b59-8ca9-9fb2f9fc0774,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-bd21cdc5-62ab-482c-aa60-111b385e24e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-0b54662d-e345-46f1-a78d-e0d92b8cc6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-e20f7d78-e227-42de-acae-8e25d579521d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408498516-172.17.0.16-1595713615970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35848,DS-274edfa4-5225-4eba-8322-d96670bd6681,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-ff24f9ba-5135-4960-a2d5-b0091fa497e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-9a0b624b-ef8a-4dd8-ae68-2f18bf4552e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-f63c8b46-bd20-4970-b787-eee0663b5b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-4e8989cf-8afd-4b59-8ca9-9fb2f9fc0774,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-bd21cdc5-62ab-482c-aa60-111b385e24e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-0b54662d-e345-46f1-a78d-e0d92b8cc6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-e20f7d78-e227-42de-acae-8e25d579521d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274413612-172.17.0.16-1595714439926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36976,DS-11de6699-c6d5-40d8-ac8b-49fa96b19e27,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-58f21edf-624c-4f6e-8fd4-017867ed0ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-8452f42d-50e3-4982-a2b1-2754a11e2425,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-79b0a5e9-1250-450f-93da-7232e3b6913d,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-7e47e9bb-5525-4ca7-aed5-88cc0cd9ad3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-3ade09cb-e930-4a62-83c8-d485671e0c99,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-a43770ca-a735-466e-96f1-9c14de388c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-a5b0b7fe-a707-4691-ac4f-d009452cfb71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274413612-172.17.0.16-1595714439926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36976,DS-11de6699-c6d5-40d8-ac8b-49fa96b19e27,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-58f21edf-624c-4f6e-8fd4-017867ed0ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-8452f42d-50e3-4982-a2b1-2754a11e2425,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-79b0a5e9-1250-450f-93da-7232e3b6913d,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-7e47e9bb-5525-4ca7-aed5-88cc0cd9ad3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-3ade09cb-e930-4a62-83c8-d485671e0c99,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-a43770ca-a735-466e-96f1-9c14de388c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-a5b0b7fe-a707-4691-ac4f-d009452cfb71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-450188131-172.17.0.16-1595714473195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40590,DS-31ed1091-c6c2-4f30-ab7c-ecd1aebbf983,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-9b27ddb3-b4e0-48c4-9c80-196b2a3fafae,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-6f7cb3bf-4d46-4f6f-8afc-d3d7b9fb4919,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-ee4ed271-39be-48d7-8e36-0124baedf5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-cb0b91cf-2bf3-4cbe-9bd6-9477c5498418,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-c7ae1f78-a323-4b88-b77e-a0c42bbf7f80,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-bbc28406-fd86-41f9-b8a0-708ef331fb47,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-4515c41f-f02c-4c15-816b-0a320a257c44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-450188131-172.17.0.16-1595714473195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40590,DS-31ed1091-c6c2-4f30-ab7c-ecd1aebbf983,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-9b27ddb3-b4e0-48c4-9c80-196b2a3fafae,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-6f7cb3bf-4d46-4f6f-8afc-d3d7b9fb4919,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-ee4ed271-39be-48d7-8e36-0124baedf5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-cb0b91cf-2bf3-4cbe-9bd6-9477c5498418,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-c7ae1f78-a323-4b88-b77e-a0c42bbf7f80,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-bbc28406-fd86-41f9-b8a0-708ef331fb47,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-4515c41f-f02c-4c15-816b-0a320a257c44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614950888-172.17.0.16-1595714672594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39736,DS-f19832b0-1d0d-4e66-928a-597ff130ee4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-3590f814-0dbe-4bbd-92c2-4a06c6df028f,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-2cfd864c-c8f8-461b-8476-0179a43d0123,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-e9e73f27-7f94-411f-b987-0b6cd1edf431,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-23d848a0-e3e9-46d8-85ae-9f184c14381c,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-89c5165b-2a14-4beb-84cb-a53a1feb7a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-a0874b18-a932-4336-a5f5-39251cfff762,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-49d815e0-092b-4002-b934-88c4b6a4a8de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614950888-172.17.0.16-1595714672594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39736,DS-f19832b0-1d0d-4e66-928a-597ff130ee4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-3590f814-0dbe-4bbd-92c2-4a06c6df028f,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-2cfd864c-c8f8-461b-8476-0179a43d0123,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-e9e73f27-7f94-411f-b987-0b6cd1edf431,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-23d848a0-e3e9-46d8-85ae-9f184c14381c,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-89c5165b-2a14-4beb-84cb-a53a1feb7a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-a0874b18-a932-4336-a5f5-39251cfff762,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-49d815e0-092b-4002-b934-88c4b6a4a8de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190391688-172.17.0.16-1595714795535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35687,DS-4d4e54d7-6243-4dd8-ac8e-51f7030d50de,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-f3bcf1a7-b7d8-4dd1-8f43-9655034ba951,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-184fb7a9-1e5b-4a09-9b62-2c4344c033e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-422256e3-ad62-4ad2-9640-7f26ed4165b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-304a6a11-7468-4868-b085-d6bf18779cec,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-5b2d6b1e-64fd-4806-9fb7-fd60295bda01,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-5518f12a-8b7b-4106-b9fb-5a4da08f0277,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-504678cb-767c-4868-85e1-7a1fde758fab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190391688-172.17.0.16-1595714795535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35687,DS-4d4e54d7-6243-4dd8-ac8e-51f7030d50de,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-f3bcf1a7-b7d8-4dd1-8f43-9655034ba951,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-184fb7a9-1e5b-4a09-9b62-2c4344c033e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-422256e3-ad62-4ad2-9640-7f26ed4165b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-304a6a11-7468-4868-b085-d6bf18779cec,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-5b2d6b1e-64fd-4806-9fb7-fd60295bda01,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-5518f12a-8b7b-4106-b9fb-5a4da08f0277,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-504678cb-767c-4868-85e1-7a1fde758fab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-568692823-172.17.0.16-1595714821596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39385,DS-aabf778d-da22-46f3-842f-e1dced0e3f23,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-12799759-3a56-4d9c-acb5-6be0c474d55d,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-80ee8737-484e-41ee-aeb9-cf0d75da5ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-ae6f6d2d-3fcd-4e13-bc67-8e7792bd948a,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-f9f01bb8-0516-4a5b-bd12-84472e70f4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-3eb67db9-2738-4304-98d8-63e5c36af560,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-ab43bfc3-dbfd-47f0-bdc6-adc53403e0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-63b04953-baf1-4f68-9e0e-50675231ec5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-568692823-172.17.0.16-1595714821596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39385,DS-aabf778d-da22-46f3-842f-e1dced0e3f23,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-12799759-3a56-4d9c-acb5-6be0c474d55d,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-80ee8737-484e-41ee-aeb9-cf0d75da5ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-ae6f6d2d-3fcd-4e13-bc67-8e7792bd948a,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-f9f01bb8-0516-4a5b-bd12-84472e70f4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-3eb67db9-2738-4304-98d8-63e5c36af560,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-ab43bfc3-dbfd-47f0-bdc6-adc53403e0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-63b04953-baf1-4f68-9e0e-50675231ec5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5243
