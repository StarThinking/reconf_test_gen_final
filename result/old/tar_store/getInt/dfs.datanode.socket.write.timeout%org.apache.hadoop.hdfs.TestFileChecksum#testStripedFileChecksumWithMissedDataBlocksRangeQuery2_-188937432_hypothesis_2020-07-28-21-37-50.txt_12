reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318487519-172.17.0.18-1595972657107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42627,DS-e3e0f2f2-8158-46d2-9f8e-fb2246853e78,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-6dbb759c-dbec-41b7-b291-e42e9786b718,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-053af156-7ec1-4204-8eed-540cce457e69,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-c14fac8c-aabf-41d2-84d6-7dfadfc42bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-5b2cff2c-2ca3-4e93-808a-927335825924,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-74d64250-4380-4e19-b1d1-93006d50c3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-33e28a58-3498-4a77-b019-d9e64249f012,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-79667308-8c82-4de7-8c60-f613bdd38ae7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318487519-172.17.0.18-1595972657107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42627,DS-e3e0f2f2-8158-46d2-9f8e-fb2246853e78,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-6dbb759c-dbec-41b7-b291-e42e9786b718,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-053af156-7ec1-4204-8eed-540cce457e69,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-c14fac8c-aabf-41d2-84d6-7dfadfc42bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-5b2cff2c-2ca3-4e93-808a-927335825924,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-74d64250-4380-4e19-b1d1-93006d50c3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-33e28a58-3498-4a77-b019-d9e64249f012,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-79667308-8c82-4de7-8c60-f613bdd38ae7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1209759373-172.17.0.18-1595972784319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34973,DS-bfdb96e1-28b3-404f-9993-5a736e7e2e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-f3f15cae-3669-47a0-9318-59b1c25c82a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-e0bd9d6e-3e1e-44d8-9e00-12a8d1b23423,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-51534bf8-60d8-499d-8d4c-de4f297a829f,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-a00b503b-d2cb-424e-b8e1-ef556f7ed581,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-e49110a6-be8b-40e6-bd51-0b8409d204b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-426cf043-c1f8-4f77-9ba1-fc46b034efd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-66db8593-b891-4c9f-b5fa-5cfb1f52f87a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1209759373-172.17.0.18-1595972784319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34973,DS-bfdb96e1-28b3-404f-9993-5a736e7e2e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-f3f15cae-3669-47a0-9318-59b1c25c82a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-e0bd9d6e-3e1e-44d8-9e00-12a8d1b23423,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-51534bf8-60d8-499d-8d4c-de4f297a829f,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-a00b503b-d2cb-424e-b8e1-ef556f7ed581,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-e49110a6-be8b-40e6-bd51-0b8409d204b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-426cf043-c1f8-4f77-9ba1-fc46b034efd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-66db8593-b891-4c9f-b5fa-5cfb1f52f87a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-768675120-172.17.0.18-1595972849705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35004,DS-9a90a8e2-c509-447f-80d2-7ec4c75a574d,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-eb6f535f-d4f8-4ffb-8c49-987dd8c8e98e,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-e3ebca60-1a39-4169-aca5-7d3be6c938c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-6b1f0a61-a041-4d16-ab42-f5fe3df90845,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-f2c45a2a-6c9d-4661-8e0a-3489f3225ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-25476fc6-9fbb-43fd-9bcd-5dc261d70017,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-f7fb2680-2a2f-4481-b85c-ff6f0fb33b51,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-bcfb30b5-336a-4fa5-bc01-2b97d5110bec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-768675120-172.17.0.18-1595972849705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35004,DS-9a90a8e2-c509-447f-80d2-7ec4c75a574d,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-eb6f535f-d4f8-4ffb-8c49-987dd8c8e98e,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-e3ebca60-1a39-4169-aca5-7d3be6c938c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-6b1f0a61-a041-4d16-ab42-f5fe3df90845,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-f2c45a2a-6c9d-4661-8e0a-3489f3225ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-25476fc6-9fbb-43fd-9bcd-5dc261d70017,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-f7fb2680-2a2f-4481-b85c-ff6f0fb33b51,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-bcfb30b5-336a-4fa5-bc01-2b97d5110bec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-813150490-172.17.0.18-1595972941339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41925,DS-2c9d5263-f484-4f23-901b-e65cc68ae591,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-c4a4981a-b721-4de7-ba34-800e9dac2422,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-45b516e4-0114-4a51-a2de-3278e3d5013b,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-342bd583-c922-415d-b01e-85157d09aa97,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-6f5eb974-2d4a-400b-aa70-b2a17f8e6fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-223beec7-7001-417f-a6a0-e2948941c8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-a48787f0-6c59-44ee-9f55-6c8d67bda1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-aa0284ee-c180-4033-9c2b-6c89cac05ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-813150490-172.17.0.18-1595972941339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41925,DS-2c9d5263-f484-4f23-901b-e65cc68ae591,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-c4a4981a-b721-4de7-ba34-800e9dac2422,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-45b516e4-0114-4a51-a2de-3278e3d5013b,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-342bd583-c922-415d-b01e-85157d09aa97,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-6f5eb974-2d4a-400b-aa70-b2a17f8e6fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-223beec7-7001-417f-a6a0-e2948941c8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-a48787f0-6c59-44ee-9f55-6c8d67bda1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-aa0284ee-c180-4033-9c2b-6c89cac05ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577831565-172.17.0.18-1595973216285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37158,DS-adc9f743-ef05-47cc-b1da-dad3ec14de76,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-0a2187d2-bb00-4ef3-8c7e-faa14290ddb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-689f264b-9817-4b44-ad84-ae7dc212e7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-1fb9b257-08ab-4fbb-a03f-87f2363d47ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-7bbad702-c311-4776-a027-24145d3ec2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-8121c0c6-5f7a-46af-bf6e-869316821170,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-c73f6ec9-dfd4-4b03-9201-41719d827fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-1bb6c2f9-0c2a-49b0-8bf0-fbe9583af6f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577831565-172.17.0.18-1595973216285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37158,DS-adc9f743-ef05-47cc-b1da-dad3ec14de76,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-0a2187d2-bb00-4ef3-8c7e-faa14290ddb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-689f264b-9817-4b44-ad84-ae7dc212e7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-1fb9b257-08ab-4fbb-a03f-87f2363d47ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-7bbad702-c311-4776-a027-24145d3ec2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-8121c0c6-5f7a-46af-bf6e-869316821170,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-c73f6ec9-dfd4-4b03-9201-41719d827fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-1bb6c2f9-0c2a-49b0-8bf0-fbe9583af6f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-18055876-172.17.0.18-1595973472376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36251,DS-7088f9a1-a433-4787-adc3-0693f8e30f97,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-22f41ec4-5707-437c-8869-5c0915edd743,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-1351908b-7a92-4081-9fea-8926bcfae0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-3f35e6f1-fc31-4e05-b33d-efa13b70bb02,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-4cfd3bd5-22ec-4271-b3e6-3e2a24aa7e04,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-15a318ea-275b-4d86-8a6e-9140c61817ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-adc8b9e6-3e53-4f37-a983-a010fa970203,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-2d2f9717-015d-4403-9033-1687bff62b24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-18055876-172.17.0.18-1595973472376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36251,DS-7088f9a1-a433-4787-adc3-0693f8e30f97,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-22f41ec4-5707-437c-8869-5c0915edd743,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-1351908b-7a92-4081-9fea-8926bcfae0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-3f35e6f1-fc31-4e05-b33d-efa13b70bb02,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-4cfd3bd5-22ec-4271-b3e6-3e2a24aa7e04,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-15a318ea-275b-4d86-8a6e-9140c61817ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-adc8b9e6-3e53-4f37-a983-a010fa970203,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-2d2f9717-015d-4403-9033-1687bff62b24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-425799671-172.17.0.18-1595973627862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44365,DS-33afba57-04f8-4aa6-8964-27f08c3a342e,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-e66b7b86-2af2-4cef-b25c-5de490bdf023,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-7314575a-b075-4154-99d1-47f3c5613dee,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-3b94b24e-9687-4c7f-bf0c-dd03955c9b78,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-05a1e1df-c6a5-48fa-99ec-7ff5d57c65e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-3356500a-9281-4752-877f-da9325bfcc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-e5e5f362-bb4d-4333-8662-5abc73874d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-abef5b0f-8bad-4dd1-b652-409360f35192,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-425799671-172.17.0.18-1595973627862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44365,DS-33afba57-04f8-4aa6-8964-27f08c3a342e,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-e66b7b86-2af2-4cef-b25c-5de490bdf023,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-7314575a-b075-4154-99d1-47f3c5613dee,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-3b94b24e-9687-4c7f-bf0c-dd03955c9b78,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-05a1e1df-c6a5-48fa-99ec-7ff5d57c65e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-3356500a-9281-4752-877f-da9325bfcc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-e5e5f362-bb4d-4333-8662-5abc73874d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-abef5b0f-8bad-4dd1-b652-409360f35192,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137537503-172.17.0.18-1595973732987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45794,DS-432500c5-ab0e-4bf0-b08d-c9acec160371,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-5936c8b6-7b12-4f74-b929-98efc4652726,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-f5d2983a-ab71-4285-9cfb-f33fc79a47f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-81456025-0da3-4f7a-aac0-2a128eb068db,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-4817a0d1-f178-4a0d-9571-f2ce58b2477a,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-93bcd47c-64e5-420c-8708-1389c5ed4cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-0e30577c-e185-436b-ad5e-b1e77c60b6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-b0758175-4e66-451c-b9fb-f666a41e186d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137537503-172.17.0.18-1595973732987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45794,DS-432500c5-ab0e-4bf0-b08d-c9acec160371,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-5936c8b6-7b12-4f74-b929-98efc4652726,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-f5d2983a-ab71-4285-9cfb-f33fc79a47f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-81456025-0da3-4f7a-aac0-2a128eb068db,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-4817a0d1-f178-4a0d-9571-f2ce58b2477a,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-93bcd47c-64e5-420c-8708-1389c5ed4cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-0e30577c-e185-436b-ad5e-b1e77c60b6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-b0758175-4e66-451c-b9fb-f666a41e186d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383741242-172.17.0.18-1595974700495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38050,DS-67e1a08c-ad83-4011-982c-29b1e1c1ebed,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-c4d442f7-b7af-4710-9206-53a66e1d741f,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-3056e9db-c0ac-437f-aea7-0f00b85cfa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-4bc902bd-ad7b-447f-b434-08ea10390b34,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-10d25b54-88e1-49e7-aaf3-625677e56854,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-1478666b-f84f-425c-9430-cc71adcababb,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-8a7e2072-aa02-4f26-8cb0-f07a16545203,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-b3c36d58-067f-4fb6-9334-d436a7c9182c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383741242-172.17.0.18-1595974700495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38050,DS-67e1a08c-ad83-4011-982c-29b1e1c1ebed,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-c4d442f7-b7af-4710-9206-53a66e1d741f,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-3056e9db-c0ac-437f-aea7-0f00b85cfa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-4bc902bd-ad7b-447f-b434-08ea10390b34,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-10d25b54-88e1-49e7-aaf3-625677e56854,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-1478666b-f84f-425c-9430-cc71adcababb,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-8a7e2072-aa02-4f26-8cb0-f07a16545203,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-b3c36d58-067f-4fb6-9334-d436a7c9182c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778262729-172.17.0.18-1595974851296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42657,DS-5e700485-ad36-4037-93f5-e80f47daf58d,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-473fce88-674c-4d2f-8f9b-9987f16e0633,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-def37733-8eba-4e55-bfce-8c069276a750,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-aad57130-a576-472d-9280-6df84d5ae821,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-a466a012-a65e-4404-9cbb-8c5ec7bef3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-250b9f43-eb7f-49c1-8280-9335ad07bf54,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-a30392e4-f545-427c-987c-e4197a51c29f,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-30724c13-8311-403c-a21b-d33777e8088f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778262729-172.17.0.18-1595974851296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42657,DS-5e700485-ad36-4037-93f5-e80f47daf58d,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-473fce88-674c-4d2f-8f9b-9987f16e0633,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-def37733-8eba-4e55-bfce-8c069276a750,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-aad57130-a576-472d-9280-6df84d5ae821,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-a466a012-a65e-4404-9cbb-8c5ec7bef3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-250b9f43-eb7f-49c1-8280-9335ad07bf54,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-a30392e4-f545-427c-987c-e4197a51c29f,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-30724c13-8311-403c-a21b-d33777e8088f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514519775-172.17.0.18-1595975147525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44362,DS-0280384d-34ef-409f-be04-2cd0019690df,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-85f7b4c7-d8f0-447a-bfb8-d5f57b2cb081,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-8136b25a-316d-49d9-af73-1b162449a4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-67618c5d-e32d-4d75-8b88-8564422793c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-030c9c8f-6a8d-4cce-af2d-e1ccf5c61418,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-a32a2b46-fddd-48e4-90c7-5bbd7deb3020,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-44af08ac-7766-4d22-9208-076acd150347,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-ecf17582-c9b9-4106-b155-724cbbacc36d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514519775-172.17.0.18-1595975147525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44362,DS-0280384d-34ef-409f-be04-2cd0019690df,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-85f7b4c7-d8f0-447a-bfb8-d5f57b2cb081,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-8136b25a-316d-49d9-af73-1b162449a4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-67618c5d-e32d-4d75-8b88-8564422793c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-030c9c8f-6a8d-4cce-af2d-e1ccf5c61418,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-a32a2b46-fddd-48e4-90c7-5bbd7deb3020,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-44af08ac-7766-4d22-9208-076acd150347,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-ecf17582-c9b9-4106-b155-724cbbacc36d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020647335-172.17.0.18-1595975267789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35058,DS-b5c8d691-7068-4667-a237-735b5a0bd3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-b6ac6b75-2688-42cb-8944-bc52d34d6968,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-26b58eb0-07fd-4894-9d2a-62d555a37dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-7e879495-e6e6-4aac-8b40-236308eca0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-52edf88d-2d95-417e-aec6-d2c912ac4f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-68066d57-484a-4e7d-87d7-e5b66de124f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-feca333b-8153-41d2-bb99-b4b1d09889c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-6c6b1a52-0e14-430e-a315-aa71d887f8d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020647335-172.17.0.18-1595975267789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35058,DS-b5c8d691-7068-4667-a237-735b5a0bd3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-b6ac6b75-2688-42cb-8944-bc52d34d6968,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-26b58eb0-07fd-4894-9d2a-62d555a37dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-7e879495-e6e6-4aac-8b40-236308eca0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-52edf88d-2d95-417e-aec6-d2c912ac4f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-68066d57-484a-4e7d-87d7-e5b66de124f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-feca333b-8153-41d2-bb99-b4b1d09889c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-6c6b1a52-0e14-430e-a315-aa71d887f8d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-177764946-172.17.0.18-1595975690055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46563,DS-907f60d1-667b-4ce1-b527-f2825ccbe0da,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-23fb2ee2-b532-4897-ae8e-96c7b590a35c,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-f24358d1-22a9-4d2c-a30f-07dbafb2e6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-27da1365-a65f-446c-897c-b81bbfb9b109,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-b742857c-9ee9-4ed0-926f-a1a7998032c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-c74104b2-c229-4655-8cea-351b3f03b791,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-e25cab0b-81cb-4837-ab23-ac45b2186c41,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-204f4ae8-1f27-45f6-9665-1ad1cd196f03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-177764946-172.17.0.18-1595975690055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46563,DS-907f60d1-667b-4ce1-b527-f2825ccbe0da,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-23fb2ee2-b532-4897-ae8e-96c7b590a35c,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-f24358d1-22a9-4d2c-a30f-07dbafb2e6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-27da1365-a65f-446c-897c-b81bbfb9b109,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-b742857c-9ee9-4ed0-926f-a1a7998032c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-c74104b2-c229-4655-8cea-351b3f03b791,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-e25cab0b-81cb-4837-ab23-ac45b2186c41,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-204f4ae8-1f27-45f6-9665-1ad1cd196f03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252395055-172.17.0.18-1595976006222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32775,DS-f510aa03-e8dc-45d3-b19e-a46a96c8d187,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-c94935af-270c-4557-83ad-2e16c44d5c01,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-b8e9fcde-3593-4b2f-88aa-cb7f0997a98e,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-00e6a202-01b5-4ea4-a740-4a3db24078e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-7b6c62be-c18a-4836-9f8b-f9e88821ad1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-39b5083d-3d4a-47fb-ba36-83767f506c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-3a02b107-e1f5-4207-b4ce-2c3f9f85f76c,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-44482bca-7384-4f59-80da-08a019f47274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252395055-172.17.0.18-1595976006222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32775,DS-f510aa03-e8dc-45d3-b19e-a46a96c8d187,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-c94935af-270c-4557-83ad-2e16c44d5c01,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-b8e9fcde-3593-4b2f-88aa-cb7f0997a98e,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-00e6a202-01b5-4ea4-a740-4a3db24078e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-7b6c62be-c18a-4836-9f8b-f9e88821ad1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-39b5083d-3d4a-47fb-ba36-83767f506c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-3a02b107-e1f5-4207-b4ce-2c3f9f85f76c,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-44482bca-7384-4f59-80da-08a019f47274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616296908-172.17.0.18-1595976043266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45670,DS-4037559d-0559-403c-9fee-0c5fddfdd4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-fdb0f097-4782-434d-9f54-ef70ff55aedf,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-888e472c-f43d-4358-946b-0f8b34aff30f,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-04a24dea-716e-456f-a55b-1715e2471f67,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-141d8286-ffaf-4251-9696-8bc22445fc20,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-db0eba26-add1-4c53-a473-fa1d09ee8ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-4cca01ea-22c3-4956-92e0-04b92cadabbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-c5b9b24d-54c2-4613-88d3-c04180e5e4c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616296908-172.17.0.18-1595976043266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45670,DS-4037559d-0559-403c-9fee-0c5fddfdd4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-fdb0f097-4782-434d-9f54-ef70ff55aedf,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-888e472c-f43d-4358-946b-0f8b34aff30f,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-04a24dea-716e-456f-a55b-1715e2471f67,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-141d8286-ffaf-4251-9696-8bc22445fc20,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-db0eba26-add1-4c53-a473-fa1d09ee8ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-4cca01ea-22c3-4956-92e0-04b92cadabbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-c5b9b24d-54c2-4613-88d3-c04180e5e4c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278668436-172.17.0.18-1595976881655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44054,DS-8f126b93-1e13-4aea-be15-3c8b84146e70,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-36c89032-56f4-4196-9810-ba676494f7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-9465c753-aac6-425a-bdbb-b6f553687d80,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-c812af51-4e0b-481e-a2e4-6fb2ea9e8add,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-f8cb6171-1f2f-41ab-9315-6648640ea5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-77a8be57-5cdf-4861-aa56-518419eef9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-b42252dd-6852-4704-94b3-1afdc92cb141,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-d8fbabb3-6baf-4445-af29-9293c4ca8c8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278668436-172.17.0.18-1595976881655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44054,DS-8f126b93-1e13-4aea-be15-3c8b84146e70,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-36c89032-56f4-4196-9810-ba676494f7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-9465c753-aac6-425a-bdbb-b6f553687d80,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-c812af51-4e0b-481e-a2e4-6fb2ea9e8add,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-f8cb6171-1f2f-41ab-9315-6648640ea5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-77a8be57-5cdf-4861-aa56-518419eef9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-b42252dd-6852-4704-94b3-1afdc92cb141,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-d8fbabb3-6baf-4445-af29-9293c4ca8c8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2054743858-172.17.0.18-1595976946352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40237,DS-013301b0-4937-42be-aa71-071fe21fafe1,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-62c7f231-7052-4a51-a184-8fe74964f29b,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-0bfa5fce-9e02-483c-b5fc-31f2c0c3f4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-e1a2f2cc-8df9-46b3-bcd4-b97fa658ecdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-b3ddbb9e-ee11-4b55-8e06-5973917d7fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-328b024e-5381-45f7-abdd-d29de96a7364,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-66d6d41d-9bf8-47fa-a4c6-45f250814ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-46f99f3d-ca24-4340-906d-05999a10459b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2054743858-172.17.0.18-1595976946352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40237,DS-013301b0-4937-42be-aa71-071fe21fafe1,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-62c7f231-7052-4a51-a184-8fe74964f29b,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-0bfa5fce-9e02-483c-b5fc-31f2c0c3f4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-e1a2f2cc-8df9-46b3-bcd4-b97fa658ecdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-b3ddbb9e-ee11-4b55-8e06-5973917d7fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-328b024e-5381-45f7-abdd-d29de96a7364,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-66d6d41d-9bf8-47fa-a4c6-45f250814ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-46f99f3d-ca24-4340-906d-05999a10459b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232341485-172.17.0.18-1595977150054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37017,DS-de20aba8-bc3f-4c8c-bf54-4807db0f7d86,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-781a60c0-c150-489b-ad14-ed6178f249df,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-98df0e80-01a1-46c1-9759-210fe71c68ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-beb6b530-c23e-47b4-a82d-1c5dbf387670,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-38c96407-879b-4220-9124-86d59cc1cae7,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-6a387e82-212c-499f-8a6f-b539efe503e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-c334b5c3-7fec-4e89-aac6-3cf13cc48df4,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-d965d579-172b-4300-b9b0-19a3b38d0fa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232341485-172.17.0.18-1595977150054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37017,DS-de20aba8-bc3f-4c8c-bf54-4807db0f7d86,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-781a60c0-c150-489b-ad14-ed6178f249df,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-98df0e80-01a1-46c1-9759-210fe71c68ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-beb6b530-c23e-47b4-a82d-1c5dbf387670,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-38c96407-879b-4220-9124-86d59cc1cae7,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-6a387e82-212c-499f-8a6f-b539efe503e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-c334b5c3-7fec-4e89-aac6-3cf13cc48df4,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-d965d579-172b-4300-b9b0-19a3b38d0fa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1871779002-172.17.0.18-1595977216092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43835,DS-0dae5610-14c5-4d4f-af4c-053cca5e1529,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-ebc03a1c-aa35-47c2-880d-59391f94457b,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-d638fe44-2daa-4ab2-b100-dbb1c99e4d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-2b3d2484-2467-4d38-9b1b-bcfda7064182,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-979743f5-3ed7-4785-91d4-cc724e556520,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-b20b01ee-95e4-4d8a-a191-dfe1a3cda7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-54adbe71-7439-4019-acbc-1b6f950591a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-f22cfee2-3852-4738-95a7-f654b434d3f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1871779002-172.17.0.18-1595977216092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43835,DS-0dae5610-14c5-4d4f-af4c-053cca5e1529,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-ebc03a1c-aa35-47c2-880d-59391f94457b,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-d638fe44-2daa-4ab2-b100-dbb1c99e4d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-2b3d2484-2467-4d38-9b1b-bcfda7064182,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-979743f5-3ed7-4785-91d4-cc724e556520,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-b20b01ee-95e4-4d8a-a191-dfe1a3cda7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-54adbe71-7439-4019-acbc-1b6f950591a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-f22cfee2-3852-4738-95a7-f654b434d3f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2101309978-172.17.0.18-1595977251296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33985,DS-44db0051-0017-4456-9ad4-fb2adf6697fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-782f8f26-bdbf-45f0-a98b-ac20f72b86ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-b880040e-5512-48a0-923d-38f375f73a16,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-cf472db4-7098-4fcc-a54a-ecad32bd5eea,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-f673ba67-2dae-45df-91db-17033beba137,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-671551b0-96b9-4137-bf0b-3edcde30229c,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-fa4637c2-4f05-4c9f-b3f6-c2d6438fa954,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-cfcc9914-5de5-432e-9739-c38e3f00bcd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2101309978-172.17.0.18-1595977251296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33985,DS-44db0051-0017-4456-9ad4-fb2adf6697fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-782f8f26-bdbf-45f0-a98b-ac20f72b86ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-b880040e-5512-48a0-923d-38f375f73a16,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-cf472db4-7098-4fcc-a54a-ecad32bd5eea,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-f673ba67-2dae-45df-91db-17033beba137,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-671551b0-96b9-4137-bf0b-3edcde30229c,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-fa4637c2-4f05-4c9f-b3f6-c2d6438fa954,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-cfcc9914-5de5-432e-9739-c38e3f00bcd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053812805-172.17.0.18-1595977403021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33215,DS-75fe9121-adc6-4460-9907-46755f9ae8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-daaddfae-10be-41c5-bd79-af4230fa0292,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-d3e1fbb0-7b25-4f67-9d0a-f037aa6682ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-27c9881f-ed6a-4f86-bcc8-5674919ef2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-f75e4c21-7f98-448c-81ed-5473bdb12cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-13e98c0d-2a3d-4115-9d40-8b84098d4544,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-6a29d295-e6f4-43ba-b39d-6d64ace25b47,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-14619012-47dd-4b6f-9ef2-c18e9a1a96f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053812805-172.17.0.18-1595977403021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33215,DS-75fe9121-adc6-4460-9907-46755f9ae8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-daaddfae-10be-41c5-bd79-af4230fa0292,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-d3e1fbb0-7b25-4f67-9d0a-f037aa6682ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-27c9881f-ed6a-4f86-bcc8-5674919ef2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-f75e4c21-7f98-448c-81ed-5473bdb12cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-13e98c0d-2a3d-4115-9d40-8b84098d4544,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-6a29d295-e6f4-43ba-b39d-6d64ace25b47,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-14619012-47dd-4b6f-9ef2-c18e9a1a96f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5271
