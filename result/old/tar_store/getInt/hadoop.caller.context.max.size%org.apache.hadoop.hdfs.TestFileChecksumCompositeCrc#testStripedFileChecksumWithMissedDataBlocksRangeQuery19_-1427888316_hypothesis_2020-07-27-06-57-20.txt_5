reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 8
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 8
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2098024168-172.17.0.20-1595833355977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40757,DS-4d963f93-a012-41b2-990f-63fd9e379814,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-0c31d899-e4a9-4d83-a4b6-963b442ecad7,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-3bdf0c74-e5d6-4033-adfe-5381afcc04eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-7d807e28-83bb-4b94-9b4d-8d300f2269f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-9978f945-6a4d-4142-9d15-0b99316a4faa,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-62c1d481-183d-4932-ae4c-f3663542be05,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-c1fbdc8b-0e53-4898-bca4-95f3eedd19a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-849d5578-a5ec-41c9-884b-1429adb45b23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2098024168-172.17.0.20-1595833355977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40757,DS-4d963f93-a012-41b2-990f-63fd9e379814,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-0c31d899-e4a9-4d83-a4b6-963b442ecad7,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-3bdf0c74-e5d6-4033-adfe-5381afcc04eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-7d807e28-83bb-4b94-9b4d-8d300f2269f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-9978f945-6a4d-4142-9d15-0b99316a4faa,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-62c1d481-183d-4932-ae4c-f3663542be05,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-c1fbdc8b-0e53-4898-bca4-95f3eedd19a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-849d5578-a5ec-41c9-884b-1429adb45b23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 8
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1692099670-172.17.0.20-1595833499556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33653,DS-e41f0a88-d709-4d50-b562-40be0997c714,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-5f5e1b12-4ca3-4c62-9f9f-91aae58b4ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-c333e910-b201-4f97-80ea-b4af1f9ce925,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-0201ac39-bfc7-4b3f-b886-0090e3744463,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-8cdc636d-94fa-4098-a181-1db38492cb48,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-7c26a741-a2d7-4e75-b1ce-0df287630ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-498ba624-e5ae-4d9e-b40f-c5a56e6573e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-3bafbd3a-7ec9-4ce0-a0af-5b2503eac1f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1692099670-172.17.0.20-1595833499556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33653,DS-e41f0a88-d709-4d50-b562-40be0997c714,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-5f5e1b12-4ca3-4c62-9f9f-91aae58b4ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-c333e910-b201-4f97-80ea-b4af1f9ce925,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-0201ac39-bfc7-4b3f-b886-0090e3744463,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-8cdc636d-94fa-4098-a181-1db38492cb48,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-7c26a741-a2d7-4e75-b1ce-0df287630ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-498ba624-e5ae-4d9e-b40f-c5a56e6573e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-3bafbd3a-7ec9-4ce0-a0af-5b2503eac1f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 8
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683124731-172.17.0.20-1595833571377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45424,DS-05291bb6-4304-4d2f-bdd3-c4e8fafe066d,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-9ab05ce8-8c8e-49b2-9d7d-b5306410b801,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-86c405e8-775f-4784-af9b-5b87fa85a137,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-ea3f55e4-bcfa-49bd-97c6-6d93f1dfc366,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-2dba80ca-11b3-4beb-84a9-1743f1566dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-aee71c2c-b618-4e0e-815f-ee7db6afe491,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-8f3dc99c-6202-4b65-8392-8149569f7dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-022f4bef-74f3-4bd4-b469-1dfb0b974272,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683124731-172.17.0.20-1595833571377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45424,DS-05291bb6-4304-4d2f-bdd3-c4e8fafe066d,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-9ab05ce8-8c8e-49b2-9d7d-b5306410b801,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-86c405e8-775f-4784-af9b-5b87fa85a137,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-ea3f55e4-bcfa-49bd-97c6-6d93f1dfc366,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-2dba80ca-11b3-4beb-84a9-1743f1566dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-aee71c2c-b618-4e0e-815f-ee7db6afe491,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-8f3dc99c-6202-4b65-8392-8149569f7dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-022f4bef-74f3-4bd4-b469-1dfb0b974272,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 8
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2092142710-172.17.0.20-1595833778609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41277,DS-89254ae6-cef6-4efb-af5e-dbec3ea614bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-4c43ddcb-8b4a-4e6d-a63c-ec305e1bc2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-b4c989df-f7d7-4c1f-b661-97f92eb4038b,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-62c46460-9289-4e32-8738-fc3ffe21c9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-d166b33f-cc45-4c5d-8210-c39d2c998926,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-0b1e474f-34f7-49e3-8b5a-0f5685d7565c,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-c0815678-5c60-4bda-8cad-bbab7447783b,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-88e40734-8b8b-40a7-b6fb-8484c470c685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2092142710-172.17.0.20-1595833778609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41277,DS-89254ae6-cef6-4efb-af5e-dbec3ea614bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-4c43ddcb-8b4a-4e6d-a63c-ec305e1bc2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-b4c989df-f7d7-4c1f-b661-97f92eb4038b,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-62c46460-9289-4e32-8738-fc3ffe21c9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-d166b33f-cc45-4c5d-8210-c39d2c998926,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-0b1e474f-34f7-49e3-8b5a-0f5685d7565c,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-c0815678-5c60-4bda-8cad-bbab7447783b,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-88e40734-8b8b-40a7-b6fb-8484c470c685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 8
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1139331858-172.17.0.20-1595834166449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35949,DS-c73a0b50-1f22-46cc-ae83-3fcf439680f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-5e86435d-4047-49b6-95a0-f5c047cd9023,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-59db0f6d-6010-4f92-9bec-a7f880bec0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-a7e4ce85-20bb-4dd4-9354-3baa16d54280,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-b040be51-626c-4348-998f-10d50d1ccd08,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-ff77bb23-c7d7-4f85-8084-b5ce56afc6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-974b45bc-5306-449b-8f63-f357dde1dc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-511f1aa4-f742-4b59-90ee-b0dcf186df3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1139331858-172.17.0.20-1595834166449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35949,DS-c73a0b50-1f22-46cc-ae83-3fcf439680f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-5e86435d-4047-49b6-95a0-f5c047cd9023,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-59db0f6d-6010-4f92-9bec-a7f880bec0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-a7e4ce85-20bb-4dd4-9354-3baa16d54280,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-b040be51-626c-4348-998f-10d50d1ccd08,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-ff77bb23-c7d7-4f85-8084-b5ce56afc6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-974b45bc-5306-449b-8f63-f357dde1dc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-511f1aa4-f742-4b59-90ee-b0dcf186df3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 8
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1242811184-172.17.0.20-1595834796188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33699,DS-36ff3310-30fb-4a7d-8343-611d082253c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-a5294402-acf2-4cf8-9abd-8e8f0f816831,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-ef428d9b-159b-47a4-95da-958cf408c4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-9a313080-f17a-461c-b006-026d4125389e,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-c16c0acf-c238-41e3-9422-ea894b9d8b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-8ed281d8-5ba4-4028-b425-63f2fd98209a,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-363dfd1c-ab18-4566-a40f-ebef7589a286,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-a832f3ec-73fa-421c-8ee0-b7851a8ae6e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1242811184-172.17.0.20-1595834796188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33699,DS-36ff3310-30fb-4a7d-8343-611d082253c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-a5294402-acf2-4cf8-9abd-8e8f0f816831,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-ef428d9b-159b-47a4-95da-958cf408c4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-9a313080-f17a-461c-b006-026d4125389e,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-c16c0acf-c238-41e3-9422-ea894b9d8b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-8ed281d8-5ba4-4028-b425-63f2fd98209a,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-363dfd1c-ab18-4566-a40f-ebef7589a286,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-a832f3ec-73fa-421c-8ee0-b7851a8ae6e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 8
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-47135347-172.17.0.20-1595834882739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45977,DS-c3e303e5-c087-4d72-9e21-0d0924582455,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-9dbb3ae2-b23c-49f3-9f5e-43799888711e,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-9b4a1bc3-ba81-4309-b32b-50035a63fa8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-68f170c5-6121-4c9f-b2d7-ecc0a7a1bdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-364b3d0c-7005-4d37-ac98-0a4ed997aad0,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-35dcd22b-4fdb-492f-a576-dc8e7a1a0f21,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-4d36505c-7a07-49f6-93f2-df3aabbca612,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-9d19c1e6-81dc-4338-8faf-a075d6f1fe29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-47135347-172.17.0.20-1595834882739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45977,DS-c3e303e5-c087-4d72-9e21-0d0924582455,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-9dbb3ae2-b23c-49f3-9f5e-43799888711e,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-9b4a1bc3-ba81-4309-b32b-50035a63fa8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-68f170c5-6121-4c9f-b2d7-ecc0a7a1bdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-364b3d0c-7005-4d37-ac98-0a4ed997aad0,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-35dcd22b-4fdb-492f-a576-dc8e7a1a0f21,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-4d36505c-7a07-49f6-93f2-df3aabbca612,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-9d19c1e6-81dc-4338-8faf-a075d6f1fe29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 8
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1014151463-172.17.0.20-1595835087054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40424,DS-e09644da-6316-4eb7-8ff1-1112d354ff5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-79c677b4-e400-44e8-acce-4b7d4940d9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-8beb5c21-7462-49d1-8505-391e4b96753f,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-d1423192-cf4d-48be-98a1-9cade94aa6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-69ad4fb9-c071-4798-870f-a5ae8be890db,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-211cc00b-c064-4d82-955b-32ea7a7152ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-be3ad4b6-da25-468a-8439-12b8172de517,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-47b1cb34-404c-4a54-8f4f-7700433554a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1014151463-172.17.0.20-1595835087054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40424,DS-e09644da-6316-4eb7-8ff1-1112d354ff5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-79c677b4-e400-44e8-acce-4b7d4940d9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-8beb5c21-7462-49d1-8505-391e4b96753f,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-d1423192-cf4d-48be-98a1-9cade94aa6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-69ad4fb9-c071-4798-870f-a5ae8be890db,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-211cc00b-c064-4d82-955b-32ea7a7152ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-be3ad4b6-da25-468a-8439-12b8172de517,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-47b1cb34-404c-4a54-8f4f-7700433554a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 8
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624453541-172.17.0.20-1595835509118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43558,DS-e8fed20c-8953-40d8-a7f4-6857e04a62c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-455cd371-7ea2-46fb-a3b1-b1ecd596ecb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-5303fb33-2a14-485a-8632-a1a88187a313,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-fced15c8-337b-440c-88e1-177d57d9a4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-2c56f61d-48a2-4322-b00b-600e0b2d76c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-76e70e5b-1b53-4587-ade5-67a614e7ce4e,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-d966333f-4bdd-4754-89f9-9806aef3746c,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-c920cd81-a9e3-49da-a65b-9a70e1e26663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624453541-172.17.0.20-1595835509118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43558,DS-e8fed20c-8953-40d8-a7f4-6857e04a62c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-455cd371-7ea2-46fb-a3b1-b1ecd596ecb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-5303fb33-2a14-485a-8632-a1a88187a313,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-fced15c8-337b-440c-88e1-177d57d9a4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-2c56f61d-48a2-4322-b00b-600e0b2d76c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-76e70e5b-1b53-4587-ade5-67a614e7ce4e,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-d966333f-4bdd-4754-89f9-9806aef3746c,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-c920cd81-a9e3-49da-a65b-9a70e1e26663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 8
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-499204061-172.17.0.20-1595836232796:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36418,DS-3e18e82b-9ab6-413d-a4ba-913f332b1286,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-e9e03f89-dbd1-4762-8e07-0006891e5c52,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-9a86d52a-d54e-45ee-9b31-df47bf22c694,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-cd9c84b3-48ba-4e93-86e8-15ab6adab519,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-f60d6cd8-aaf3-4374-b02d-1f923d225b05,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-3bdc689a-91c1-4c5b-aaa0-698d67c25212,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-9dd24ecc-016f-4c61-97ef-f71a2a9d758a,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-678bd46e-108a-42d8-af35-798c548ca461,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-499204061-172.17.0.20-1595836232796:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36418,DS-3e18e82b-9ab6-413d-a4ba-913f332b1286,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-e9e03f89-dbd1-4762-8e07-0006891e5c52,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-9a86d52a-d54e-45ee-9b31-df47bf22c694,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-cd9c84b3-48ba-4e93-86e8-15ab6adab519,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-f60d6cd8-aaf3-4374-b02d-1f923d225b05,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-3bdc689a-91c1-4c5b-aaa0-698d67c25212,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-9dd24ecc-016f-4c61-97ef-f71a2a9d758a,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-678bd46e-108a-42d8-af35-798c548ca461,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 8
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577303046-172.17.0.20-1595836784216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45567,DS-05f9de04-3b37-401e-a5c1-6d4f80d099f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-a0ef3426-afe9-4dad-9469-e048a0d6334c,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-662f7aba-b3f8-4d1c-9cb1-8ed75d1bf28e,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-b7941f2d-1939-470e-ab06-101bc9c90cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-a149caca-6fb9-4b0c-91ae-01b0789bccee,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-7eb16145-0058-470a-85d4-b8a037f5e637,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-be7d9693-233d-46b4-9cb0-e2a1b582f8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-d1f3e02c-9e9e-42d5-b6f7-fdbea5d1b719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577303046-172.17.0.20-1595836784216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45567,DS-05f9de04-3b37-401e-a5c1-6d4f80d099f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-a0ef3426-afe9-4dad-9469-e048a0d6334c,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-662f7aba-b3f8-4d1c-9cb1-8ed75d1bf28e,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-b7941f2d-1939-470e-ab06-101bc9c90cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-a149caca-6fb9-4b0c-91ae-01b0789bccee,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-7eb16145-0058-470a-85d4-b8a037f5e637,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-be7d9693-233d-46b4-9cb0-e2a1b582f8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-d1f3e02c-9e9e-42d5-b6f7-fdbea5d1b719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 8
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-627644817-172.17.0.20-1595836856247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42514,DS-b2275c33-3b28-4640-9563-bcba66c2f085,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-fd30088b-4137-422d-b2bd-2416c234a778,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-77a2d8f3-7cdb-44b6-8012-d6bf66fbcf82,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-5f2afae7-d757-4f60-98d3-e7fafee071ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-7c0ab8c4-8925-4e2e-b27c-9df62f91684e,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-1d70530e-a301-4349-a176-ff8ca607f08f,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-dd9729aa-9be0-4332-a4ba-4303e7994128,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-3a90210d-8dbe-40a7-982a-8d732129f59e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-627644817-172.17.0.20-1595836856247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42514,DS-b2275c33-3b28-4640-9563-bcba66c2f085,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-fd30088b-4137-422d-b2bd-2416c234a778,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-77a2d8f3-7cdb-44b6-8012-d6bf66fbcf82,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-5f2afae7-d757-4f60-98d3-e7fafee071ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-7c0ab8c4-8925-4e2e-b27c-9df62f91684e,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-1d70530e-a301-4349-a176-ff8ca607f08f,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-dd9729aa-9be0-4332-a4ba-4303e7994128,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-3a90210d-8dbe-40a7-982a-8d732129f59e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 8
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1947640074-172.17.0.20-1595837036833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40089,DS-4e773cbb-2e90-4b28-9104-3ce626e8b0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-92f23d12-ee90-48e9-b4fb-83df812423f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-6bc8ba64-30bc-4419-a506-d93212121c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-326afaf7-4a6d-4ee7-9e2e-f83fc43dbcb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-0427fbd7-50fd-43e1-8d0c-291a97acb5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-7ac8ea76-aa56-4710-9d18-397166521f70,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-3ce41cad-339f-459f-b100-b57f65afd2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-f3d10d2c-0b64-4cb6-9772-02618b06b431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1947640074-172.17.0.20-1595837036833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40089,DS-4e773cbb-2e90-4b28-9104-3ce626e8b0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-92f23d12-ee90-48e9-b4fb-83df812423f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-6bc8ba64-30bc-4419-a506-d93212121c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-326afaf7-4a6d-4ee7-9e2e-f83fc43dbcb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-0427fbd7-50fd-43e1-8d0c-291a97acb5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-7ac8ea76-aa56-4710-9d18-397166521f70,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-3ce41cad-339f-459f-b100-b57f65afd2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-f3d10d2c-0b64-4cb6-9772-02618b06b431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 8
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1778568044-172.17.0.20-1595837095347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34420,DS-7b0450c6-9091-4b41-9ea4-4e8079845134,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-0275d1af-a1e1-489e-9542-98dbedb287f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-d4ef4fbb-2a1b-4122-abaa-09840106f450,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-e60404f7-7e0f-4691-b4cb-3c63763f4188,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-8a81da1d-5c57-4ce5-bf02-9b3e72213169,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-5019c977-c82a-4633-8a7a-5501a9a4027b,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-de658c1a-0e57-4a37-9382-8a7f70e6eab7,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-09b19b28-1974-4af7-8661-e7e87e69ef01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1778568044-172.17.0.20-1595837095347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34420,DS-7b0450c6-9091-4b41-9ea4-4e8079845134,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-0275d1af-a1e1-489e-9542-98dbedb287f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-d4ef4fbb-2a1b-4122-abaa-09840106f450,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-e60404f7-7e0f-4691-b4cb-3c63763f4188,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-8a81da1d-5c57-4ce5-bf02-9b3e72213169,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-5019c977-c82a-4633-8a7a-5501a9a4027b,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-de658c1a-0e57-4a37-9382-8a7f70e6eab7,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-09b19b28-1974-4af7-8661-e7e87e69ef01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 8
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127525760-172.17.0.20-1595837184141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40207,DS-f203dbf5-0c0a-44a1-b3b2-1b3e2212b6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-4514e8d3-c31d-47c0-b5df-9ef2fd316939,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-70e54583-de5d-4902-b90e-43d29dcbdc34,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-8e70a4cf-7260-430c-8af5-4461f6af3e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-86e700b6-6761-4d33-aad4-e8c8a6facc68,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-28bdf5a4-8259-4ced-a370-8c5d218b6671,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-b68d4544-f9af-42de-bb35-cbc58433bc52,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-8c113763-c900-489b-a1fb-bd57dfe3acc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127525760-172.17.0.20-1595837184141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40207,DS-f203dbf5-0c0a-44a1-b3b2-1b3e2212b6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-4514e8d3-c31d-47c0-b5df-9ef2fd316939,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-70e54583-de5d-4902-b90e-43d29dcbdc34,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-8e70a4cf-7260-430c-8af5-4461f6af3e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-86e700b6-6761-4d33-aad4-e8c8a6facc68,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-28bdf5a4-8259-4ced-a370-8c5d218b6671,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-b68d4544-f9af-42de-bb35-cbc58433bc52,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-8c113763-c900-489b-a1fb-bd57dfe3acc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 8
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-501846580-172.17.0.20-1595837341137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35341,DS-82ee3829-6fc9-493a-a23a-b8024b7155b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-f7e22a9d-9a42-40cd-a072-cd174a182ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-248d50b1-e737-444b-a5de-863f7c2cb5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-6c04b2cf-5a15-4d50-bfba-9d9814d999b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-bc9025fa-13e9-4ecd-b686-7331079b118b,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-d871afa0-9873-481d-990b-b51a54a74221,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-e1c71014-1506-4fb6-a9dc-78124a4db0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-1b4a7d1f-ea0f-45df-8414-143f549fee50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-501846580-172.17.0.20-1595837341137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35341,DS-82ee3829-6fc9-493a-a23a-b8024b7155b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-f7e22a9d-9a42-40cd-a072-cd174a182ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-248d50b1-e737-444b-a5de-863f7c2cb5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-6c04b2cf-5a15-4d50-bfba-9d9814d999b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-bc9025fa-13e9-4ecd-b686-7331079b118b,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-d871afa0-9873-481d-990b-b51a54a74221,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-e1c71014-1506-4fb6-a9dc-78124a4db0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-1b4a7d1f-ea0f-45df-8414-143f549fee50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 8
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1401110070-172.17.0.20-1595837400505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33242,DS-1890e565-31f6-43f6-89ce-b77947eb13a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-5a133e00-d9df-4297-a5de-7aaa3c548eed,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-c3a8511a-3815-4b96-87c9-3b9211b40755,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-419fc4d4-67e0-45ce-84cc-efb2282320ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-de090b03-940b-4830-a008-8183eda615fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-f6236892-6379-4b60-81d0-8fc045f5d5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-0704888f-ae9f-40c2-a499-ccef38102440,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-e6cd6918-9c56-4159-b5c4-33a8701ce3f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1401110070-172.17.0.20-1595837400505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33242,DS-1890e565-31f6-43f6-89ce-b77947eb13a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-5a133e00-d9df-4297-a5de-7aaa3c548eed,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-c3a8511a-3815-4b96-87c9-3b9211b40755,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-419fc4d4-67e0-45ce-84cc-efb2282320ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-de090b03-940b-4830-a008-8183eda615fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-f6236892-6379-4b60-81d0-8fc045f5d5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-0704888f-ae9f-40c2-a499-ccef38102440,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-e6cd6918-9c56-4159-b5c4-33a8701ce3f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 8
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1739821090-172.17.0.20-1595837433055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34368,DS-9d8d6903-296a-4f93-9390-bbf841935bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-5cb20342-4e7f-4e77-ab98-2cd885cdad49,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-19eb95c1-6bda-4159-adc5-9d1275e724c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-4af6d4f4-7563-4863-bd23-fb4efd363885,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-2ac30d88-2d1c-4461-b8fc-c8521ca5b6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-7492d09c-4655-46a1-8294-8f47d3e9a854,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-89bbd064-6f16-4d79-89c1-4ea975446094,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-a0990215-50f4-4215-b892-d6f424d4edb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1739821090-172.17.0.20-1595837433055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34368,DS-9d8d6903-296a-4f93-9390-bbf841935bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-5cb20342-4e7f-4e77-ab98-2cd885cdad49,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-19eb95c1-6bda-4159-adc5-9d1275e724c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-4af6d4f4-7563-4863-bd23-fb4efd363885,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-2ac30d88-2d1c-4461-b8fc-c8521ca5b6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-7492d09c-4655-46a1-8294-8f47d3e9a854,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-89bbd064-6f16-4d79-89c1-4ea975446094,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-a0990215-50f4-4215-b892-d6f424d4edb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 8
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994999133-172.17.0.20-1595837692095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37506,DS-5740852f-da40-4615-ba8f-19a4732e6831,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-328d13d2-1a7d-4318-a231-1d68d319dba8,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-19f2538b-b946-40b8-a6d9-03fb98e463d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-b824e054-e353-4e55-9fab-630920bbbe9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-e5295e89-4f25-4787-b82a-a1723d4109fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-6c6c996b-ed39-4c37-aaf7-3c24eaf5b652,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-936483de-5398-4acd-834a-6b4564c43ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-c6c1734e-4ce3-45d8-9d6d-351df7ea76d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994999133-172.17.0.20-1595837692095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37506,DS-5740852f-da40-4615-ba8f-19a4732e6831,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-328d13d2-1a7d-4318-a231-1d68d319dba8,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-19f2538b-b946-40b8-a6d9-03fb98e463d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-b824e054-e353-4e55-9fab-630920bbbe9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-e5295e89-4f25-4787-b82a-a1723d4109fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-6c6c996b-ed39-4c37-aaf7-3c24eaf5b652,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-936483de-5398-4acd-834a-6b4564c43ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-c6c1734e-4ce3-45d8-9d6d-351df7ea76d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 8
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-735378421-172.17.0.20-1595837894163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35413,DS-befdf09c-2dc2-4149-80ef-0c4dc8acf728,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-11f5637f-d960-4d3d-a818-1db1729431f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-a1862475-dfb2-4cfd-83fe-3ea91a34f8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-9aa6d734-66fd-4b67-9ec3-da0d51822f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-c8572160-13c6-40b8-9c08-5a03f1dec666,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-74a1ee50-98dc-47b4-9fca-7eb0de07d2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-3c84bf16-cc5c-4d9b-b0de-b2d60ffb50e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-8c29ca3c-e5c0-4c3a-937e-fc4dcf2ad33c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-735378421-172.17.0.20-1595837894163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35413,DS-befdf09c-2dc2-4149-80ef-0c4dc8acf728,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-11f5637f-d960-4d3d-a818-1db1729431f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-a1862475-dfb2-4cfd-83fe-3ea91a34f8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-9aa6d734-66fd-4b67-9ec3-da0d51822f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-c8572160-13c6-40b8-9c08-5a03f1dec666,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-74a1ee50-98dc-47b4-9fca-7eb0de07d2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-3c84bf16-cc5c-4d9b-b0de-b2d60ffb50e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-8c29ca3c-e5c0-4c3a-937e-fc4dcf2ad33c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 8
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1692466901-172.17.0.20-1595837927054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34009,DS-f7b7acdd-16f8-4112-8f84-e1e9d5ae3e38,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-67084c2b-b964-41bc-8e36-b6b29f116fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-8200f2db-8c46-4f9e-bacb-7754bae898a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-551e4698-1272-4158-acde-75e9b6059f50,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-6da364e6-4eeb-4e60-8151-b043eabbecbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-d0babc75-2044-47bd-a162-7978a45e4ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-e0095d63-e767-4c00-b46c-d8fe9728a4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-767c9ace-1bde-4514-8d98-f4b4300f778b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1692466901-172.17.0.20-1595837927054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34009,DS-f7b7acdd-16f8-4112-8f84-e1e9d5ae3e38,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-67084c2b-b964-41bc-8e36-b6b29f116fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-8200f2db-8c46-4f9e-bacb-7754bae898a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-551e4698-1272-4158-acde-75e9b6059f50,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-6da364e6-4eeb-4e60-8151-b043eabbecbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-d0babc75-2044-47bd-a162-7978a45e4ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-e0095d63-e767-4c00-b46c-d8fe9728a4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-767c9ace-1bde-4514-8d98-f4b4300f778b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 4944
