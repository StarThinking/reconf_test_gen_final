reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-418936356-172.17.0.19-1595547699943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40474,DS-2a61a1cf-b7a7-470e-a283-835c6ffeba5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-ef74ee22-4030-44cb-a0bd-6988d0f9c2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-1bb56596-f98b-4679-9df5-1dab52949501,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-c5554a59-8a16-468a-81a0-f0399207bef4,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-f0d95f81-372b-4e2f-83af-6eaac7eb571f,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-60eac3cb-c740-4b68-b63a-be1a082c29d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-4e9768c8-5b0d-4b86-9ccc-e564ac60149a,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-030ab89c-f6f3-48d7-81f6-50aeac8051d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-418936356-172.17.0.19-1595547699943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40474,DS-2a61a1cf-b7a7-470e-a283-835c6ffeba5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-ef74ee22-4030-44cb-a0bd-6988d0f9c2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-1bb56596-f98b-4679-9df5-1dab52949501,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-c5554a59-8a16-468a-81a0-f0399207bef4,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-f0d95f81-372b-4e2f-83af-6eaac7eb571f,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-60eac3cb-c740-4b68-b63a-be1a082c29d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-4e9768c8-5b0d-4b86-9ccc-e564ac60149a,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-030ab89c-f6f3-48d7-81f6-50aeac8051d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2010886731-172.17.0.19-1595548108790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38539,DS-6c2f40e5-d60b-4316-8a48-64d2ef282ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-88e6f4d8-0cc0-4922-a0c3-5cedee1289fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-ba732b3a-86de-483b-92ce-5b6ed884ae2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-a3d80f5b-4283-4310-9b14-c628337bce4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-3553bb19-ee08-4e43-bc2c-d6cab85cd03b,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-77ac28e9-e7b9-440c-b6df-6d5b56b6c3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-dbee5003-d7c3-4a2c-9933-8a9cac213eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-80994da1-7f67-4389-bbc5-71c0aad26fdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2010886731-172.17.0.19-1595548108790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38539,DS-6c2f40e5-d60b-4316-8a48-64d2ef282ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-88e6f4d8-0cc0-4922-a0c3-5cedee1289fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-ba732b3a-86de-483b-92ce-5b6ed884ae2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-a3d80f5b-4283-4310-9b14-c628337bce4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-3553bb19-ee08-4e43-bc2c-d6cab85cd03b,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-77ac28e9-e7b9-440c-b6df-6d5b56b6c3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-dbee5003-d7c3-4a2c-9933-8a9cac213eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-80994da1-7f67-4389-bbc5-71c0aad26fdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717721230-172.17.0.19-1595548201228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37833,DS-031e48bf-d254-4b5d-aa92-8ac35e56c3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-bf9f63f5-8fef-48a0-9b1e-be0033c5f5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-c72cfaa9-0b7d-4100-97a7-7066cf8bb74a,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-234df790-487d-4ad9-bada-1432983a15fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-de8065a1-3595-444e-8a6b-e5aadc5fc3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-2357f534-afd3-4fe2-8920-cfbfc53b0ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-7d073594-4358-402c-b591-337b967e1baa,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-8d99ff90-927b-4064-b7d8-40ff0e7e068c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717721230-172.17.0.19-1595548201228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37833,DS-031e48bf-d254-4b5d-aa92-8ac35e56c3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-bf9f63f5-8fef-48a0-9b1e-be0033c5f5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-c72cfaa9-0b7d-4100-97a7-7066cf8bb74a,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-234df790-487d-4ad9-bada-1432983a15fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-de8065a1-3595-444e-8a6b-e5aadc5fc3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-2357f534-afd3-4fe2-8920-cfbfc53b0ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-7d073594-4358-402c-b591-337b967e1baa,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-8d99ff90-927b-4064-b7d8-40ff0e7e068c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1892284382-172.17.0.19-1595548257829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45992,DS-a266d185-cf5d-44b3-8fb5-ec85b6a7f5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-c26870aa-8dc8-42d5-a9ee-8440b6bede2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-ac0af7f4-3d88-48bd-bde0-0c3c41d49142,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-ba310ba2-dfed-46ce-a527-e9c57d0b20cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-d92577a2-8fa4-4075-ba17-a6312c265f17,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-e59eeae7-9b8b-45cc-97e7-40a0714268cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-c49fb707-460f-4255-812e-38dffff65045,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-ffd88f3e-6f1d-4c4f-acec-163dc1aa39ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1892284382-172.17.0.19-1595548257829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45992,DS-a266d185-cf5d-44b3-8fb5-ec85b6a7f5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-c26870aa-8dc8-42d5-a9ee-8440b6bede2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-ac0af7f4-3d88-48bd-bde0-0c3c41d49142,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-ba310ba2-dfed-46ce-a527-e9c57d0b20cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-d92577a2-8fa4-4075-ba17-a6312c265f17,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-e59eeae7-9b8b-45cc-97e7-40a0714268cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-c49fb707-460f-4255-812e-38dffff65045,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-ffd88f3e-6f1d-4c4f-acec-163dc1aa39ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-884014965-172.17.0.19-1595548621218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33830,DS-418fc521-8e8c-49da-a33d-36ce32428b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-42397714-b665-4b13-a803-49118baf78af,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-c8a23a4d-25eb-4211-aa5e-69b05f430923,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-6f2d2901-82dc-438b-bd29-7c93b20b0c33,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-cf37a070-3643-4cc3-91c0-a61dd5b507b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-26f14a0b-59ed-472e-9e7a-6550c4e9a550,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-a8fcd4cc-4863-42d1-8509-c45075aa8a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-7bf3ee92-e8f5-4da6-b7de-4516a269332d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-884014965-172.17.0.19-1595548621218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33830,DS-418fc521-8e8c-49da-a33d-36ce32428b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-42397714-b665-4b13-a803-49118baf78af,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-c8a23a4d-25eb-4211-aa5e-69b05f430923,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-6f2d2901-82dc-438b-bd29-7c93b20b0c33,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-cf37a070-3643-4cc3-91c0-a61dd5b507b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-26f14a0b-59ed-472e-9e7a-6550c4e9a550,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-a8fcd4cc-4863-42d1-8509-c45075aa8a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-7bf3ee92-e8f5-4da6-b7de-4516a269332d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1832359598-172.17.0.19-1595548793361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46705,DS-a1d5dffd-c796-42b0-a092-017f393f9285,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-b2ed21b8-ad9e-4823-94c7-888fecf80041,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-ebc59751-f505-4429-afa8-929083d349b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-545cc084-255f-4be3-9ae5-8a71930202c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-1bd2a972-b342-4556-9be3-892863c0402c,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-4fc7fc3b-3f03-49e5-9150-8dac74c09e82,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-27f57378-7d4d-41c6-a5db-5ad1524b394d,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-b8fe399b-cef1-46bc-80d3-034530533c22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1832359598-172.17.0.19-1595548793361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46705,DS-a1d5dffd-c796-42b0-a092-017f393f9285,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-b2ed21b8-ad9e-4823-94c7-888fecf80041,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-ebc59751-f505-4429-afa8-929083d349b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-545cc084-255f-4be3-9ae5-8a71930202c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-1bd2a972-b342-4556-9be3-892863c0402c,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-4fc7fc3b-3f03-49e5-9150-8dac74c09e82,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-27f57378-7d4d-41c6-a5db-5ad1524b394d,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-b8fe399b-cef1-46bc-80d3-034530533c22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1760292402-172.17.0.19-1595548871630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36280,DS-a4e37f27-e6b7-4531-9f8a-900c0ba3df2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-bc9eb09e-0d76-4925-92de-b27cd0795357,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-1545196a-0a4b-4209-a5ea-0366b094a2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-27b17714-80a0-4eba-8101-9c96541257fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-1c567e9b-e228-4130-b0c7-d0bdf0ae56be,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-61d9f261-9ec2-40f2-ad22-9ce663fc2a14,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-6a0adac0-f621-4942-9d54-25981c0c7dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-f02b9be4-8eaa-4cba-a300-e63f01d910c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1760292402-172.17.0.19-1595548871630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36280,DS-a4e37f27-e6b7-4531-9f8a-900c0ba3df2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-bc9eb09e-0d76-4925-92de-b27cd0795357,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-1545196a-0a4b-4209-a5ea-0366b094a2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-27b17714-80a0-4eba-8101-9c96541257fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-1c567e9b-e228-4130-b0c7-d0bdf0ae56be,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-61d9f261-9ec2-40f2-ad22-9ce663fc2a14,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-6a0adac0-f621-4942-9d54-25981c0c7dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-f02b9be4-8eaa-4cba-a300-e63f01d910c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743637971-172.17.0.19-1595549798713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38283,DS-0b3e2882-32e1-4313-8a9f-5804e498afea,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-56588bd2-45e8-4413-a379-f817e0df1aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-87de5f0b-2406-4c4c-ab7c-7774f9335888,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-38f0da0a-7d19-488d-9cf1-4d114aa40149,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-c6b9c530-3c92-476d-a9a4-fe586d130d30,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-4c0ee08f-dcec-40e0-bbeb-58993f1fbc02,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-4cd0252a-029b-4482-8397-dcc0279b8f42,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-4ed83324-3070-4b24-bb0c-5acba31122b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743637971-172.17.0.19-1595549798713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38283,DS-0b3e2882-32e1-4313-8a9f-5804e498afea,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-56588bd2-45e8-4413-a379-f817e0df1aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-87de5f0b-2406-4c4c-ab7c-7774f9335888,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-38f0da0a-7d19-488d-9cf1-4d114aa40149,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-c6b9c530-3c92-476d-a9a4-fe586d130d30,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-4c0ee08f-dcec-40e0-bbeb-58993f1fbc02,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-4cd0252a-029b-4482-8397-dcc0279b8f42,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-4ed83324-3070-4b24-bb0c-5acba31122b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1660737797-172.17.0.19-1595550282849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42174,DS-a1c29f1c-50fa-4e11-be62-6f1f59d7c685,DISK], DatanodeInfoWithStorage[127.0.0.1:44180,DS-f9c89aef-5d75-4f6e-bcdf-6ec18e050470,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-98f78ce5-fcdf-45da-9f7b-d5c17a2684ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-147cc4e7-a45c-4e7a-bd37-45c156cd79fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-8c2097c1-b4dd-4188-af7f-73ce2bf0aee5,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-529d2953-c687-4996-852c-0a1a762d64cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-b6e57db2-4a83-4b28-9dc8-1aed4d21dda5,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-c5087c85-d9a2-4c65-a4ce-5fcb5361f5af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1660737797-172.17.0.19-1595550282849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42174,DS-a1c29f1c-50fa-4e11-be62-6f1f59d7c685,DISK], DatanodeInfoWithStorage[127.0.0.1:44180,DS-f9c89aef-5d75-4f6e-bcdf-6ec18e050470,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-98f78ce5-fcdf-45da-9f7b-d5c17a2684ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-147cc4e7-a45c-4e7a-bd37-45c156cd79fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-8c2097c1-b4dd-4188-af7f-73ce2bf0aee5,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-529d2953-c687-4996-852c-0a1a762d64cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-b6e57db2-4a83-4b28-9dc8-1aed4d21dda5,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-c5087c85-d9a2-4c65-a4ce-5fcb5361f5af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-238058053-172.17.0.19-1595551395656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36501,DS-9dbd94e0-7727-4c50-9c21-fe3bc3ff1e02,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-516fd730-5b74-4570-82f8-589c99abda2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-0bd791d0-c7b8-4be6-802b-047ca891d5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-04d7eb6c-5ec7-4f54-ad12-6f81fbac881b,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-73bc7e24-b42c-4ed5-8a50-778ce2121049,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-1ffc6ecd-cdd2-40c7-bafb-f08c0502317f,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-24201f8a-31f0-4f2e-b1df-0f5174778042,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-ec7a34b7-5af4-4472-b1fc-b3726b33e0be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-238058053-172.17.0.19-1595551395656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36501,DS-9dbd94e0-7727-4c50-9c21-fe3bc3ff1e02,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-516fd730-5b74-4570-82f8-589c99abda2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-0bd791d0-c7b8-4be6-802b-047ca891d5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-04d7eb6c-5ec7-4f54-ad12-6f81fbac881b,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-73bc7e24-b42c-4ed5-8a50-778ce2121049,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-1ffc6ecd-cdd2-40c7-bafb-f08c0502317f,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-24201f8a-31f0-4f2e-b1df-0f5174778042,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-ec7a34b7-5af4-4472-b1fc-b3726b33e0be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-221798827-172.17.0.19-1595551443807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34093,DS-c19f6e5e-c12e-4f71-8abe-e87d7cbf3524,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-c3da26a3-f958-44ee-a4f4-c04a20df20f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-ebc1167d-8ef7-43d4-95d3-e52317e13ead,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-8636c014-af8b-422f-9515-b6e1c01ea2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-7fa25bc4-05cb-4c57-9bdd-01cb1e01b994,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-455ba2ac-7a0d-4695-b46b-b9b4b059a36e,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-f09152f2-bfe2-4f91-bc57-8fec7c068fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-b6aeda7d-0c5b-43c8-ae04-8b8737067597,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-221798827-172.17.0.19-1595551443807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34093,DS-c19f6e5e-c12e-4f71-8abe-e87d7cbf3524,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-c3da26a3-f958-44ee-a4f4-c04a20df20f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-ebc1167d-8ef7-43d4-95d3-e52317e13ead,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-8636c014-af8b-422f-9515-b6e1c01ea2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-7fa25bc4-05cb-4c57-9bdd-01cb1e01b994,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-455ba2ac-7a0d-4695-b46b-b9b4b059a36e,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-f09152f2-bfe2-4f91-bc57-8fec7c068fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-b6aeda7d-0c5b-43c8-ae04-8b8737067597,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1098242079-172.17.0.19-1595552025265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42933,DS-fbe203fb-ded9-4d1f-aea3-b27642dbcd32,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-08d71e89-2af7-4af2-9e47-f8eb4e313949,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-6f004d73-fd27-4102-8947-57ca566c3dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-d5004f6b-0069-4ed8-8ea5-c05d772a92f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-04ad4c29-e8b8-4b38-998b-f76a55764510,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-9818d03c-8f09-4ca2-a2b5-8e6f3f93d2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-f8f28740-9695-41d8-bd48-2bb1b3ecadee,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-8565b5a5-b4fe-47c7-a9a9-ee9dabec49b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1098242079-172.17.0.19-1595552025265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42933,DS-fbe203fb-ded9-4d1f-aea3-b27642dbcd32,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-08d71e89-2af7-4af2-9e47-f8eb4e313949,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-6f004d73-fd27-4102-8947-57ca566c3dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-d5004f6b-0069-4ed8-8ea5-c05d772a92f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-04ad4c29-e8b8-4b38-998b-f76a55764510,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-9818d03c-8f09-4ca2-a2b5-8e6f3f93d2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-f8f28740-9695-41d8-bd48-2bb1b3ecadee,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-8565b5a5-b4fe-47c7-a9a9-ee9dabec49b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1498546859-172.17.0.19-1595552443182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46772,DS-8b01050d-d18a-4bb4-8ba4-83a98c1893d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-35dce6c7-4c42-4627-9a81-a26a56ba4752,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-ade79bca-8d09-49a1-acea-db035db6ffd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-a319b96a-b1d9-4e52-866b-4171600f6526,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-aadf6de5-302c-4088-8b54-444f8fd10d56,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-3419beb1-057a-4112-b1e9-d4061f18e2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-c75f26f1-c6e3-41ef-a888-e822dcf2ffb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-71656af9-cf20-42cf-894e-2d04a58fa57f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1498546859-172.17.0.19-1595552443182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46772,DS-8b01050d-d18a-4bb4-8ba4-83a98c1893d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-35dce6c7-4c42-4627-9a81-a26a56ba4752,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-ade79bca-8d09-49a1-acea-db035db6ffd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-a319b96a-b1d9-4e52-866b-4171600f6526,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-aadf6de5-302c-4088-8b54-444f8fd10d56,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-3419beb1-057a-4112-b1e9-d4061f18e2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-c75f26f1-c6e3-41ef-a888-e822dcf2ffb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-71656af9-cf20-42cf-894e-2d04a58fa57f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-322368231-172.17.0.19-1595552884086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36844,DS-26614467-a9d2-4ff2-8482-c0b43764c0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-0218d211-a0e2-4cc9-8c91-bed5ac386170,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-a9c9d5ae-2f5f-4fcc-84f1-f8c4e6479ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-a9171c4d-2dba-4e28-ab75-9b388f316b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-ccc43e33-0197-4999-95b2-cf12b12e105b,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-8a91968c-5797-4e14-9cf3-9672967a1013,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-419890ba-fe0f-4790-9cf4-bfcd33e22115,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-e3987914-17b1-40ce-be54-b21012910b72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-322368231-172.17.0.19-1595552884086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36844,DS-26614467-a9d2-4ff2-8482-c0b43764c0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-0218d211-a0e2-4cc9-8c91-bed5ac386170,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-a9c9d5ae-2f5f-4fcc-84f1-f8c4e6479ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-a9171c4d-2dba-4e28-ab75-9b388f316b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-ccc43e33-0197-4999-95b2-cf12b12e105b,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-8a91968c-5797-4e14-9cf3-9672967a1013,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-419890ba-fe0f-4790-9cf4-bfcd33e22115,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-e3987914-17b1-40ce-be54-b21012910b72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-16030027-172.17.0.19-1595553121081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37492,DS-0a534854-27dc-4942-85dc-efb6a2357558,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-1cf31ab1-7852-4d02-99eb-e48070904293,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-5fac5146-84e9-4d49-8701-baeab8f4b9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-0f742f24-0e03-4d8b-876f-f2dc03330f85,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-75c4dcd5-a0ca-4b32-aca0-12ebd724b2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-f273d56b-beef-4737-9c70-339ff41069e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-b4d67df1-e62e-4deb-9999-4814485440ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-f1883cbd-5307-465e-938b-8d666146e04e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-16030027-172.17.0.19-1595553121081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37492,DS-0a534854-27dc-4942-85dc-efb6a2357558,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-1cf31ab1-7852-4d02-99eb-e48070904293,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-5fac5146-84e9-4d49-8701-baeab8f4b9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-0f742f24-0e03-4d8b-876f-f2dc03330f85,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-75c4dcd5-a0ca-4b32-aca0-12ebd724b2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-f273d56b-beef-4737-9c70-339ff41069e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-b4d67df1-e62e-4deb-9999-4814485440ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-f1883cbd-5307-465e-938b-8d666146e04e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6505
