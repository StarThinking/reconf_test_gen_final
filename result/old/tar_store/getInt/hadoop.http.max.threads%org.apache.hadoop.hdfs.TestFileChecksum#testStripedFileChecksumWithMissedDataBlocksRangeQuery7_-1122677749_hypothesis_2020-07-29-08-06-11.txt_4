reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696261506-172.17.0.9-1596010349870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41789,DS-9c9b2e84-7187-4c4c-9465-7d3eff2c9bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-9953c2bc-a81b-409a-bc98-1552efc81576,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-aabfe91f-d63e-441e-ad5d-f1d00df946f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-9a987eab-c84b-4971-9593-bf1713b2e1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-ccf99054-25d5-4fd8-8ffa-8669f4122b56,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-b9028f0e-3417-43fd-93aa-9a48354bf820,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-f418f5d1-8851-41f9-beaa-33a5a69e5370,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-4d6768ed-83f0-405c-8ea9-dd833e418ef3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696261506-172.17.0.9-1596010349870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41789,DS-9c9b2e84-7187-4c4c-9465-7d3eff2c9bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-9953c2bc-a81b-409a-bc98-1552efc81576,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-aabfe91f-d63e-441e-ad5d-f1d00df946f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-9a987eab-c84b-4971-9593-bf1713b2e1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-ccf99054-25d5-4fd8-8ffa-8669f4122b56,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-b9028f0e-3417-43fd-93aa-9a48354bf820,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-f418f5d1-8851-41f9-beaa-33a5a69e5370,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-4d6768ed-83f0-405c-8ea9-dd833e418ef3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656840902-172.17.0.9-1596010387421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34692,DS-3bc6fff4-a26e-4b39-bc97-ca50087b702d,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-ffd3fc5b-1e88-4e41-bfd3-f25da13d3034,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-2e2dbff4-1919-4a84-8b88-6f97ddffc5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-ac296204-5c30-4f70-88b5-4660115e54ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-f7e288ee-bc30-437b-8c36-caed031f1fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-5b342ea7-c41c-4200-a7d3-2b0c27f56528,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-41bd9555-5a68-4319-bb09-b58e53bd33c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-31a52ee2-a0d2-435d-af40-d78b4d04be20,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656840902-172.17.0.9-1596010387421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34692,DS-3bc6fff4-a26e-4b39-bc97-ca50087b702d,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-ffd3fc5b-1e88-4e41-bfd3-f25da13d3034,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-2e2dbff4-1919-4a84-8b88-6f97ddffc5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-ac296204-5c30-4f70-88b5-4660115e54ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-f7e288ee-bc30-437b-8c36-caed031f1fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-5b342ea7-c41c-4200-a7d3-2b0c27f56528,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-41bd9555-5a68-4319-bb09-b58e53bd33c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-31a52ee2-a0d2-435d-af40-d78b4d04be20,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187599251-172.17.0.9-1596010432979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45774,DS-e33adf1a-9d55-4935-9e94-79a80ecd9dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-cfbba953-a581-47ab-9d8a-cc9cfbb596f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-2b42ebc3-1aa1-4bc3-9db8-da4c48b7e16f,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-e0a346e5-fb56-429a-916f-36cde7aad376,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-c2237584-9f36-4ced-b3ba-def36b0f9906,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-f6dcb5a5-ab99-403f-85b8-2ac50e788549,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-24dc46a7-9ab2-4179-88fc-6768c1d2aaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-18254809-d73c-4db6-b961-fe2d536016e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187599251-172.17.0.9-1596010432979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45774,DS-e33adf1a-9d55-4935-9e94-79a80ecd9dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-cfbba953-a581-47ab-9d8a-cc9cfbb596f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-2b42ebc3-1aa1-4bc3-9db8-da4c48b7e16f,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-e0a346e5-fb56-429a-916f-36cde7aad376,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-c2237584-9f36-4ced-b3ba-def36b0f9906,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-f6dcb5a5-ab99-403f-85b8-2ac50e788549,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-24dc46a7-9ab2-4179-88fc-6768c1d2aaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-18254809-d73c-4db6-b961-fe2d536016e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432906053-172.17.0.9-1596010556142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41549,DS-e2e30d1e-c629-47af-9704-a79196844f07,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-39a07b20-6252-4e9e-b8c0-c5a7a8cd467d,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-748c13c7-d659-4268-8a3c-fe7c1e939280,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-8380fe28-2287-4097-95bd-25bdcf0a8dba,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-2dd46555-6f5c-4894-bde9-d2012e2e05e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-74230e51-3224-4b17-8efa-170aea7e1b39,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-1c25e8f8-86a4-4045-9696-d64405336782,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-d45f167f-72df-45f8-b35a-1a4f6992321d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432906053-172.17.0.9-1596010556142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41549,DS-e2e30d1e-c629-47af-9704-a79196844f07,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-39a07b20-6252-4e9e-b8c0-c5a7a8cd467d,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-748c13c7-d659-4268-8a3c-fe7c1e939280,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-8380fe28-2287-4097-95bd-25bdcf0a8dba,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-2dd46555-6f5c-4894-bde9-d2012e2e05e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-74230e51-3224-4b17-8efa-170aea7e1b39,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-1c25e8f8-86a4-4045-9696-d64405336782,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-d45f167f-72df-45f8-b35a-1a4f6992321d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-872177998-172.17.0.9-1596010594837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37796,DS-c6594f7f-abf3-47f3-8fa7-548683ea8582,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-b3b8f66a-b0f7-4fc4-85d0-984d40f1a476,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-e44eaffd-f5e7-45f0-9944-9949326de10e,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-9f5e8ecf-a35c-4f0e-adec-96e1e7e4b401,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-a9fadabb-6a47-4b59-a9df-377f82d3717a,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-8b79a0a0-2584-4a99-914d-57d49ae14c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-97d9e3f9-5a8e-47e6-b925-0d51d043c02a,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-90e2d152-28cc-4a1d-bc4e-892daaa3a9fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-872177998-172.17.0.9-1596010594837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37796,DS-c6594f7f-abf3-47f3-8fa7-548683ea8582,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-b3b8f66a-b0f7-4fc4-85d0-984d40f1a476,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-e44eaffd-f5e7-45f0-9944-9949326de10e,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-9f5e8ecf-a35c-4f0e-adec-96e1e7e4b401,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-a9fadabb-6a47-4b59-a9df-377f82d3717a,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-8b79a0a0-2584-4a99-914d-57d49ae14c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-97d9e3f9-5a8e-47e6-b925-0d51d043c02a,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-90e2d152-28cc-4a1d-bc4e-892daaa3a9fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906584831-172.17.0.9-1596010712545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32993,DS-6f6c0eae-7f58-4373-bb29-7863bff07feb,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-1f3611bf-8fcf-43b4-bea4-68c8c147d14c,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-50b5ab7c-8a44-4b3e-a7c4-2644e41750ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-4ce8d5ac-741d-4fc9-8168-7c7143f6ee5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-b49b3c0f-e7e5-4df1-9eeb-63ec881042b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-26597378-02b6-4fbc-a67b-8880a9e9788f,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-66ef8cf3-bdc8-41c3-b199-099009b91b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-5197aaea-2427-4744-aeb9-7786c819300f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906584831-172.17.0.9-1596010712545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32993,DS-6f6c0eae-7f58-4373-bb29-7863bff07feb,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-1f3611bf-8fcf-43b4-bea4-68c8c147d14c,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-50b5ab7c-8a44-4b3e-a7c4-2644e41750ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-4ce8d5ac-741d-4fc9-8168-7c7143f6ee5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-b49b3c0f-e7e5-4df1-9eeb-63ec881042b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-26597378-02b6-4fbc-a67b-8880a9e9788f,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-66ef8cf3-bdc8-41c3-b199-099009b91b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-5197aaea-2427-4744-aeb9-7786c819300f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851055239-172.17.0.9-1596011105517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39860,DS-61d68b68-9e33-4c2d-bfe5-20d9897cfa30,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-475aea4e-3d56-4064-b24c-9a68a072fbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-db90f8b4-2fc1-42e7-8edd-392ce2d2d1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-14ac10a2-641f-4172-9a94-bd9797482bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-29515d18-c8a6-4226-962a-c53a90a5912e,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-65c2b767-1ae1-4cdb-a273-c3291e79f15c,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-29ee0b60-b6bc-44c5-941c-622d895ab697,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-3fab8bb1-7bd3-4089-bc0e-3b1dd0003bd0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851055239-172.17.0.9-1596011105517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39860,DS-61d68b68-9e33-4c2d-bfe5-20d9897cfa30,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-475aea4e-3d56-4064-b24c-9a68a072fbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-db90f8b4-2fc1-42e7-8edd-392ce2d2d1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-14ac10a2-641f-4172-9a94-bd9797482bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-29515d18-c8a6-4226-962a-c53a90a5912e,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-65c2b767-1ae1-4cdb-a273-c3291e79f15c,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-29ee0b60-b6bc-44c5-941c-622d895ab697,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-3fab8bb1-7bd3-4089-bc0e-3b1dd0003bd0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128190793-172.17.0.9-1596011220623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36430,DS-1715605c-2d88-4986-a939-d4aa339e185b,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-59b227c5-4655-43d2-9831-6a3359b64e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-b1ab035b-5bd0-42fd-83ff-2882df822a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-ffd2c08e-4a6a-4be3-8c1f-0f1ac4c2b643,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-dfa5f21e-3285-42e7-9fd4-f3baaa033d25,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-ded894f9-8ce7-42d5-8f43-a81972c5da1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-9f47a876-7e20-43bc-9495-568a5472cbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-a849b509-bd48-4928-bbfc-bdc33017985c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128190793-172.17.0.9-1596011220623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36430,DS-1715605c-2d88-4986-a939-d4aa339e185b,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-59b227c5-4655-43d2-9831-6a3359b64e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-b1ab035b-5bd0-42fd-83ff-2882df822a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-ffd2c08e-4a6a-4be3-8c1f-0f1ac4c2b643,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-dfa5f21e-3285-42e7-9fd4-f3baaa033d25,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-ded894f9-8ce7-42d5-8f43-a81972c5da1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-9f47a876-7e20-43bc-9495-568a5472cbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-a849b509-bd48-4928-bbfc-bdc33017985c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474796090-172.17.0.9-1596011616230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34863,DS-1666e2af-0689-4c90-8d0a-d8fb608c2505,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-1e49d280-2b61-46e1-9178-5d2a31b89877,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-12eb02fa-c7f9-4e6d-88fe-f2cdec42193a,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-44ea0c4b-53bf-4f82-bc6f-ea1e2473af27,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-a74549f8-5910-44fd-ad6b-25a626332a17,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-8812a4b0-499c-4eb6-98da-f4def83ef3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-06bb1812-ca00-4bce-87bf-55bc808183fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-b715609d-57da-4ef0-9ce6-cf409f420ff5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474796090-172.17.0.9-1596011616230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34863,DS-1666e2af-0689-4c90-8d0a-d8fb608c2505,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-1e49d280-2b61-46e1-9178-5d2a31b89877,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-12eb02fa-c7f9-4e6d-88fe-f2cdec42193a,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-44ea0c4b-53bf-4f82-bc6f-ea1e2473af27,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-a74549f8-5910-44fd-ad6b-25a626332a17,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-8812a4b0-499c-4eb6-98da-f4def83ef3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-06bb1812-ca00-4bce-87bf-55bc808183fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-b715609d-57da-4ef0-9ce6-cf409f420ff5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667167389-172.17.0.9-1596011919597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46379,DS-5da259c6-afc5-4920-93a6-e0bc880d9f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-f194f826-6ede-4ca7-9721-d5a8dc3ff6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-b3da48cf-fef5-4b93-a3ec-140d347fb8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-eafaec58-6f43-494c-9f5f-1f0713730041,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-29d783bb-460b-44f2-8be4-63e1bd55370f,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-7ad52958-ea21-4b07-9f09-5964ca9b34fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-0f26ba18-0452-410a-a4de-2c1c98f25f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-1a3ec742-3b33-44f2-92be-47421328ed1c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667167389-172.17.0.9-1596011919597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46379,DS-5da259c6-afc5-4920-93a6-e0bc880d9f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-f194f826-6ede-4ca7-9721-d5a8dc3ff6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-b3da48cf-fef5-4b93-a3ec-140d347fb8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-eafaec58-6f43-494c-9f5f-1f0713730041,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-29d783bb-460b-44f2-8be4-63e1bd55370f,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-7ad52958-ea21-4b07-9f09-5964ca9b34fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-0f26ba18-0452-410a-a4de-2c1c98f25f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-1a3ec742-3b33-44f2-92be-47421328ed1c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-573484094-172.17.0.9-1596011998304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33724,DS-c4cfd6b4-a204-4e14-aab8-3e7b561c3641,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-50be9673-4bda-4763-83eb-970ba1197854,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-bd576ffe-4c5a-4cfc-b872-2c22ed6e9fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-95a2c36d-0f74-44cb-83d5-f97180796a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-28311bca-73eb-4522-8ec6-58d0aef86e46,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-05d838a1-1b51-4ccb-9e77-721b550ddd16,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-4ba84635-1f3b-4f6d-8fb0-ef6bce06ca72,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-feb097a0-2fce-4dd7-acc4-da9afb934a4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-573484094-172.17.0.9-1596011998304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33724,DS-c4cfd6b4-a204-4e14-aab8-3e7b561c3641,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-50be9673-4bda-4763-83eb-970ba1197854,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-bd576ffe-4c5a-4cfc-b872-2c22ed6e9fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-95a2c36d-0f74-44cb-83d5-f97180796a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-28311bca-73eb-4522-8ec6-58d0aef86e46,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-05d838a1-1b51-4ccb-9e77-721b550ddd16,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-4ba84635-1f3b-4f6d-8fb0-ef6bce06ca72,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-feb097a0-2fce-4dd7-acc4-da9afb934a4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1943809166-172.17.0.9-1596012039469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42195,DS-97b1bdd2-50e5-44b1-8a62-cee2928ce3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-e67be3a0-ec35-4793-bb2c-ed0d390735ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-f28add54-bca2-4169-89b4-093ccfb2fd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-e77f978a-66ca-40e7-ae75-53b2f8cab203,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-b83517f5-aff5-4d1e-bb18-5c8f6a25777e,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-d6f86d40-71ef-4c9f-9e06-b98eb6389ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-88eca39b-99c4-4c73-92e0-87de4e3fc6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-f58a02dc-2e20-4080-891f-25e18b0e1a99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1943809166-172.17.0.9-1596012039469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42195,DS-97b1bdd2-50e5-44b1-8a62-cee2928ce3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-e67be3a0-ec35-4793-bb2c-ed0d390735ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-f28add54-bca2-4169-89b4-093ccfb2fd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-e77f978a-66ca-40e7-ae75-53b2f8cab203,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-b83517f5-aff5-4d1e-bb18-5c8f6a25777e,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-d6f86d40-71ef-4c9f-9e06-b98eb6389ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-88eca39b-99c4-4c73-92e0-87de4e3fc6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-f58a02dc-2e20-4080-891f-25e18b0e1a99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192294764-172.17.0.9-1596012267957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38765,DS-46d114c7-3fa5-4191-ac7b-34100235817a,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-4991b617-4802-4c52-9a00-7d0e732e36b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-3bedd43f-6a36-4393-8ab2-9a0d35718067,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-58b6b424-415d-44e6-b6ae-45ae8528304f,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-ce4db874-899d-40ea-ba6a-1b434571cbae,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-fd935a61-d414-4847-9299-efb0ef198855,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-a435f115-12bd-4ada-b94a-da239730be57,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-e11ebca2-a5e7-4563-b3f5-98efd7a07156,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192294764-172.17.0.9-1596012267957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38765,DS-46d114c7-3fa5-4191-ac7b-34100235817a,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-4991b617-4802-4c52-9a00-7d0e732e36b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-3bedd43f-6a36-4393-8ab2-9a0d35718067,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-58b6b424-415d-44e6-b6ae-45ae8528304f,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-ce4db874-899d-40ea-ba6a-1b434571cbae,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-fd935a61-d414-4847-9299-efb0ef198855,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-a435f115-12bd-4ada-b94a-da239730be57,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-e11ebca2-a5e7-4563-b3f5-98efd7a07156,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1472124372-172.17.0.9-1596012471858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38398,DS-d80102d8-96a2-493f-a8c3-df025fc77d66,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-ac46aa5b-6cd9-4a07-82f4-7e5d41a7c33a,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-19997fb5-a12b-4cc2-93d6-e1af3c79efe0,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-50c840ec-4b75-4573-acad-54249a0d1e98,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-7e7e635f-8d59-46e7-a745-028ac5dd0c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-8fd45866-0632-462b-94a8-966b98d166ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-78f368c8-bc60-4793-8cd6-a07be7b735b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-17497998-d3b6-47d3-ac2b-57fc07ebcbc3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1472124372-172.17.0.9-1596012471858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38398,DS-d80102d8-96a2-493f-a8c3-df025fc77d66,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-ac46aa5b-6cd9-4a07-82f4-7e5d41a7c33a,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-19997fb5-a12b-4cc2-93d6-e1af3c79efe0,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-50c840ec-4b75-4573-acad-54249a0d1e98,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-7e7e635f-8d59-46e7-a745-028ac5dd0c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-8fd45866-0632-462b-94a8-966b98d166ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-78f368c8-bc60-4793-8cd6-a07be7b735b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-17497998-d3b6-47d3-ac2b-57fc07ebcbc3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-97683112-172.17.0.9-1596012510513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40834,DS-1176f943-2615-4227-b80d-d769af89952f,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-e0aeb947-545a-4fcd-aa8d-87cf92ad5197,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-0fab7ccb-1c4d-4756-b49a-bc0bc1f869a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-6536851b-26da-4fb5-9c8d-908e6b31a0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-721bb3f9-7433-47a5-8a70-9307e4286442,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-73715dc5-afb2-4ce9-abb6-b73789417aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-927b2920-6c88-46ff-99cc-ae61167781fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-41028d1e-bf70-42d3-af0a-78137cb95eab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-97683112-172.17.0.9-1596012510513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40834,DS-1176f943-2615-4227-b80d-d769af89952f,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-e0aeb947-545a-4fcd-aa8d-87cf92ad5197,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-0fab7ccb-1c4d-4756-b49a-bc0bc1f869a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-6536851b-26da-4fb5-9c8d-908e6b31a0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-721bb3f9-7433-47a5-8a70-9307e4286442,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-73715dc5-afb2-4ce9-abb6-b73789417aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-927b2920-6c88-46ff-99cc-ae61167781fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-41028d1e-bf70-42d3-af0a-78137cb95eab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560259098-172.17.0.9-1596012589441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46206,DS-0849af4c-43de-4026-83b4-18b009795464,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-96872748-b767-4de1-a7a0-d4004df60d21,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-8a14b415-11cb-4ff5-9ca1-fb1709699610,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-25d504c5-5d6a-4337-9a13-8f24ac46400e,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-0b891438-a1e0-40bc-943a-9faff25c8b82,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-9a88c119-7e2a-4c66-8306-5cd628848f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-48bb4413-abdc-4dd1-9308-f22cd1147ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-fd652427-66c7-4b49-8876-5a4a672a71db,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560259098-172.17.0.9-1596012589441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46206,DS-0849af4c-43de-4026-83b4-18b009795464,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-96872748-b767-4de1-a7a0-d4004df60d21,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-8a14b415-11cb-4ff5-9ca1-fb1709699610,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-25d504c5-5d6a-4337-9a13-8f24ac46400e,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-0b891438-a1e0-40bc-943a-9faff25c8b82,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-9a88c119-7e2a-4c66-8306-5cd628848f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-48bb4413-abdc-4dd1-9308-f22cd1147ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-fd652427-66c7-4b49-8876-5a4a672a71db,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-73004409-172.17.0.9-1596012706982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37271,DS-15ebbf4e-7a3f-4c04-bb1e-64fc98568d65,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-5688a253-3a81-48ae-b5e4-90b0305a2b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-bfd87da7-ba12-46b3-8c30-a017a445c4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-863d63b5-6e33-4e6b-b1b1-83459c870d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-eca80eb6-9f8a-448d-bc90-42fb0cb1207f,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-ca882f50-0fa0-4cd5-a9fa-d4294768000c,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-fc10f5c4-69cc-44e1-a4a2-d85346f3cf98,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-23c6267c-afa6-4191-84f4-72bf341eeb78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-73004409-172.17.0.9-1596012706982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37271,DS-15ebbf4e-7a3f-4c04-bb1e-64fc98568d65,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-5688a253-3a81-48ae-b5e4-90b0305a2b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-bfd87da7-ba12-46b3-8c30-a017a445c4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-863d63b5-6e33-4e6b-b1b1-83459c870d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-eca80eb6-9f8a-448d-bc90-42fb0cb1207f,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-ca882f50-0fa0-4cd5-a9fa-d4294768000c,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-fc10f5c4-69cc-44e1-a4a2-d85346f3cf98,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-23c6267c-afa6-4191-84f4-72bf341eeb78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1953584192-172.17.0.9-1596012790561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38727,DS-557feabb-6b23-4fb6-a54a-e9e104c6d0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-a383d5dc-98a4-4ea7-af36-e77470e4c755,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-a9d9699b-8894-458a-9344-4d59e6f542bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-d62224c0-db6d-4dee-8de1-0197ae3ee67c,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-5e466d3f-48eb-4ed3-980f-b9bfb3aa725a,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-3c2b5d88-e9ec-4e92-860d-982e464e144d,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-606f5e8a-a59f-4a93-b5f2-f82cc7ccacf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-d768372b-ae19-4a04-aaad-6a3773346a95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1953584192-172.17.0.9-1596012790561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38727,DS-557feabb-6b23-4fb6-a54a-e9e104c6d0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-a383d5dc-98a4-4ea7-af36-e77470e4c755,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-a9d9699b-8894-458a-9344-4d59e6f542bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-d62224c0-db6d-4dee-8de1-0197ae3ee67c,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-5e466d3f-48eb-4ed3-980f-b9bfb3aa725a,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-3c2b5d88-e9ec-4e92-860d-982e464e144d,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-606f5e8a-a59f-4a93-b5f2-f82cc7ccacf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-d768372b-ae19-4a04-aaad-6a3773346a95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726858640-172.17.0.9-1596012833214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36290,DS-fb4cc307-8eda-433e-b5c7-80de97e7dcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-42eeb3a2-b10d-4bd4-9a7d-c29631993a15,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-404abcc2-46e4-4d1d-af8b-166d9d98d2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-bdbdee7c-95b4-4581-a9ad-fc28b65ffc78,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-7951b99c-3d48-4f7d-9c60-f8af948f5603,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-5c976083-05f9-4234-b6c3-ddd67c5b0058,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-446d7172-5623-42c4-9b53-efa419e100b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-b0051890-d97e-41c6-a858-7eb9e586d6b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726858640-172.17.0.9-1596012833214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36290,DS-fb4cc307-8eda-433e-b5c7-80de97e7dcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-42eeb3a2-b10d-4bd4-9a7d-c29631993a15,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-404abcc2-46e4-4d1d-af8b-166d9d98d2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-bdbdee7c-95b4-4581-a9ad-fc28b65ffc78,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-7951b99c-3d48-4f7d-9c60-f8af948f5603,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-5c976083-05f9-4234-b6c3-ddd67c5b0058,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-446d7172-5623-42c4-9b53-efa419e100b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-b0051890-d97e-41c6-a858-7eb9e586d6b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1932846173-172.17.0.9-1596012913939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44768,DS-68f76f98-32af-4ac3-86a6-0ac374a53221,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-57a951ff-8e53-4b20-b4bf-2d966960fea6,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-065f8682-383f-4b95-9abf-0891385fbd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-c3630a2d-c9e9-4d14-b5a5-bafc81631917,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-ec9cfc0a-d17b-4208-9ced-701116f4c0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-8d7cf337-ead1-4cf4-b977-43e659488162,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-10f64e25-095a-4da8-84a8-5d2f585803ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-8d4b89f7-0c37-469a-a47c-a27a3289faae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1932846173-172.17.0.9-1596012913939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44768,DS-68f76f98-32af-4ac3-86a6-0ac374a53221,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-57a951ff-8e53-4b20-b4bf-2d966960fea6,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-065f8682-383f-4b95-9abf-0891385fbd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-c3630a2d-c9e9-4d14-b5a5-bafc81631917,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-ec9cfc0a-d17b-4208-9ced-701116f4c0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-8d7cf337-ead1-4cf4-b977-43e659488162,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-10f64e25-095a-4da8-84a8-5d2f585803ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-8d4b89f7-0c37-469a-a47c-a27a3289faae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703999869-172.17.0.9-1596012991473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37117,DS-c3781356-deaa-41e6-85d4-c960034938ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-23856492-abd9-4f46-abcb-0123247089c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-d4bab73b-f953-447d-87da-7b03783c52a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-c877f6fa-00ac-4ea9-8356-093a4c93784d,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-0758ae50-33f4-4e1c-9b94-2c2ca0041aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-e63785cc-4b4f-444a-b0f4-cc06260f21af,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-1fb14d1c-835f-41d6-ad8b-038d0f397ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-9ac656e9-4811-435d-8844-595edefc4caf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703999869-172.17.0.9-1596012991473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37117,DS-c3781356-deaa-41e6-85d4-c960034938ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-23856492-abd9-4f46-abcb-0123247089c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-d4bab73b-f953-447d-87da-7b03783c52a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-c877f6fa-00ac-4ea9-8356-093a4c93784d,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-0758ae50-33f4-4e1c-9b94-2c2ca0041aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-e63785cc-4b4f-444a-b0f4-cc06260f21af,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-1fb14d1c-835f-41d6-ad8b-038d0f397ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-9ac656e9-4811-435d-8844-595edefc4caf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638446956-172.17.0.9-1596013028603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36304,DS-43a25113-c001-4b4f-be18-e3440c4b08bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-25f50e0f-6ba5-4bbf-b494-318d9c669db4,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-83ea3d71-c8a9-4e15-91b7-686f72ef9256,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-e6cd1134-0262-4854-a319-0d886f517192,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-1a3e78d1-0434-44b5-9761-5f0ca73ecec6,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-5a003de4-e3c3-4c80-a0a9-d487aad7eb28,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-71130e1d-8b8a-4ccb-982f-a2fdbde27fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-cf055c27-1a45-44f3-8ae5-08936f3ab8ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638446956-172.17.0.9-1596013028603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36304,DS-43a25113-c001-4b4f-be18-e3440c4b08bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-25f50e0f-6ba5-4bbf-b494-318d9c669db4,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-83ea3d71-c8a9-4e15-91b7-686f72ef9256,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-e6cd1134-0262-4854-a319-0d886f517192,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-1a3e78d1-0434-44b5-9761-5f0ca73ecec6,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-5a003de4-e3c3-4c80-a0a9-d487aad7eb28,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-71130e1d-8b8a-4ccb-982f-a2fdbde27fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-cf055c27-1a45-44f3-8ae5-08936f3ab8ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856297394-172.17.0.9-1596013150990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39435,DS-ca83d3e8-921c-4384-9d86-38bcfe6940a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-ec28cf20-27a7-4447-bab5-dba52b596804,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-9deee404-849b-42a1-8b9f-c4590a66e246,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-c3c1248c-21f2-48d3-830e-c206d3d253d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-e47f8157-be35-4c4a-8d51-a459203206cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-947a4084-cfcd-499b-bf97-be6e02b3ceea,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-bcb99792-9d40-41f4-a8c5-41cd351384ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-fb3059fb-6e2b-4594-99e8-15c7fee91eed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856297394-172.17.0.9-1596013150990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39435,DS-ca83d3e8-921c-4384-9d86-38bcfe6940a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-ec28cf20-27a7-4447-bab5-dba52b596804,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-9deee404-849b-42a1-8b9f-c4590a66e246,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-c3c1248c-21f2-48d3-830e-c206d3d253d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-e47f8157-be35-4c4a-8d51-a459203206cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-947a4084-cfcd-499b-bf97-be6e02b3ceea,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-bcb99792-9d40-41f4-a8c5-41cd351384ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-fb3059fb-6e2b-4594-99e8-15c7fee91eed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-441774094-172.17.0.9-1596013267135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45446,DS-9bd2c780-8c04-441f-8734-3cb09bdde26e,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-5420d5a6-691d-4fc2-bae6-3bdb0d1a4fef,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-0e7fbc31-45c1-45b0-91f3-6d18cffc7be9,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-6c98dd9b-0ed6-457e-93e6-8ec1dbf75af2,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-c545726b-63a4-406d-a721-e057414a4cca,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-b807dd72-5e93-42b2-80b4-e9589c939780,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-0b38f6d4-a7ae-46d0-8c60-eed7cd5dc2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-d9fad4bd-58a7-4d77-a76e-1060a2be62ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-441774094-172.17.0.9-1596013267135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45446,DS-9bd2c780-8c04-441f-8734-3cb09bdde26e,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-5420d5a6-691d-4fc2-bae6-3bdb0d1a4fef,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-0e7fbc31-45c1-45b0-91f3-6d18cffc7be9,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-6c98dd9b-0ed6-457e-93e6-8ec1dbf75af2,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-c545726b-63a4-406d-a721-e057414a4cca,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-b807dd72-5e93-42b2-80b4-e9589c939780,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-0b38f6d4-a7ae-46d0-8c60-eed7cd5dc2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-d9fad4bd-58a7-4d77-a76e-1060a2be62ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840800098-172.17.0.9-1596013345253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37285,DS-d0884d36-0c9e-41b7-8c50-eae490e4656a,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-7331322c-cd2e-4d7b-a8f8-77241c1b56a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-68c3ab47-31ce-4fd0-bd1a-4ae8387f8212,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-d5e84a22-fcb7-41dc-8589-14f4b6aa1249,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-8e460234-92ed-4daf-a3da-784837977586,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-feb31586-58a7-4301-981d-89f6729e6947,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-a811c6f2-f9e4-4d31-a977-1b4490ba73f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-4f9120e2-25f2-4220-b3b4-302bc839ce56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840800098-172.17.0.9-1596013345253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37285,DS-d0884d36-0c9e-41b7-8c50-eae490e4656a,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-7331322c-cd2e-4d7b-a8f8-77241c1b56a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-68c3ab47-31ce-4fd0-bd1a-4ae8387f8212,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-d5e84a22-fcb7-41dc-8589-14f4b6aa1249,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-8e460234-92ed-4daf-a3da-784837977586,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-feb31586-58a7-4301-981d-89f6729e6947,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-a811c6f2-f9e4-4d31-a977-1b4490ba73f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-4f9120e2-25f2-4220-b3b4-302bc839ce56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700944003-172.17.0.9-1596013496487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37021,DS-1ff29c33-5ba6-422d-a567-837688c95a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-f35dba52-4efc-4024-b574-268c75f975cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-7403da13-85f2-47df-9a24-28a35f19836f,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-c39b0190-9ee1-47d8-a21b-04503d939db5,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-2456fcef-7dfa-492a-9d00-3562aa8e1913,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-a91fd998-a7a1-4447-bdeb-db338a9854e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-6d8f0057-33b1-4c94-b400-902a0fa76eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-4a8387e1-42d9-4593-88c9-d0b38364b2c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700944003-172.17.0.9-1596013496487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37021,DS-1ff29c33-5ba6-422d-a567-837688c95a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-f35dba52-4efc-4024-b574-268c75f975cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-7403da13-85f2-47df-9a24-28a35f19836f,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-c39b0190-9ee1-47d8-a21b-04503d939db5,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-2456fcef-7dfa-492a-9d00-3562aa8e1913,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-a91fd998-a7a1-4447-bdeb-db338a9854e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-6d8f0057-33b1-4c94-b400-902a0fa76eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-4a8387e1-42d9-4593-88c9-d0b38364b2c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811307635-172.17.0.9-1596013574161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42006,DS-1a83d176-203f-4d62-ac19-f6b463eebb78,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-133d00ed-fd8e-4df1-bde8-d50cb7c6e079,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-a88d435d-60b3-47b4-99f8-822a226d3221,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-beccb87d-ea1b-468c-a5cd-858d0aabe604,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-b6a6035d-11a0-4082-9fd6-87069d436b62,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-a7513deb-424b-4e6c-a83a-a6f5fb0bfe56,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-5b3715cf-6b59-4946-99bf-b25f9d7416b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-cf7db4c2-9cdf-4818-a02f-330b92571958,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811307635-172.17.0.9-1596013574161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42006,DS-1a83d176-203f-4d62-ac19-f6b463eebb78,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-133d00ed-fd8e-4df1-bde8-d50cb7c6e079,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-a88d435d-60b3-47b4-99f8-822a226d3221,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-beccb87d-ea1b-468c-a5cd-858d0aabe604,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-b6a6035d-11a0-4082-9fd6-87069d436b62,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-a7513deb-424b-4e6c-a83a-a6f5fb0bfe56,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-5b3715cf-6b59-4946-99bf-b25f9d7416b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-cf7db4c2-9cdf-4818-a02f-330b92571958,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1387939263-172.17.0.9-1596013803899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39528,DS-200aadfd-91a2-4f02-bfbb-409c3bb0f4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-c9befae7-8c0a-4671-8756-3597da86fd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-86bab61a-54a5-4028-b120-dbfebcbbe54e,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-a5645cd6-b098-41f1-b06d-bd56604fc9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-66a9d454-9b35-4f50-9b84-74f23cdde48d,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-1bf662fe-73d6-4e58-96f6-fb302c428ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-bdf9ceba-506a-46a7-aba9-c75a8f2f4257,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-5888661b-32a9-46bf-b531-ee1433616dfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1387939263-172.17.0.9-1596013803899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39528,DS-200aadfd-91a2-4f02-bfbb-409c3bb0f4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-c9befae7-8c0a-4671-8756-3597da86fd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-86bab61a-54a5-4028-b120-dbfebcbbe54e,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-a5645cd6-b098-41f1-b06d-bd56604fc9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-66a9d454-9b35-4f50-9b84-74f23cdde48d,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-1bf662fe-73d6-4e58-96f6-fb302c428ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-bdf9ceba-506a-46a7-aba9-c75a8f2f4257,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-5888661b-32a9-46bf-b531-ee1433616dfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3798597-172.17.0.9-1596013880161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36746,DS-6f138357-b2b8-4a62-9efe-8b8688da0e55,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-1ebc4f59-1297-4883-b707-7711cc570647,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-006728e9-5a7b-480d-9676-7725973ad987,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-9de1efd3-0307-4978-bb95-79e8b53f8491,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-01eea6b6-6d52-4281-948f-9494c5a9846a,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-72b67422-c4a3-484b-88ae-a90c0a10fba7,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-2ebc8b6d-2742-4499-a05e-bb11c1065aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-ea89f89c-8d8b-4936-921a-37ebdcb62d32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3798597-172.17.0.9-1596013880161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36746,DS-6f138357-b2b8-4a62-9efe-8b8688da0e55,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-1ebc4f59-1297-4883-b707-7711cc570647,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-006728e9-5a7b-480d-9676-7725973ad987,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-9de1efd3-0307-4978-bb95-79e8b53f8491,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-01eea6b6-6d52-4281-948f-9494c5a9846a,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-72b67422-c4a3-484b-88ae-a90c0a10fba7,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-2ebc8b6d-2742-4499-a05e-bb11c1065aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-ea89f89c-8d8b-4936-921a-37ebdcb62d32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689277092-172.17.0.9-1596014145454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34437,DS-a8d891fa-6cbd-4bdf-bcbb-1d5fc6f5e672,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-c4e9e545-9714-4e1a-9f42-6f9c7ef03eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-e7f02f1c-1042-43b9-a429-a31532736017,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-e337e685-0e4e-4c82-a7d6-22aeb212c0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-0d78e0a3-fd5d-4e19-8210-400e53ded092,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-596c2274-7464-4401-b7f9-5965ef04bc07,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-cef0fde1-f6e9-4ccd-9f13-1760e5dbc263,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-25d71ea8-488a-41f2-a081-3d0894b7501a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689277092-172.17.0.9-1596014145454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34437,DS-a8d891fa-6cbd-4bdf-bcbb-1d5fc6f5e672,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-c4e9e545-9714-4e1a-9f42-6f9c7ef03eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-e7f02f1c-1042-43b9-a429-a31532736017,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-e337e685-0e4e-4c82-a7d6-22aeb212c0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-0d78e0a3-fd5d-4e19-8210-400e53ded092,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-596c2274-7464-4401-b7f9-5965ef04bc07,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-cef0fde1-f6e9-4ccd-9f13-1760e5dbc263,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-25d71ea8-488a-41f2-a081-3d0894b7501a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-733518813-172.17.0.9-1596014182202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44355,DS-fd083681-36b9-4727-ba7f-85bde6df145d,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-55e8fc43-6d68-463e-a82e-07fe55107fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-6f27e35d-f436-4c63-96d5-336a53c272b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-5a2fb9c1-ae95-45f6-a1ce-35f4671ba34e,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-17b79b67-526f-4878-b8f2-7f4035d2caec,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-d23881f9-88a2-4574-bbb0-345f59ef233d,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-f24330aa-4dcc-40e0-a82c-b46a33115685,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-83e1b5e6-391d-4073-beea-058adfecbec1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-733518813-172.17.0.9-1596014182202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44355,DS-fd083681-36b9-4727-ba7f-85bde6df145d,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-55e8fc43-6d68-463e-a82e-07fe55107fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-6f27e35d-f436-4c63-96d5-336a53c272b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-5a2fb9c1-ae95-45f6-a1ce-35f4671ba34e,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-17b79b67-526f-4878-b8f2-7f4035d2caec,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-d23881f9-88a2-4574-bbb0-345f59ef233d,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-f24330aa-4dcc-40e0-a82c-b46a33115685,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-83e1b5e6-391d-4073-beea-058adfecbec1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22611999-172.17.0.9-1596014259285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33395,DS-6a9a794d-5e30-42a4-8ef0-a983844cee94,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-fc2f17bf-2f69-4726-864d-e9fa4b6b605b,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-b7491105-1ec0-488d-9538-67c1af81d92e,DISK], DatanodeInfoWithStorage[127.0.0.1:36767,DS-0da2cf4f-3cdb-4d3a-9926-d466a5d5b823,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-90874427-9471-474a-ad4b-e8324059f2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-16941cb3-7f27-4040-b1be-35c2789f00f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-02cc93e2-bb6d-43b3-bca8-f1f8b68383e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-28b60ff2-786d-4ed7-830d-4904d09d066e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22611999-172.17.0.9-1596014259285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33395,DS-6a9a794d-5e30-42a4-8ef0-a983844cee94,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-fc2f17bf-2f69-4726-864d-e9fa4b6b605b,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-b7491105-1ec0-488d-9538-67c1af81d92e,DISK], DatanodeInfoWithStorage[127.0.0.1:36767,DS-0da2cf4f-3cdb-4d3a-9926-d466a5d5b823,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-90874427-9471-474a-ad4b-e8324059f2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-16941cb3-7f27-4040-b1be-35c2789f00f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-02cc93e2-bb6d-43b3-bca8-f1f8b68383e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-28b60ff2-786d-4ed7-830d-4904d09d066e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371183616-172.17.0.9-1596014296440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46140,DS-9bdfc123-1151-4337-84df-a57af6442fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-70a4abc2-daf8-45c8-a1ec-4c0d199238e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-5292291e-1b65-4a25-8838-4cfa9521e8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-dc9d0b90-47a5-45d8-b844-ca18a7e7e610,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-9ea94fd6-a8a9-4304-a1bb-bab1808ee50b,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-e57a2b0d-373f-4a11-ab1f-7015afd0d84c,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-63a8dc58-b2ae-4af4-b7c4-3732bab06d86,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-f68b5b2f-259c-467c-8e67-b9ff86b87045,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371183616-172.17.0.9-1596014296440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46140,DS-9bdfc123-1151-4337-84df-a57af6442fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-70a4abc2-daf8-45c8-a1ec-4c0d199238e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-5292291e-1b65-4a25-8838-4cfa9521e8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-dc9d0b90-47a5-45d8-b844-ca18a7e7e610,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-9ea94fd6-a8a9-4304-a1bb-bab1808ee50b,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-e57a2b0d-373f-4a11-ab1f-7015afd0d84c,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-63a8dc58-b2ae-4af4-b7c4-3732bab06d86,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-f68b5b2f-259c-467c-8e67-b9ff86b87045,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418759897-172.17.0.9-1596014452385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34585,DS-6ff76f74-9c2c-4100-a00f-a06c8c627bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-e8c4ab40-5285-4bac-8b2d-1d9996a17e60,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-1b802591-c26a-4e90-9f18-299e877a8774,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-f4b1266c-f381-4936-bdf3-e6001ee4fad2,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-baa41b33-9c48-42af-8375-401fa1a1a3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-791c1cee-0648-471c-8cb6-bd331fab6ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-b509413b-2b15-4934-b447-d00eae6aafef,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-fc842362-e6d9-426c-b20e-a8e06fca1eec,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418759897-172.17.0.9-1596014452385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34585,DS-6ff76f74-9c2c-4100-a00f-a06c8c627bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-e8c4ab40-5285-4bac-8b2d-1d9996a17e60,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-1b802591-c26a-4e90-9f18-299e877a8774,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-f4b1266c-f381-4936-bdf3-e6001ee4fad2,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-baa41b33-9c48-42af-8375-401fa1a1a3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-791c1cee-0648-471c-8cb6-bd331fab6ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-b509413b-2b15-4934-b447-d00eae6aafef,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-fc842362-e6d9-426c-b20e-a8e06fca1eec,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412039416-172.17.0.9-1596014896624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36067,DS-3355ccd5-2ae1-4a0b-9f37-32bccd8a0c10,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-6fdd844e-f78c-4d20-8256-0cb0d2f7cf32,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-04f1df44-9540-4f6c-b5c6-cb7ab2704870,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-0ae4d4c6-3d62-4067-ad5f-9a2eb9464752,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-3fb1a554-0572-44b3-b82d-864175c2bcef,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-1b048bef-2a43-4ceb-b66a-92b5fdedbd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-df88b09c-4f49-403f-81e3-668d790e1c96,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-ec74d534-51bc-4e2e-93bb-f69b40987151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412039416-172.17.0.9-1596014896624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36067,DS-3355ccd5-2ae1-4a0b-9f37-32bccd8a0c10,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-6fdd844e-f78c-4d20-8256-0cb0d2f7cf32,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-04f1df44-9540-4f6c-b5c6-cb7ab2704870,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-0ae4d4c6-3d62-4067-ad5f-9a2eb9464752,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-3fb1a554-0572-44b3-b82d-864175c2bcef,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-1b048bef-2a43-4ceb-b66a-92b5fdedbd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-df88b09c-4f49-403f-81e3-668d790e1c96,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-ec74d534-51bc-4e2e-93bb-f69b40987151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959457455-172.17.0.9-1596014940481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42606,DS-1580a900-01ff-453e-a6a9-e43699d9b5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-c4ede497-e960-49eb-9752-637500c7a90b,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-651bbc13-22a7-4af9-abb9-109ad2811ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-77c86980-f734-4961-a923-e04dee137a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-3999e41f-294c-4065-b70a-b0a7e3aab9db,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-a72c956b-8923-4382-82d2-49b1733da72d,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-2b5a1fa0-032c-40a0-aaf6-848d47dd7c97,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-5041603c-5b0d-44e0-835c-1fcf0bbb2229,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959457455-172.17.0.9-1596014940481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42606,DS-1580a900-01ff-453e-a6a9-e43699d9b5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-c4ede497-e960-49eb-9752-637500c7a90b,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-651bbc13-22a7-4af9-abb9-109ad2811ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-77c86980-f734-4961-a923-e04dee137a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-3999e41f-294c-4065-b70a-b0a7e3aab9db,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-a72c956b-8923-4382-82d2-49b1733da72d,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-2b5a1fa0-032c-40a0-aaf6-848d47dd7c97,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-5041603c-5b0d-44e0-835c-1fcf0bbb2229,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83636729-172.17.0.9-1596015010896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43767,DS-c68d71fb-6436-46ff-a49a-54e4683eca7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-f0cbcad9-2ef5-49d7-8a41-aaa8a892c735,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-e0ba14a6-c833-448f-85ee-34e6ff40417a,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-f42a9071-b14e-4fac-97f7-1ac685a62b43,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-b4416ac4-53fe-4335-83d7-054f601210c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-eda142dd-4fa4-42e2-8fa7-0745ec345ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-dd2b0243-3599-414a-9692-f689fe59e69e,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-94908f81-0d05-4ffa-bedd-ac1d693c2c94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83636729-172.17.0.9-1596015010896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43767,DS-c68d71fb-6436-46ff-a49a-54e4683eca7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-f0cbcad9-2ef5-49d7-8a41-aaa8a892c735,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-e0ba14a6-c833-448f-85ee-34e6ff40417a,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-f42a9071-b14e-4fac-97f7-1ac685a62b43,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-b4416ac4-53fe-4335-83d7-054f601210c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-eda142dd-4fa4-42e2-8fa7-0745ec345ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-dd2b0243-3599-414a-9692-f689fe59e69e,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-94908f81-0d05-4ffa-bedd-ac1d693c2c94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146430057-172.17.0.9-1596015350308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35179,DS-e543a96f-e7ac-4403-b742-aa9bb301dc44,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-801d7a6a-892b-499c-93b8-f2c6cbd86a71,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-e8864fe1-4a8e-4bae-b147-589a371c5472,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-6a0e8934-540c-4396-b046-85a7b2bf52ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-795532d9-b848-47da-9d28-f1a36b163ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-0ea65a62-1011-4673-921d-8aba6deacb78,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-2ca20aae-454c-4dee-b106-0d1fb92673d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-7e3be6a7-a379-4b45-9cee-5a5416286ef1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146430057-172.17.0.9-1596015350308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35179,DS-e543a96f-e7ac-4403-b742-aa9bb301dc44,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-801d7a6a-892b-499c-93b8-f2c6cbd86a71,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-e8864fe1-4a8e-4bae-b147-589a371c5472,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-6a0e8934-540c-4396-b046-85a7b2bf52ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-795532d9-b848-47da-9d28-f1a36b163ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-0ea65a62-1011-4673-921d-8aba6deacb78,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-2ca20aae-454c-4dee-b106-0d1fb92673d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-7e3be6a7-a379-4b45-9cee-5a5416286ef1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099335800-172.17.0.9-1596015420789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43580,DS-aeafe85f-a869-437e-93ec-176caab5564b,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-6d1145b5-c462-41ac-a76e-347258ea5c83,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-925243ac-8a4d-43d1-b3b3-b9cc623ca80e,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-072c380c-4f23-4ef6-a46a-c6e574344413,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-690ef0ec-8ebd-403b-8af8-622a6507ad4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-5ed66a7e-676e-449f-a12c-052eadeb1376,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-d5488d04-46ba-4dfe-9b2e-24028db5e11f,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-0fc2a066-0a86-406e-bf9a-3119c5a5098d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099335800-172.17.0.9-1596015420789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43580,DS-aeafe85f-a869-437e-93ec-176caab5564b,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-6d1145b5-c462-41ac-a76e-347258ea5c83,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-925243ac-8a4d-43d1-b3b3-b9cc623ca80e,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-072c380c-4f23-4ef6-a46a-c6e574344413,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-690ef0ec-8ebd-403b-8af8-622a6507ad4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-5ed66a7e-676e-449f-a12c-052eadeb1376,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-d5488d04-46ba-4dfe-9b2e-24028db5e11f,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-0fc2a066-0a86-406e-bf9a-3119c5a5098d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255245985-172.17.0.9-1596015499240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41631,DS-40633c14-290b-44f0-b99a-af71e30b35f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-a1dd9e99-3a63-40ff-85c8-97df18a33c22,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-43b68423-4c6e-4d95-92ca-4198240661f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-85c8d6ef-a258-4877-99c0-96f854e9342b,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-1b75deed-e7fb-4843-8da4-0edf0f0dc5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-49f09b26-3a85-47cc-a927-9cf734b78661,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-7803880d-98cc-4fec-853f-78da9f66cba3,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-2e9b39dc-a56e-4d45-b23d-de4952645c8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255245985-172.17.0.9-1596015499240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41631,DS-40633c14-290b-44f0-b99a-af71e30b35f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-a1dd9e99-3a63-40ff-85c8-97df18a33c22,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-43b68423-4c6e-4d95-92ca-4198240661f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-85c8d6ef-a258-4877-99c0-96f854e9342b,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-1b75deed-e7fb-4843-8da4-0edf0f0dc5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-49f09b26-3a85-47cc-a927-9cf734b78661,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-7803880d-98cc-4fec-853f-78da9f66cba3,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-2e9b39dc-a56e-4d45-b23d-de4952645c8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1620907127-172.17.0.9-1596015616773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36592,DS-6b3f0599-f70a-404a-8fb0-65393a7f1980,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-3e78e3ce-2be8-49c9-bf94-99286fe94323,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-3972c16f-9377-4cc5-a6a9-cd770d1ef073,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-6df5d05e-8316-4241-b5ba-410ccf8842b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-9f8ce064-69cd-4e81-ae65-9616b91d9431,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-9b0502a0-31ad-4572-9dc8-9475d6ad08a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-5befdcb2-53dd-4ca7-8bce-de5aac0f9756,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-7925643c-9893-45a8-a102-ed841a14b3bf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1620907127-172.17.0.9-1596015616773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36592,DS-6b3f0599-f70a-404a-8fb0-65393a7f1980,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-3e78e3ce-2be8-49c9-bf94-99286fe94323,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-3972c16f-9377-4cc5-a6a9-cd770d1ef073,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-6df5d05e-8316-4241-b5ba-410ccf8842b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-9f8ce064-69cd-4e81-ae65-9616b91d9431,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-9b0502a0-31ad-4572-9dc8-9475d6ad08a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-5befdcb2-53dd-4ca7-8bce-de5aac0f9756,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-7925643c-9893-45a8-a102-ed841a14b3bf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 24 out of 50
result: false positive !!!
Total execution time in seconds : 5818
