reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712198595-172.17.0.13-1595526186686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40547,DS-90455aa7-abee-4b57-833a-5b3365d064c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-546ac0c1-62ef-48dd-9c60-c78002861973,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-9ebbd524-ba25-4057-9cbb-bbf1812c0b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-fdcfd489-4323-4036-b974-39d161dff83e,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-a2579578-3ea3-430d-b846-32d87a7e16bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-080af453-0ac1-4fd9-94dc-b032006d6b20,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-53e81de0-93e8-49a9-8cfa-48bb90a9d392,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-cb5c3d14-d731-46ed-bc42-01909741c142,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712198595-172.17.0.13-1595526186686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40547,DS-90455aa7-abee-4b57-833a-5b3365d064c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-546ac0c1-62ef-48dd-9c60-c78002861973,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-9ebbd524-ba25-4057-9cbb-bbf1812c0b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-fdcfd489-4323-4036-b974-39d161dff83e,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-a2579578-3ea3-430d-b846-32d87a7e16bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-080af453-0ac1-4fd9-94dc-b032006d6b20,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-53e81de0-93e8-49a9-8cfa-48bb90a9d392,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-cb5c3d14-d731-46ed-bc42-01909741c142,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077898893-172.17.0.13-1595526700562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35895,DS-98ef0406-d74f-4c98-bfae-4625c2e34246,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-2b3b5827-1d8e-47b4-8239-77e715e63349,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-a84c8406-396f-448e-982c-2b01f04c8377,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-e6365d19-51fb-41cd-b22d-18309df0580d,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-5c7b5fca-6b3e-4f5f-ace4-1d51496df69e,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-30a605a2-57fc-446f-986b-4e15397e438c,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-537eb7f8-001c-435a-9c0c-3260e7ad508c,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-d08dec29-c1c1-4dc0-91a9-e30914b35496,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077898893-172.17.0.13-1595526700562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35895,DS-98ef0406-d74f-4c98-bfae-4625c2e34246,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-2b3b5827-1d8e-47b4-8239-77e715e63349,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-a84c8406-396f-448e-982c-2b01f04c8377,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-e6365d19-51fb-41cd-b22d-18309df0580d,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-5c7b5fca-6b3e-4f5f-ace4-1d51496df69e,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-30a605a2-57fc-446f-986b-4e15397e438c,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-537eb7f8-001c-435a-9c0c-3260e7ad508c,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-d08dec29-c1c1-4dc0-91a9-e30914b35496,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146899778-172.17.0.13-1595526887370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40253,DS-01347e06-305c-4679-aa6a-bcbbbd2d60e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-e946f3bb-f5bb-4aa8-a5b2-bceef8bc00e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34590,DS-f68d6726-0649-4a85-b761-ebd3b10b8215,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-3d09ae00-c7e2-4f9c-8321-f21d71725ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-3d2ddda4-87b1-4b5e-aac0-b5505a1ab88b,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-c0f8c03c-b700-4808-b221-f86ca6abce31,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-51be84bc-a4f4-4a1e-9a90-8e7e0a43ee67,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-6c9c39ed-948e-416c-8af1-8e70bdda25e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146899778-172.17.0.13-1595526887370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40253,DS-01347e06-305c-4679-aa6a-bcbbbd2d60e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-e946f3bb-f5bb-4aa8-a5b2-bceef8bc00e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34590,DS-f68d6726-0649-4a85-b761-ebd3b10b8215,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-3d09ae00-c7e2-4f9c-8321-f21d71725ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-3d2ddda4-87b1-4b5e-aac0-b5505a1ab88b,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-c0f8c03c-b700-4808-b221-f86ca6abce31,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-51be84bc-a4f4-4a1e-9a90-8e7e0a43ee67,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-6c9c39ed-948e-416c-8af1-8e70bdda25e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398133557-172.17.0.13-1595526976516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41055,DS-40a65225-eba5-4543-8696-3d8e912ebaba,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-62f16c40-2e97-471d-bc7f-fe6d32d21e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-3be804c2-a7a7-4570-b367-fc005a31d930,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-1064a66a-ddb9-448f-8a2d-5d5f4c6c506a,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-206cccc6-b672-4a54-a519-a3e68bcf1886,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-e7ea5e37-15d6-423e-9fe9-a15fa96226a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-8d9d96f8-c5aa-4cd9-b381-ce1e0ed2b463,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-52121772-44c3-43a8-8ef8-3067bd8ee659,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398133557-172.17.0.13-1595526976516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41055,DS-40a65225-eba5-4543-8696-3d8e912ebaba,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-62f16c40-2e97-471d-bc7f-fe6d32d21e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-3be804c2-a7a7-4570-b367-fc005a31d930,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-1064a66a-ddb9-448f-8a2d-5d5f4c6c506a,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-206cccc6-b672-4a54-a519-a3e68bcf1886,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-e7ea5e37-15d6-423e-9fe9-a15fa96226a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-8d9d96f8-c5aa-4cd9-b381-ce1e0ed2b463,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-52121772-44c3-43a8-8ef8-3067bd8ee659,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-445781966-172.17.0.13-1595527358373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33372,DS-4076dc6a-7376-4271-889e-e899fab7a8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-a877f58d-4a99-46c0-837c-458f19bfc2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-bed14acf-b23b-4d9f-966e-11101ae4352b,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-4bd0ca9a-b7de-4351-afce-1ce37dcd3531,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-2e780672-3643-4864-86a4-a50335d7f88f,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-923200d7-d2b9-4ee4-981f-b0b5236b88a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-10750707-2881-4147-8964-e086c4ff5d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-79b4ce6b-ce07-4f1a-973c-c72de2f13604,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-445781966-172.17.0.13-1595527358373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33372,DS-4076dc6a-7376-4271-889e-e899fab7a8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-a877f58d-4a99-46c0-837c-458f19bfc2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-bed14acf-b23b-4d9f-966e-11101ae4352b,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-4bd0ca9a-b7de-4351-afce-1ce37dcd3531,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-2e780672-3643-4864-86a4-a50335d7f88f,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-923200d7-d2b9-4ee4-981f-b0b5236b88a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-10750707-2881-4147-8964-e086c4ff5d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-79b4ce6b-ce07-4f1a-973c-c72de2f13604,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1803976125-172.17.0.13-1595527835149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39214,DS-352f25ca-03a2-43aa-bff9-ad399492b310,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-cb5e75f7-2f74-43e3-95f2-70b15b50c27b,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-0aa6fb89-3997-468b-9558-e2556048c3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-7e263469-41e8-4d28-9442-5cb147f8972d,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-f25b0557-12ef-486b-b491-e5993a7a3278,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-4612a3bd-fce4-4f5e-9072-944dd5ff5298,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-c0fee890-653f-4cd7-b9ca-a3cdadd6c78b,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-25da413c-6626-476c-af43-e82d1c506377,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1803976125-172.17.0.13-1595527835149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39214,DS-352f25ca-03a2-43aa-bff9-ad399492b310,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-cb5e75f7-2f74-43e3-95f2-70b15b50c27b,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-0aa6fb89-3997-468b-9558-e2556048c3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-7e263469-41e8-4d28-9442-5cb147f8972d,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-f25b0557-12ef-486b-b491-e5993a7a3278,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-4612a3bd-fce4-4f5e-9072-944dd5ff5298,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-c0fee890-653f-4cd7-b9ca-a3cdadd6c78b,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-25da413c-6626-476c-af43-e82d1c506377,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1049154045-172.17.0.13-1595529440134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46053,DS-e1de5996-6f56-4841-a35c-8a312e3ef106,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-d8c7d1de-e4ca-4f08-9205-8f57e41d0783,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-4378047c-9c0e-4de9-a6c4-4995a16434f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-1056363b-8542-4f9e-8f6d-4f51752365ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-12a5e36d-a330-467d-848c-cdfea40b8de1,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-5530d9da-bd4c-495b-9ff7-79123f5af119,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-c5e02408-163b-4836-8115-6a485d1859b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-2109c86e-c3ea-48a1-92e3-dd0a5ab907f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1049154045-172.17.0.13-1595529440134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46053,DS-e1de5996-6f56-4841-a35c-8a312e3ef106,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-d8c7d1de-e4ca-4f08-9205-8f57e41d0783,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-4378047c-9c0e-4de9-a6c4-4995a16434f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-1056363b-8542-4f9e-8f6d-4f51752365ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-12a5e36d-a330-467d-848c-cdfea40b8de1,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-5530d9da-bd4c-495b-9ff7-79123f5af119,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-c5e02408-163b-4836-8115-6a485d1859b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-2109c86e-c3ea-48a1-92e3-dd0a5ab907f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1193876233-172.17.0.13-1595530050901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39345,DS-022952fa-1cf6-4608-a88a-5fbadbd70401,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-7d1bf19d-0eec-47d8-abf6-28462d8f82dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-625ffd65-c0a3-4cdc-a845-b8bc56b85f00,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-7ba7698d-cb41-447b-a2d2-fa1bb31d1777,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-cc870eec-cd90-45d1-96f0-c64e1cf03a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-324489b3-261d-42c1-8f70-4b485dc681a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-532e55dd-b715-4736-b83c-15904a96b53f,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-679cbc9e-c652-4165-b5c1-42ce629dedf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1193876233-172.17.0.13-1595530050901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39345,DS-022952fa-1cf6-4608-a88a-5fbadbd70401,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-7d1bf19d-0eec-47d8-abf6-28462d8f82dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-625ffd65-c0a3-4cdc-a845-b8bc56b85f00,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-7ba7698d-cb41-447b-a2d2-fa1bb31d1777,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-cc870eec-cd90-45d1-96f0-c64e1cf03a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-324489b3-261d-42c1-8f70-4b485dc681a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-532e55dd-b715-4736-b83c-15904a96b53f,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-679cbc9e-c652-4165-b5c1-42ce629dedf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185720431-172.17.0.13-1595530596376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38429,DS-2dbbf4ed-fb7b-436e-a843-6e9e90f66839,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-c466b51d-97c2-4504-a068-cf098f5b0527,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-fa6fd98a-fe8c-47b3-ae2f-adda5e945559,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-f3073898-0bc7-46db-86f5-83271705ccde,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-8f2501b5-ca6b-450b-977d-8a3d54070b38,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-f24b5329-98c8-48bf-8b77-5faa0e4bdd74,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-6aa09c5a-e0e8-4e32-b0ba-089108a62d28,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-e8bad9e6-e2a4-41b9-9827-86c240f2ec61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185720431-172.17.0.13-1595530596376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38429,DS-2dbbf4ed-fb7b-436e-a843-6e9e90f66839,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-c466b51d-97c2-4504-a068-cf098f5b0527,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-fa6fd98a-fe8c-47b3-ae2f-adda5e945559,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-f3073898-0bc7-46db-86f5-83271705ccde,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-8f2501b5-ca6b-450b-977d-8a3d54070b38,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-f24b5329-98c8-48bf-8b77-5faa0e4bdd74,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-6aa09c5a-e0e8-4e32-b0ba-089108a62d28,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-e8bad9e6-e2a4-41b9-9827-86c240f2ec61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1287246267-172.17.0.13-1595531987789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37969,DS-a082ba6a-621c-42d8-ae06-ff519c30f662,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-322d6c04-d221-47d9-970c-95c9b3e056ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-1886cd60-8189-4c87-b6da-70fd7ccc17d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-6a17312a-3bb7-44d2-ae9a-54045d910420,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-32ecffff-fd1c-450d-ace8-83e6b02f0bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-3805ce6c-77e7-424e-bd7f-be98b7129694,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-307d2eb9-e173-4199-a737-8212a1eba21b,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-b48af8dd-2315-4ad3-966e-482d1f7c2a6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1287246267-172.17.0.13-1595531987789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37969,DS-a082ba6a-621c-42d8-ae06-ff519c30f662,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-322d6c04-d221-47d9-970c-95c9b3e056ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-1886cd60-8189-4c87-b6da-70fd7ccc17d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-6a17312a-3bb7-44d2-ae9a-54045d910420,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-32ecffff-fd1c-450d-ace8-83e6b02f0bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-3805ce6c-77e7-424e-bd7f-be98b7129694,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-307d2eb9-e173-4199-a737-8212a1eba21b,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-b48af8dd-2315-4ad3-966e-482d1f7c2a6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1017458787-172.17.0.13-1595532386729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35785,DS-c0927ced-6468-4140-89e0-6bffb7f43ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-22e79a1d-ced8-41c6-8fea-8a2328ac35c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-17ac9337-bb96-4da8-aa98-a738feec7db6,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-2ef6c37e-0be9-48c4-b337-1d179f2b3cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-5c9bf526-97ae-4605-a5a8-18719a5f400a,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-5e188848-8ff9-419b-961e-d2b95c60555b,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-7c382a27-a1ea-48d1-b107-d0742a35bfac,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-cabfab45-b0b0-4dfc-bd7d-032b8436cbb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1017458787-172.17.0.13-1595532386729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35785,DS-c0927ced-6468-4140-89e0-6bffb7f43ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-22e79a1d-ced8-41c6-8fea-8a2328ac35c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-17ac9337-bb96-4da8-aa98-a738feec7db6,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-2ef6c37e-0be9-48c4-b337-1d179f2b3cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-5c9bf526-97ae-4605-a5a8-18719a5f400a,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-5e188848-8ff9-419b-961e-d2b95c60555b,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-7c382a27-a1ea-48d1-b107-d0742a35bfac,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-cabfab45-b0b0-4dfc-bd7d-032b8436cbb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183487428-172.17.0.13-1595532425966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34835,DS-ec05de9b-30af-4b45-84ef-3ec33aeb1883,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-a7cca935-ab00-40f9-9d80-d06bed8f29f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-55323062-cbf1-4301-b9f6-05fa1b66b1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-03627065-4624-4ba9-b98f-4e7479cda7da,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-67949dd0-9ebe-4c63-8a35-2e398df5f14a,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-58e038e8-1fdb-43e6-b745-0507c7266a95,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-4671ca0b-170c-4c2f-b94d-c0aa9a38ac94,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-81eded02-f3b6-4d7e-a207-7f730a585a83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183487428-172.17.0.13-1595532425966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34835,DS-ec05de9b-30af-4b45-84ef-3ec33aeb1883,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-a7cca935-ab00-40f9-9d80-d06bed8f29f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-55323062-cbf1-4301-b9f6-05fa1b66b1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-03627065-4624-4ba9-b98f-4e7479cda7da,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-67949dd0-9ebe-4c63-8a35-2e398df5f14a,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-58e038e8-1fdb-43e6-b745-0507c7266a95,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-4671ca0b-170c-4c2f-b94d-c0aa9a38ac94,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-81eded02-f3b6-4d7e-a207-7f730a585a83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045431544-172.17.0.13-1595532470881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41308,DS-76aab81a-a816-4107-b0b6-192eeefbe8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-eb0a8b37-94aa-4cdd-ab84-8ed1d73433a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-f6579159-d9eb-49f8-8472-df1b846b6fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-1d2fae6c-6904-45e4-854e-7f174c27f70a,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-ee1425db-e760-4bc7-8698-c5702efec956,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-64b41a39-21d4-46fd-8449-18c3c58ff734,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-87c097dd-8ee7-422c-86b9-2bbf4a07e983,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-6db92192-82c0-46bd-8603-b17a80c39653,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045431544-172.17.0.13-1595532470881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41308,DS-76aab81a-a816-4107-b0b6-192eeefbe8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-eb0a8b37-94aa-4cdd-ab84-8ed1d73433a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-f6579159-d9eb-49f8-8472-df1b846b6fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-1d2fae6c-6904-45e4-854e-7f174c27f70a,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-ee1425db-e760-4bc7-8698-c5702efec956,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-64b41a39-21d4-46fd-8449-18c3c58ff734,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-87c097dd-8ee7-422c-86b9-2bbf4a07e983,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-6db92192-82c0-46bd-8603-b17a80c39653,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 6823
