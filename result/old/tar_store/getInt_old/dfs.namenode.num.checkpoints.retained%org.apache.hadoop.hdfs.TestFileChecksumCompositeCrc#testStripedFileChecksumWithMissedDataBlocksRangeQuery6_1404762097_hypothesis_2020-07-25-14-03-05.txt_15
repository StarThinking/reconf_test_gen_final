reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-555849797-172.17.0.20-1595685907534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38070,DS-65203e53-15ea-49b8-bd65-dcd1ca842774,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-85f3cd25-6594-44fa-8f6b-6cc904090791,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-a58915da-f42f-4597-861d-fa1eefaa0108,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-add8413c-b281-4279-9c23-55105085ea9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-2e8b477d-9c9f-422f-94ff-3c33f0409ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-5e58bdca-5455-4889-9727-104d68017f84,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-13528ec2-9aef-40d7-af12-c8ac1eff3d18,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-bba4bb78-29d1-45e6-8c43-5adab7daeefe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-555849797-172.17.0.20-1595685907534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38070,DS-65203e53-15ea-49b8-bd65-dcd1ca842774,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-85f3cd25-6594-44fa-8f6b-6cc904090791,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-a58915da-f42f-4597-861d-fa1eefaa0108,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-add8413c-b281-4279-9c23-55105085ea9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-2e8b477d-9c9f-422f-94ff-3c33f0409ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-5e58bdca-5455-4889-9727-104d68017f84,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-13528ec2-9aef-40d7-af12-c8ac1eff3d18,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-bba4bb78-29d1-45e6-8c43-5adab7daeefe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214051602-172.17.0.20-1595685976353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40265,DS-86c5c64f-3ae4-4fb5-8fd1-c84392e6ec00,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-d8b5a821-1f01-4022-b2a1-91ee5930be37,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-19716c52-d4ff-4cff-affd-9f7d74279a20,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-e99ea9f0-5514-4b62-be48-68872a0beb49,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-12ddaae1-0425-4a32-8494-1926597b4702,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-88438cac-e457-4a70-92f6-b22a32b0306d,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-ac80372d-7b37-410a-89bd-b70dbbc22114,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-e49bede8-6c95-486c-af1b-b4e301839f8e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214051602-172.17.0.20-1595685976353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40265,DS-86c5c64f-3ae4-4fb5-8fd1-c84392e6ec00,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-d8b5a821-1f01-4022-b2a1-91ee5930be37,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-19716c52-d4ff-4cff-affd-9f7d74279a20,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-e99ea9f0-5514-4b62-be48-68872a0beb49,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-12ddaae1-0425-4a32-8494-1926597b4702,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-88438cac-e457-4a70-92f6-b22a32b0306d,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-ac80372d-7b37-410a-89bd-b70dbbc22114,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-e49bede8-6c95-486c-af1b-b4e301839f8e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193204466-172.17.0.20-1595686043882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40107,DS-b10e1a28-0189-4d1b-ada8-308e2ab655e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-befe99e2-1ea0-4d2e-aa56-b460636fbdca,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-f0d234d1-aeb3-45ab-84ce-f1a33404397e,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-d32b5726-af35-47fa-811d-3bd78fac5cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-31fa1d91-ce44-435f-8124-368a8a566e33,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-8b536136-95d4-4b45-baf5-20e86463972e,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-644890b3-cb08-4528-a5d0-38343a9f42eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-35b0f4bf-2d39-40a1-af6b-532e3ba91589,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193204466-172.17.0.20-1595686043882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40107,DS-b10e1a28-0189-4d1b-ada8-308e2ab655e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-befe99e2-1ea0-4d2e-aa56-b460636fbdca,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-f0d234d1-aeb3-45ab-84ce-f1a33404397e,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-d32b5726-af35-47fa-811d-3bd78fac5cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-31fa1d91-ce44-435f-8124-368a8a566e33,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-8b536136-95d4-4b45-baf5-20e86463972e,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-644890b3-cb08-4528-a5d0-38343a9f42eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-35b0f4bf-2d39-40a1-af6b-532e3ba91589,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892270685-172.17.0.20-1595686114242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38502,DS-83ffb93b-1ad2-4b35-819d-e48cc22eba2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-f9a6d36d-44f0-4ae7-9c42-bdcfa1a4ba44,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-075b971e-f511-4992-bbe0-1c2ad6439542,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-61d66d4a-9e08-4560-9113-82d1516c88a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-cb02b1ee-8d75-4be6-906c-602a0fdccc01,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-746b9edc-df1a-4b3e-ae46-d062761e66ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-fbd4b2b4-1874-4410-bc17-717246541d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-db24e05f-b183-40e2-92eb-dfa0518997a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892270685-172.17.0.20-1595686114242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38502,DS-83ffb93b-1ad2-4b35-819d-e48cc22eba2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-f9a6d36d-44f0-4ae7-9c42-bdcfa1a4ba44,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-075b971e-f511-4992-bbe0-1c2ad6439542,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-61d66d4a-9e08-4560-9113-82d1516c88a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-cb02b1ee-8d75-4be6-906c-602a0fdccc01,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-746b9edc-df1a-4b3e-ae46-d062761e66ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-fbd4b2b4-1874-4410-bc17-717246541d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-db24e05f-b183-40e2-92eb-dfa0518997a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102695654-172.17.0.20-1595686243634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37661,DS-acbb5d4f-d753-4860-9e23-beb86f206697,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-2b3706eb-6fd7-4594-8171-3eb13fbf166c,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-efa7d1b3-52dc-4d71-b72a-6de2bbf896d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-de140f39-f7c8-4826-9323-00bde1e4ea9f,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-def3f11e-e648-4569-96ff-0587920455d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-717656b4-8cff-441e-ad81-ea4430bf941b,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-e301663f-b15f-4807-918d-659045b5a5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-e5205f13-90a1-4e3b-b1a0-751a762250b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102695654-172.17.0.20-1595686243634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37661,DS-acbb5d4f-d753-4860-9e23-beb86f206697,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-2b3706eb-6fd7-4594-8171-3eb13fbf166c,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-efa7d1b3-52dc-4d71-b72a-6de2bbf896d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-de140f39-f7c8-4826-9323-00bde1e4ea9f,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-def3f11e-e648-4569-96ff-0587920455d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-717656b4-8cff-441e-ad81-ea4430bf941b,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-e301663f-b15f-4807-918d-659045b5a5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-e5205f13-90a1-4e3b-b1a0-751a762250b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-867692547-172.17.0.20-1595686522743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43135,DS-7fddfe08-c7da-49d9-852c-b9df7269f6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-7973d224-3f6c-4067-a694-48a9fbcf8337,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-9854f34f-258e-45c0-b263-ce5f25f65d72,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-a3bd2819-6e40-4a65-b0a7-a69ee0876c13,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-4caf525e-8c39-4918-bad3-670194de2b47,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-50a78f2e-d0e5-4498-9738-c4305db2abae,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-19a67404-e625-4b19-8cee-1dd9a68f2933,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-05f90a9f-35bc-43e1-b11c-5bf1c0a52f44,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-867692547-172.17.0.20-1595686522743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43135,DS-7fddfe08-c7da-49d9-852c-b9df7269f6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-7973d224-3f6c-4067-a694-48a9fbcf8337,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-9854f34f-258e-45c0-b263-ce5f25f65d72,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-a3bd2819-6e40-4a65-b0a7-a69ee0876c13,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-4caf525e-8c39-4918-bad3-670194de2b47,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-50a78f2e-d0e5-4498-9738-c4305db2abae,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-19a67404-e625-4b19-8cee-1dd9a68f2933,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-05f90a9f-35bc-43e1-b11c-5bf1c0a52f44,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136881018-172.17.0.20-1595686588403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33293,DS-d06be973-79e0-4e80-8851-81ae1e751a32,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-f3292f3a-60ab-436b-b28a-7792583e9409,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-dc516b98-90c2-46be-afa4-a8e77430e8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-15381eb5-b0d4-483a-8e07-2e478c15df81,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-bc5a1de3-ec78-47d3-b8b9-c8e479e3275a,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-bc86c54d-9cfe-4321-bfb8-c3ff6c465a55,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-b911b986-dca3-410f-ac83-4bb6dba8c02a,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-b457cda1-4894-43e5-a59a-8185f3892558,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136881018-172.17.0.20-1595686588403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33293,DS-d06be973-79e0-4e80-8851-81ae1e751a32,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-f3292f3a-60ab-436b-b28a-7792583e9409,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-dc516b98-90c2-46be-afa4-a8e77430e8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-15381eb5-b0d4-483a-8e07-2e478c15df81,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-bc5a1de3-ec78-47d3-b8b9-c8e479e3275a,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-bc86c54d-9cfe-4321-bfb8-c3ff6c465a55,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-b911b986-dca3-410f-ac83-4bb6dba8c02a,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-b457cda1-4894-43e5-a59a-8185f3892558,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344362796-172.17.0.20-1595686732489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41829,DS-1204c429-125e-409b-ac60-1bbe51acf805,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-1f8f97d5-1dc9-48bb-acd2-13ea33085270,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-94d3e927-c09d-4a6e-9e59-9756c2329f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-9f3c3054-eb7c-469b-b6e1-afd8e8ccbe5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-b1fa873d-677a-4857-b604-c3527562489e,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-1a2c49f2-03e1-4655-93f1-38a6fc52518e,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-ac564704-33f8-4aa8-a4c0-7e9681217238,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-86052db7-f5da-4ee7-882c-37a18fb959dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344362796-172.17.0.20-1595686732489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41829,DS-1204c429-125e-409b-ac60-1bbe51acf805,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-1f8f97d5-1dc9-48bb-acd2-13ea33085270,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-94d3e927-c09d-4a6e-9e59-9756c2329f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-9f3c3054-eb7c-469b-b6e1-afd8e8ccbe5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-b1fa873d-677a-4857-b604-c3527562489e,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-1a2c49f2-03e1-4655-93f1-38a6fc52518e,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-ac564704-33f8-4aa8-a4c0-7e9681217238,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-86052db7-f5da-4ee7-882c-37a18fb959dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1949693650-172.17.0.20-1595686932580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46462,DS-6d791f1a-1cb3-4080-9dfc-1c1b9a1eb04b,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-c333509c-5404-43f6-86ed-f8cce6a108d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-7f91f78e-aa80-47a9-aaf5-1f97f6ea9b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-73b02411-9014-4ef6-bab4-54fdfecda3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-d9f61c09-e149-4111-bcf1-67a00934d130,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-6ff5957d-c7b8-43bb-8ad9-7455d3532bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-ff5fad8a-9d31-47a6-992b-3b049f6b208e,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-07b60e5e-85d5-45ca-aba6-ffddf4a13a6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1949693650-172.17.0.20-1595686932580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46462,DS-6d791f1a-1cb3-4080-9dfc-1c1b9a1eb04b,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-c333509c-5404-43f6-86ed-f8cce6a108d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-7f91f78e-aa80-47a9-aaf5-1f97f6ea9b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-73b02411-9014-4ef6-bab4-54fdfecda3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-d9f61c09-e149-4111-bcf1-67a00934d130,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-6ff5957d-c7b8-43bb-8ad9-7455d3532bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-ff5fad8a-9d31-47a6-992b-3b049f6b208e,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-07b60e5e-85d5-45ca-aba6-ffddf4a13a6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076168175-172.17.0.20-1595687214620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44669,DS-9d4a8fac-7dbd-4ca9-af1a-66a70ebedbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-c2d438e7-d7a5-4565-b171-2d5b365c55dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-224bea0e-ba32-4a35-aeee-8c4ba4d1a735,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-16683506-0249-448d-bc7b-8ee519989d59,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-6ee5debd-6077-4c56-9743-2b02a7540c10,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-d5cb05c9-d96e-45bf-901b-73870754d421,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-0a34abcd-7451-437c-b958-37328b890ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-5c5a39f9-bb27-4ed2-baa5-7865818ca875,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076168175-172.17.0.20-1595687214620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44669,DS-9d4a8fac-7dbd-4ca9-af1a-66a70ebedbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-c2d438e7-d7a5-4565-b171-2d5b365c55dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-224bea0e-ba32-4a35-aeee-8c4ba4d1a735,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-16683506-0249-448d-bc7b-8ee519989d59,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-6ee5debd-6077-4c56-9743-2b02a7540c10,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-d5cb05c9-d96e-45bf-901b-73870754d421,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-0a34abcd-7451-437c-b958-37328b890ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-5c5a39f9-bb27-4ed2-baa5-7865818ca875,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533647671-172.17.0.20-1595687687128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38531,DS-f3cf10a7-3d22-4c90-b3e7-180139cb475d,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-b9223399-468a-4871-8c85-0bcad6ea9b83,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-1d9b60b3-c3bc-4ddf-9057-709bc3d5ea80,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-6e99133b-75a9-44d3-b3a1-332e648a9b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-918546e8-3142-470e-b490-4ca63c7a49c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-a4131cea-f220-444a-9590-3755005ed69f,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-f5274c92-3bc9-4b49-a664-1ae917cec024,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-5c5de0ee-3a63-4b17-b1ab-894353d4a41f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533647671-172.17.0.20-1595687687128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38531,DS-f3cf10a7-3d22-4c90-b3e7-180139cb475d,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-b9223399-468a-4871-8c85-0bcad6ea9b83,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-1d9b60b3-c3bc-4ddf-9057-709bc3d5ea80,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-6e99133b-75a9-44d3-b3a1-332e648a9b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-918546e8-3142-470e-b490-4ca63c7a49c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-a4131cea-f220-444a-9590-3755005ed69f,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-f5274c92-3bc9-4b49-a664-1ae917cec024,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-5c5de0ee-3a63-4b17-b1ab-894353d4a41f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-949185737-172.17.0.20-1595687757397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46783,DS-ec4baa16-6690-4ce9-b847-a8b5e4b030ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-7e241747-96c7-4050-9380-03af79bfd295,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-db79dd65-cb94-42fe-ad56-02eca4be1350,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-bd190bc7-9972-4a13-9acc-ce85cc7b3fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-881c54f1-aec7-440b-8846-cfaef213c438,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-2edb59ef-af71-4215-a017-5f720e2463e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-4a299f2e-d765-42f8-b590-48186d7ed4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-be973d8c-e296-4fe9-b90c-a3086af160ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-949185737-172.17.0.20-1595687757397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46783,DS-ec4baa16-6690-4ce9-b847-a8b5e4b030ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-7e241747-96c7-4050-9380-03af79bfd295,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-db79dd65-cb94-42fe-ad56-02eca4be1350,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-bd190bc7-9972-4a13-9acc-ce85cc7b3fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-881c54f1-aec7-440b-8846-cfaef213c438,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-2edb59ef-af71-4215-a017-5f720e2463e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-4a299f2e-d765-42f8-b590-48186d7ed4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-be973d8c-e296-4fe9-b90c-a3086af160ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988665011-172.17.0.20-1595687961560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43895,DS-6699dfc2-4e94-44f7-8b22-737fee8db6be,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-ae86f403-54cd-484b-89d3-fb4cc35bc39c,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-8a842275-be13-4366-8ac6-3f93e8f8294c,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-e6ed487c-dfc2-4d90-a5ea-a9562049d502,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-36c484bb-dd07-449f-8318-36227b143bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-93b7796b-8ba0-4f71-8f55-d8810fd87679,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-4ca46176-299f-4f7d-93d9-7d1c4015f948,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-1ce6f799-16e5-4ca5-8e45-983c01b4972f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988665011-172.17.0.20-1595687961560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43895,DS-6699dfc2-4e94-44f7-8b22-737fee8db6be,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-ae86f403-54cd-484b-89d3-fb4cc35bc39c,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-8a842275-be13-4366-8ac6-3f93e8f8294c,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-e6ed487c-dfc2-4d90-a5ea-a9562049d502,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-36c484bb-dd07-449f-8318-36227b143bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-93b7796b-8ba0-4f71-8f55-d8810fd87679,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-4ca46176-299f-4f7d-93d9-7d1c4015f948,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-1ce6f799-16e5-4ca5-8e45-983c01b4972f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345672367-172.17.0.20-1595688174267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34555,DS-ec6c3d56-0369-459c-a135-f79c2d7bbdad,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-5760d33e-bcf4-4f94-b590-43879d107674,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-45539489-856a-4820-992b-1b8f41602fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-dad7907a-3b6f-48ec-805e-11fd92a00b77,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-0fa15a2f-e05f-473e-af7f-9d404abdcefa,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-3753bfa2-68a5-458d-9703-87e22c9b5418,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-5960a22b-5e4a-4c60-8278-ba68118c80ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-13f061f7-4365-481f-947c-a0bb03f1cfe7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345672367-172.17.0.20-1595688174267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34555,DS-ec6c3d56-0369-459c-a135-f79c2d7bbdad,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-5760d33e-bcf4-4f94-b590-43879d107674,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-45539489-856a-4820-992b-1b8f41602fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-dad7907a-3b6f-48ec-805e-11fd92a00b77,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-0fa15a2f-e05f-473e-af7f-9d404abdcefa,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-3753bfa2-68a5-458d-9703-87e22c9b5418,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-5960a22b-5e4a-4c60-8278-ba68118c80ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-13f061f7-4365-481f-947c-a0bb03f1cfe7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909156106-172.17.0.20-1595688439544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40733,DS-4af9833b-73b2-4178-bb24-8e9315468011,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-14307714-fdfc-40ee-baa1-88d09176ca99,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-27dafb7e-d84c-4d9c-80e8-e4752190cd92,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-7dca4fef-9368-401e-acc2-0b68dbbd02fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-b3f70c49-95fb-4db2-bb99-22d74b1dd63d,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-0b1154b9-ad9c-4650-beba-9489ba2faf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-e7929f35-0cd0-4832-a27a-70aed05b5319,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-176098a2-3e81-4c58-b361-83829c60a659,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909156106-172.17.0.20-1595688439544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40733,DS-4af9833b-73b2-4178-bb24-8e9315468011,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-14307714-fdfc-40ee-baa1-88d09176ca99,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-27dafb7e-d84c-4d9c-80e8-e4752190cd92,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-7dca4fef-9368-401e-acc2-0b68dbbd02fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-b3f70c49-95fb-4db2-bb99-22d74b1dd63d,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-0b1154b9-ad9c-4650-beba-9489ba2faf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-e7929f35-0cd0-4832-a27a-70aed05b5319,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-176098a2-3e81-4c58-b361-83829c60a659,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652365497-172.17.0.20-1595688505319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36558,DS-98b56763-0ff1-49b9-ac74-d850b2459357,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-dd7bba9a-6c60-469c-812c-c8ddd392a384,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-faf2b164-0842-447b-921a-12aa7a76558a,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-fc9d4bbc-ee48-44e7-ac5c-6252325f0ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-8f20cc20-cb36-4842-8251-41cb52a22745,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-2c77a980-0da2-4922-93d4-ef75da285500,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-0cec874e-3f10-4f22-b0db-2f5ef882871e,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-3c7035c2-c697-4674-a294-94303806f421,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652365497-172.17.0.20-1595688505319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36558,DS-98b56763-0ff1-49b9-ac74-d850b2459357,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-dd7bba9a-6c60-469c-812c-c8ddd392a384,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-faf2b164-0842-447b-921a-12aa7a76558a,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-fc9d4bbc-ee48-44e7-ac5c-6252325f0ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-8f20cc20-cb36-4842-8251-41cb52a22745,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-2c77a980-0da2-4922-93d4-ef75da285500,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-0cec874e-3f10-4f22-b0db-2f5ef882871e,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-3c7035c2-c697-4674-a294-94303806f421,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-695576696-172.17.0.20-1595688883006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43826,DS-e065b8c3-6ebb-4114-9bf7-31fe68d78e62,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-a35bf689-00b9-413b-b218-709ecb135719,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-5ae9adb8-5516-400a-ab2a-2a25799d475e,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-2e551fad-7eed-4a03-a132-0536aa7f4940,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-eb5a7b0a-372a-4d90-957c-bae0f5fbd25e,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-69e345ad-b0d0-4df7-95df-bf67e81e2b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-a5d8f2c0-8a2b-4d5c-ba1b-54b08f21a495,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-46dcd204-48c7-4a40-9532-adca2763543d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-695576696-172.17.0.20-1595688883006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43826,DS-e065b8c3-6ebb-4114-9bf7-31fe68d78e62,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-a35bf689-00b9-413b-b218-709ecb135719,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-5ae9adb8-5516-400a-ab2a-2a25799d475e,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-2e551fad-7eed-4a03-a132-0536aa7f4940,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-eb5a7b0a-372a-4d90-957c-bae0f5fbd25e,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-69e345ad-b0d0-4df7-95df-bf67e81e2b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-a5d8f2c0-8a2b-4d5c-ba1b-54b08f21a495,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-46dcd204-48c7-4a40-9532-adca2763543d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727573002-172.17.0.20-1595689065473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32824,DS-395fab01-1ada-4dfb-937f-6315f5534f51,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-1b9a825d-b916-480a-821e-32c184db009c,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-b156f28c-cf8a-4ba2-830e-cce646f02544,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-a9d2bf07-e6bf-4f79-b06d-d3d70969b9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-45078f15-088d-4c91-bfb0-f7d06b8a161e,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-a95a1435-dcd7-4341-8801-815a63827f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-c70253d4-ba31-4b2d-86f9-38358f91ef35,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-9c45c318-5fc4-4a64-b1ff-25d8e9dffa7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727573002-172.17.0.20-1595689065473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32824,DS-395fab01-1ada-4dfb-937f-6315f5534f51,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-1b9a825d-b916-480a-821e-32c184db009c,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-b156f28c-cf8a-4ba2-830e-cce646f02544,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-a9d2bf07-e6bf-4f79-b06d-d3d70969b9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-45078f15-088d-4c91-bfb0-f7d06b8a161e,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-a95a1435-dcd7-4341-8801-815a63827f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-c70253d4-ba31-4b2d-86f9-38358f91ef35,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-9c45c318-5fc4-4a64-b1ff-25d8e9dffa7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008119170-172.17.0.20-1595689137885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38559,DS-cd0fb69f-2ccd-4e4b-82b6-0578875b0419,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-30eb0780-50dc-432d-aaad-00714a6fc72b,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-3fc809c7-cf17-4b34-86b0-6766af2112fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-e9df1dc1-54e5-4d5e-aaa4-43a37357ed85,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-52e88c80-b8e7-4f66-bfa6-fbf1006a06a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-c8d66e53-481a-488b-b6e9-5b655ac7e9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-c66b35ee-ed80-4e4e-831c-02862993b581,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-bb2b8771-bb02-4d6c-b9ca-d005ed9ff0b2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008119170-172.17.0.20-1595689137885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38559,DS-cd0fb69f-2ccd-4e4b-82b6-0578875b0419,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-30eb0780-50dc-432d-aaad-00714a6fc72b,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-3fc809c7-cf17-4b34-86b0-6766af2112fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-e9df1dc1-54e5-4d5e-aaa4-43a37357ed85,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-52e88c80-b8e7-4f66-bfa6-fbf1006a06a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-c8d66e53-481a-488b-b6e9-5b655ac7e9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-c66b35ee-ed80-4e4e-831c-02862993b581,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-bb2b8771-bb02-4d6c-b9ca-d005ed9ff0b2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077112282-172.17.0.20-1595689379499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45151,DS-1791f97c-2b39-491e-9fc3-3de61751bdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-a8e27e68-25d2-4bc7-8166-985d0bbf9ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-c9ee834f-227e-4651-b93d-1fe5f3b7c34a,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-28fd8dda-b2f4-46be-aabf-cb88de382a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-a2635433-2646-4000-86c8-7f99d7911103,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-f931391f-0db0-4600-9128-ae18d8a16249,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-7075a37f-6a4e-4e92-ae16-081194b48c11,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-a252835b-013e-452a-8a38-b89639a473cb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077112282-172.17.0.20-1595689379499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45151,DS-1791f97c-2b39-491e-9fc3-3de61751bdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-a8e27e68-25d2-4bc7-8166-985d0bbf9ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-c9ee834f-227e-4651-b93d-1fe5f3b7c34a,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-28fd8dda-b2f4-46be-aabf-cb88de382a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-a2635433-2646-4000-86c8-7f99d7911103,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-f931391f-0db0-4600-9128-ae18d8a16249,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-7075a37f-6a4e-4e92-ae16-081194b48c11,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-a252835b-013e-452a-8a38-b89639a473cb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1055428907-172.17.0.20-1595690061070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42164,DS-b6887c3b-dc20-4753-bf65-18a6ba063c80,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-c95ccf79-5523-4d89-a629-422ea37fc729,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-1492eab7-db5a-4e0a-abe7-b7a632a91a46,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-7613cd23-4fe0-4368-89ba-816fad5a7a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-6489ab95-9128-45d1-9b6a-72499ef5fbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-3098088f-0772-4872-a96e-e50c4c775543,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-9ba7d07d-b3ac-43c2-95b7-57a39c64c16b,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-916f4139-71fe-4437-814e-8e63fc099f66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1055428907-172.17.0.20-1595690061070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42164,DS-b6887c3b-dc20-4753-bf65-18a6ba063c80,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-c95ccf79-5523-4d89-a629-422ea37fc729,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-1492eab7-db5a-4e0a-abe7-b7a632a91a46,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-7613cd23-4fe0-4368-89ba-816fad5a7a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-6489ab95-9128-45d1-9b6a-72499ef5fbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-3098088f-0772-4872-a96e-e50c4c775543,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-9ba7d07d-b3ac-43c2-95b7-57a39c64c16b,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-916f4139-71fe-4437-814e-8e63fc099f66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2134881277-172.17.0.20-1595690126107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46055,DS-a9a9fcde-cd73-457b-b370-f77a51a31908,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-9e67e157-0522-4dc9-bf71-4fd93e56bee5,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-aefb8352-7c3e-4b87-8e66-83407d7b1f02,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-91e246af-3149-418c-94b5-2c9fd399f443,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-d6d32c78-605b-4a7e-8bce-bc33492b9453,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-a41805f2-f43c-488d-957c-7869a8594170,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-b2341740-281d-4623-8ebb-5eb67b63ca83,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-a2b444a3-db9e-442f-ab30-2072e6216938,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2134881277-172.17.0.20-1595690126107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46055,DS-a9a9fcde-cd73-457b-b370-f77a51a31908,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-9e67e157-0522-4dc9-bf71-4fd93e56bee5,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-aefb8352-7c3e-4b87-8e66-83407d7b1f02,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-91e246af-3149-418c-94b5-2c9fd399f443,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-d6d32c78-605b-4a7e-8bce-bc33492b9453,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-a41805f2-f43c-488d-957c-7869a8594170,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-b2341740-281d-4623-8ebb-5eb67b63ca83,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-a2b444a3-db9e-442f-ab30-2072e6216938,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1173614271-172.17.0.20-1595690397071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43205,DS-df7dd185-cb89-4187-a0ed-774b0c68e852,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-81b93063-774a-4ada-bdf4-fbb9d356ed2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-7a0364eb-823e-4364-b2b4-ca4c68f5bb61,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-eb284ef5-3be4-441d-87d0-0e498b25d8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-f9112aa3-8c3c-4d00-b303-fe00b538ca42,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-95ab13b5-d7b2-4172-ba34-d75a1bbba057,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-48c8d4bc-31a0-4aed-a6b3-f5e814fbb67c,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-117f371e-b830-43e0-b72e-eecf4b6b9f09,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1173614271-172.17.0.20-1595690397071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43205,DS-df7dd185-cb89-4187-a0ed-774b0c68e852,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-81b93063-774a-4ada-bdf4-fbb9d356ed2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-7a0364eb-823e-4364-b2b4-ca4c68f5bb61,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-eb284ef5-3be4-441d-87d0-0e498b25d8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-f9112aa3-8c3c-4d00-b303-fe00b538ca42,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-95ab13b5-d7b2-4172-ba34-d75a1bbba057,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-48c8d4bc-31a0-4aed-a6b3-f5e814fbb67c,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-117f371e-b830-43e0-b72e-eecf4b6b9f09,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203997463-172.17.0.20-1595690428144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41802,DS-7e10824b-0ba5-434f-94ba-c36693b755bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-94503268-679d-40b4-aece-667448830aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-1dfbee2b-5ca6-44ed-bd3e-342ff86100eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-59c05ceb-9691-4fe0-a700-24a27e269c42,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-f0d3c4e7-7749-482a-8484-76f98f4550a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-d79a5f25-6e82-4761-83d6-8f4fe89d784b,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-cd60d857-52e7-4c43-ab2a-cb9da3deaad6,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-67201196-aca2-4f2b-a797-8cbc20e68d70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203997463-172.17.0.20-1595690428144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41802,DS-7e10824b-0ba5-434f-94ba-c36693b755bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-94503268-679d-40b4-aece-667448830aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-1dfbee2b-5ca6-44ed-bd3e-342ff86100eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-59c05ceb-9691-4fe0-a700-24a27e269c42,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-f0d3c4e7-7749-482a-8484-76f98f4550a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-d79a5f25-6e82-4761-83d6-8f4fe89d784b,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-cd60d857-52e7-4c43-ab2a-cb9da3deaad6,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-67201196-aca2-4f2b-a797-8cbc20e68d70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2099575214-172.17.0.20-1595690493452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33462,DS-60d9c266-5b49-4613-82fa-a62c4a6c7b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-d3ec7f3c-d5f8-412b-918a-96dca7be14c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-00a29bd3-3446-44d7-9374-b4f0c2440b04,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-e29a6b25-cbf8-4867-9aaf-9d7e1165627b,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-1ba4a0eb-0d63-44ac-9115-838589c9d066,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-098236d0-dc26-4f19-ac4b-dfe5bbd2a66e,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-10fabcfb-c2a4-4ced-bdc3-d4be8116869a,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-5b79366f-d861-4da3-afe3-625e83e80968,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2099575214-172.17.0.20-1595690493452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33462,DS-60d9c266-5b49-4613-82fa-a62c4a6c7b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-d3ec7f3c-d5f8-412b-918a-96dca7be14c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-00a29bd3-3446-44d7-9374-b4f0c2440b04,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-e29a6b25-cbf8-4867-9aaf-9d7e1165627b,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-1ba4a0eb-0d63-44ac-9115-838589c9d066,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-098236d0-dc26-4f19-ac4b-dfe5bbd2a66e,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-10fabcfb-c2a4-4ced-bdc3-d4be8116869a,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-5b79366f-d861-4da3-afe3-625e83e80968,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337129190-172.17.0.20-1595690620807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42412,DS-b9e46f18-443e-4d0b-8ecb-811e127f0d52,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-97c5cea0-7168-4d3e-abc7-ddbb8afeeb17,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-13608ff7-81aa-4f00-b728-2592404e35d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-0745a271-f77f-476e-929f-c340f94d2b91,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-48e7ee9d-70fc-461c-bbf4-8b32fd2f2fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-0abdbc5d-e2d4-462e-b9aa-185cce0e1be7,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-2f7cb383-ac15-42a5-886f-e81952c8cd07,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-67e5698e-05a8-444d-9491-5d8e494e362b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337129190-172.17.0.20-1595690620807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42412,DS-b9e46f18-443e-4d0b-8ecb-811e127f0d52,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-97c5cea0-7168-4d3e-abc7-ddbb8afeeb17,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-13608ff7-81aa-4f00-b728-2592404e35d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-0745a271-f77f-476e-929f-c340f94d2b91,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-48e7ee9d-70fc-461c-bbf4-8b32fd2f2fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-0abdbc5d-e2d4-462e-b9aa-185cce0e1be7,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-2f7cb383-ac15-42a5-886f-e81952c8cd07,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-67e5698e-05a8-444d-9491-5d8e494e362b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826482191-172.17.0.20-1595690793271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43592,DS-0d5db855-cd81-4682-a3aa-a4cb4ac91f73,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-31869999-1c7d-4840-867f-211553d36d27,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-aa0c914f-b6b4-438b-bf2a-99714aa3a47b,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-47096dfb-223e-4256-a297-fd90f1f3ce79,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-7036ffd3-75d1-4670-898d-a5faba443cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-23e9caf0-dc64-4a07-94d7-92b5ac4e6fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-a7bc6d29-207f-428b-980e-573c4e230b35,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-4801f707-7b38-4a21-81f2-f8592af2a125,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826482191-172.17.0.20-1595690793271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43592,DS-0d5db855-cd81-4682-a3aa-a4cb4ac91f73,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-31869999-1c7d-4840-867f-211553d36d27,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-aa0c914f-b6b4-438b-bf2a-99714aa3a47b,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-47096dfb-223e-4256-a297-fd90f1f3ce79,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-7036ffd3-75d1-4670-898d-a5faba443cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-23e9caf0-dc64-4a07-94d7-92b5ac4e6fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-a7bc6d29-207f-428b-980e-573c4e230b35,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-4801f707-7b38-4a21-81f2-f8592af2a125,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029283978-172.17.0.20-1595690903160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34479,DS-9be9f52d-e298-42d7-a21d-1db3a5545994,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-a4cd48ab-7983-4d1c-8971-e4937056f36e,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-ebf471ad-5f1d-4461-936c-6f43e02b53db,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-e8b5dd6e-9041-4126-9e16-e612ed2bc0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-0ccbaeee-3fb7-49f2-be45-ea433de642cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-c932aa70-84f9-4d87-bb2f-3739f31497ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-87b126c0-066d-4a8f-9aa1-bc79ed2f203d,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-a4a0d451-d7ae-47e2-839c-a43268f3ed93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029283978-172.17.0.20-1595690903160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34479,DS-9be9f52d-e298-42d7-a21d-1db3a5545994,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-a4cd48ab-7983-4d1c-8971-e4937056f36e,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-ebf471ad-5f1d-4461-936c-6f43e02b53db,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-e8b5dd6e-9041-4126-9e16-e612ed2bc0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-0ccbaeee-3fb7-49f2-be45-ea433de642cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-c932aa70-84f9-4d87-bb2f-3739f31497ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-87b126c0-066d-4a8f-9aa1-bc79ed2f203d,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-a4a0d451-d7ae-47e2-839c-a43268f3ed93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5170
