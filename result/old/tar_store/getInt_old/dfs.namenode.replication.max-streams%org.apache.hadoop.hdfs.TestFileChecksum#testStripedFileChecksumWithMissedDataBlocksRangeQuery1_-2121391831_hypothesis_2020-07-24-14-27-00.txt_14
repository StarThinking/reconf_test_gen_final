reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1265466989-172.17.0.6-1595600900471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34100,DS-b4752b27-4409-4d1d-b14e-9edb4db577d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-7e4e6318-765a-4701-a12d-70ebc16e69a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-df2e8894-46d7-4b35-9739-2239d2ad483d,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-45166130-bea6-48be-b853-dbae0f696697,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-d5cacbe4-4eaa-4f24-ad21-2d8a819783c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-df6f71c2-4380-48a2-9e83-a20afd0693b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-8c78f0f0-90cf-4ce4-93f4-fd00e3e0f810,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-b76b6a63-2ecf-47e7-a37f-0f7eee697d39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1265466989-172.17.0.6-1595600900471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34100,DS-b4752b27-4409-4d1d-b14e-9edb4db577d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-7e4e6318-765a-4701-a12d-70ebc16e69a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-df2e8894-46d7-4b35-9739-2239d2ad483d,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-45166130-bea6-48be-b853-dbae0f696697,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-d5cacbe4-4eaa-4f24-ad21-2d8a819783c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-df6f71c2-4380-48a2-9e83-a20afd0693b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-8c78f0f0-90cf-4ce4-93f4-fd00e3e0f810,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-b76b6a63-2ecf-47e7-a37f-0f7eee697d39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1417278690-172.17.0.6-1595601058385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45113,DS-a2157223-86b0-486f-9757-6c897d462179,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-0e56decc-d007-4623-b17d-63e69c317150,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-633b76e5-d2b0-4e7f-9b36-13cd1656281b,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-071bf606-df53-4bf3-8533-ec1651111f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-47402dec-5a12-4404-bc01-3edb0fa71a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-75e95929-bb7d-4b83-83cf-239ddbf93743,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-f573b16d-3e07-4eab-aac5-7327e8200ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-7d2cd844-9164-4eeb-9c5f-a25f6a708044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1417278690-172.17.0.6-1595601058385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45113,DS-a2157223-86b0-486f-9757-6c897d462179,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-0e56decc-d007-4623-b17d-63e69c317150,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-633b76e5-d2b0-4e7f-9b36-13cd1656281b,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-071bf606-df53-4bf3-8533-ec1651111f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-47402dec-5a12-4404-bc01-3edb0fa71a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-75e95929-bb7d-4b83-83cf-239ddbf93743,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-f573b16d-3e07-4eab-aac5-7327e8200ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-7d2cd844-9164-4eeb-9c5f-a25f6a708044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800368547-172.17.0.6-1595601555240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38445,DS-384f041e-e65c-4ff9-bc2c-6a2958047451,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-b3480528-6823-4efb-93cc-2f5d84ded684,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-986bcb2a-3cfe-4cc7-b87c-20b4b3148e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-96003827-5c77-480d-b819-cda060c830b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-f986ae2e-fb35-4f41-a9a7-96e98acc104f,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-c554ab5a-953a-4736-80aa-b1d96af39a74,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-f75cf393-e655-40eb-8f05-3acd6edc1af6,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-30b8f779-d176-4771-a8f4-b9de219ef43a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800368547-172.17.0.6-1595601555240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38445,DS-384f041e-e65c-4ff9-bc2c-6a2958047451,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-b3480528-6823-4efb-93cc-2f5d84ded684,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-986bcb2a-3cfe-4cc7-b87c-20b4b3148e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-96003827-5c77-480d-b819-cda060c830b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-f986ae2e-fb35-4f41-a9a7-96e98acc104f,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-c554ab5a-953a-4736-80aa-b1d96af39a74,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-f75cf393-e655-40eb-8f05-3acd6edc1af6,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-30b8f779-d176-4771-a8f4-b9de219ef43a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663093615-172.17.0.6-1595601773236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44424,DS-cc029eb1-9475-41db-8f1b-bef5f5f4f8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-94952a60-cab7-49cf-ab33-2cf52d6e1b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-adff5d32-6538-4870-953d-924d87fce493,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-f6d78071-7d02-4a2c-a627-3326d7773c73,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-0d7b0623-cd92-4f86-8927-eabc9ad8afac,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-9781a6ec-4032-4cc7-a818-310cfbd00e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-a6e7cc39-26c9-4776-81aa-95e39acc2a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-6326fc31-a491-4ef8-925e-c9e86bdedc35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663093615-172.17.0.6-1595601773236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44424,DS-cc029eb1-9475-41db-8f1b-bef5f5f4f8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-94952a60-cab7-49cf-ab33-2cf52d6e1b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-adff5d32-6538-4870-953d-924d87fce493,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-f6d78071-7d02-4a2c-a627-3326d7773c73,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-0d7b0623-cd92-4f86-8927-eabc9ad8afac,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-9781a6ec-4032-4cc7-a818-310cfbd00e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-a6e7cc39-26c9-4776-81aa-95e39acc2a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-6326fc31-a491-4ef8-925e-c9e86bdedc35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1000493990-172.17.0.6-1595602250852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43454,DS-358e031c-e455-4aba-87c4-235b38cf0c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-97a7e702-ef37-44fc-b4f5-5b55d46e770f,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-5f5c6219-2657-4ab7-ab9a-f9c78592924f,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-ac8e696e-7b5a-49a1-9915-e18b5501b1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-7537f8a8-9966-4cec-8032-cb21c9199fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-a9f33aa0-d554-4cd6-87c8-224fd9d354e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-005a56b7-ac56-4e31-8be0-1f52ce0cbe62,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-541815f4-9130-4292-b266-05686999ccbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1000493990-172.17.0.6-1595602250852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43454,DS-358e031c-e455-4aba-87c4-235b38cf0c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-97a7e702-ef37-44fc-b4f5-5b55d46e770f,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-5f5c6219-2657-4ab7-ab9a-f9c78592924f,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-ac8e696e-7b5a-49a1-9915-e18b5501b1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-7537f8a8-9966-4cec-8032-cb21c9199fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-a9f33aa0-d554-4cd6-87c8-224fd9d354e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-005a56b7-ac56-4e31-8be0-1f52ce0cbe62,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-541815f4-9130-4292-b266-05686999ccbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-150273946-172.17.0.6-1595602889777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40703,DS-1ba71618-994e-4fe6-828f-dfebeb24e221,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-d9d03195-7731-4722-82e3-5851b5e1257a,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-63e175a4-f4c1-4c1f-8e8f-a25976b6bffc,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-79e0591d-c2b0-4dbb-8094-c96b83c143fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-b08192d8-551e-4ee8-8bb7-3d37c8781dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-c7b4b6c8-8cad-4a49-a277-d1e27dd33678,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-50fe17b6-2a02-48a7-b9c9-90c6627d2254,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-1618242c-b79e-45e8-915b-47ed018336cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-150273946-172.17.0.6-1595602889777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40703,DS-1ba71618-994e-4fe6-828f-dfebeb24e221,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-d9d03195-7731-4722-82e3-5851b5e1257a,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-63e175a4-f4c1-4c1f-8e8f-a25976b6bffc,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-79e0591d-c2b0-4dbb-8094-c96b83c143fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-b08192d8-551e-4ee8-8bb7-3d37c8781dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-c7b4b6c8-8cad-4a49-a277-d1e27dd33678,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-50fe17b6-2a02-48a7-b9c9-90c6627d2254,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-1618242c-b79e-45e8-915b-47ed018336cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809604152-172.17.0.6-1595603110754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36445,DS-938d8e6f-d5b8-4c32-9192-fd2e77868ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-92b6b48b-5950-41ea-9f28-f4404fb5050d,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-fff2eaec-afc8-4940-8535-e02d5d3395f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-d1e6b818-7bc2-4c72-bbad-76f05bb0f5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-677938d3-d075-4ae3-9e9b-f25c5311b095,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-ab38266b-bb8c-4d6c-a4ac-6b6f102f1cea,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-18b1e8f3-f9d3-477e-9f0d-b9c66e7134e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-a258fac6-7d08-4445-bb92-20965449663c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809604152-172.17.0.6-1595603110754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36445,DS-938d8e6f-d5b8-4c32-9192-fd2e77868ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-92b6b48b-5950-41ea-9f28-f4404fb5050d,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-fff2eaec-afc8-4940-8535-e02d5d3395f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-d1e6b818-7bc2-4c72-bbad-76f05bb0f5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-677938d3-d075-4ae3-9e9b-f25c5311b095,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-ab38266b-bb8c-4d6c-a4ac-6b6f102f1cea,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-18b1e8f3-f9d3-477e-9f0d-b9c66e7134e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-a258fac6-7d08-4445-bb92-20965449663c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086735255-172.17.0.6-1595603423798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43764,DS-6399717b-ae95-4f28-b1ec-704e7e988dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-7414fa5f-b334-4146-be68-cd0ae30e4305,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-6864930d-4b52-4562-a34b-3588bbdb1cda,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-0c338619-4228-46e5-a5a6-91fffdaa4241,DISK], DatanodeInfoWithStorage[127.0.0.1:37930,DS-6d531966-f4c5-4378-84fc-b16c6658b06f,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-1bf0e1bb-555d-4312-9479-3484ef7feaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-d0fa21f3-2f95-4111-94bb-ee598110dbff,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-a9a98955-de95-4aa6-99f1-96576edf78a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086735255-172.17.0.6-1595603423798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43764,DS-6399717b-ae95-4f28-b1ec-704e7e988dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-7414fa5f-b334-4146-be68-cd0ae30e4305,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-6864930d-4b52-4562-a34b-3588bbdb1cda,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-0c338619-4228-46e5-a5a6-91fffdaa4241,DISK], DatanodeInfoWithStorage[127.0.0.1:37930,DS-6d531966-f4c5-4378-84fc-b16c6658b06f,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-1bf0e1bb-555d-4312-9479-3484ef7feaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-d0fa21f3-2f95-4111-94bb-ee598110dbff,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-a9a98955-de95-4aa6-99f1-96576edf78a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289285753-172.17.0.6-1595604916243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34711,DS-7c5dec38-43c8-4d22-84db-4f57a45bd1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-20c32c0d-8907-47fd-b11b-266f1b510bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-9343de8d-8018-438c-9605-360521d6687b,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-5f6d58be-64fc-4014-87bb-0db727c1822f,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-33cdc44d-9de5-426c-9a2d-5103ce223541,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-4e30bcd0-5ebd-407f-8b9a-bc75e3f88e73,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-f518b28a-cc88-480f-a3f8-64eadd574402,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-760d0565-fbf1-4f46-b979-cd1a9375ec38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289285753-172.17.0.6-1595604916243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34711,DS-7c5dec38-43c8-4d22-84db-4f57a45bd1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-20c32c0d-8907-47fd-b11b-266f1b510bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-9343de8d-8018-438c-9605-360521d6687b,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-5f6d58be-64fc-4014-87bb-0db727c1822f,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-33cdc44d-9de5-426c-9a2d-5103ce223541,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-4e30bcd0-5ebd-407f-8b9a-bc75e3f88e73,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-f518b28a-cc88-480f-a3f8-64eadd574402,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-760d0565-fbf1-4f46-b979-cd1a9375ec38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741522634-172.17.0.6-1595605134213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44660,DS-16a600fe-c9d7-4a99-b3eb-bd284082a721,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-996cc451-8483-47d9-b4ba-28e8da0cc668,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-faf973e5-97f9-4a59-bf7f-11f28e037e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-e6db5b69-c953-4db9-998e-eac37f29816f,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-05c612aa-96e5-47e0-8e3f-be001b85c6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-15b261e9-cd23-4ba1-913f-a03470dbecd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-ff0d0599-aa08-42b1-9ae8-65e227145021,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-d053e787-77c2-4b1a-b0ef-00b10dc8a1c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741522634-172.17.0.6-1595605134213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44660,DS-16a600fe-c9d7-4a99-b3eb-bd284082a721,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-996cc451-8483-47d9-b4ba-28e8da0cc668,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-faf973e5-97f9-4a59-bf7f-11f28e037e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-e6db5b69-c953-4db9-998e-eac37f29816f,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-05c612aa-96e5-47e0-8e3f-be001b85c6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-15b261e9-cd23-4ba1-913f-a03470dbecd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-ff0d0599-aa08-42b1-9ae8-65e227145021,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-d053e787-77c2-4b1a-b0ef-00b10dc8a1c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055079116-172.17.0.6-1595605997066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33635,DS-e33ce624-f73e-438b-919e-15acbf266980,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-4ca46c67-3a43-43e1-b332-c39585f379bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-2ca0e3da-c998-42e9-94dd-806a76b67ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-813b4b85-0255-4715-959e-709f1e366ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-6eccfa2f-b763-4cb8-9995-0d211836fe2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-5c290a3f-8fba-43d8-b502-cbffe99001dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-45a6c7e6-6f98-4092-9de0-5b02019c41c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-ba356fc3-4d95-4198-a492-19e542a8b296,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055079116-172.17.0.6-1595605997066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33635,DS-e33ce624-f73e-438b-919e-15acbf266980,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-4ca46c67-3a43-43e1-b332-c39585f379bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-2ca0e3da-c998-42e9-94dd-806a76b67ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-813b4b85-0255-4715-959e-709f1e366ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-6eccfa2f-b763-4cb8-9995-0d211836fe2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-5c290a3f-8fba-43d8-b502-cbffe99001dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-45a6c7e6-6f98-4092-9de0-5b02019c41c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-ba356fc3-4d95-4198-a492-19e542a8b296,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 5300
