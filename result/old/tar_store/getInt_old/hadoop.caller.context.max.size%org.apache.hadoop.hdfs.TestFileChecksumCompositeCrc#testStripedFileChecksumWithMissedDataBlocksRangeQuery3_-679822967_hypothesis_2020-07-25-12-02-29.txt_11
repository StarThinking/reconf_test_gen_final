reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894127778-172.17.0.7-1595678868421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42484,DS-d05db442-2dea-41b9-9f9e-c0ebc4124eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-43ee7d76-3da2-43b7-a185-6c5c7f632b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-4479d1e1-36f6-4fba-a865-efb8bbcb8df1,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-ecd54b01-2e10-4f21-a1d2-b274577409ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-2413ba58-6df3-4110-806a-cf26bde3c9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-9a4f1ec0-656d-47b8-97d5-483b4fd848a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-8fe21b94-b95a-4c19-9edb-724a58b075c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-0b60c3d2-04fb-4583-a77c-b60a2f023cf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894127778-172.17.0.7-1595678868421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42484,DS-d05db442-2dea-41b9-9f9e-c0ebc4124eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-43ee7d76-3da2-43b7-a185-6c5c7f632b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-4479d1e1-36f6-4fba-a865-efb8bbcb8df1,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-ecd54b01-2e10-4f21-a1d2-b274577409ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-2413ba58-6df3-4110-806a-cf26bde3c9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-9a4f1ec0-656d-47b8-97d5-483b4fd848a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-8fe21b94-b95a-4c19-9edb-724a58b075c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-0b60c3d2-04fb-4583-a77c-b60a2f023cf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66259087-172.17.0.7-1595679416235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43493,DS-cc2de6cd-e2de-4ff2-a26f-eb2965d8c712,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-867fb364-19fe-4632-a162-0ea9d5f98362,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-216b9431-500b-4eeb-a630-bd8d89d9bcde,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-2ce434e6-3e56-4695-9a42-e0708175209c,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-32123994-71be-429e-aae5-b43d52b1f6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-11d72571-2d37-4286-a28d-49b75dff0ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-b8ce96d8-3327-4499-a722-3bb306c59a24,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-1e985d62-5b16-4a67-9209-0bc1436e9d25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66259087-172.17.0.7-1595679416235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43493,DS-cc2de6cd-e2de-4ff2-a26f-eb2965d8c712,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-867fb364-19fe-4632-a162-0ea9d5f98362,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-216b9431-500b-4eeb-a630-bd8d89d9bcde,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-2ce434e6-3e56-4695-9a42-e0708175209c,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-32123994-71be-429e-aae5-b43d52b1f6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-11d72571-2d37-4286-a28d-49b75dff0ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-b8ce96d8-3327-4499-a722-3bb306c59a24,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-1e985d62-5b16-4a67-9209-0bc1436e9d25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1600577993-172.17.0.7-1595679545098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38310,DS-3ebe06bb-3987-479d-89b5-7a615879f27d,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-fc9207f3-b791-4d04-9778-675e31e6161a,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-0628db30-a961-4c23-8e21-452f62db9ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-b3c6ec7e-784e-4cd8-b6da-0c9c32844430,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-9ac8a02a-f84a-4c5a-a0f1-4dfbe6345f63,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-27d46bdd-2c5e-4494-b195-a6770e5760b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-8abee0a3-2f9e-488b-8a67-62ed01c6e261,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-25c9be48-43c2-4839-b213-43fc0c08874f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1600577993-172.17.0.7-1595679545098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38310,DS-3ebe06bb-3987-479d-89b5-7a615879f27d,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-fc9207f3-b791-4d04-9778-675e31e6161a,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-0628db30-a961-4c23-8e21-452f62db9ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-b3c6ec7e-784e-4cd8-b6da-0c9c32844430,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-9ac8a02a-f84a-4c5a-a0f1-4dfbe6345f63,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-27d46bdd-2c5e-4494-b195-a6770e5760b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-8abee0a3-2f9e-488b-8a67-62ed01c6e261,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-25c9be48-43c2-4839-b213-43fc0c08874f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800932246-172.17.0.7-1595679586492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42433,DS-f0820b4c-00b4-4811-9a8e-29c5959876f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-7bfd5780-57d8-4f81-88ee-73697bbbb324,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-aff7af48-2dfc-4ef7-a65d-a8a0c7f3e5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-56b1eb85-e1ba-4b52-9f63-53eab45c2073,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-5189a3f2-a15a-4041-96fc-8dbec5e1fd06,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-56663809-8902-41bb-8523-ebb2c71a7fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-60519ac9-ed6d-48cc-a34f-10d768871f95,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-cc89bbc1-d905-4466-8cac-6818195f1e30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800932246-172.17.0.7-1595679586492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42433,DS-f0820b4c-00b4-4811-9a8e-29c5959876f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-7bfd5780-57d8-4f81-88ee-73697bbbb324,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-aff7af48-2dfc-4ef7-a65d-a8a0c7f3e5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-56b1eb85-e1ba-4b52-9f63-53eab45c2073,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-5189a3f2-a15a-4041-96fc-8dbec5e1fd06,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-56663809-8902-41bb-8523-ebb2c71a7fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-60519ac9-ed6d-48cc-a34f-10d768871f95,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-cc89bbc1-d905-4466-8cac-6818195f1e30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502203989-172.17.0.7-1595679778648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41802,DS-6ef05696-0ca7-4969-9bb6-970ed8c2df9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-6f08ac39-60e7-418a-a0ab-2047eab8cbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-45469b32-90a7-4233-970a-cd5708ce2b10,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-8d6eb416-7847-422d-a400-6ef8c78d7ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-ebc59a9d-a5d2-4460-b742-9b12ca115639,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-5e4a3ba7-e88a-4fb6-b283-88cc24dc70ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-8304830d-3fe7-4824-934c-fcdfe20311bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-60b3bb0a-a9a5-46f0-b158-578b6f7eb135,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502203989-172.17.0.7-1595679778648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41802,DS-6ef05696-0ca7-4969-9bb6-970ed8c2df9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-6f08ac39-60e7-418a-a0ab-2047eab8cbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-45469b32-90a7-4233-970a-cd5708ce2b10,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-8d6eb416-7847-422d-a400-6ef8c78d7ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-ebc59a9d-a5d2-4460-b742-9b12ca115639,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-5e4a3ba7-e88a-4fb6-b283-88cc24dc70ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-8304830d-3fe7-4824-934c-fcdfe20311bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-60b3bb0a-a9a5-46f0-b158-578b6f7eb135,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664819464-172.17.0.7-1595679818548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41224,DS-cae4ee93-19cb-4ab7-be7c-26854d931cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-c556ca4d-4b7d-4e8f-8130-35a1690d1ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-54f6b8a3-1435-48f6-a408-60b66e359895,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-d2bab9ac-a0c0-4285-831e-9a646a308ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-5aea6c62-a8e7-496c-88ec-3625e5e784d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-0452542d-c688-456d-8e62-d38607556daa,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-32ec7e93-5084-4879-981f-3f23f433681d,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-c01f9c91-56f1-4fde-be87-38c6649518aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664819464-172.17.0.7-1595679818548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41224,DS-cae4ee93-19cb-4ab7-be7c-26854d931cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-c556ca4d-4b7d-4e8f-8130-35a1690d1ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-54f6b8a3-1435-48f6-a408-60b66e359895,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-d2bab9ac-a0c0-4285-831e-9a646a308ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-5aea6c62-a8e7-496c-88ec-3625e5e784d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-0452542d-c688-456d-8e62-d38607556daa,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-32ec7e93-5084-4879-981f-3f23f433681d,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-c01f9c91-56f1-4fde-be87-38c6649518aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963531493-172.17.0.7-1595680167000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36414,DS-db6bea95-1761-4821-9544-c15de9e2a98c,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-f6bb5260-790b-4acd-9abd-27cf20ca2f44,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-882637bd-3900-43b3-96df-ebb61519d98a,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-1cd7c1da-58ad-4260-960b-9ab7971bdcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-e66f78bd-ec47-4bfe-af7c-acbf1cca6aec,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-731c71f1-536c-4d1b-98c1-771341f0dbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-5c9d68e2-9f3f-47d2-829f-af6781d0c87b,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-9a2e8f3c-d3c6-4ad2-a3b6-dffb5ff79811,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963531493-172.17.0.7-1595680167000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36414,DS-db6bea95-1761-4821-9544-c15de9e2a98c,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-f6bb5260-790b-4acd-9abd-27cf20ca2f44,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-882637bd-3900-43b3-96df-ebb61519d98a,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-1cd7c1da-58ad-4260-960b-9ab7971bdcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-e66f78bd-ec47-4bfe-af7c-acbf1cca6aec,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-731c71f1-536c-4d1b-98c1-771341f0dbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-5c9d68e2-9f3f-47d2-829f-af6781d0c87b,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-9a2e8f3c-d3c6-4ad2-a3b6-dffb5ff79811,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-952023690-172.17.0.7-1595680201833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40813,DS-15d3288b-69af-4530-91e2-5efafb7e815f,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-2e595fa4-0c8f-434b-a2b0-300eb4602b75,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-f9a1bf3c-df4d-4031-9775-284c03fb36bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-461de6cf-77a2-4395-a3e5-6c7350d8a8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-7b74610e-f0b2-42af-b3cf-c523895be042,DISK], DatanodeInfoWithStorage[127.0.0.1:41071,DS-6780ee4c-1b17-462a-a2b4-9fed6281b6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-6a84b3c3-a014-4628-9f5e-682b46c9dd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-2ff38767-6e5a-44b9-8df3-e81335adc29e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-952023690-172.17.0.7-1595680201833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40813,DS-15d3288b-69af-4530-91e2-5efafb7e815f,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-2e595fa4-0c8f-434b-a2b0-300eb4602b75,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-f9a1bf3c-df4d-4031-9775-284c03fb36bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-461de6cf-77a2-4395-a3e5-6c7350d8a8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-7b74610e-f0b2-42af-b3cf-c523895be042,DISK], DatanodeInfoWithStorage[127.0.0.1:41071,DS-6780ee4c-1b17-462a-a2b4-9fed6281b6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-6a84b3c3-a014-4628-9f5e-682b46c9dd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-2ff38767-6e5a-44b9-8df3-e81335adc29e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1033094693-172.17.0.7-1595680243336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45158,DS-b8a2b376-8391-4499-aa6c-1066af847aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-5896ed8e-bd5b-46bd-bfa0-e724934777c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-eec7c065-4233-4a73-842e-02272cb5934f,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-489a4ed6-7082-49b8-b9aa-82ec21c58632,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-ec5d5e2b-64d8-49b7-bfc0-8e0d922dafe8,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-3933185a-2a77-4641-8a54-4d5e5470ef31,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-1dde1861-2d66-44cc-bef7-b77339f20d20,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-3b79ac93-1e1a-4246-a2d1-9a609ea388ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1033094693-172.17.0.7-1595680243336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45158,DS-b8a2b376-8391-4499-aa6c-1066af847aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-5896ed8e-bd5b-46bd-bfa0-e724934777c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-eec7c065-4233-4a73-842e-02272cb5934f,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-489a4ed6-7082-49b8-b9aa-82ec21c58632,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-ec5d5e2b-64d8-49b7-bfc0-8e0d922dafe8,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-3933185a-2a77-4641-8a54-4d5e5470ef31,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-1dde1861-2d66-44cc-bef7-b77339f20d20,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-3b79ac93-1e1a-4246-a2d1-9a609ea388ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330675582-172.17.0.7-1595680920700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36448,DS-7dfa2f0e-23f8-4415-b9b0-dd642ff4e55d,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-6c7ab083-9f82-4703-a567-db279b2394f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-5189f445-ccc3-4dc7-b812-0b5ea967a79f,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-a4d65bd3-bbe9-4026-9d77-8c3c3288c0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-a27304e6-ead4-4da7-a9cb-29544959cf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-19c7796d-4e6c-438d-a3c0-f1dda95b3c92,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-372bb644-4a6f-4584-ab78-be7a0ef54c63,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-966ddaa8-390a-498f-bacd-708acfe45a5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330675582-172.17.0.7-1595680920700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36448,DS-7dfa2f0e-23f8-4415-b9b0-dd642ff4e55d,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-6c7ab083-9f82-4703-a567-db279b2394f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-5189f445-ccc3-4dc7-b812-0b5ea967a79f,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-a4d65bd3-bbe9-4026-9d77-8c3c3288c0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-a27304e6-ead4-4da7-a9cb-29544959cf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-19c7796d-4e6c-438d-a3c0-f1dda95b3c92,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-372bb644-4a6f-4584-ab78-be7a0ef54c63,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-966ddaa8-390a-498f-bacd-708acfe45a5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452338486-172.17.0.7-1595681026583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35616,DS-af0f347d-c659-4e6b-b97d-7704d7bd5417,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-8fca2f0d-a767-4053-bbb1-b26fca76f852,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-bcc2e8a6-855c-4582-bcd0-e56507d8e8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-e348322c-5e2f-4e64-8af0-eb0e9dcff56c,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-0c4e7c92-360c-4ba0-a709-f6165809df27,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-20242d55-261b-49aa-bd1d-b27bc2caaa95,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-48664c4a-ac56-4568-a075-076a496ab12c,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-535dac0a-3a28-403f-bdf2-47897475890b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452338486-172.17.0.7-1595681026583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35616,DS-af0f347d-c659-4e6b-b97d-7704d7bd5417,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-8fca2f0d-a767-4053-bbb1-b26fca76f852,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-bcc2e8a6-855c-4582-bcd0-e56507d8e8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-e348322c-5e2f-4e64-8af0-eb0e9dcff56c,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-0c4e7c92-360c-4ba0-a709-f6165809df27,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-20242d55-261b-49aa-bd1d-b27bc2caaa95,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-48664c4a-ac56-4568-a075-076a496ab12c,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-535dac0a-3a28-403f-bdf2-47897475890b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1671634762-172.17.0.7-1595681109424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38635,DS-d03288f3-ae78-49a6-a489-df292afcb902,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-8e042a42-4e29-45c2-9432-7c60b5e737eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-d9c1c868-486b-43c3-8612-3903468a4902,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-bd5f3cd9-06b1-4d62-908b-4ed04b625096,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-2b0ff21b-37f9-4014-8200-a37bb239d18a,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-77811b58-9162-4848-bc2e-506b0b9b96fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-55b18579-f479-4681-a4da-492d5b19fb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-3ce4411e-4674-4f44-9341-379073a3116a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1671634762-172.17.0.7-1595681109424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38635,DS-d03288f3-ae78-49a6-a489-df292afcb902,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-8e042a42-4e29-45c2-9432-7c60b5e737eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-d9c1c868-486b-43c3-8612-3903468a4902,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-bd5f3cd9-06b1-4d62-908b-4ed04b625096,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-2b0ff21b-37f9-4014-8200-a37bb239d18a,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-77811b58-9162-4848-bc2e-506b0b9b96fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-55b18579-f479-4681-a4da-492d5b19fb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-3ce4411e-4674-4f44-9341-379073a3116a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1756592609-172.17.0.7-1595681476243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43754,DS-47870ec0-5be8-449b-87e3-39f2553fc5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-1350549d-271a-4899-8452-fd1ebaa33f96,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-ca5b3a0f-487b-4335-83e0-27fda078bbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-c1d8742f-00bb-4f85-b88b-db9f70e31df7,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-15d424ba-0eae-4919-a126-08ed4edd58e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-baddccd9-b981-4bfb-bb6b-105eefd3fcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-f7fde259-a17a-499d-820e-532ee0cba791,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-e603057a-c61a-470e-961f-0cd211df0b0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1756592609-172.17.0.7-1595681476243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43754,DS-47870ec0-5be8-449b-87e3-39f2553fc5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-1350549d-271a-4899-8452-fd1ebaa33f96,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-ca5b3a0f-487b-4335-83e0-27fda078bbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-c1d8742f-00bb-4f85-b88b-db9f70e31df7,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-15d424ba-0eae-4919-a126-08ed4edd58e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-baddccd9-b981-4bfb-bb6b-105eefd3fcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-f7fde259-a17a-499d-820e-532ee0cba791,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-e603057a-c61a-470e-961f-0cd211df0b0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695441991-172.17.0.7-1595681786046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37929,DS-88eb3764-a270-4d13-ba3b-e46991112cce,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-14e0bc58-e420-4492-8321-f5930b96800e,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-cb3591f0-4f76-4e71-867d-c6cd6985dfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-0b4d7bad-1c1a-4fee-b324-2f5b493b22d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-42c8930e-ed83-47e1-a518-2b1214d1ec30,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-952d9b8f-fec5-4621-b30a-8a45e9a6d754,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-9bd75810-5817-44af-af37-89d76960e0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-a1f67c9e-87b2-4987-951c-75a22aac1acd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695441991-172.17.0.7-1595681786046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37929,DS-88eb3764-a270-4d13-ba3b-e46991112cce,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-14e0bc58-e420-4492-8321-f5930b96800e,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-cb3591f0-4f76-4e71-867d-c6cd6985dfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-0b4d7bad-1c1a-4fee-b324-2f5b493b22d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-42c8930e-ed83-47e1-a518-2b1214d1ec30,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-952d9b8f-fec5-4621-b30a-8a45e9a6d754,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-9bd75810-5817-44af-af37-89d76960e0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-a1f67c9e-87b2-4987-951c-75a22aac1acd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108118140-172.17.0.7-1595681879766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40312,DS-22229092-16e9-4843-a53d-229f09135c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-4cc175ff-062c-46c7-b2e9-2597b797586b,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-1b381a81-7113-4004-ac85-729cb776ac0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-7940d8ef-d955-4092-9638-36fc15c8fb23,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-2ee127d3-b5c8-4d60-99f1-84daaf94e6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-8383b06d-0bad-4482-92fe-edb2cfccf088,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-034b2296-a8a8-4ac8-a975-b6c47f3cbbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-11c4d758-d0e4-4297-afef-48cf181cee75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108118140-172.17.0.7-1595681879766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40312,DS-22229092-16e9-4843-a53d-229f09135c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-4cc175ff-062c-46c7-b2e9-2597b797586b,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-1b381a81-7113-4004-ac85-729cb776ac0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-7940d8ef-d955-4092-9638-36fc15c8fb23,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-2ee127d3-b5c8-4d60-99f1-84daaf94e6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-8383b06d-0bad-4482-92fe-edb2cfccf088,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-034b2296-a8a8-4ac8-a975-b6c47f3cbbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-11c4d758-d0e4-4297-afef-48cf181cee75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901447822-172.17.0.7-1595682953350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39141,DS-47bd4b4b-3aa5-4323-b20c-f8e776a94df1,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-d9e7380d-d4a4-4143-8583-6663b818088f,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-9f0e3089-4f3a-4a85-95eb-406a76641867,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-227adeb0-b641-4f0f-9c81-e5d0669208e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-87ff811e-71cb-407e-ab40-a6086f0210f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-4c2fcd01-8419-4f2f-9e04-08ea8b89da74,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-f2755d69-77a1-4e5d-8b7f-ab5aac57242b,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-5004ae77-399c-4916-a870-381d7a38a8e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901447822-172.17.0.7-1595682953350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39141,DS-47bd4b4b-3aa5-4323-b20c-f8e776a94df1,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-d9e7380d-d4a4-4143-8583-6663b818088f,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-9f0e3089-4f3a-4a85-95eb-406a76641867,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-227adeb0-b641-4f0f-9c81-e5d0669208e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-87ff811e-71cb-407e-ab40-a6086f0210f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-4c2fcd01-8419-4f2f-9e04-08ea8b89da74,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-f2755d69-77a1-4e5d-8b7f-ab5aac57242b,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-5004ae77-399c-4916-a870-381d7a38a8e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1947746338-172.17.0.7-1595682995124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46623,DS-184a8fdf-00e6-439c-8d79-12812e266885,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-5110bbf2-1550-4544-ae9c-e71ee730fa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-e559b65b-cc38-4ccd-9d62-d9ac8ed36de8,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-7a1adc87-8d2e-4873-ae55-a4136c95ca5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-3b9542c4-2a65-4cc7-804d-1801fe5bbb22,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-3bd9101a-daae-4c96-ab5f-0d27d0289c79,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-3e716f3b-634c-483e-8070-48ef135306b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-690601ff-4db1-45dc-8519-c31d1d3143e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1947746338-172.17.0.7-1595682995124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46623,DS-184a8fdf-00e6-439c-8d79-12812e266885,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-5110bbf2-1550-4544-ae9c-e71ee730fa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-e559b65b-cc38-4ccd-9d62-d9ac8ed36de8,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-7a1adc87-8d2e-4873-ae55-a4136c95ca5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-3b9542c4-2a65-4cc7-804d-1801fe5bbb22,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-3bd9101a-daae-4c96-ab5f-0d27d0289c79,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-3e716f3b-634c-483e-8070-48ef135306b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-690601ff-4db1-45dc-8519-c31d1d3143e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2126165047-172.17.0.7-1595683713097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45238,DS-dbf5244b-1db2-4b6e-9fb4-810ede2710cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-e524c5b7-b3ab-4fa0-97e6-d4fc2cd30e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-59103ee2-6704-4b47-991c-03d388c964c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-00264007-b937-46a7-bd86-8dfa9cc00345,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-9231d6f8-1511-4e55-8153-f8c420b8acd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-3846e01a-beb5-480a-8811-191f3898c585,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-d2cd2b70-a236-46ee-ba75-81d252ffdf33,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-b75c44ea-3a34-4710-86f0-0a9e00733ded,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2126165047-172.17.0.7-1595683713097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45238,DS-dbf5244b-1db2-4b6e-9fb4-810ede2710cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-e524c5b7-b3ab-4fa0-97e6-d4fc2cd30e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-59103ee2-6704-4b47-991c-03d388c964c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-00264007-b937-46a7-bd86-8dfa9cc00345,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-9231d6f8-1511-4e55-8153-f8c420b8acd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-3846e01a-beb5-480a-8811-191f3898c585,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-d2cd2b70-a236-46ee-ba75-81d252ffdf33,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-b75c44ea-3a34-4710-86f0-0a9e00733ded,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062653957-172.17.0.7-1595683750130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34157,DS-5483549b-cfb9-49a2-9331-6797cc0f1687,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-6e47116a-5285-4e39-b1df-8b667a3fd54c,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-5e96a9f7-b601-4eca-b5f5-39ebef701729,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-ad092706-30ac-44f1-bf70-0d8e2c0b7f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-46443ee1-8ad8-452d-a8f8-fbabc1e05c86,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-076d4bde-eb02-4558-86c5-644b7a750824,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-da1f87b9-30de-455c-b6d7-fa0d4fec3582,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-d4884ec3-5b4d-4abd-b156-d55a2b10e5cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062653957-172.17.0.7-1595683750130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34157,DS-5483549b-cfb9-49a2-9331-6797cc0f1687,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-6e47116a-5285-4e39-b1df-8b667a3fd54c,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-5e96a9f7-b601-4eca-b5f5-39ebef701729,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-ad092706-30ac-44f1-bf70-0d8e2c0b7f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-46443ee1-8ad8-452d-a8f8-fbabc1e05c86,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-076d4bde-eb02-4558-86c5-644b7a750824,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-da1f87b9-30de-455c-b6d7-fa0d4fec3582,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-d4884ec3-5b4d-4abd-b156-d55a2b10e5cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612062398-172.17.0.7-1595684044982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40397,DS-003a9fa1-73c3-4edf-ba2a-6e30cd3ab434,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-9d07d408-1679-4457-8d1b-b31159d5a4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-23f20d88-395a-4bed-ab6b-792019711d15,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-4186416e-52b5-40b4-b1a0-7092d58beb79,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-5535dd5c-9263-4204-abeb-7a91a47756d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-988f364a-0706-4fde-a423-53d9aaff7c39,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-9706a98a-360a-4b28-8444-4d863809e750,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-dc4e07f0-491f-4f04-8c63-2b36e9fda3c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612062398-172.17.0.7-1595684044982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40397,DS-003a9fa1-73c3-4edf-ba2a-6e30cd3ab434,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-9d07d408-1679-4457-8d1b-b31159d5a4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-23f20d88-395a-4bed-ab6b-792019711d15,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-4186416e-52b5-40b4-b1a0-7092d58beb79,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-5535dd5c-9263-4204-abeb-7a91a47756d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-988f364a-0706-4fde-a423-53d9aaff7c39,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-9706a98a-360a-4b28-8444-4d863809e750,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-dc4e07f0-491f-4f04-8c63-2b36e9fda3c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-941302381-172.17.0.7-1595684297864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42939,DS-75cb6536-bfa7-490b-bebd-869d668ec583,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-36c4daa1-8a7d-4ee6-861b-bcc8f4123114,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-bccf29ab-249d-4d56-82e5-43f323a1f3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-a51e2423-c54a-4261-a77b-2c8c387aded3,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-78f161b9-9411-4c8e-bfc9-00bb2bcb417a,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-c8211b64-9887-4355-a25e-ef6a056d6c81,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-100066d1-b0e1-4837-a988-9b13ca2cde2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-a60c9ec8-4b7a-4c5f-a805-6c67a83ac07e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-941302381-172.17.0.7-1595684297864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42939,DS-75cb6536-bfa7-490b-bebd-869d668ec583,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-36c4daa1-8a7d-4ee6-861b-bcc8f4123114,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-bccf29ab-249d-4d56-82e5-43f323a1f3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-a51e2423-c54a-4261-a77b-2c8c387aded3,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-78f161b9-9411-4c8e-bfc9-00bb2bcb417a,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-c8211b64-9887-4355-a25e-ef6a056d6c81,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-100066d1-b0e1-4837-a988-9b13ca2cde2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-a60c9ec8-4b7a-4c5f-a805-6c67a83ac07e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-541203438-172.17.0.7-1595684541656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43974,DS-5468d82f-71a0-4fd9-8223-44b8f35850c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-de424d0a-8bb0-4040-a811-d8e167ac4614,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-a343a717-8bab-4094-951c-9370c2779996,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-d09afc2b-0382-4095-9bc8-5ea42914f065,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-7c7f1428-ee38-4edf-b85c-f60facb94f55,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-ec540c17-6be1-4975-b235-cef643592f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-74dd2c0e-42d2-4f51-963b-08610b2414a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-93264960-9388-43ac-bb48-75138d150611,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-541203438-172.17.0.7-1595684541656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43974,DS-5468d82f-71a0-4fd9-8223-44b8f35850c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-de424d0a-8bb0-4040-a811-d8e167ac4614,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-a343a717-8bab-4094-951c-9370c2779996,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-d09afc2b-0382-4095-9bc8-5ea42914f065,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-7c7f1428-ee38-4edf-b85c-f60facb94f55,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-ec540c17-6be1-4975-b235-cef643592f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-74dd2c0e-42d2-4f51-963b-08610b2414a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-93264960-9388-43ac-bb48-75138d150611,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768582898-172.17.0.7-1595684965304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38813,DS-b9e040d1-ccac-49d0-8295-d47753859179,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-2338fe54-1559-41c4-91d4-d10f1f41f8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-dd076286-0755-45b4-b4b2-767c93ac2b72,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-547898ae-6785-4001-8621-2a0d8ee56dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-1c54433b-6fb8-4f8c-b493-f788d91cb51b,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-05748d40-3780-4894-b5c4-032954e33913,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-372f4f02-27fc-4085-853e-f53f065a1214,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-5f719cf0-a49a-4648-a21d-0089579836b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768582898-172.17.0.7-1595684965304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38813,DS-b9e040d1-ccac-49d0-8295-d47753859179,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-2338fe54-1559-41c4-91d4-d10f1f41f8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-dd076286-0755-45b4-b4b2-767c93ac2b72,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-547898ae-6785-4001-8621-2a0d8ee56dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-1c54433b-6fb8-4f8c-b493-f788d91cb51b,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-05748d40-3780-4894-b5c4-032954e33913,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-372f4f02-27fc-4085-853e-f53f065a1214,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-5f719cf0-a49a-4648-a21d-0089579836b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011511393-172.17.0.7-1595685189946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44667,DS-18490c46-fabc-4e21-8523-f5a3ca05a6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-c6c7c0a4-8644-4580-9163-04609b2a9503,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-5d0bfaa8-f2e2-407e-becb-cce4eace138e,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-d2440039-b5ab-4bf7-96f0-ec9b983ac06e,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-7048ae78-97e5-4190-b347-c3d5b2606eed,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-8acf7f1a-3c1b-4b20-b068-83cbfab30cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-14e05cca-097b-4d15-9a37-7b036dec5326,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-ca79dee7-b8cd-4497-b006-74fc9ef8b642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011511393-172.17.0.7-1595685189946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44667,DS-18490c46-fabc-4e21-8523-f5a3ca05a6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-c6c7c0a4-8644-4580-9163-04609b2a9503,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-5d0bfaa8-f2e2-407e-becb-cce4eace138e,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-d2440039-b5ab-4bf7-96f0-ec9b983ac06e,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-7048ae78-97e5-4190-b347-c3d5b2606eed,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-8acf7f1a-3c1b-4b20-b068-83cbfab30cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-14e05cca-097b-4d15-9a37-7b036dec5326,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-ca79dee7-b8cd-4497-b006-74fc9ef8b642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6663
