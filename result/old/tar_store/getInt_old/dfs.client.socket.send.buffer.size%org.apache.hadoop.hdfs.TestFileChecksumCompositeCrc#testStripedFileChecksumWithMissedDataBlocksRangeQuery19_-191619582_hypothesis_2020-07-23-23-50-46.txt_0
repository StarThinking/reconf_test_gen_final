reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1824938741-172.17.0.17-1595548257370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42910,DS-4fab0a81-4742-45f8-b299-e28b05e89180,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-00d69497-bfd2-4563-be06-c7c1fdf935bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-7cee2528-f071-49c5-a72b-4aeafa637796,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-b818fddf-19ad-49ee-b308-2d00991f7f71,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-bd9cfd4e-38a5-483b-a149-f13a218127c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-a07bd2c2-8be6-4c6d-b99e-9cf5fc244d29,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-e6da9b40-8412-4f75-b84e-7288e94ee60b,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-9d0bcff8-d018-4174-8900-59004e801725,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1824938741-172.17.0.17-1595548257370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42910,DS-4fab0a81-4742-45f8-b299-e28b05e89180,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-00d69497-bfd2-4563-be06-c7c1fdf935bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-7cee2528-f071-49c5-a72b-4aeafa637796,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-b818fddf-19ad-49ee-b308-2d00991f7f71,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-bd9cfd4e-38a5-483b-a149-f13a218127c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-a07bd2c2-8be6-4c6d-b99e-9cf5fc244d29,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-e6da9b40-8412-4f75-b84e-7288e94ee60b,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-9d0bcff8-d018-4174-8900-59004e801725,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1660852559-172.17.0.17-1595548435657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37061,DS-3908aeb2-80cd-43bd-98da-dfa342ec18d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-c219831e-bea2-4e59-9571-499aba2e4c18,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-a97ec519-8d87-4cd2-8686-e656d5f927f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-a0fb09b9-7c5f-4055-b7dc-583523bbfdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-8166b4ec-1b2b-45d9-85b3-6e8a386358d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-1fb848ee-662e-4e9d-b577-007d878fd77d,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-b77044b5-2aef-4d38-9df7-6ce4bdd76e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-eef9907a-8b24-4aa4-a2c6-d3cb0fe7190e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1660852559-172.17.0.17-1595548435657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37061,DS-3908aeb2-80cd-43bd-98da-dfa342ec18d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-c219831e-bea2-4e59-9571-499aba2e4c18,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-a97ec519-8d87-4cd2-8686-e656d5f927f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-a0fb09b9-7c5f-4055-b7dc-583523bbfdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-8166b4ec-1b2b-45d9-85b3-6e8a386358d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-1fb848ee-662e-4e9d-b577-007d878fd77d,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-b77044b5-2aef-4d38-9df7-6ce4bdd76e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-eef9907a-8b24-4aa4-a2c6-d3cb0fe7190e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969051801-172.17.0.17-1595548904810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43961,DS-0fcb7c66-e3ab-419b-a5be-ed0a0b860280,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-bd91237a-3278-44f4-80d7-2dc1dfe095fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-ea697527-d4ed-4a0a-b622-c7ea4a0a8869,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-01dcf21b-3d50-4d69-88d4-5684c471f10e,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-cd1ab280-a5b9-410d-b9cf-43ce536bc6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-697d9d5a-b622-446f-8379-4e8dc45708aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-5692cb5c-63c5-4033-91bf-0b139c8d438b,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-110c17d8-4b86-4bf7-b8b4-2e61ff272ef1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969051801-172.17.0.17-1595548904810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43961,DS-0fcb7c66-e3ab-419b-a5be-ed0a0b860280,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-bd91237a-3278-44f4-80d7-2dc1dfe095fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-ea697527-d4ed-4a0a-b622-c7ea4a0a8869,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-01dcf21b-3d50-4d69-88d4-5684c471f10e,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-cd1ab280-a5b9-410d-b9cf-43ce536bc6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-697d9d5a-b622-446f-8379-4e8dc45708aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-5692cb5c-63c5-4033-91bf-0b139c8d438b,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-110c17d8-4b86-4bf7-b8b4-2e61ff272ef1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-254464532-172.17.0.17-1595549283394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41121,DS-f9afdfa1-7da2-4e41-9e0a-643d25311e21,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-1441ccd0-b034-4f25-a89f-b56b2a5905fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-5e2b13e7-b295-46c2-835a-8f392a916db8,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-2343d8e7-316b-40c0-bdb0-7acb143c67ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-0ef30dad-0cc1-4fec-978e-52131bd14f51,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-8b6c5ec3-275e-4236-99ce-b50200910089,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-39eedc25-bdb0-4ad3-9be0-d5a9072a2169,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-074c44f1-a909-44fa-8470-26ab4d3e97d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-254464532-172.17.0.17-1595549283394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41121,DS-f9afdfa1-7da2-4e41-9e0a-643d25311e21,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-1441ccd0-b034-4f25-a89f-b56b2a5905fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-5e2b13e7-b295-46c2-835a-8f392a916db8,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-2343d8e7-316b-40c0-bdb0-7acb143c67ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-0ef30dad-0cc1-4fec-978e-52131bd14f51,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-8b6c5ec3-275e-4236-99ce-b50200910089,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-39eedc25-bdb0-4ad3-9be0-d5a9072a2169,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-074c44f1-a909-44fa-8470-26ab4d3e97d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2046029229-172.17.0.17-1595549365552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40790,DS-3214f373-bbae-4a1b-8555-10c7b9c126b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-7dea8c9f-6cf6-426c-82cd-d426ce42106d,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-1888d367-c6a1-44d1-82c9-a4551343d6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-0d6f89bd-a8c6-4b86-b6aa-fde033ece3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-f0fbf814-ee83-49a1-b9b4-07428cf4c3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-cbe9be3d-d65d-42d8-8505-07fbbbe6a89e,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-72afd81f-df85-4393-8009-8a429f87320a,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-5d9999d3-3ddf-449a-aeac-fc9347a6894b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2046029229-172.17.0.17-1595549365552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40790,DS-3214f373-bbae-4a1b-8555-10c7b9c126b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-7dea8c9f-6cf6-426c-82cd-d426ce42106d,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-1888d367-c6a1-44d1-82c9-a4551343d6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-0d6f89bd-a8c6-4b86-b6aa-fde033ece3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-f0fbf814-ee83-49a1-b9b4-07428cf4c3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-cbe9be3d-d65d-42d8-8505-07fbbbe6a89e,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-72afd81f-df85-4393-8009-8a429f87320a,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-5d9999d3-3ddf-449a-aeac-fc9347a6894b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-301222358-172.17.0.17-1595549768424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42032,DS-b9718d42-b4e5-4354-b11e-dbd8b1ed4844,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-8f778074-1d44-44d8-9142-aebf0a40e2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-c75be780-9001-4cbb-82f1-27a872599145,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-f5ea3a6f-0e7e-4ce4-91a3-c01676bfb9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-8601d695-91cf-42f1-8096-e488e1c10b05,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-21a8d057-7d6c-4c68-b2da-64674e2bce91,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-f3fb7759-eab2-422a-8e72-e320d9d49b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-9559d82d-38a2-48c8-9042-9b4742f73140,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-301222358-172.17.0.17-1595549768424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42032,DS-b9718d42-b4e5-4354-b11e-dbd8b1ed4844,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-8f778074-1d44-44d8-9142-aebf0a40e2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-c75be780-9001-4cbb-82f1-27a872599145,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-f5ea3a6f-0e7e-4ce4-91a3-c01676bfb9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-8601d695-91cf-42f1-8096-e488e1c10b05,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-21a8d057-7d6c-4c68-b2da-64674e2bce91,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-f3fb7759-eab2-422a-8e72-e320d9d49b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-9559d82d-38a2-48c8-9042-9b4742f73140,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1283034334-172.17.0.17-1595550106094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34492,DS-5efc16de-e641-4403-bebf-06d4940bf855,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-1e24356e-1cbb-403e-93d0-5e1387b69835,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-52e16da7-53d6-4143-8e77-3768560df0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-635bd60f-eeaa-4073-bd2c-99776f0e5979,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-4e8706ae-6d2a-4b03-ad45-eb49df59f801,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-32885697-f52f-4a02-99da-e288ecd39615,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-511f47c1-b353-4af5-bcdc-c69b7dcfde08,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-b94583bc-aec3-4bc2-8d4e-ba7633203bab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1283034334-172.17.0.17-1595550106094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34492,DS-5efc16de-e641-4403-bebf-06d4940bf855,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-1e24356e-1cbb-403e-93d0-5e1387b69835,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-52e16da7-53d6-4143-8e77-3768560df0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-635bd60f-eeaa-4073-bd2c-99776f0e5979,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-4e8706ae-6d2a-4b03-ad45-eb49df59f801,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-32885697-f52f-4a02-99da-e288ecd39615,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-511f47c1-b353-4af5-bcdc-c69b7dcfde08,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-b94583bc-aec3-4bc2-8d4e-ba7633203bab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1495126536-172.17.0.17-1595550376489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41962,DS-65b6e1dc-aaab-4e54-877b-f928023e9c43,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-aee9daba-c142-4895-97da-e7852482d362,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-74d4bb69-857b-4db3-b61d-e9ceec276279,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-400f8390-0398-448b-95c2-8694c9257c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-5741c54b-a2ab-469a-9e3f-b3ec3193da08,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-08a2c70a-50d9-4b06-b76b-d09cf227cc26,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-82dbe2cc-2f8d-40a8-87ca-2929bb44f5af,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-92165ad0-5e7d-4faa-a1a4-303c3d531617,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1495126536-172.17.0.17-1595550376489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41962,DS-65b6e1dc-aaab-4e54-877b-f928023e9c43,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-aee9daba-c142-4895-97da-e7852482d362,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-74d4bb69-857b-4db3-b61d-e9ceec276279,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-400f8390-0398-448b-95c2-8694c9257c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-5741c54b-a2ab-469a-9e3f-b3ec3193da08,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-08a2c70a-50d9-4b06-b76b-d09cf227cc26,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-82dbe2cc-2f8d-40a8-87ca-2929bb44f5af,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-92165ad0-5e7d-4faa-a1a4-303c3d531617,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1403199229-172.17.0.17-1595551217969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42801,DS-a5e5b54f-d5e8-4f01-9b40-906a11b5b2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-36ce6cfe-1c85-40de-b464-153ebbe1749f,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-1f0a9f91-6166-4218-86cc-afa593e3940f,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-2c960ec0-a046-46b8-985e-65a33b94bebd,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-eff8c9f3-22e0-4d38-b044-1d8a52ba15a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-1a83dfe4-3c1a-4dfa-b486-bca22e5f7c28,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-a8ceb7f7-d697-4d37-97c4-a3b0d5331776,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-f0eada65-6692-4dba-be42-511f522bf5d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1403199229-172.17.0.17-1595551217969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42801,DS-a5e5b54f-d5e8-4f01-9b40-906a11b5b2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-36ce6cfe-1c85-40de-b464-153ebbe1749f,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-1f0a9f91-6166-4218-86cc-afa593e3940f,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-2c960ec0-a046-46b8-985e-65a33b94bebd,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-eff8c9f3-22e0-4d38-b044-1d8a52ba15a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-1a83dfe4-3c1a-4dfa-b486-bca22e5f7c28,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-a8ceb7f7-d697-4d37-97c4-a3b0d5331776,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-f0eada65-6692-4dba-be42-511f522bf5d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1598406411-172.17.0.17-1595551327587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37395,DS-826b774a-76d4-42a8-94c1-dea3f9aab019,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-7e2fe03f-d3b4-4294-b8ff-8cb7182d932f,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-b706ccbe-0674-4198-a28f-6d92ffecbef5,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-afd268d4-46df-4dea-8f42-151123e30175,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-3d7dafac-b276-4229-9b38-ed400ec77eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-b191fca8-fa81-40ba-be49-1a024088c1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-c57ccb0d-11cb-4944-81c8-203cadbb6538,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-888ad5ef-07d6-4db0-bd33-348f1d2b50dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1598406411-172.17.0.17-1595551327587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37395,DS-826b774a-76d4-42a8-94c1-dea3f9aab019,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-7e2fe03f-d3b4-4294-b8ff-8cb7182d932f,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-b706ccbe-0674-4198-a28f-6d92ffecbef5,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-afd268d4-46df-4dea-8f42-151123e30175,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-3d7dafac-b276-4229-9b38-ed400ec77eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-b191fca8-fa81-40ba-be49-1a024088c1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-c57ccb0d-11cb-4944-81c8-203cadbb6538,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-888ad5ef-07d6-4db0-bd33-348f1d2b50dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-829491609-172.17.0.17-1595551616198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42177,DS-f7e19012-3be5-4c00-ac6a-612710b505ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-31b65498-b74f-4317-ad80-b3c6699c5bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-60c03021-528e-4f13-8e9c-8be168b8761e,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-bac12ebe-b23f-4a63-87b7-6def9e9b82a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-61ca12a6-adfc-4766-ab0f-0980a9c72977,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-cecc6a0c-8501-402c-89d4-f1b5ea091f62,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-69b0a35d-b1e5-469c-9ef8-49361a533251,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-86ac49ff-187a-41da-a88f-e49a4bbdfa90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-829491609-172.17.0.17-1595551616198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42177,DS-f7e19012-3be5-4c00-ac6a-612710b505ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-31b65498-b74f-4317-ad80-b3c6699c5bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-60c03021-528e-4f13-8e9c-8be168b8761e,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-bac12ebe-b23f-4a63-87b7-6def9e9b82a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-61ca12a6-adfc-4766-ab0f-0980a9c72977,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-cecc6a0c-8501-402c-89d4-f1b5ea091f62,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-69b0a35d-b1e5-469c-9ef8-49361a533251,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-86ac49ff-187a-41da-a88f-e49a4bbdfa90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-214859877-172.17.0.17-1595551719686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39681,DS-baacc247-17c3-4938-b7fd-d9b43f61c80f,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-f848a8cd-be5b-4aec-b52c-e35df58c5844,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-763e90e0-b253-4add-856a-8681ee34a581,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-38b38a6f-eac8-43dd-8a9b-68eea5c6adb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-0760398d-a70e-4d88-834a-5e92c44b97b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-318c2733-892a-4d72-ae52-e31e00df3184,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-6155a1fd-b05e-494f-8f36-06a50f72bfca,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-07eb68a6-c01e-40e6-9e74-9c6fce752782,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-214859877-172.17.0.17-1595551719686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39681,DS-baacc247-17c3-4938-b7fd-d9b43f61c80f,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-f848a8cd-be5b-4aec-b52c-e35df58c5844,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-763e90e0-b253-4add-856a-8681ee34a581,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-38b38a6f-eac8-43dd-8a9b-68eea5c6adb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-0760398d-a70e-4d88-834a-5e92c44b97b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-318c2733-892a-4d72-ae52-e31e00df3184,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-6155a1fd-b05e-494f-8f36-06a50f72bfca,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-07eb68a6-c01e-40e6-9e74-9c6fce752782,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-94180565-172.17.0.17-1595551901118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39009,DS-ba45543b-0dc7-447d-9377-1176762f6630,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-7e2303c8-0d2b-4bb4-a7d5-0a99284a5380,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-6b40b342-cbce-4089-882e-3b193238743c,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-5c5f41cd-0acf-447b-ae05-8a54e1e41318,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-e34723fd-c89d-44c3-a7b4-5898de45c741,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-31132b2f-c540-49e9-bdf4-d3dcd5b37d25,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-5de29408-e9e7-4e08-a3c5-221e88d7ace2,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-0042f454-5c02-4aa1-b835-49a0ea26a903,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-94180565-172.17.0.17-1595551901118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39009,DS-ba45543b-0dc7-447d-9377-1176762f6630,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-7e2303c8-0d2b-4bb4-a7d5-0a99284a5380,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-6b40b342-cbce-4089-882e-3b193238743c,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-5c5f41cd-0acf-447b-ae05-8a54e1e41318,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-e34723fd-c89d-44c3-a7b4-5898de45c741,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-31132b2f-c540-49e9-bdf4-d3dcd5b37d25,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-5de29408-e9e7-4e08-a3c5-221e88d7ace2,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-0042f454-5c02-4aa1-b835-49a0ea26a903,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1851804642-172.17.0.17-1595552087211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33276,DS-d14975e2-4de4-4109-bff7-3a581d22e1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-2054d2c9-f8b6-4394-8ec6-32d2115b599e,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-3e0370ae-3cee-486d-948e-a97ae11787b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-fd7ca033-b7f5-4ba7-9967-b5fbe3bff032,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-689029fc-a31b-40d5-8af5-c8df1b39527a,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-0054510e-6b7b-4f44-b062-9034798cb349,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-15315d91-7fc0-4e27-836e-940872d14c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-40c6ffcf-de91-4d1a-8ab0-7c26fc20f014,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1851804642-172.17.0.17-1595552087211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33276,DS-d14975e2-4de4-4109-bff7-3a581d22e1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-2054d2c9-f8b6-4394-8ec6-32d2115b599e,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-3e0370ae-3cee-486d-948e-a97ae11787b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-fd7ca033-b7f5-4ba7-9967-b5fbe3bff032,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-689029fc-a31b-40d5-8af5-c8df1b39527a,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-0054510e-6b7b-4f44-b062-9034798cb349,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-15315d91-7fc0-4e27-836e-940872d14c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-40c6ffcf-de91-4d1a-8ab0-7c26fc20f014,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-699702642-172.17.0.17-1595552119149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35724,DS-a6b671ef-10e0-4976-9ce1-80ae44add995,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-40872c2d-5627-4a97-9c5f-2aaef515130e,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-c1f30613-c3fb-49cf-9836-c8fda7face36,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-d4210d64-6726-4ea0-b449-9de1f284908d,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-34c5e8a9-6044-4a92-af2d-ae866de5ebd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-c29bc4a2-133f-42bb-8726-de826b16cf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-caa3e162-ece5-4357-a4cf-f2330e4b0ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-d9ebc6a1-ffac-499c-a443-26b03c4f3932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-699702642-172.17.0.17-1595552119149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35724,DS-a6b671ef-10e0-4976-9ce1-80ae44add995,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-40872c2d-5627-4a97-9c5f-2aaef515130e,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-c1f30613-c3fb-49cf-9836-c8fda7face36,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-d4210d64-6726-4ea0-b449-9de1f284908d,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-34c5e8a9-6044-4a92-af2d-ae866de5ebd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-c29bc4a2-133f-42bb-8726-de826b16cf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-caa3e162-ece5-4357-a4cf-f2330e4b0ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-d9ebc6a1-ffac-499c-a443-26b03c4f3932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022412602-172.17.0.17-1595552314194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46778,DS-9cc23a20-0a34-48e4-9af3-c5eb892ce133,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-dd00f8c3-ae6e-442c-b4d1-431f0c1a9e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-6a9c4466-5884-4fb1-9053-140a74237079,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-ae1fea14-72ed-4429-b802-3e5429d5fd14,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-9b36013b-925d-4412-a79a-a6573a290453,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-348fd576-25ea-4130-b4ec-b0dd0989f8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-9657fb1b-27bb-4b25-aed0-fd1a14f87401,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-f5d2f578-4c68-4219-906e-05ee3cdce300,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022412602-172.17.0.17-1595552314194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46778,DS-9cc23a20-0a34-48e4-9af3-c5eb892ce133,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-dd00f8c3-ae6e-442c-b4d1-431f0c1a9e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-6a9c4466-5884-4fb1-9053-140a74237079,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-ae1fea14-72ed-4429-b802-3e5429d5fd14,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-9b36013b-925d-4412-a79a-a6573a290453,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-348fd576-25ea-4130-b4ec-b0dd0989f8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-9657fb1b-27bb-4b25-aed0-fd1a14f87401,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-f5d2f578-4c68-4219-906e-05ee3cdce300,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-676463084-172.17.0.17-1595552502371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38249,DS-09459a40-e492-491c-9846-14e754e993e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-1b6c8456-8ffb-4f4e-8cfb-0e9ed5f87477,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-7373ec6b-052b-4053-a12f-84b2bfe436c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-146a5a15-a0d9-4796-b668-b1489c54e68b,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-c445a04b-080b-46fb-9f17-7642f33e55a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-54cddb90-e015-48c8-a3a0-0a8e02b1fef1,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-37d7be6f-4dad-4f5b-bd20-413f32b6ad4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-1c3f18a0-1212-41b8-9dc6-14fa80d248c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-676463084-172.17.0.17-1595552502371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38249,DS-09459a40-e492-491c-9846-14e754e993e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-1b6c8456-8ffb-4f4e-8cfb-0e9ed5f87477,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-7373ec6b-052b-4053-a12f-84b2bfe436c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-146a5a15-a0d9-4796-b668-b1489c54e68b,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-c445a04b-080b-46fb-9f17-7642f33e55a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-54cddb90-e015-48c8-a3a0-0a8e02b1fef1,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-37d7be6f-4dad-4f5b-bd20-413f32b6ad4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-1c3f18a0-1212-41b8-9dc6-14fa80d248c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1708580241-172.17.0.17-1595552537857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35035,DS-3f31d194-b6c1-479a-8bad-77be1e07309e,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-47e72f52-55b1-46af-aad9-e67b7d16835c,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-85b31f58-60c8-480c-bd89-2721d200a4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-9dab5dcd-44e0-4fac-87f9-b0ac4183d9df,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-a0c14453-dc3b-4218-97d1-a19f7384142d,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-cea03f42-a90b-4a41-97c1-4197e14a694f,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-34379074-2b5d-4c6b-91a6-51224d2071a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-33ff709f-882d-45fa-ba36-0c46fc688d9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1708580241-172.17.0.17-1595552537857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35035,DS-3f31d194-b6c1-479a-8bad-77be1e07309e,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-47e72f52-55b1-46af-aad9-e67b7d16835c,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-85b31f58-60c8-480c-bd89-2721d200a4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-9dab5dcd-44e0-4fac-87f9-b0ac4183d9df,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-a0c14453-dc3b-4218-97d1-a19f7384142d,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-cea03f42-a90b-4a41-97c1-4197e14a694f,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-34379074-2b5d-4c6b-91a6-51224d2071a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-33ff709f-882d-45fa-ba36-0c46fc688d9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2087477561-172.17.0.17-1595552650693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36105,DS-0993eb53-9857-41d0-89f0-d96c51ce0876,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-8f454aa2-dc27-4a6e-b86f-c28f8f1457a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-eafbc836-2338-4876-8a45-092f915b9c56,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-3bad413b-c231-4fc2-a9e5-d7e6fcb60f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-2adab602-0369-45b4-8751-010171baf4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-4babefc0-d683-4b9f-8ea2-d90c7e927ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-16227328-a706-4b8f-ba23-8c0ae67dd672,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-1d383b9a-f285-49e9-8ecb-178c114ca4a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2087477561-172.17.0.17-1595552650693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36105,DS-0993eb53-9857-41d0-89f0-d96c51ce0876,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-8f454aa2-dc27-4a6e-b86f-c28f8f1457a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-eafbc836-2338-4876-8a45-092f915b9c56,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-3bad413b-c231-4fc2-a9e5-d7e6fcb60f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-2adab602-0369-45b4-8751-010171baf4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-4babefc0-d683-4b9f-8ea2-d90c7e927ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-16227328-a706-4b8f-ba23-8c0ae67dd672,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-1d383b9a-f285-49e9-8ecb-178c114ca4a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1929490957-172.17.0.17-1595552733146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46753,DS-79802a02-da41-4976-b0ac-cc9bc10b30ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-eed62da5-273c-4264-82b3-f5e09630337e,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-8700f4f6-f15e-41f5-9ad9-307405a8aa18,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-5251d3e7-613e-450b-9604-dca6ba2fefa0,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-6cced9a3-b67f-4803-b8f5-645ff60323d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-e62a1a27-0c7a-46f5-b746-61ad133bed4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-9c1ed22a-aeec-436a-825b-06710142aaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-bd6cf7e5-66cc-4550-9af2-3e7e00d62d29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1929490957-172.17.0.17-1595552733146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46753,DS-79802a02-da41-4976-b0ac-cc9bc10b30ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-eed62da5-273c-4264-82b3-f5e09630337e,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-8700f4f6-f15e-41f5-9ad9-307405a8aa18,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-5251d3e7-613e-450b-9604-dca6ba2fefa0,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-6cced9a3-b67f-4803-b8f5-645ff60323d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-e62a1a27-0c7a-46f5-b746-61ad133bed4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-9c1ed22a-aeec-436a-825b-06710142aaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-bd6cf7e5-66cc-4550-9af2-3e7e00d62d29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-333796900-172.17.0.17-1595552769626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37750,DS-7f237723-ed3f-4609-8c74-76e6bb296b29,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-ad3d6310-0cb6-4231-9c34-8bf6dd96c099,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-d4fc2f02-7848-4355-995d-50c6ee425d04,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-1ab91823-fa0a-4e89-ba29-5ca5dcce09a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-b3298281-66c9-46dd-b3d2-4318f42ee153,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-4bbe8aed-9a41-40f2-904f-c2f27dc4af20,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-38e5cb0e-5327-45b3-bee6-877c4eb8b095,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-773c5375-e143-4223-946b-93cb5359c9c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-333796900-172.17.0.17-1595552769626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37750,DS-7f237723-ed3f-4609-8c74-76e6bb296b29,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-ad3d6310-0cb6-4231-9c34-8bf6dd96c099,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-d4fc2f02-7848-4355-995d-50c6ee425d04,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-1ab91823-fa0a-4e89-ba29-5ca5dcce09a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-b3298281-66c9-46dd-b3d2-4318f42ee153,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-4bbe8aed-9a41-40f2-904f-c2f27dc4af20,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-38e5cb0e-5327-45b3-bee6-877c4eb8b095,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-773c5375-e143-4223-946b-93cb5359c9c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377786152-172.17.0.17-1595553058576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40350,DS-ba9e319a-7d7f-48d3-980f-f0ebe2ea4501,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-ec6dd18f-930f-4352-9c9e-dc26a35bf808,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-0749ae34-fbff-4264-9848-be081001bbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-911e319a-5a4c-4d13-9c8e-b1eb217aa69b,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-af9e4ba3-e06b-4a8f-9748-a49f931776aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-5e50e74d-45a4-41f1-bef1-7d5651799be7,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-ec2ec0a9-eaf9-44b7-949a-d93fd851f368,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-e91cd4aa-3e51-437d-9c10-650e144991b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377786152-172.17.0.17-1595553058576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40350,DS-ba9e319a-7d7f-48d3-980f-f0ebe2ea4501,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-ec6dd18f-930f-4352-9c9e-dc26a35bf808,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-0749ae34-fbff-4264-9848-be081001bbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-911e319a-5a4c-4d13-9c8e-b1eb217aa69b,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-af9e4ba3-e06b-4a8f-9748-a49f931776aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-5e50e74d-45a4-41f1-bef1-7d5651799be7,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-ec2ec0a9-eaf9-44b7-949a-d93fd851f368,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-e91cd4aa-3e51-437d-9c10-650e144991b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1002886389-172.17.0.17-1595553272695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45918,DS-ce9846fd-beb5-44b9-99b4-5be9e5532869,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-493af0b6-0dbc-4272-babf-a62ab7163283,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-060e3a96-ad6a-4a41-a72d-f00cf464f0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-c4fdeefe-21d3-4625-9674-3721914730b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-a81dcfe6-c934-4ae0-93cc-a15f777e380f,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-795dfbb8-a412-433b-a8bb-801341aff22a,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-5a041793-553e-4e8f-ab58-1386bd81df15,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-36200c1b-0600-4658-bd08-b3bbbf91f044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1002886389-172.17.0.17-1595553272695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45918,DS-ce9846fd-beb5-44b9-99b4-5be9e5532869,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-493af0b6-0dbc-4272-babf-a62ab7163283,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-060e3a96-ad6a-4a41-a72d-f00cf464f0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-c4fdeefe-21d3-4625-9674-3721914730b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-a81dcfe6-c934-4ae0-93cc-a15f777e380f,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-795dfbb8-a412-433b-a8bb-801341aff22a,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-5a041793-553e-4e8f-ab58-1386bd81df15,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-36200c1b-0600-4658-bd08-b3bbbf91f044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-288610823-172.17.0.17-1595553469791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43528,DS-b40af587-30ca-406d-89fc-a995011c9c07,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-d1a482d4-9f6e-438f-8fbf-6ee9f8be443c,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-fa6229b4-f8f2-4081-b104-58f83a2a9267,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-eb250817-7198-4d50-91c8-f8463563f79a,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-b80f9776-8310-4237-af9f-6cfb70a950b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-b91db5e5-0888-4f7f-ad15-4ce303971ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-0de2468b-c3ef-4997-a7d6-b06dcf7c69f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-e3d34754-1f9b-4588-8d2a-4a4eca8030ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-288610823-172.17.0.17-1595553469791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43528,DS-b40af587-30ca-406d-89fc-a995011c9c07,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-d1a482d4-9f6e-438f-8fbf-6ee9f8be443c,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-fa6229b4-f8f2-4081-b104-58f83a2a9267,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-eb250817-7198-4d50-91c8-f8463563f79a,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-b80f9776-8310-4237-af9f-6cfb70a950b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-b91db5e5-0888-4f7f-ad15-4ce303971ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-0de2468b-c3ef-4997-a7d6-b06dcf7c69f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-e3d34754-1f9b-4588-8d2a-4a4eca8030ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5495
