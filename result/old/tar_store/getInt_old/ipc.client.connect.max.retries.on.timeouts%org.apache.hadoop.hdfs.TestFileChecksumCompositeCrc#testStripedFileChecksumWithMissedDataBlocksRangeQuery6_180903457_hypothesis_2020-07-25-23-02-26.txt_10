reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81222967-172.17.0.18-1595718359200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37342,DS-bc8adf65-d561-4e17-b7c3-f2a99eb3c4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-5af6b4ea-079c-4763-87bb-06242d57440d,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-f3d7c8c8-459e-4f92-b542-cff02bd21b93,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-4b9a2285-88ae-414f-9f71-cfd22ecd3d76,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-4f967f07-b6ab-4296-929f-455d76e8df0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-2ae8e3b3-6bee-4b85-98aa-86b0618c9ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-5b0ab2ab-0135-49f0-8583-ea9c48f45469,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-49dd45e9-bfa0-436a-b937-504a5131510d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81222967-172.17.0.18-1595718359200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37342,DS-bc8adf65-d561-4e17-b7c3-f2a99eb3c4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-5af6b4ea-079c-4763-87bb-06242d57440d,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-f3d7c8c8-459e-4f92-b542-cff02bd21b93,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-4b9a2285-88ae-414f-9f71-cfd22ecd3d76,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-4f967f07-b6ab-4296-929f-455d76e8df0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-2ae8e3b3-6bee-4b85-98aa-86b0618c9ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-5b0ab2ab-0135-49f0-8583-ea9c48f45469,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-49dd45e9-bfa0-436a-b937-504a5131510d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-470938556-172.17.0.18-1595718449376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33501,DS-70dc6fa9-82e5-4992-ae4e-8ab4ef03269f,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-0fcb3c59-fa50-42ba-81eb-ea2b2f989969,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-fbdda7a1-f154-4b7d-a22b-37c92e7341a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-1b3d734c-7369-4b9c-801a-5c85835e9144,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-3ed67116-dc71-4d0e-9205-b709e99fd902,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-d848ef91-85a7-4a49-91c0-212d52d34adc,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-a3661526-3f36-4fcd-afa1-e0d520585be5,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-8ce0e16c-c296-472a-97a7-08c489a35697,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-470938556-172.17.0.18-1595718449376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33501,DS-70dc6fa9-82e5-4992-ae4e-8ab4ef03269f,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-0fcb3c59-fa50-42ba-81eb-ea2b2f989969,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-fbdda7a1-f154-4b7d-a22b-37c92e7341a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-1b3d734c-7369-4b9c-801a-5c85835e9144,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-3ed67116-dc71-4d0e-9205-b709e99fd902,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-d848ef91-85a7-4a49-91c0-212d52d34adc,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-a3661526-3f36-4fcd-afa1-e0d520585be5,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-8ce0e16c-c296-472a-97a7-08c489a35697,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692832068-172.17.0.18-1595718925004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45574,DS-ff366af0-6add-40f1-9756-8b8a9c60a3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-127c53c0-d27f-49f7-a585-9afafcb4764a,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-2724c4f7-1911-48ba-9adf-051f703b800c,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-28cdf4d8-54e0-4441-ac65-9dc8c4ad6034,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-27364b4b-14c0-444f-a89d-0ad89a067eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-5b74bb36-be7e-4b86-8679-a4f645bbb3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-580b75a1-3667-4841-8402-2072848ddec1,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-d6016954-b200-462f-954f-a2e44e4e6434,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692832068-172.17.0.18-1595718925004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45574,DS-ff366af0-6add-40f1-9756-8b8a9c60a3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-127c53c0-d27f-49f7-a585-9afafcb4764a,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-2724c4f7-1911-48ba-9adf-051f703b800c,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-28cdf4d8-54e0-4441-ac65-9dc8c4ad6034,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-27364b4b-14c0-444f-a89d-0ad89a067eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-5b74bb36-be7e-4b86-8679-a4f645bbb3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-580b75a1-3667-4841-8402-2072848ddec1,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-d6016954-b200-462f-954f-a2e44e4e6434,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963776148-172.17.0.18-1595719105036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34303,DS-2009a588-2e40-48d9-8a37-492ff306c8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-d1950f59-f5db-4962-b934-579714c7eb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-8d8c3d40-64ff-43c5-a8ca-a8f8033c0135,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-178fe08d-7568-47bb-a11d-cfe1044aa3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-20f01b1e-f0cc-42f2-8683-cb4d47413b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-589461f8-d11b-43df-b908-74bb5eb83868,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-01a4b5c3-8c82-4a8c-a2c2-55d100415cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-8e601196-f0ae-4155-a8d8-7ec5aaeb18aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963776148-172.17.0.18-1595719105036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34303,DS-2009a588-2e40-48d9-8a37-492ff306c8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-d1950f59-f5db-4962-b934-579714c7eb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-8d8c3d40-64ff-43c5-a8ca-a8f8033c0135,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-178fe08d-7568-47bb-a11d-cfe1044aa3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-20f01b1e-f0cc-42f2-8683-cb4d47413b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-589461f8-d11b-43df-b908-74bb5eb83868,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-01a4b5c3-8c82-4a8c-a2c2-55d100415cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-8e601196-f0ae-4155-a8d8-7ec5aaeb18aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817283172-172.17.0.18-1595719668081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32955,DS-62fe9915-a07a-4558-bea8-24f9565ba469,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-bf69c5f4-6db1-4ce9-ad72-79025ae06324,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-ea214a22-09d8-408e-8167-5bdb92fd7f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-e9d422fc-d4e1-4730-aa65-0e52bc5e27d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-52afdf28-7a8e-433b-bbd8-d1c82c26ee1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-b6a61c60-f7c9-4e35-aea7-897fbda1a732,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-4ae48c78-4140-42f8-ab08-3e1a8b0e1c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-92521721-c2f6-4996-90c5-91b50b029886,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817283172-172.17.0.18-1595719668081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32955,DS-62fe9915-a07a-4558-bea8-24f9565ba469,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-bf69c5f4-6db1-4ce9-ad72-79025ae06324,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-ea214a22-09d8-408e-8167-5bdb92fd7f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-e9d422fc-d4e1-4730-aa65-0e52bc5e27d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-52afdf28-7a8e-433b-bbd8-d1c82c26ee1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-b6a61c60-f7c9-4e35-aea7-897fbda1a732,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-4ae48c78-4140-42f8-ab08-3e1a8b0e1c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-92521721-c2f6-4996-90c5-91b50b029886,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1443655766-172.17.0.18-1595719758169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41272,DS-d0cd2ad6-7901-4bba-b30c-759995135346,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-0e1237e6-7510-4d4e-a382-838be6e40247,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-353d58b4-4f4f-4407-9883-849d295aa1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-34ed9548-5122-46a2-8ba3-274f240e1bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-798be6dc-1ba0-4287-9ee7-b1de8221c184,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-366ccd6e-d505-46d9-8c44-c815bc242a29,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-15171c70-4c59-4dac-9ab3-d0d7ab86b9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-f2b194e1-a40e-4cb7-a52f-2e58b188c9dc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1443655766-172.17.0.18-1595719758169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41272,DS-d0cd2ad6-7901-4bba-b30c-759995135346,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-0e1237e6-7510-4d4e-a382-838be6e40247,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-353d58b4-4f4f-4407-9883-849d295aa1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-34ed9548-5122-46a2-8ba3-274f240e1bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-798be6dc-1ba0-4287-9ee7-b1de8221c184,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-366ccd6e-d505-46d9-8c44-c815bc242a29,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-15171c70-4c59-4dac-9ab3-d0d7ab86b9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-f2b194e1-a40e-4cb7-a52f-2e58b188c9dc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325090359-172.17.0.18-1595719802036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41635,DS-486ca664-338b-4be2-a7e9-402a742ddfba,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-4bcba8b3-0d02-4f20-9e79-25cf7f8799ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-256b134d-62eb-481d-96a2-c60964203dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-69af45d5-b619-4658-953e-54cc551e71bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-cbc872e5-c3fa-464a-a77c-fa86f6aa1e51,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-82725bbb-16b9-4cdf-8d7a-9e69d006c277,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-27440103-defe-4f90-b7e3-86987ef6564d,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-6d0af04b-f002-4138-91f2-1ab0fc7da24b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325090359-172.17.0.18-1595719802036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41635,DS-486ca664-338b-4be2-a7e9-402a742ddfba,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-4bcba8b3-0d02-4f20-9e79-25cf7f8799ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-256b134d-62eb-481d-96a2-c60964203dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-69af45d5-b619-4658-953e-54cc551e71bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-cbc872e5-c3fa-464a-a77c-fa86f6aa1e51,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-82725bbb-16b9-4cdf-8d7a-9e69d006c277,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-27440103-defe-4f90-b7e3-86987ef6564d,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-6d0af04b-f002-4138-91f2-1ab0fc7da24b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1679752146-172.17.0.18-1595719934991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40717,DS-7a4e9b80-762d-4fa9-8c32-8f8f4a23dbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-7a448d85-0d53-4f17-902e-3ab0553e2d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-04ac9070-3b39-466e-8b63-1b4623db05e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-93ce4338-9e7a-4fb7-868f-63d37299cf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-14479f10-90ea-4dae-8e95-ccec3dbb8a42,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-8c94c21a-91eb-4b97-bb16-d5c5e8a05153,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-da38427a-7645-4774-b283-4b8c0d6c4909,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-86a96f84-e65f-4514-9225-7a93b517f052,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1679752146-172.17.0.18-1595719934991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40717,DS-7a4e9b80-762d-4fa9-8c32-8f8f4a23dbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-7a448d85-0d53-4f17-902e-3ab0553e2d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-04ac9070-3b39-466e-8b63-1b4623db05e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-93ce4338-9e7a-4fb7-868f-63d37299cf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-14479f10-90ea-4dae-8e95-ccec3dbb8a42,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-8c94c21a-91eb-4b97-bb16-d5c5e8a05153,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-da38427a-7645-4774-b283-4b8c0d6c4909,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-86a96f84-e65f-4514-9225-7a93b517f052,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1409279264-172.17.0.18-1595720406919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42671,DS-fd86d77f-9bb7-4748-8816-40348ece9d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-018a2cc4-32ea-4f35-8e1d-04b94f137eec,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-2d0a71e4-67f3-452c-9cfc-d34cd53dc661,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-31e689d0-6673-4336-95f2-8c817bfdc161,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-bd890aee-50db-434c-99cc-96bd140c2dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-339aef40-7d32-469b-be01-7b68b6ce6185,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-6631c4f7-f360-44dd-880e-9b32e1ddf5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-743ef26e-e2a4-4232-b9e1-aa32e67ca699,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1409279264-172.17.0.18-1595720406919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42671,DS-fd86d77f-9bb7-4748-8816-40348ece9d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-018a2cc4-32ea-4f35-8e1d-04b94f137eec,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-2d0a71e4-67f3-452c-9cfc-d34cd53dc661,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-31e689d0-6673-4336-95f2-8c817bfdc161,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-bd890aee-50db-434c-99cc-96bd140c2dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-339aef40-7d32-469b-be01-7b68b6ce6185,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-6631c4f7-f360-44dd-880e-9b32e1ddf5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-743ef26e-e2a4-4232-b9e1-aa32e67ca699,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783273516-172.17.0.18-1595720559056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44954,DS-846aa685-d4c2-47b9-bae9-f4ae9a464971,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-dad52518-b881-4601-89f7-a3453f4867bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-c5f7f100-05f8-48dc-87ce-ed9d061ec434,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-97923b72-f4f0-49a6-b5fd-3536bc74e8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-ba8c391d-418a-4a14-8e4f-3e360f4f29cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-a0fa7286-367b-441d-adf7-41181dfe0447,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-06a8ea64-d650-4878-8e9f-a81c8d7e19bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-ec554e6c-386e-499c-aa3a-d43effa7515d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783273516-172.17.0.18-1595720559056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44954,DS-846aa685-d4c2-47b9-bae9-f4ae9a464971,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-dad52518-b881-4601-89f7-a3453f4867bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-c5f7f100-05f8-48dc-87ce-ed9d061ec434,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-97923b72-f4f0-49a6-b5fd-3536bc74e8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-ba8c391d-418a-4a14-8e4f-3e360f4f29cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-a0fa7286-367b-441d-adf7-41181dfe0447,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-06a8ea64-d650-4878-8e9f-a81c8d7e19bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-ec554e6c-386e-499c-aa3a-d43effa7515d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659106146-172.17.0.18-1595720599845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45349,DS-a9382c58-9944-446d-95f4-62fa3d40a130,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-5e562f0a-0400-4355-b0fb-fb161ec9b199,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-60a201dd-7198-4bac-a1d2-534ef8d10271,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-f70ce38f-b7d7-4bdf-8386-6ad0616271bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-eb036f34-81d3-4ec3-92ea-27b148193014,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-f7f2fccf-721e-4189-bdbf-5cec11d7376c,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-a8580841-c24d-436c-a721-b979cd75e3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-79830280-67a4-4904-91fb-b7ceabc698fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659106146-172.17.0.18-1595720599845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45349,DS-a9382c58-9944-446d-95f4-62fa3d40a130,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-5e562f0a-0400-4355-b0fb-fb161ec9b199,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-60a201dd-7198-4bac-a1d2-534ef8d10271,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-f70ce38f-b7d7-4bdf-8386-6ad0616271bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-eb036f34-81d3-4ec3-92ea-27b148193014,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-f7f2fccf-721e-4189-bdbf-5cec11d7376c,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-a8580841-c24d-436c-a721-b979cd75e3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-79830280-67a4-4904-91fb-b7ceabc698fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915099820-172.17.0.18-1595720947037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34193,DS-15b685cd-e9b0-46d3-8bad-69b70285b181,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-671983fc-327d-4e1a-9657-947bf72df1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-f5548399-1319-4f4c-992b-8745eb2205c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-a908149d-5954-42d8-b6ef-dc9b7142b9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-16d871a4-cc50-4b83-8ad0-84b0f2ade98e,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-05118154-7cb0-406b-9d15-60a6c037c84d,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-f027b0c0-a939-4cc5-b67d-1b66b5cb2ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-2b74e8c3-d62e-4188-b991-a11f871c6b74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915099820-172.17.0.18-1595720947037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34193,DS-15b685cd-e9b0-46d3-8bad-69b70285b181,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-671983fc-327d-4e1a-9657-947bf72df1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-f5548399-1319-4f4c-992b-8745eb2205c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-a908149d-5954-42d8-b6ef-dc9b7142b9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-16d871a4-cc50-4b83-8ad0-84b0f2ade98e,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-05118154-7cb0-406b-9d15-60a6c037c84d,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-f027b0c0-a939-4cc5-b67d-1b66b5cb2ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-2b74e8c3-d62e-4188-b991-a11f871c6b74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171904300-172.17.0.18-1595720982274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38247,DS-0afe956a-1669-4ef8-9aea-bd1f349500da,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-14cecd51-2114-47c7-82f0-6543da535fac,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-9c6ffa75-96e9-4181-87f1-7bdad7fedcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-c27b51a6-7fa4-4202-9516-45fa7b5ac2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-9db7813f-8d30-4971-a10f-3749adbe94f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-a1e7369b-d09c-461c-8017-da08076d5510,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-9a79ca2a-5b3a-4fe8-83a7-ad6a6592e964,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-a8678d95-02b2-48ed-8ca4-add7718a1e32,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171904300-172.17.0.18-1595720982274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38247,DS-0afe956a-1669-4ef8-9aea-bd1f349500da,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-14cecd51-2114-47c7-82f0-6543da535fac,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-9c6ffa75-96e9-4181-87f1-7bdad7fedcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-c27b51a6-7fa4-4202-9516-45fa7b5ac2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-9db7813f-8d30-4971-a10f-3749adbe94f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-a1e7369b-d09c-461c-8017-da08076d5510,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-9a79ca2a-5b3a-4fe8-83a7-ad6a6592e964,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-a8678d95-02b2-48ed-8ca4-add7718a1e32,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487219007-172.17.0.18-1595721175529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36622,DS-49aec69f-c83f-4e3f-98b3-ead7946c08da,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-34553904-8db7-4d39-aa07-699413a85c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-be482475-cda8-4286-8161-0d61c6538241,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-2ffe5609-a1cf-4ce9-bed9-cfbede3a96b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-3636b949-127a-4fbd-8c16-d39d0011dfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-ef5b5c6b-5cec-4e52-9bc1-f403a2f89362,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-48033d8d-79c5-4b95-8033-35ac7882acec,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-6a3f1a66-6739-492f-a9c9-b043501cf0b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487219007-172.17.0.18-1595721175529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36622,DS-49aec69f-c83f-4e3f-98b3-ead7946c08da,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-34553904-8db7-4d39-aa07-699413a85c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-be482475-cda8-4286-8161-0d61c6538241,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-2ffe5609-a1cf-4ce9-bed9-cfbede3a96b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-3636b949-127a-4fbd-8c16-d39d0011dfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-ef5b5c6b-5cec-4e52-9bc1-f403a2f89362,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-48033d8d-79c5-4b95-8033-35ac7882acec,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-6a3f1a66-6739-492f-a9c9-b043501cf0b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-206699057-172.17.0.18-1595721225149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46869,DS-65026289-1a66-4c9b-a1e3-c5c335439483,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-2e5aa039-0b30-4791-bc5c-821e0c4ec241,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-6392c85d-58af-45f0-8728-ca64935e82b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-960e6d30-703d-483f-a19e-264d4318d31f,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-a0703e32-db6a-410a-9daa-5f7e762116c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-9f1ef179-af5e-407c-97e5-0c6efb1ec2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-681bb127-9929-4138-a69e-8f7774abc821,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-d9d70aa0-eddd-4dae-8d60-c801b082f9a2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-206699057-172.17.0.18-1595721225149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46869,DS-65026289-1a66-4c9b-a1e3-c5c335439483,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-2e5aa039-0b30-4791-bc5c-821e0c4ec241,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-6392c85d-58af-45f0-8728-ca64935e82b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-960e6d30-703d-483f-a19e-264d4318d31f,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-a0703e32-db6a-410a-9daa-5f7e762116c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-9f1ef179-af5e-407c-97e5-0c6efb1ec2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-681bb127-9929-4138-a69e-8f7774abc821,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-d9d70aa0-eddd-4dae-8d60-c801b082f9a2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704109352-172.17.0.18-1595721268009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44659,DS-0db19fec-5eee-441f-a438-c0998e045031,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-a985c0bd-21e1-4066-9f82-3abcab3e3e77,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-9d798201-85af-481f-b1c6-33e31d64ac7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-bf0658b9-595e-4f84-b0c1-3dbd78712f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-8875a62f-77c3-426a-8fb6-63c13bb09ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-c6b1dafa-af0f-4d5f-bc93-b21fa45c489e,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-594ff497-b119-438f-ba58-0ad94cfad2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-61a9af94-adaf-437c-a919-1bc49cc29c39,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704109352-172.17.0.18-1595721268009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44659,DS-0db19fec-5eee-441f-a438-c0998e045031,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-a985c0bd-21e1-4066-9f82-3abcab3e3e77,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-9d798201-85af-481f-b1c6-33e31d64ac7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-bf0658b9-595e-4f84-b0c1-3dbd78712f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-8875a62f-77c3-426a-8fb6-63c13bb09ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-c6b1dafa-af0f-4d5f-bc93-b21fa45c489e,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-594ff497-b119-438f-ba58-0ad94cfad2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-61a9af94-adaf-437c-a919-1bc49cc29c39,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016201268-172.17.0.18-1595721383871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34560,DS-a4a2605a-d48e-4410-9a98-1b840a44fa79,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-a94428a9-f837-4ff0-9660-a1968d347ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-0c848f10-7db6-4702-b525-77dbf6b0905b,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-8c600fc9-5750-4219-ae35-d7312f035e21,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-35f2d1e5-6c06-4e2b-87fe-5bf54e83f2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-fe953600-d968-42f7-beaa-b713b57fd328,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-6d23629a-5035-4252-9840-8234d723bdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-4f257073-f202-4e6f-967c-5aa043c90ea4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016201268-172.17.0.18-1595721383871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34560,DS-a4a2605a-d48e-4410-9a98-1b840a44fa79,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-a94428a9-f837-4ff0-9660-a1968d347ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-0c848f10-7db6-4702-b525-77dbf6b0905b,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-8c600fc9-5750-4219-ae35-d7312f035e21,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-35f2d1e5-6c06-4e2b-87fe-5bf54e83f2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-fe953600-d968-42f7-beaa-b713b57fd328,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-6d23629a-5035-4252-9840-8234d723bdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-4f257073-f202-4e6f-967c-5aa043c90ea4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-534217459-172.17.0.18-1595721595008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43436,DS-9b4828da-cf57-4484-af26-54e0d622b8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-d6e1a000-4936-4320-8215-7567dd1c08fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-4b59fa64-ee2f-40d8-ac60-1f612ac9e05a,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-aadb04cc-4a9c-4cbc-a597-604d1918a43e,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-e53aa761-ab91-4cda-b62a-abe491c46154,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-9e6e8dcf-101c-4d26-8914-35feb37dc368,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-967697c1-13b9-4eaf-84bf-d2aa7255a7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-78c7df42-d360-4840-9f42-71139e72e99f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-534217459-172.17.0.18-1595721595008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43436,DS-9b4828da-cf57-4484-af26-54e0d622b8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-d6e1a000-4936-4320-8215-7567dd1c08fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-4b59fa64-ee2f-40d8-ac60-1f612ac9e05a,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-aadb04cc-4a9c-4cbc-a597-604d1918a43e,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-e53aa761-ab91-4cda-b62a-abe491c46154,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-9e6e8dcf-101c-4d26-8914-35feb37dc368,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-967697c1-13b9-4eaf-84bf-d2aa7255a7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-78c7df42-d360-4840-9f42-71139e72e99f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187422646-172.17.0.18-1595721628879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45606,DS-c8ace24c-191e-4d63-9361-1e491fda3881,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-f285f1c1-4a0a-46a0-a53a-0d18165b2532,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-4c20409f-ccae-4aef-83b9-d91a60f26173,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-ebc99b64-3562-428e-9843-771432108c24,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-c396bff1-8c39-4e37-8d28-ac0cea5f752c,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-28d841e9-a465-4ea6-be7a-653db001173e,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-d16484f6-80f4-410c-9119-1415ba59e294,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-6b2fab0a-c522-4b32-a198-b78d7ca81279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187422646-172.17.0.18-1595721628879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45606,DS-c8ace24c-191e-4d63-9361-1e491fda3881,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-f285f1c1-4a0a-46a0-a53a-0d18165b2532,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-4c20409f-ccae-4aef-83b9-d91a60f26173,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-ebc99b64-3562-428e-9843-771432108c24,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-c396bff1-8c39-4e37-8d28-ac0cea5f752c,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-28d841e9-a465-4ea6-be7a-653db001173e,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-d16484f6-80f4-410c-9119-1415ba59e294,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-6b2fab0a-c522-4b32-a198-b78d7ca81279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1989396243-172.17.0.18-1595721774416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37203,DS-fa12c168-c145-4af0-a616-7fa95c526385,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-78b26848-4a79-47a6-bd11-1dfd8f3bea0f,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-6d10e2b6-3f46-4cbb-aac0-7391fe191278,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-ea288727-9008-40e4-aff5-5070ed5d4d66,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-ebc923df-ec4b-41f3-bc39-ada1c8670456,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-2e8f9d9b-7c3e-47b0-8d8a-680cd41db0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-0adc4127-b67f-4bf6-970b-54bf513de7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-f13b2cb7-62f5-4854-ab28-9d3b49f76018,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1989396243-172.17.0.18-1595721774416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37203,DS-fa12c168-c145-4af0-a616-7fa95c526385,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-78b26848-4a79-47a6-bd11-1dfd8f3bea0f,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-6d10e2b6-3f46-4cbb-aac0-7391fe191278,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-ea288727-9008-40e4-aff5-5070ed5d4d66,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-ebc923df-ec4b-41f3-bc39-ada1c8670456,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-2e8f9d9b-7c3e-47b0-8d8a-680cd41db0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-0adc4127-b67f-4bf6-970b-54bf513de7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-f13b2cb7-62f5-4854-ab28-9d3b49f76018,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908935849-172.17.0.18-1595722091888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44950,DS-029becb7-8412-4e78-9fcf-03ad96ea84a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-499d325d-1f90-45d2-9cbb-4c4d7ce0f567,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-5549c78a-37b2-490d-8db4-086712a8ccb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-f6a67a88-9ba7-40e5-a3d8-23ee55e7820b,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-3de0dc87-426c-4de2-a15c-276e20720466,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-9e7dc0d2-11ae-4e24-ba32-00e6e46f2e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-20ed4783-cef8-4178-99cc-6fd56b340ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-e68353f4-5d36-4c4f-9621-c74e23ab2868,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908935849-172.17.0.18-1595722091888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44950,DS-029becb7-8412-4e78-9fcf-03ad96ea84a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-499d325d-1f90-45d2-9cbb-4c4d7ce0f567,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-5549c78a-37b2-490d-8db4-086712a8ccb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-f6a67a88-9ba7-40e5-a3d8-23ee55e7820b,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-3de0dc87-426c-4de2-a15c-276e20720466,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-9e7dc0d2-11ae-4e24-ba32-00e6e46f2e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-20ed4783-cef8-4178-99cc-6fd56b340ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-e68353f4-5d36-4c4f-9621-c74e23ab2868,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884022604-172.17.0.18-1595722489621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38438,DS-50c00538-63f3-43a0-8f91-74b92255d938,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-c121efa1-6188-48b0-b9bd-ed422e1d8a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-c07e53fb-c128-40e7-97be-34100b4844d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-d9bded62-f39e-4210-a05f-356971a2482e,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-6dc09f6d-1aed-4fe2-acbb-ddeac0e5ae56,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-2f75a070-feb9-47b8-a39d-0250ea9a29b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-97c68fbf-82cf-4fca-86a1-bf34d52b470a,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-eccdee8c-dbaa-48a0-be33-5f96702e5961,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884022604-172.17.0.18-1595722489621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38438,DS-50c00538-63f3-43a0-8f91-74b92255d938,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-c121efa1-6188-48b0-b9bd-ed422e1d8a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-c07e53fb-c128-40e7-97be-34100b4844d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-d9bded62-f39e-4210-a05f-356971a2482e,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-6dc09f6d-1aed-4fe2-acbb-ddeac0e5ae56,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-2f75a070-feb9-47b8-a39d-0250ea9a29b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-97c68fbf-82cf-4fca-86a1-bf34d52b470a,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-eccdee8c-dbaa-48a0-be33-5f96702e5961,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1910993816-172.17.0.18-1595722743578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36643,DS-d1f16938-71ce-44ec-9de4-04418613ecb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-a721350e-d69b-4fda-a579-b00c2c04b226,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-ba95d8ee-bab4-40f3-802b-c616e6917bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-c9525c0f-8ffc-4976-994f-da889b10f21d,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-15d8e24d-df71-4bbc-95b3-50cc3afa259d,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-6b29f40d-5722-426f-8840-0fc708577bae,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-19d3bfa4-5f42-48bf-b546-5e82f3d4a13e,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-6113a2ef-0e8d-4521-b722-28fdc4472301,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1910993816-172.17.0.18-1595722743578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36643,DS-d1f16938-71ce-44ec-9de4-04418613ecb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-a721350e-d69b-4fda-a579-b00c2c04b226,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-ba95d8ee-bab4-40f3-802b-c616e6917bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-c9525c0f-8ffc-4976-994f-da889b10f21d,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-15d8e24d-df71-4bbc-95b3-50cc3afa259d,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-6b29f40d-5722-426f-8840-0fc708577bae,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-19d3bfa4-5f42-48bf-b546-5e82f3d4a13e,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-6113a2ef-0e8d-4521-b722-28fdc4472301,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787398990-172.17.0.18-1595722864007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35749,DS-b5671269-f69a-4ad3-a7da-c8c6b3fa7300,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-e6ab4bd4-7c8f-478a-a5e8-5f5b2d76cc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-2704f98c-e15c-4896-986d-9d806fdadccd,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-61dfe577-8db0-4289-a414-402fefcc740a,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-3caaa64a-8de8-4d80-9391-5a4fb63b0482,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-57b1dcd6-4680-4685-9e5c-a4ac2e0761ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-5849eee6-f7cf-4760-a3d3-a8286dc44c37,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-c0ab4a2f-8f7f-4324-9452-4108660710d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787398990-172.17.0.18-1595722864007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35749,DS-b5671269-f69a-4ad3-a7da-c8c6b3fa7300,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-e6ab4bd4-7c8f-478a-a5e8-5f5b2d76cc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-2704f98c-e15c-4896-986d-9d806fdadccd,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-61dfe577-8db0-4289-a414-402fefcc740a,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-3caaa64a-8de8-4d80-9391-5a4fb63b0482,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-57b1dcd6-4680-4685-9e5c-a4ac2e0761ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-5849eee6-f7cf-4760-a3d3-a8286dc44c37,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-c0ab4a2f-8f7f-4324-9452-4108660710d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016324126-172.17.0.18-1595722899472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35530,DS-862c5e21-11b8-427d-9cf5-d274ea52f0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-dd5d82cc-7e45-48b3-acaa-8aa0d0f3f540,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-063d5a94-ab68-410e-a782-003bf6f122d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-9743bc19-8c47-49c2-aace-c9b70b4643a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-b6f5fc53-298a-4b94-9caa-40d61ab721ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-df779b19-9bd3-444e-9023-a461a376af0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-40bd1e62-9b56-4083-82e1-e73c21610b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-5ea12356-c6ed-492c-a41f-e38c25303475,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016324126-172.17.0.18-1595722899472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35530,DS-862c5e21-11b8-427d-9cf5-d274ea52f0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-dd5d82cc-7e45-48b3-acaa-8aa0d0f3f540,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-063d5a94-ab68-410e-a782-003bf6f122d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-9743bc19-8c47-49c2-aace-c9b70b4643a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-b6f5fc53-298a-4b94-9caa-40d61ab721ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-df779b19-9bd3-444e-9023-a461a376af0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-40bd1e62-9b56-4083-82e1-e73c21610b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-5ea12356-c6ed-492c-a41f-e38c25303475,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1882535750-172.17.0.18-1595723284806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38916,DS-9f09e4b4-defe-4f89-a197-4a3d363166dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-679d4268-d8d2-4c7a-a18c-acc149ee8ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-0687af43-6c89-4a64-b9b0-b69e84f92db8,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-e958a30a-0bf0-4f59-a158-9939b2448a49,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-36a66f75-9d77-4b7a-a127-11598e310b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-c0ef084d-7471-40d2-ba25-93f8d8521c94,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-3c0186e8-2f8e-47d9-9f65-1dfe0428c8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-af06db42-a69c-4457-8d9a-0ca3fc0667c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1882535750-172.17.0.18-1595723284806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38916,DS-9f09e4b4-defe-4f89-a197-4a3d363166dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-679d4268-d8d2-4c7a-a18c-acc149ee8ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-0687af43-6c89-4a64-b9b0-b69e84f92db8,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-e958a30a-0bf0-4f59-a158-9939b2448a49,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-36a66f75-9d77-4b7a-a127-11598e310b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-c0ef084d-7471-40d2-ba25-93f8d8521c94,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-3c0186e8-2f8e-47d9-9f65-1dfe0428c8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-af06db42-a69c-4457-8d9a-0ca3fc0667c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-480599644-172.17.0.18-1595723757502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39560,DS-f85a0690-af03-407d-8437-01070b81b1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-35fb108d-1e14-4e91-9f22-e73806b91cea,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-7e6294f5-939e-4c66-8af5-d3a32221a3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-403cf9fd-5305-4963-8a91-a54f945edba4,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-42c14393-6bd8-4fc8-b30a-f25eb5f7534f,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-3b250fd3-2d96-461a-beee-3a33dd581bef,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-906c7486-67fb-42bf-8a50-b698d5b7dc34,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-ba9593df-c4de-4090-a82a-312a3f1af6e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-480599644-172.17.0.18-1595723757502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39560,DS-f85a0690-af03-407d-8437-01070b81b1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-35fb108d-1e14-4e91-9f22-e73806b91cea,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-7e6294f5-939e-4c66-8af5-d3a32221a3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-403cf9fd-5305-4963-8a91-a54f945edba4,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-42c14393-6bd8-4fc8-b30a-f25eb5f7534f,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-3b250fd3-2d96-461a-beee-3a33dd581bef,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-906c7486-67fb-42bf-8a50-b698d5b7dc34,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-ba9593df-c4de-4090-a82a-312a3f1af6e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-627506531-172.17.0.18-1595723809204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33333,DS-3f806de4-bbe2-4469-97ef-bba802f3c7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-0ad44690-ec7e-4d46-a3b1-e78f9e3a574f,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-88856e00-63cc-4b3f-a947-2f87b02eb8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-f0fb1c5a-a9ae-4ac2-b874-01ee12eedb17,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-4a4d26da-60b3-42e7-ad0b-52f7e5fa58b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-f7c20098-74fd-439a-9b47-79339e118ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-722f7fbf-a959-4e67-8f69-05128717e2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-6acfe194-423a-4d21-90fb-232e9f859d5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-627506531-172.17.0.18-1595723809204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33333,DS-3f806de4-bbe2-4469-97ef-bba802f3c7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-0ad44690-ec7e-4d46-a3b1-e78f9e3a574f,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-88856e00-63cc-4b3f-a947-2f87b02eb8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-f0fb1c5a-a9ae-4ac2-b874-01ee12eedb17,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-4a4d26da-60b3-42e7-ad0b-52f7e5fa58b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-f7c20098-74fd-439a-9b47-79339e118ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-722f7fbf-a959-4e67-8f69-05128717e2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-6acfe194-423a-4d21-90fb-232e9f859d5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133475691-172.17.0.18-1595723847968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34929,DS-2e331139-632f-4949-bb1f-99d55f75f0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-c6048d83-2e93-4214-b0d0-9ada4501d14a,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-705d7b86-0912-451c-8e8a-707e9f040cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-f8ee3209-8897-4a1f-8edf-1e73375ff087,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-d8f3f29b-70ab-47a5-bd2b-9d54a75e3e97,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-1855ffdd-d0b5-4b77-a2f5-9068927d87ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-f952a727-82e4-4f32-ae18-3eeda82b5ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-8b93f50e-b489-413e-8e91-32c54e21ed63,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133475691-172.17.0.18-1595723847968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34929,DS-2e331139-632f-4949-bb1f-99d55f75f0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-c6048d83-2e93-4214-b0d0-9ada4501d14a,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-705d7b86-0912-451c-8e8a-707e9f040cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-f8ee3209-8897-4a1f-8edf-1e73375ff087,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-d8f3f29b-70ab-47a5-bd2b-9d54a75e3e97,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-1855ffdd-d0b5-4b77-a2f5-9068927d87ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-f952a727-82e4-4f32-ae18-3eeda82b5ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-8b93f50e-b489-413e-8e91-32c54e21ed63,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999511724-172.17.0.18-1595724090897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45580,DS-58b49876-c582-4f93-87b2-dee48956f84c,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-f8ea9679-1f66-46b3-a038-4c07bf3737d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-26d8986d-6686-4cb3-8b27-8032252eefc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-5cb30e3a-43eb-4d40-9087-c89494405067,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-5d13da76-06fa-445a-bf2c-45c77a60339c,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-edf9ee37-c4e0-4a13-84f1-9ce2ae61f61f,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-9954b59d-2377-4e04-aae1-4f12a774c11b,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-714970f8-9b2f-477e-b7f6-bb90ac27e935,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999511724-172.17.0.18-1595724090897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45580,DS-58b49876-c582-4f93-87b2-dee48956f84c,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-f8ea9679-1f66-46b3-a038-4c07bf3737d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-26d8986d-6686-4cb3-8b27-8032252eefc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-5cb30e3a-43eb-4d40-9087-c89494405067,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-5d13da76-06fa-445a-bf2c-45c77a60339c,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-edf9ee37-c4e0-4a13-84f1-9ce2ae61f61f,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-9954b59d-2377-4e04-aae1-4f12a774c11b,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-714970f8-9b2f-477e-b7f6-bb90ac27e935,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 6238
