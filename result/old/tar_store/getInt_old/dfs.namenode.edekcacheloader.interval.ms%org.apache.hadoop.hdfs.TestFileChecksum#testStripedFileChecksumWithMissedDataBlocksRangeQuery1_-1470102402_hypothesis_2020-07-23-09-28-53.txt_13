reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1333391248-172.17.0.21-1595497286671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42431,DS-e849e33d-e8c2-4017-9b24-d996255ff300,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-09092ccb-7acc-4512-aa1b-e460937deb27,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-316ed182-cee8-4f3d-8463-4e2ab30e53be,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-a5d5b0d2-3f95-4d0b-a12b-721d3a5ac633,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-64d33315-33aa-423c-9e95-8bde0955c085,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-52193656-c550-4636-9ed1-3658b0430086,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-bee180d3-684b-422a-86aa-deec3fcb7d16,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-1e047245-a08b-416b-bf86-a45709c8b39e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1333391248-172.17.0.21-1595497286671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42431,DS-e849e33d-e8c2-4017-9b24-d996255ff300,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-09092ccb-7acc-4512-aa1b-e460937deb27,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-316ed182-cee8-4f3d-8463-4e2ab30e53be,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-a5d5b0d2-3f95-4d0b-a12b-721d3a5ac633,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-64d33315-33aa-423c-9e95-8bde0955c085,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-52193656-c550-4636-9ed1-3658b0430086,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-bee180d3-684b-422a-86aa-deec3fcb7d16,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-1e047245-a08b-416b-bf86-a45709c8b39e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-881472872-172.17.0.21-1595498172972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44084,DS-148fa949-ce1a-42ad-a12a-ba9b4d62523d,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-a78b3f6c-9dfd-402b-813e-03f88578e5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-5a49b006-57fb-438b-bea9-d4ca4e71916c,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-6100772c-e15d-4cb8-a961-d8e83cf320c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-fd5a60d9-b093-43f4-9edb-048119285268,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-809f0bd0-191b-4a75-ba04-5b9686e5708e,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-6f966588-31de-48a5-a6f2-4ea9019037d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-3992e022-3469-4575-97e4-f5d099a0b0e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-881472872-172.17.0.21-1595498172972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44084,DS-148fa949-ce1a-42ad-a12a-ba9b4d62523d,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-a78b3f6c-9dfd-402b-813e-03f88578e5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-5a49b006-57fb-438b-bea9-d4ca4e71916c,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-6100772c-e15d-4cb8-a961-d8e83cf320c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-fd5a60d9-b093-43f4-9edb-048119285268,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-809f0bd0-191b-4a75-ba04-5b9686e5708e,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-6f966588-31de-48a5-a6f2-4ea9019037d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-3992e022-3469-4575-97e4-f5d099a0b0e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439105116-172.17.0.21-1595498546967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33047,DS-9cb92f2d-10b6-4063-b1e0-419853a7fe52,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-f53a7673-1975-46ba-89f7-965bd527ee76,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-5f7245e7-e771-4e4b-af7e-9ceb627549a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-2041f5b6-3549-4a12-a86c-998aff12a433,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-469e3dac-0a05-46fe-9101-fdcde6af66b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-0d281df8-5cdb-47d6-ac51-b7611d8f189d,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-bc9f364b-46cb-42a3-839a-fc3d3d7b9e14,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-5c4568df-a483-4e56-a946-ba7356633b71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439105116-172.17.0.21-1595498546967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33047,DS-9cb92f2d-10b6-4063-b1e0-419853a7fe52,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-f53a7673-1975-46ba-89f7-965bd527ee76,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-5f7245e7-e771-4e4b-af7e-9ceb627549a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-2041f5b6-3549-4a12-a86c-998aff12a433,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-469e3dac-0a05-46fe-9101-fdcde6af66b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-0d281df8-5cdb-47d6-ac51-b7611d8f189d,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-bc9f364b-46cb-42a3-839a-fc3d3d7b9e14,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-5c4568df-a483-4e56-a946-ba7356633b71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-828584933-172.17.0.21-1595498742497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37290,DS-3fbbccb3-0fea-4748-9cf3-a132ca52c55e,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-2bf6f797-b11c-4aab-8e39-d3369cb2107d,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-582f3e6f-dd43-4c49-8796-7517cf9cdd96,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-868df58a-971c-464d-87d4-769ec8785dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-bd5c7718-4541-473e-897f-09dbbbe3ae03,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-df5870d3-aa72-48ec-80fd-88daa152a4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-ba0fbd45-aebb-4a8b-b97d-639b80d8f941,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-4b8c444a-e76b-4bc6-957b-49734dd92d3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-828584933-172.17.0.21-1595498742497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37290,DS-3fbbccb3-0fea-4748-9cf3-a132ca52c55e,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-2bf6f797-b11c-4aab-8e39-d3369cb2107d,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-582f3e6f-dd43-4c49-8796-7517cf9cdd96,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-868df58a-971c-464d-87d4-769ec8785dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-bd5c7718-4541-473e-897f-09dbbbe3ae03,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-df5870d3-aa72-48ec-80fd-88daa152a4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-ba0fbd45-aebb-4a8b-b97d-639b80d8f941,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-4b8c444a-e76b-4bc6-957b-49734dd92d3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462014019-172.17.0.21-1595498853540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38007,DS-4a146468-519c-4406-89da-8f9d831d3742,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-0b54022c-6ccc-40cf-b10f-d0374ee81730,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-bde5ff7b-fc9c-4267-80d8-83af4c76e7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-18158589-6f83-4947-9974-2a473e665a05,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-7c165c9a-aac6-42b2-925a-5c89ea246844,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-a7c233a3-0f22-4805-bf55-e238e6677f80,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-1aa151c3-72d2-4b5b-a0a3-3b8a0aafb41c,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-b9fd5568-edbe-4046-af24-7daeda58ca44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462014019-172.17.0.21-1595498853540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38007,DS-4a146468-519c-4406-89da-8f9d831d3742,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-0b54022c-6ccc-40cf-b10f-d0374ee81730,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-bde5ff7b-fc9c-4267-80d8-83af4c76e7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-18158589-6f83-4947-9974-2a473e665a05,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-7c165c9a-aac6-42b2-925a-5c89ea246844,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-a7c233a3-0f22-4805-bf55-e238e6677f80,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-1aa151c3-72d2-4b5b-a0a3-3b8a0aafb41c,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-b9fd5568-edbe-4046-af24-7daeda58ca44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1236998901-172.17.0.21-1595499012306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38236,DS-39be0450-e458-4e95-9280-1ef8f7fc0c87,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-66187ae3-aa32-40ab-8611-3512830407da,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-0717269a-98cf-4187-ab26-7c25667e86d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-310869f0-89c2-473f-86be-cf0da328dfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-bacbee58-4f64-428d-82c2-00baadf8d101,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-0132819e-05a9-4222-8da1-bbd7444196ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-778e4006-833e-4854-8c4c-bf4a5aced630,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-a7a1adcf-06e5-4758-a9e7-3726c3f1d50f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1236998901-172.17.0.21-1595499012306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38236,DS-39be0450-e458-4e95-9280-1ef8f7fc0c87,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-66187ae3-aa32-40ab-8611-3512830407da,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-0717269a-98cf-4187-ab26-7c25667e86d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-310869f0-89c2-473f-86be-cf0da328dfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-bacbee58-4f64-428d-82c2-00baadf8d101,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-0132819e-05a9-4222-8da1-bbd7444196ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-778e4006-833e-4854-8c4c-bf4a5aced630,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-a7a1adcf-06e5-4758-a9e7-3726c3f1d50f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278671757-172.17.0.21-1595499097148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38469,DS-cec6cb09-bab0-4fa6-8cd0-b8c9a5f9f460,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-9520618e-8e5e-412d-97a5-cae73357ca5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-941e4b93-efba-4c92-bcf7-8f423f8c24d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-ac5e2101-09af-4307-aeac-a8bf49a48276,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-944edcf0-cf9f-472c-93d5-f6b14b51c2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-6fe33175-9cf7-432f-8cc0-9aa80c736a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-21fa3d73-1a3f-42aa-b195-161a6c6b80d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45005,DS-6bf43bb3-7b1b-4a47-9933-1d913acd76c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278671757-172.17.0.21-1595499097148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38469,DS-cec6cb09-bab0-4fa6-8cd0-b8c9a5f9f460,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-9520618e-8e5e-412d-97a5-cae73357ca5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-941e4b93-efba-4c92-bcf7-8f423f8c24d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-ac5e2101-09af-4307-aeac-a8bf49a48276,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-944edcf0-cf9f-472c-93d5-f6b14b51c2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-6fe33175-9cf7-432f-8cc0-9aa80c736a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-21fa3d73-1a3f-42aa-b195-161a6c6b80d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45005,DS-6bf43bb3-7b1b-4a47-9933-1d913acd76c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851595949-172.17.0.21-1595499178100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46808,DS-e0abede6-b4e2-4a0d-9bee-f6acdc062c64,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-bf652143-1d57-4c3a-b76b-5eda37abf6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-c8e40963-b2fb-4641-b331-6124bd84e014,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-34992352-a4bc-4716-8a05-aaaaa81f5394,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-40be4658-f2d3-4e03-9189-c0fd3f8656cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-953bdf76-1b47-4221-b109-3f443bc55f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-f8524f6e-0dad-4e4c-9c63-4d4440eaf559,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-3596e2e6-b479-4f37-af09-ad303829c930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851595949-172.17.0.21-1595499178100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46808,DS-e0abede6-b4e2-4a0d-9bee-f6acdc062c64,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-bf652143-1d57-4c3a-b76b-5eda37abf6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-c8e40963-b2fb-4641-b331-6124bd84e014,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-34992352-a4bc-4716-8a05-aaaaa81f5394,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-40be4658-f2d3-4e03-9189-c0fd3f8656cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-953bdf76-1b47-4221-b109-3f443bc55f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-f8524f6e-0dad-4e4c-9c63-4d4440eaf559,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-3596e2e6-b479-4f37-af09-ad303829c930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752072214-172.17.0.21-1595500169150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44940,DS-35a5263f-6b34-4790-8110-019e08dc5473,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-01a035d2-d240-462c-af73-944abcb407aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-292f5d22-c396-42ca-90b1-3f9577404b18,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-2e7709f0-8dbd-4e5a-92a9-13d17899b4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-8cc7638c-6731-4e17-9af5-e14f09bd51f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-de17106c-fd92-4def-bbb1-1b5135f7907b,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-4a0c99ec-18b9-45b0-b95a-772546a69c44,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-716d684d-32c5-4965-8c63-d6b0945d0d8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752072214-172.17.0.21-1595500169150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44940,DS-35a5263f-6b34-4790-8110-019e08dc5473,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-01a035d2-d240-462c-af73-944abcb407aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-292f5d22-c396-42ca-90b1-3f9577404b18,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-2e7709f0-8dbd-4e5a-92a9-13d17899b4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-8cc7638c-6731-4e17-9af5-e14f09bd51f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-de17106c-fd92-4def-bbb1-1b5135f7907b,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-4a0c99ec-18b9-45b0-b95a-772546a69c44,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-716d684d-32c5-4965-8c63-d6b0945d0d8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-254284149-172.17.0.21-1595500920483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39569,DS-505f3b4e-d143-4104-8b87-7160167c963d,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-f6d7593c-af37-4daf-a86a-0c5b71b784ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-1d909a0b-f910-4a93-a130-6552a0c5361d,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-7fb3b831-c5ec-4cbf-acbe-c0e7d6e854a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-2f86a736-d093-400f-b864-eab841c18337,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-cd4d50ac-830d-49d2-b46c-13817b291487,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-4e9e3700-83c3-4eb1-ba50-ad6542571933,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-44ed8a86-4525-4037-9c91-c6803c342c0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-254284149-172.17.0.21-1595500920483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39569,DS-505f3b4e-d143-4104-8b87-7160167c963d,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-f6d7593c-af37-4daf-a86a-0c5b71b784ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-1d909a0b-f910-4a93-a130-6552a0c5361d,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-7fb3b831-c5ec-4cbf-acbe-c0e7d6e854a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-2f86a736-d093-400f-b864-eab841c18337,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-cd4d50ac-830d-49d2-b46c-13817b291487,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-4e9e3700-83c3-4eb1-ba50-ad6542571933,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-44ed8a86-4525-4037-9c91-c6803c342c0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980867495-172.17.0.21-1595501256410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40077,DS-0dd321d0-02da-4d35-bbe8-2678b7a39b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-42928739-48df-4680-8988-242a8bf9107a,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-2df07561-b58e-47a9-9b81-87099d3cffad,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-6b9aeba3-bb86-414c-94d1-0ef9de407a91,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-21c1f9a1-1f98-436b-86b9-42d6730c02cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-e2285fb9-9eba-4e64-9def-c823a4679be7,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-d9909223-95fc-42ea-9090-6df0a1167304,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-87281545-0029-4ab3-80b9-201f5a3e9264,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980867495-172.17.0.21-1595501256410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40077,DS-0dd321d0-02da-4d35-bbe8-2678b7a39b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-42928739-48df-4680-8988-242a8bf9107a,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-2df07561-b58e-47a9-9b81-87099d3cffad,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-6b9aeba3-bb86-414c-94d1-0ef9de407a91,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-21c1f9a1-1f98-436b-86b9-42d6730c02cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-e2285fb9-9eba-4e64-9def-c823a4679be7,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-d9909223-95fc-42ea-9090-6df0a1167304,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-87281545-0029-4ab3-80b9-201f5a3e9264,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5229
