reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590429345-172.17.0.17-1595592778533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36060,DS-41326961-e9cd-4791-a375-cf280c520ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-03a3d863-c4b8-422e-8456-8c89e4544a84,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-fc2efcc8-da0c-427b-a535-ec1943990aae,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-875a8ba0-5821-4249-9b32-e51d0d25265e,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-50410da1-76c2-46ee-b682-ee89e3e73acd,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-b0e0f73c-211b-4f8b-9839-7091e563b379,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-14cd7301-c8df-4838-b10c-80b28dcc20ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-7b173092-173e-4cd6-a739-6cdae07c6656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590429345-172.17.0.17-1595592778533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36060,DS-41326961-e9cd-4791-a375-cf280c520ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-03a3d863-c4b8-422e-8456-8c89e4544a84,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-fc2efcc8-da0c-427b-a535-ec1943990aae,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-875a8ba0-5821-4249-9b32-e51d0d25265e,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-50410da1-76c2-46ee-b682-ee89e3e73acd,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-b0e0f73c-211b-4f8b-9839-7091e563b379,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-14cd7301-c8df-4838-b10c-80b28dcc20ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-7b173092-173e-4cd6-a739-6cdae07c6656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500234459-172.17.0.17-1595592923336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44274,DS-5ea76887-73f6-4a91-beca-2ceecee8a0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-48221982-d7a4-4d79-b745-4385fe4599cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-54c012a5-5d30-4153-909e-66b3d133d0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-86c0a838-597c-4fdb-9409-2ca1bf7c8db1,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-bea49a8a-efb7-4e3c-af5b-fddbc2be737a,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-070f6dfe-4527-495d-91d9-ad1632a3a829,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-924b82de-1d5f-43bf-aae8-02ec08ecba21,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-f7adcc41-679c-4694-81b7-cf7b66e31910,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500234459-172.17.0.17-1595592923336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44274,DS-5ea76887-73f6-4a91-beca-2ceecee8a0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-48221982-d7a4-4d79-b745-4385fe4599cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-54c012a5-5d30-4153-909e-66b3d133d0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-86c0a838-597c-4fdb-9409-2ca1bf7c8db1,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-bea49a8a-efb7-4e3c-af5b-fddbc2be737a,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-070f6dfe-4527-495d-91d9-ad1632a3a829,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-924b82de-1d5f-43bf-aae8-02ec08ecba21,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-f7adcc41-679c-4694-81b7-cf7b66e31910,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486978948-172.17.0.17-1595593733477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37411,DS-d1a08a16-9ab4-4655-8531-51f1a2c5d2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-dea75ba0-9acd-454e-a6af-99adb0ab1eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-0253ca2f-4614-4e71-8605-3fd52ee9f59c,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-0a3386d1-7890-4f01-9e9b-9ff9e3274ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-09cd0450-8745-4f7d-bd7c-a441544b7e05,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-1364342d-c0f0-4a34-8100-bc4bea94c94f,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-8953ff9b-a6b3-4504-b443-1ffb4c968739,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-4ff8024b-d980-41b1-9f53-d17008341fc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486978948-172.17.0.17-1595593733477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37411,DS-d1a08a16-9ab4-4655-8531-51f1a2c5d2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-dea75ba0-9acd-454e-a6af-99adb0ab1eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-0253ca2f-4614-4e71-8605-3fd52ee9f59c,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-0a3386d1-7890-4f01-9e9b-9ff9e3274ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-09cd0450-8745-4f7d-bd7c-a441544b7e05,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-1364342d-c0f0-4a34-8100-bc4bea94c94f,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-8953ff9b-a6b3-4504-b443-1ffb4c968739,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-4ff8024b-d980-41b1-9f53-d17008341fc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1979109963-172.17.0.17-1595593765104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45014,DS-79923998-a259-4ad8-9e31-f803672983bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-3f75f670-a8be-4cac-8b62-7cf0c7532fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-7c067bc1-e73e-43fd-8f6a-b38a85aefd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-5d73c711-9a8f-4bd1-be8c-4931d5259bec,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-0e57a7c0-3e60-43de-b584-1448a2e83f63,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-1054d699-79df-45ed-a281-9c44c2de9255,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-1983d1cb-9a07-4a30-bd02-5703eac4936c,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-6fa26ecc-1d6d-4de7-b98b-e94a5bcc2277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1979109963-172.17.0.17-1595593765104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45014,DS-79923998-a259-4ad8-9e31-f803672983bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-3f75f670-a8be-4cac-8b62-7cf0c7532fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-7c067bc1-e73e-43fd-8f6a-b38a85aefd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-5d73c711-9a8f-4bd1-be8c-4931d5259bec,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-0e57a7c0-3e60-43de-b584-1448a2e83f63,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-1054d699-79df-45ed-a281-9c44c2de9255,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-1983d1cb-9a07-4a30-bd02-5703eac4936c,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-6fa26ecc-1d6d-4de7-b98b-e94a5bcc2277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933153537-172.17.0.17-1595593862546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44608,DS-ea572a84-701d-40e0-93e6-3a4d4bdaaf44,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-e112f598-89d9-4d14-a785-d17c09e5aefe,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-5e52353f-81fc-4948-b8d7-c3597cada7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-ab9f896a-a432-4821-8929-dfbb7f81f714,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-bcb2ba7f-a559-4fd4-9f0b-388d5ba5f65f,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-877d1c44-1210-49b5-a31e-3e7be39e83d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-8d4d173b-ba0d-4792-90f6-505b1cf7f55d,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-ff63aa48-1c46-4cfb-8225-7a65fafb65b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933153537-172.17.0.17-1595593862546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44608,DS-ea572a84-701d-40e0-93e6-3a4d4bdaaf44,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-e112f598-89d9-4d14-a785-d17c09e5aefe,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-5e52353f-81fc-4948-b8d7-c3597cada7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-ab9f896a-a432-4821-8929-dfbb7f81f714,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-bcb2ba7f-a559-4fd4-9f0b-388d5ba5f65f,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-877d1c44-1210-49b5-a31e-3e7be39e83d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-8d4d173b-ba0d-4792-90f6-505b1cf7f55d,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-ff63aa48-1c46-4cfb-8225-7a65fafb65b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793004702-172.17.0.17-1595594201403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39079,DS-9731e1ab-ee40-4a1c-ae76-5d1b88d83e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-1e3b9028-e889-4533-9e76-323760b24513,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-c2713d25-2737-4d2f-b5e7-7ace93bfb65e,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-67b13045-7565-4e9f-9101-6693edd7f658,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-f96d377b-4bf3-49e2-98e4-1de056b89dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-704fd3fa-d9ec-42f9-87cb-4eb1bd2ce74b,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-c79ab8de-08c7-482c-8ed2-5cb0fa84ed99,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-c2e92ba9-d7c8-495c-bdb5-861e1234df52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793004702-172.17.0.17-1595594201403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39079,DS-9731e1ab-ee40-4a1c-ae76-5d1b88d83e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-1e3b9028-e889-4533-9e76-323760b24513,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-c2713d25-2737-4d2f-b5e7-7ace93bfb65e,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-67b13045-7565-4e9f-9101-6693edd7f658,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-f96d377b-4bf3-49e2-98e4-1de056b89dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-704fd3fa-d9ec-42f9-87cb-4eb1bd2ce74b,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-c79ab8de-08c7-482c-8ed2-5cb0fa84ed99,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-c2e92ba9-d7c8-495c-bdb5-861e1234df52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085707416-172.17.0.17-1595594545224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41990,DS-12cb4c14-c805-447b-8ba3-d0e74c98a95f,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-a323d4da-e14f-41dc-9af8-40d44a958fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-9f9f26c5-c10e-4426-a589-1e1c5352ad5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-86dca7d1-1a3b-4bd5-bc1d-260db6d695d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-25c1f43a-5663-48fb-ae69-671943b20eec,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-80fca94d-c933-4309-a0a9-66f6c5ec8d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-e6f207ef-cb62-4086-8094-5e88b223648a,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-3146583b-96bf-4c76-a913-37c4601d8d27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085707416-172.17.0.17-1595594545224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41990,DS-12cb4c14-c805-447b-8ba3-d0e74c98a95f,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-a323d4da-e14f-41dc-9af8-40d44a958fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-9f9f26c5-c10e-4426-a589-1e1c5352ad5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-86dca7d1-1a3b-4bd5-bc1d-260db6d695d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-25c1f43a-5663-48fb-ae69-671943b20eec,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-80fca94d-c933-4309-a0a9-66f6c5ec8d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-e6f207ef-cb62-4086-8094-5e88b223648a,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-3146583b-96bf-4c76-a913-37c4601d8d27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1807435111-172.17.0.17-1595594877736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44446,DS-82cdede8-4d41-4bc4-8155-07d388719c50,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-3ab3c719-0080-4420-9e15-1fee96c9ec71,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-08ed8b20-09f2-492c-a9fa-804943d1f49d,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-32d9b4b6-f13b-4096-8232-501f9d64fcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-c9a3ec2c-587a-4659-8747-57a6033051a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-37e69412-4975-4455-a5e1-643e16ddc725,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-4be152a6-eb34-4d1c-ad47-6255145709ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-1aa7ec29-b810-4718-95b4-37599ffc83da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1807435111-172.17.0.17-1595594877736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44446,DS-82cdede8-4d41-4bc4-8155-07d388719c50,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-3ab3c719-0080-4420-9e15-1fee96c9ec71,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-08ed8b20-09f2-492c-a9fa-804943d1f49d,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-32d9b4b6-f13b-4096-8232-501f9d64fcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-c9a3ec2c-587a-4659-8747-57a6033051a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-37e69412-4975-4455-a5e1-643e16ddc725,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-4be152a6-eb34-4d1c-ad47-6255145709ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-1aa7ec29-b810-4718-95b4-37599ffc83da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1114296785-172.17.0.17-1595594987075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39500,DS-9a6ab6ec-9bce-462c-9f32-ec6a966be7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-421cfb90-41da-497f-985b-64b85d556e48,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-3eef3368-6314-45ca-8baf-78c01bdef6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-569a80d1-4e65-4e07-8529-47922a78c8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-2b3b25c0-3220-45d0-b7cc-d8b7dbff89d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-406de750-8930-47e0-a028-1b5f8bf7d00d,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-2f1b43ad-5e78-4000-b2a5-582ef7fe47cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-fcfbe168-bffe-4105-9f14-021d13dce77a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1114296785-172.17.0.17-1595594987075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39500,DS-9a6ab6ec-9bce-462c-9f32-ec6a966be7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-421cfb90-41da-497f-985b-64b85d556e48,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-3eef3368-6314-45ca-8baf-78c01bdef6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-569a80d1-4e65-4e07-8529-47922a78c8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-2b3b25c0-3220-45d0-b7cc-d8b7dbff89d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-406de750-8930-47e0-a028-1b5f8bf7d00d,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-2f1b43ad-5e78-4000-b2a5-582ef7fe47cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-fcfbe168-bffe-4105-9f14-021d13dce77a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310487786-172.17.0.17-1595595011875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39260,DS-4de20d21-8674-461f-87e3-b2000d23dbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-aa3b2a0e-3761-47c1-905a-aa76cf1b8d59,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-889fb774-e83d-4a76-9693-12562e5135dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-7b6f3cf6-fd3a-4903-942a-316b21108e43,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-f0d7ef53-6c14-4cd7-8746-480b64069364,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-3084a479-0fc5-4d37-8460-5399f9f54fda,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-e18da412-f69b-417a-b26f-05b6a8d72fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-b8112224-c357-4d39-9cd2-bb50c62abb9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310487786-172.17.0.17-1595595011875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39260,DS-4de20d21-8674-461f-87e3-b2000d23dbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-aa3b2a0e-3761-47c1-905a-aa76cf1b8d59,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-889fb774-e83d-4a76-9693-12562e5135dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-7b6f3cf6-fd3a-4903-942a-316b21108e43,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-f0d7ef53-6c14-4cd7-8746-480b64069364,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-3084a479-0fc5-4d37-8460-5399f9f54fda,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-e18da412-f69b-417a-b26f-05b6a8d72fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-b8112224-c357-4d39-9cd2-bb50c62abb9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351037468-172.17.0.17-1595595492821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41612,DS-ce3be037-bf8b-4fb5-980b-03dd044a7be5,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-f144def5-0a57-4b01-bcdc-74033d818ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-f5f14316-e6e2-4719-9289-3ce8e5e68f98,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-c500081f-df58-47cb-9f64-295f0336168e,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-d9e86c06-9e3f-4346-9c68-07f1e1c1f4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-51d8edaa-c0ba-4ca1-87ec-8949ebf0389d,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-626f05f6-dbfd-45dd-80ee-5eb914017236,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-1aec95cd-000b-4d59-a4b0-e1f4f9c92ca5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351037468-172.17.0.17-1595595492821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41612,DS-ce3be037-bf8b-4fb5-980b-03dd044a7be5,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-f144def5-0a57-4b01-bcdc-74033d818ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-f5f14316-e6e2-4719-9289-3ce8e5e68f98,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-c500081f-df58-47cb-9f64-295f0336168e,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-d9e86c06-9e3f-4346-9c68-07f1e1c1f4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-51d8edaa-c0ba-4ca1-87ec-8949ebf0389d,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-626f05f6-dbfd-45dd-80ee-5eb914017236,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-1aec95cd-000b-4d59-a4b0-e1f4f9c92ca5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502257624-172.17.0.17-1595595843531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37542,DS-453af4ab-c7f8-4c57-be0c-b28d1100bc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-4bb8e813-f0c5-4db2-8d21-e5a1a386ac2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-3eea5295-edc5-4d09-98db-ada603841f78,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-8393d19f-4da1-48e9-a960-2dc34885d4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-c232dab9-5491-4e43-b55d-665ff8ee89a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-3c32f01d-798f-4b7e-9388-4f2dfa1a616f,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-6fe67a74-d703-40d7-a2ba-536c3c5bfa64,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-1a6ac7a3-d54f-463d-9793-cf16879d7b5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502257624-172.17.0.17-1595595843531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37542,DS-453af4ab-c7f8-4c57-be0c-b28d1100bc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-4bb8e813-f0c5-4db2-8d21-e5a1a386ac2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-3eea5295-edc5-4d09-98db-ada603841f78,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-8393d19f-4da1-48e9-a960-2dc34885d4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-c232dab9-5491-4e43-b55d-665ff8ee89a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-3c32f01d-798f-4b7e-9388-4f2dfa1a616f,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-6fe67a74-d703-40d7-a2ba-536c3c5bfa64,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-1a6ac7a3-d54f-463d-9793-cf16879d7b5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305231329-172.17.0.17-1595596911508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44240,DS-2fa44f40-dfc9-4e27-8bd2-22c8d3dfde84,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-abfb4772-9b34-41bf-9cd1-1517b94543bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-1377d34d-c8ba-47e3-b223-46a2c9d28a53,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-dd9beeb0-c5c6-4b25-a95d-cd031638d693,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-34dd10ba-d98b-4e95-9c2f-e553dc9de0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-27f8ce04-4d09-4ec7-b219-7c66e233049f,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-c8310e70-e10c-4fa9-95ff-65a99e90e4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-8e867325-e1c7-4f19-8990-7694f6eccb9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305231329-172.17.0.17-1595596911508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44240,DS-2fa44f40-dfc9-4e27-8bd2-22c8d3dfde84,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-abfb4772-9b34-41bf-9cd1-1517b94543bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-1377d34d-c8ba-47e3-b223-46a2c9d28a53,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-dd9beeb0-c5c6-4b25-a95d-cd031638d693,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-34dd10ba-d98b-4e95-9c2f-e553dc9de0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-27f8ce04-4d09-4ec7-b219-7c66e233049f,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-c8310e70-e10c-4fa9-95ff-65a99e90e4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-8e867325-e1c7-4f19-8990-7694f6eccb9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5047
