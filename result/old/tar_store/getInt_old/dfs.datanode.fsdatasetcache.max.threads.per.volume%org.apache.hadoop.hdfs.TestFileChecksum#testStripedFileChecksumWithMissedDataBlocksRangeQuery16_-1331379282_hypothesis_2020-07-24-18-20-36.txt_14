reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-776824938-172.17.0.2-1595615682216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43436,DS-a8b6bd15-f0ed-4d4c-80c0-d1ffc2d37097,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-8ccba31f-aee8-46bd-b9dc-e25a91fcbabb,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-57e8fc3a-f308-489b-9ebe-c1e73183f2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-f3ea3f8e-9971-48bb-a08f-60f6e58b2cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-8813ac0b-c93c-42c4-b5c7-85533ae1765b,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-3415c862-13b4-49c4-8332-1a9e0de2bfb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-5adba3d2-9091-4040-86e3-3a9b362bd405,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-79234773-ca16-4494-abef-499af582d2c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-776824938-172.17.0.2-1595615682216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43436,DS-a8b6bd15-f0ed-4d4c-80c0-d1ffc2d37097,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-8ccba31f-aee8-46bd-b9dc-e25a91fcbabb,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-57e8fc3a-f308-489b-9ebe-c1e73183f2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-f3ea3f8e-9971-48bb-a08f-60f6e58b2cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-8813ac0b-c93c-42c4-b5c7-85533ae1765b,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-3415c862-13b4-49c4-8332-1a9e0de2bfb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-5adba3d2-9091-4040-86e3-3a9b362bd405,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-79234773-ca16-4494-abef-499af582d2c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-998294053-172.17.0.2-1595616121798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35653,DS-1b7f8446-fdec-42c3-b792-76f43c90e4df,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-fd0fc0a5-5567-44ad-9b19-1384bcb82248,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-34f6effd-cfcf-446e-8c1a-a9240fcf40ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-2579f755-23e3-49b5-9a6c-363c5bbb42d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-d02804d3-48da-4998-8c48-2b0bcb7758a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-c3c404cb-1cfa-4cb4-aefd-3e650abfbee5,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-693b8ae7-7572-4562-a69a-498ac0856dab,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-57b52796-ccd9-4bc9-a950-7ad2a3e2798b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-998294053-172.17.0.2-1595616121798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35653,DS-1b7f8446-fdec-42c3-b792-76f43c90e4df,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-fd0fc0a5-5567-44ad-9b19-1384bcb82248,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-34f6effd-cfcf-446e-8c1a-a9240fcf40ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-2579f755-23e3-49b5-9a6c-363c5bbb42d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-d02804d3-48da-4998-8c48-2b0bcb7758a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-c3c404cb-1cfa-4cb4-aefd-3e650abfbee5,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-693b8ae7-7572-4562-a69a-498ac0856dab,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-57b52796-ccd9-4bc9-a950-7ad2a3e2798b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1181527363-172.17.0.2-1595616394963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33981,DS-5e3685a1-db8a-4827-ac2d-fbb51ba4d704,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-c1c38aed-32cb-4154-a332-84088c2dc528,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-e4162bf8-fd16-4373-94fb-8b7ece09a50a,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-d17d3bfd-ca1b-4309-8946-7009272e2a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-69b6a5bf-8529-49c9-95a9-85cb96902710,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-667e7c54-2337-4241-a8fe-1b618f36b3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-b901de61-aa19-40d1-9404-42a848b074cf,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-dedcaf7d-5e06-4e9e-a6d3-e84c119aa7c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1181527363-172.17.0.2-1595616394963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33981,DS-5e3685a1-db8a-4827-ac2d-fbb51ba4d704,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-c1c38aed-32cb-4154-a332-84088c2dc528,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-e4162bf8-fd16-4373-94fb-8b7ece09a50a,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-d17d3bfd-ca1b-4309-8946-7009272e2a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-69b6a5bf-8529-49c9-95a9-85cb96902710,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-667e7c54-2337-4241-a8fe-1b618f36b3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-b901de61-aa19-40d1-9404-42a848b074cf,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-dedcaf7d-5e06-4e9e-a6d3-e84c119aa7c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2088700733-172.17.0.2-1595616614981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40021,DS-59206f43-34fc-4ff5-b5a0-ef98179c0d09,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-2bf9f596-ae81-443b-abe1-8532a782d050,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-f029baa5-5f4e-48f5-921a-b2f1dc22d8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-7be19a80-3174-4d7c-9486-9a6a353e9e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-b1fe47af-b386-408a-b7a1-e6115e8527c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-a08dbbab-131f-444e-966a-2f61aecee79f,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-5b9c25b0-cb69-4536-b878-fbe993950d08,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-8a8104f7-8bb0-4297-a99d-4642e4ba4cf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2088700733-172.17.0.2-1595616614981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40021,DS-59206f43-34fc-4ff5-b5a0-ef98179c0d09,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-2bf9f596-ae81-443b-abe1-8532a782d050,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-f029baa5-5f4e-48f5-921a-b2f1dc22d8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-7be19a80-3174-4d7c-9486-9a6a353e9e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-b1fe47af-b386-408a-b7a1-e6115e8527c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-a08dbbab-131f-444e-966a-2f61aecee79f,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-5b9c25b0-cb69-4536-b878-fbe993950d08,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-8a8104f7-8bb0-4297-a99d-4642e4ba4cf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1743607662-172.17.0.2-1595616743371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33483,DS-53455f85-af03-4e1f-888e-6699ca9cd2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-39c6b820-76da-43ac-a315-9288b9941807,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-140cfa86-b48d-418f-8fe9-4ee776fbed6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-115860fd-0f82-46d8-8f83-f37e105bda76,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-92a9bed8-27e6-4c73-b72c-e53cbf046691,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-30276681-3802-48d7-8b67-d73872a38124,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-76e36631-2afc-4778-ae60-c57d59edc211,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-e4e5d828-57fd-4250-b3ba-68449e278d93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1743607662-172.17.0.2-1595616743371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33483,DS-53455f85-af03-4e1f-888e-6699ca9cd2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-39c6b820-76da-43ac-a315-9288b9941807,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-140cfa86-b48d-418f-8fe9-4ee776fbed6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-115860fd-0f82-46d8-8f83-f37e105bda76,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-92a9bed8-27e6-4c73-b72c-e53cbf046691,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-30276681-3802-48d7-8b67-d73872a38124,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-76e36631-2afc-4778-ae60-c57d59edc211,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-e4e5d828-57fd-4250-b3ba-68449e278d93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-32684280-172.17.0.2-1595617148735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40190,DS-b69ceb5f-f4a6-4d2e-8d42-d571c33318a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-083b0342-d822-44cb-9bac-309ba66e89e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-bd026bc2-12d6-43e7-851a-991733b9517a,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-90f3f144-0bac-4f00-ba5a-1578def58c39,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-26a54d75-1d59-414a-9758-4ec4857e4e19,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-92409b32-f396-4814-ab16-9a73c966c699,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-d6d717b7-ccb1-4fdd-be06-c91ad03e2367,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-e84456f1-5ef7-4c19-9a22-4ee58c2d1ec7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-32684280-172.17.0.2-1595617148735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40190,DS-b69ceb5f-f4a6-4d2e-8d42-d571c33318a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-083b0342-d822-44cb-9bac-309ba66e89e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-bd026bc2-12d6-43e7-851a-991733b9517a,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-90f3f144-0bac-4f00-ba5a-1578def58c39,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-26a54d75-1d59-414a-9758-4ec4857e4e19,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-92409b32-f396-4814-ab16-9a73c966c699,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-d6d717b7-ccb1-4fdd-be06-c91ad03e2367,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-e84456f1-5ef7-4c19-9a22-4ee58c2d1ec7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2057692953-172.17.0.2-1595617927905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35431,DS-b7fbe94a-de87-4a6c-a127-4593fd703fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-d5f5bb27-206f-47ee-92e3-c32479d6248a,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-f7b62244-f29e-4a6d-9a23-15c5f4c2a553,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-19a21ef4-6d02-4636-b7f7-68dbcfd00008,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-bc98779d-245e-464a-9b24-3362f4ac67f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-1304adcb-cf5b-4ce2-82d5-2aa108bc870d,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-fabc8357-e89e-4c86-93b8-c624d3f7f130,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-60d5c6cd-2da2-4f89-9823-871390a9be9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2057692953-172.17.0.2-1595617927905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35431,DS-b7fbe94a-de87-4a6c-a127-4593fd703fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-d5f5bb27-206f-47ee-92e3-c32479d6248a,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-f7b62244-f29e-4a6d-9a23-15c5f4c2a553,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-19a21ef4-6d02-4636-b7f7-68dbcfd00008,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-bc98779d-245e-464a-9b24-3362f4ac67f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-1304adcb-cf5b-4ce2-82d5-2aa108bc870d,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-fabc8357-e89e-4c86-93b8-c624d3f7f130,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-60d5c6cd-2da2-4f89-9823-871390a9be9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1065719839-172.17.0.2-1595618102476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41806,DS-a5dd6220-f4df-45db-8e8e-e00eeea661ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-02380bf6-b9c0-4041-8e7a-8b6d02f4bf70,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-52a7b88d-5219-4044-a3f3-5a1e2a896a64,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-4672b841-a862-41c7-84e5-2a3393a71bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-07544810-ef47-449f-96b8-502a54dd1883,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-81f15461-86c2-49d5-9263-4103bc2d6458,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-719c86f4-dbb9-4fab-94f4-046032aca12a,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-fc290af9-634d-4d35-b1a0-4382cab8e70a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1065719839-172.17.0.2-1595618102476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41806,DS-a5dd6220-f4df-45db-8e8e-e00eeea661ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-02380bf6-b9c0-4041-8e7a-8b6d02f4bf70,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-52a7b88d-5219-4044-a3f3-5a1e2a896a64,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-4672b841-a862-41c7-84e5-2a3393a71bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-07544810-ef47-449f-96b8-502a54dd1883,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-81f15461-86c2-49d5-9263-4103bc2d6458,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-719c86f4-dbb9-4fab-94f4-046032aca12a,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-fc290af9-634d-4d35-b1a0-4382cab8e70a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-413637585-172.17.0.2-1595618340946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37444,DS-102cbb2c-1f9c-481e-bcbd-acd386b0fde2,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-47e75d5e-acd9-4236-887e-897f248ca022,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-5bb6b66a-25dc-4006-bb97-8d09ac4f4961,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-a612d90b-39c3-40f5-b5d8-781ffb64713e,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-5758e7cf-1baf-425f-b935-2e00e364d1de,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-b12c6e23-d9e2-4f10-9945-227382b1ae26,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-4b2f4dcd-af99-4762-b839-ea813018b2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-01f7eefb-566a-4ea0-8773-2dfa10708525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-413637585-172.17.0.2-1595618340946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37444,DS-102cbb2c-1f9c-481e-bcbd-acd386b0fde2,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-47e75d5e-acd9-4236-887e-897f248ca022,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-5bb6b66a-25dc-4006-bb97-8d09ac4f4961,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-a612d90b-39c3-40f5-b5d8-781ffb64713e,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-5758e7cf-1baf-425f-b935-2e00e364d1de,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-b12c6e23-d9e2-4f10-9945-227382b1ae26,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-4b2f4dcd-af99-4762-b839-ea813018b2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-01f7eefb-566a-4ea0-8773-2dfa10708525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464225708-172.17.0.2-1595618986537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39449,DS-ebace469-643b-44fc-9399-0ed106b9ce83,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-b1739610-4ec4-4a3a-bf11-88bc19cca0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-78f3aeda-c495-4ca6-8fde-261f416d11e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-04355b0b-137b-4a08-bed5-b58a1d6d938d,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-9954f01f-19cd-47fa-b398-a54697c9f0df,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-303ea079-816e-478d-891a-03a8860db552,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-8a884a71-e5ea-4083-ba63-a59c7ae19ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-e8a7471a-988a-4190-8bd8-6790c9becb29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464225708-172.17.0.2-1595618986537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39449,DS-ebace469-643b-44fc-9399-0ed106b9ce83,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-b1739610-4ec4-4a3a-bf11-88bc19cca0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-78f3aeda-c495-4ca6-8fde-261f416d11e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-04355b0b-137b-4a08-bed5-b58a1d6d938d,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-9954f01f-19cd-47fa-b398-a54697c9f0df,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-303ea079-816e-478d-891a-03a8860db552,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-8a884a71-e5ea-4083-ba63-a59c7ae19ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-e8a7471a-988a-4190-8bd8-6790c9becb29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544672942-172.17.0.2-1595619461205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36738,DS-50645d10-6303-4d8a-a8a8-3246d29a1edb,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-44dea786-ec3d-4d5c-b5ee-01fded6be72a,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-50981d5f-aabc-4f13-a970-e4417047d899,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-d557365f-91e6-4d2e-84fd-5286d79e86fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-fdaae728-6ba2-4f36-adf9-2409a67d7d83,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-1bb3e5b0-4816-4c82-9b6b-a9b45810d512,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-33a9f680-259d-474e-ac76-8666b7bbfd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-e5924635-8933-45e0-8fe6-a38504ef1c1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544672942-172.17.0.2-1595619461205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36738,DS-50645d10-6303-4d8a-a8a8-3246d29a1edb,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-44dea786-ec3d-4d5c-b5ee-01fded6be72a,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-50981d5f-aabc-4f13-a970-e4417047d899,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-d557365f-91e6-4d2e-84fd-5286d79e86fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-fdaae728-6ba2-4f36-adf9-2409a67d7d83,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-1bb3e5b0-4816-4c82-9b6b-a9b45810d512,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-33a9f680-259d-474e-ac76-8666b7bbfd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-e5924635-8933-45e0-8fe6-a38504ef1c1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2095631778-172.17.0.2-1595619563628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40891,DS-b7c684c0-0052-4c2d-8282-9d56a9ea198e,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-f9178ef9-20df-4a68-889a-702f2370660d,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-2a45af50-3e27-4c6b-b485-9fe13765cb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-8b4e5179-6cfd-4d25-869c-4c28f622af52,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-78248060-7609-481b-99bc-c886c3d53075,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-7cf60977-025c-4b76-b06d-20c2b03766c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-50cc7eb9-c587-4186-85ab-6d740a63ee3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-dc4f41b3-533e-43db-8254-bea714f06243,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2095631778-172.17.0.2-1595619563628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40891,DS-b7c684c0-0052-4c2d-8282-9d56a9ea198e,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-f9178ef9-20df-4a68-889a-702f2370660d,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-2a45af50-3e27-4c6b-b485-9fe13765cb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-8b4e5179-6cfd-4d25-869c-4c28f622af52,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-78248060-7609-481b-99bc-c886c3d53075,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-7cf60977-025c-4b76-b06d-20c2b03766c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-50cc7eb9-c587-4186-85ab-6d740a63ee3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-dc4f41b3-533e-43db-8254-bea714f06243,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5100
