reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1970179402-172.17.0.6-1595512673749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38183,DS-4fe4913c-bac9-4db2-a062-8696ccaf7fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-17eb91ab-1b72-42a6-b468-bc59621cecca,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-2d7d4097-c5ba-4126-8072-d1560c6f1798,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-87667d83-bdb1-4281-ad5d-77be12239441,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-f39149c1-760b-45dc-a653-c884e8c01c12,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-18627a6f-be56-43a6-ae33-8c8df6ed5748,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-91bfee3a-89db-471f-a407-99e302c76d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-309220ef-e141-4ee1-8f4e-6b8fcb03b6e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1970179402-172.17.0.6-1595512673749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38183,DS-4fe4913c-bac9-4db2-a062-8696ccaf7fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-17eb91ab-1b72-42a6-b468-bc59621cecca,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-2d7d4097-c5ba-4126-8072-d1560c6f1798,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-87667d83-bdb1-4281-ad5d-77be12239441,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-f39149c1-760b-45dc-a653-c884e8c01c12,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-18627a6f-be56-43a6-ae33-8c8df6ed5748,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-91bfee3a-89db-471f-a407-99e302c76d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-309220ef-e141-4ee1-8f4e-6b8fcb03b6e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1991672669-172.17.0.6-1595512746522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33035,DS-aa1fd339-5cd3-419e-aac8-96cd193176eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-cfc86ebe-a1d1-4c85-88de-587c7b92e8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-5a89471e-ea19-44cf-a0b4-39d7f0f6c599,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-d675ee8d-8d5c-4295-a7bd-307c0139583c,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-ba4f789e-7fa1-438a-a996-a042a2c3fe42,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-8d09bdbd-4ce6-4833-9abe-261318108f08,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-e48176a3-b7a4-4229-9499-fa2f1d659174,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-2e765beb-5b21-4137-878f-2588025fabd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1991672669-172.17.0.6-1595512746522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33035,DS-aa1fd339-5cd3-419e-aac8-96cd193176eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-cfc86ebe-a1d1-4c85-88de-587c7b92e8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-5a89471e-ea19-44cf-a0b4-39d7f0f6c599,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-d675ee8d-8d5c-4295-a7bd-307c0139583c,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-ba4f789e-7fa1-438a-a996-a042a2c3fe42,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-8d09bdbd-4ce6-4833-9abe-261318108f08,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-e48176a3-b7a4-4229-9499-fa2f1d659174,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-2e765beb-5b21-4137-878f-2588025fabd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-310322505-172.17.0.6-1595513090512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41119,DS-874bcb22-6ddc-41c3-a677-49ac56f174b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-9f061e10-fd3a-4618-850a-667b30cdddb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-439caf95-b98a-4938-a6bd-b0c1592b6ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-e44878d4-52d4-4b19-8ae2-d497636e58eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-34e379d5-acaa-4d68-b13c-937b5244999c,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-83272873-029c-470a-be54-ab0f91b064e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-57ae2803-262c-4f48-a00d-09fd57beb6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-87685820-15d0-4d45-8ccd-3ebecb4b564b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-310322505-172.17.0.6-1595513090512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41119,DS-874bcb22-6ddc-41c3-a677-49ac56f174b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-9f061e10-fd3a-4618-850a-667b30cdddb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-439caf95-b98a-4938-a6bd-b0c1592b6ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-e44878d4-52d4-4b19-8ae2-d497636e58eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-34e379d5-acaa-4d68-b13c-937b5244999c,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-83272873-029c-470a-be54-ab0f91b064e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-57ae2803-262c-4f48-a00d-09fd57beb6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-87685820-15d0-4d45-8ccd-3ebecb4b564b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2109993015-172.17.0.6-1595513964723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42354,DS-6fa216d6-71b9-4597-8037-cec7493d3d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-3f9a0b63-c680-4923-a168-a443fde38503,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-f22efa5d-6f97-4469-a89d-0347479d07eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-2a873a1f-c8a9-43c0-a224-2f89409c997b,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-3a710f24-3a4c-429e-9497-080a3fef05a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-3e556490-cd50-43fb-8364-2ecaa6036e77,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-0b372793-d7f9-4aaa-81f3-be47f33d16a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-08dbd209-bbc1-4285-936d-a240e727199b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2109993015-172.17.0.6-1595513964723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42354,DS-6fa216d6-71b9-4597-8037-cec7493d3d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-3f9a0b63-c680-4923-a168-a443fde38503,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-f22efa5d-6f97-4469-a89d-0347479d07eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-2a873a1f-c8a9-43c0-a224-2f89409c997b,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-3a710f24-3a4c-429e-9497-080a3fef05a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-3e556490-cd50-43fb-8364-2ecaa6036e77,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-0b372793-d7f9-4aaa-81f3-be47f33d16a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-08dbd209-bbc1-4285-936d-a240e727199b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1419015694-172.17.0.6-1595514217876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36006,DS-81b24517-ee21-4fc9-bfd8-47b4879ca0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-5b01f31c-123c-4d4d-9cab-72ceaae3493f,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-6ddad4e1-a1e8-413a-b38e-e22a76a97b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-c9349440-cae6-4c63-b9c8-a729e334d4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-228f234e-9093-448e-a5f9-14b1a0b6e431,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-38720816-2bb0-401e-8f24-e79602e1326a,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-cafa199a-01b7-4c4e-96ee-b78b3151a07d,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-b0abda01-5ed4-44f0-b895-bd1ade3a3436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1419015694-172.17.0.6-1595514217876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36006,DS-81b24517-ee21-4fc9-bfd8-47b4879ca0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-5b01f31c-123c-4d4d-9cab-72ceaae3493f,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-6ddad4e1-a1e8-413a-b38e-e22a76a97b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-c9349440-cae6-4c63-b9c8-a729e334d4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-228f234e-9093-448e-a5f9-14b1a0b6e431,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-38720816-2bb0-401e-8f24-e79602e1326a,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-cafa199a-01b7-4c4e-96ee-b78b3151a07d,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-b0abda01-5ed4-44f0-b895-bd1ade3a3436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1039239773-172.17.0.6-1595514792949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41330,DS-c930b72b-8299-4488-a329-38472b47027e,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-6e6481e0-f0a0-4543-9fb2-37f37835df58,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-20c33841-0b56-4e32-bcf3-56c9859b85ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-3e78c43d-fdf5-40a2-bd5e-cf883980288e,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-6016ac65-bbd0-4bb6-8b40-4e111538f239,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-678947d8-6ff3-420f-82f7-f2da736482eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-38368b85-771a-4e34-950e-0f5a5a49a084,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-4e2e3316-056a-43c3-98b5-7de80d427320,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1039239773-172.17.0.6-1595514792949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41330,DS-c930b72b-8299-4488-a329-38472b47027e,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-6e6481e0-f0a0-4543-9fb2-37f37835df58,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-20c33841-0b56-4e32-bcf3-56c9859b85ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-3e78c43d-fdf5-40a2-bd5e-cf883980288e,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-6016ac65-bbd0-4bb6-8b40-4e111538f239,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-678947d8-6ff3-420f-82f7-f2da736482eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-38368b85-771a-4e34-950e-0f5a5a49a084,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-4e2e3316-056a-43c3-98b5-7de80d427320,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1282314265-172.17.0.6-1595514829185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44049,DS-084296f5-7e27-4620-862c-650baf6034c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-edc518e6-9e6b-4fca-9124-b521d66767e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-5fea1855-841b-4d24-b32e-174f93b0d96e,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-3366dadc-c748-492a-b9e2-4e51e1bfe383,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-1f8b9862-e7e6-4775-a3cb-b1c93d800d44,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-da2c3ddd-852d-4cd7-8c5f-9d66d950f2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-6f4c449e-47b9-465f-ab2d-3bab43ce8add,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-10d65e9b-a86f-4110-b9c9-1d9c5be4ec0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1282314265-172.17.0.6-1595514829185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44049,DS-084296f5-7e27-4620-862c-650baf6034c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-edc518e6-9e6b-4fca-9124-b521d66767e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-5fea1855-841b-4d24-b32e-174f93b0d96e,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-3366dadc-c748-492a-b9e2-4e51e1bfe383,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-1f8b9862-e7e6-4775-a3cb-b1c93d800d44,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-da2c3ddd-852d-4cd7-8c5f-9d66d950f2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-6f4c449e-47b9-465f-ab2d-3bab43ce8add,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-10d65e9b-a86f-4110-b9c9-1d9c5be4ec0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577245878-172.17.0.6-1595514926207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42066,DS-5b67d7d6-3030-435a-9bcd-f50a97366d10,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-78733e04-e0f8-4398-b36e-1e4f82d0fd66,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-3498a5b7-5e0b-4bcc-9a82-4345eddf06a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-aae3cecf-dc36-427d-9e0b-fecdf0508662,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-1d48646d-d734-4e66-baf5-54b73fa7dbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-ff82f1a2-d3fb-4eda-801a-2664eb0ccb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-b2540df0-6a4f-4101-a547-58741fac806f,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-09bea4cc-d3ed-49d6-a8f8-486650c47607,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577245878-172.17.0.6-1595514926207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42066,DS-5b67d7d6-3030-435a-9bcd-f50a97366d10,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-78733e04-e0f8-4398-b36e-1e4f82d0fd66,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-3498a5b7-5e0b-4bcc-9a82-4345eddf06a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-aae3cecf-dc36-427d-9e0b-fecdf0508662,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-1d48646d-d734-4e66-baf5-54b73fa7dbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-ff82f1a2-d3fb-4eda-801a-2664eb0ccb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-b2540df0-6a4f-4101-a547-58741fac806f,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-09bea4cc-d3ed-49d6-a8f8-486650c47607,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-13272626-172.17.0.6-1595515461853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35327,DS-c306f1f7-3f94-4136-b8c1-373e9d1acc87,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-6154a829-a6a9-49e6-a271-eab4e574935b,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-be0b1b7b-c40d-4760-9694-ff02379612ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-c5769b5d-8d4b-4490-a3f6-071e1dbf0472,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-a9f00b46-e5fd-48a7-a517-7aba4351551f,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-c456d8c0-9d6d-4fce-a5bc-2da717e55676,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-9ad6a596-81b4-4deb-8fd2-3c6c089ec8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-9330c603-d83c-4ba7-8d9c-adefde4a46a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-13272626-172.17.0.6-1595515461853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35327,DS-c306f1f7-3f94-4136-b8c1-373e9d1acc87,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-6154a829-a6a9-49e6-a271-eab4e574935b,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-be0b1b7b-c40d-4760-9694-ff02379612ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-c5769b5d-8d4b-4490-a3f6-071e1dbf0472,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-a9f00b46-e5fd-48a7-a517-7aba4351551f,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-c456d8c0-9d6d-4fce-a5bc-2da717e55676,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-9ad6a596-81b4-4deb-8fd2-3c6c089ec8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-9330c603-d83c-4ba7-8d9c-adefde4a46a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209094551-172.17.0.6-1595515589621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34448,DS-cbc060bd-bc61-4c24-bc17-aac6329c11c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-b1684556-0d13-40c7-a47c-7ae180fa6aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-ebf1c957-d161-402a-a1ad-5ea19e66131b,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-c6ef3bd2-bf8d-4a0b-ae61-b313f89a4b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-80e2c29d-2c0f-4ad5-a87a-166f41264bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-0c932e76-ebdf-4491-a1de-8e07c7f8e836,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-a45c53f7-8f46-4cd2-9a2c-380c2b8a6647,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-f17bfcbf-1dd6-4aff-8139-1979abf9348c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209094551-172.17.0.6-1595515589621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34448,DS-cbc060bd-bc61-4c24-bc17-aac6329c11c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-b1684556-0d13-40c7-a47c-7ae180fa6aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-ebf1c957-d161-402a-a1ad-5ea19e66131b,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-c6ef3bd2-bf8d-4a0b-ae61-b313f89a4b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-80e2c29d-2c0f-4ad5-a87a-166f41264bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-0c932e76-ebdf-4491-a1de-8e07c7f8e836,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-a45c53f7-8f46-4cd2-9a2c-380c2b8a6647,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-f17bfcbf-1dd6-4aff-8139-1979abf9348c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-580059967-172.17.0.6-1595515842896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34442,DS-5a02ffa9-88f1-4ae5-99e6-bc3ba6eb05aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-8eae8bce-7944-4f57-a228-fda3cb10b669,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-eceda197-2005-46f1-954c-284c05311f94,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-2be930d8-4db8-40b5-8c3a-9294970a19b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-e6bfdc19-4dee-4459-b953-6d4b34aabf08,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-cfe69f1e-c3a2-433c-9169-443954edc4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-fe938cbe-cf61-46e1-8e70-7ee0a10a35e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-a75f425b-4eaa-47b8-823d-d1cd82c7e399,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-580059967-172.17.0.6-1595515842896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34442,DS-5a02ffa9-88f1-4ae5-99e6-bc3ba6eb05aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-8eae8bce-7944-4f57-a228-fda3cb10b669,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-eceda197-2005-46f1-954c-284c05311f94,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-2be930d8-4db8-40b5-8c3a-9294970a19b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-e6bfdc19-4dee-4459-b953-6d4b34aabf08,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-cfe69f1e-c3a2-433c-9169-443954edc4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-fe938cbe-cf61-46e1-8e70-7ee0a10a35e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-a75f425b-4eaa-47b8-823d-d1cd82c7e399,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-5698151-172.17.0.6-1595516129075:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39366,DS-59d252c9-d146-4859-b46f-efc4cb6a2f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-ffc498d5-f66d-4fc1-abaa-5dbd9c2f6ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-9d618228-519d-4492-83e6-79c5ac1d9418,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-f417a277-8f15-4fa7-87e6-8a7221289a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-9ac0359c-6628-4152-a463-c2457c9b144f,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-f863427a-9a1f-4bb0-b9aa-ff12aaa2ddc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-b9272fd1-34af-478d-a230-9bc9efb777c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-304d3bfd-1a54-483a-8390-ea664939d3af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-5698151-172.17.0.6-1595516129075:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39366,DS-59d252c9-d146-4859-b46f-efc4cb6a2f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-ffc498d5-f66d-4fc1-abaa-5dbd9c2f6ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-9d618228-519d-4492-83e6-79c5ac1d9418,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-f417a277-8f15-4fa7-87e6-8a7221289a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-9ac0359c-6628-4152-a463-c2457c9b144f,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-f863427a-9a1f-4bb0-b9aa-ff12aaa2ddc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-b9272fd1-34af-478d-a230-9bc9efb777c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-304d3bfd-1a54-483a-8390-ea664939d3af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-949694826-172.17.0.6-1595516196541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45367,DS-36dc7b7b-6ca7-410e-a279-afebd3330770,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-c7124990-25d6-44cb-9656-4a53faf4c53d,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-576b4669-446e-49ff-b094-d7d61de34638,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-d346521e-adab-4931-9dbd-2fcbc4ab67da,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-12a9c907-a3ce-4c28-acee-9a1b223dcc92,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-87b284dd-a65f-4441-92e1-8c8f19ba2e64,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-1ef9127a-a6bc-49cd-aee4-203d5bc27238,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-e4ad26bc-cc7a-4041-8ded-ad98d211df0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-949694826-172.17.0.6-1595516196541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45367,DS-36dc7b7b-6ca7-410e-a279-afebd3330770,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-c7124990-25d6-44cb-9656-4a53faf4c53d,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-576b4669-446e-49ff-b094-d7d61de34638,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-d346521e-adab-4931-9dbd-2fcbc4ab67da,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-12a9c907-a3ce-4c28-acee-9a1b223dcc92,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-87b284dd-a65f-4441-92e1-8c8f19ba2e64,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-1ef9127a-a6bc-49cd-aee4-203d5bc27238,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-e4ad26bc-cc7a-4041-8ded-ad98d211df0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1868722843-172.17.0.6-1595516465943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38229,DS-ce786aae-33c2-44eb-b512-bff95aaaf54b,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-b5f937be-4de5-4da7-a10c-8677fa21ebfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-cc6d19c7-72b7-4ecd-acd3-0722ec3dc987,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-3b152912-9c89-481f-82db-475b0a91d5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-e91efc9c-d0a8-42c6-8c4f-3ac375ae97a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-5221daf5-3a74-452d-8495-132b0eea47d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-44a89a3f-2798-48d3-91ea-76c3c166692d,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-f7416d4d-b204-40b2-bdac-307f3299b305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1868722843-172.17.0.6-1595516465943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38229,DS-ce786aae-33c2-44eb-b512-bff95aaaf54b,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-b5f937be-4de5-4da7-a10c-8677fa21ebfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-cc6d19c7-72b7-4ecd-acd3-0722ec3dc987,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-3b152912-9c89-481f-82db-475b0a91d5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-e91efc9c-d0a8-42c6-8c4f-3ac375ae97a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-5221daf5-3a74-452d-8495-132b0eea47d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-44a89a3f-2798-48d3-91ea-76c3c166692d,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-f7416d4d-b204-40b2-bdac-307f3299b305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1653465815-172.17.0.6-1595516534447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35658,DS-3716d621-2367-4e25-9b54-8d2c25ebe25a,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-4220c89f-384e-4b0f-acc4-f9b2cb0df707,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-6bdd27f0-20e7-433a-9c99-0fcb59e5e065,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-d2b7df2b-376a-44c5-91be-1386e7f71c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-01100c9f-672b-44fd-a2a4-3d3b1d43ae0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-a45c1d00-07d8-4cc0-957a-186ab8893074,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-65e192ab-73e8-4d72-b6c6-5640bc5d1d95,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-d31838e7-c0e1-4776-b005-24a2f3811d3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1653465815-172.17.0.6-1595516534447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35658,DS-3716d621-2367-4e25-9b54-8d2c25ebe25a,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-4220c89f-384e-4b0f-acc4-f9b2cb0df707,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-6bdd27f0-20e7-433a-9c99-0fcb59e5e065,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-d2b7df2b-376a-44c5-91be-1386e7f71c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-01100c9f-672b-44fd-a2a4-3d3b1d43ae0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-a45c1d00-07d8-4cc0-957a-186ab8893074,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-65e192ab-73e8-4d72-b6c6-5640bc5d1d95,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-d31838e7-c0e1-4776-b005-24a2f3811d3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1530703597-172.17.0.6-1595516602391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44971,DS-4a3973a2-8bd9-42ca-bd79-344e5b2ebbde,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-bedcae15-198b-4a16-89b7-bb78a33cbbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-a7691812-4e35-484b-8dc7-12b29a5eab67,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-ac1f6c05-ee78-4623-b663-21ac59115724,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-ba74c1ba-aefe-4446-a243-090bc270eec6,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-2f8e98c2-9f6a-4ac2-a8ee-1308942810f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-dd9a91e9-2bc8-4f4d-b700-7b70c29611ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-df412f6c-f12c-40b5-8d60-9fdb7bf977c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1530703597-172.17.0.6-1595516602391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44971,DS-4a3973a2-8bd9-42ca-bd79-344e5b2ebbde,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-bedcae15-198b-4a16-89b7-bb78a33cbbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-a7691812-4e35-484b-8dc7-12b29a5eab67,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-ac1f6c05-ee78-4623-b663-21ac59115724,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-ba74c1ba-aefe-4446-a243-090bc270eec6,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-2f8e98c2-9f6a-4ac2-a8ee-1308942810f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-dd9a91e9-2bc8-4f4d-b700-7b70c29611ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-df412f6c-f12c-40b5-8d60-9fdb7bf977c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1884570008-172.17.0.6-1595517392719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34478,DS-95c1f2e4-ee96-4658-a589-1cf5aab92997,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-b919c1af-7ebf-4067-a2c8-9d9da0247344,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-2f917545-768e-4612-87e5-72e424722c49,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-31df0199-9cec-4907-a92c-6350d1ee2450,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-861f4601-14c5-4582-af95-a1a99aa56e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-afbaefab-f076-424d-bf19-e1252941ac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-7027cfab-5e21-4cd7-b798-81ccfafffc95,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-2f5c756b-c87c-4d36-bd22-99d06b686fba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1884570008-172.17.0.6-1595517392719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34478,DS-95c1f2e4-ee96-4658-a589-1cf5aab92997,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-b919c1af-7ebf-4067-a2c8-9d9da0247344,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-2f917545-768e-4612-87e5-72e424722c49,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-31df0199-9cec-4907-a92c-6350d1ee2450,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-861f4601-14c5-4582-af95-a1a99aa56e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-afbaefab-f076-424d-bf19-e1252941ac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-7027cfab-5e21-4cd7-b798-81ccfafffc95,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-2f5c756b-c87c-4d36-bd22-99d06b686fba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5124
