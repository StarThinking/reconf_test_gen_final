reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1531501005-172.17.0.10-1595561907453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46003,DS-0fa23cd7-a638-47fa-9ca8-bd979ad617fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-3f563b1c-1172-4aa7-aef2-67e3c3fdb48e,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-1fa53ec2-b466-4645-8fe5-f9413fc2a103,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-dc3678ad-efe5-4ed4-b361-29e8339f38ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-ad9ac524-4f22-45a7-a574-83281da04358,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-84147f16-29b0-4fd7-9d5d-b0441ae1fb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-a06284d8-f934-4764-b94d-66a83a6e1fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-f87ede3b-ad9c-48de-abe5-66eaa40f326b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1531501005-172.17.0.10-1595561907453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46003,DS-0fa23cd7-a638-47fa-9ca8-bd979ad617fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-3f563b1c-1172-4aa7-aef2-67e3c3fdb48e,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-1fa53ec2-b466-4645-8fe5-f9413fc2a103,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-dc3678ad-efe5-4ed4-b361-29e8339f38ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-ad9ac524-4f22-45a7-a574-83281da04358,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-84147f16-29b0-4fd7-9d5d-b0441ae1fb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-a06284d8-f934-4764-b94d-66a83a6e1fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-f87ede3b-ad9c-48de-abe5-66eaa40f326b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-863709037-172.17.0.10-1595562002348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45786,DS-ff496919-da79-4ce2-95b8-72bf73dab183,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-60ec3c66-97bf-4705-a8af-6870863659b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-84ad7daf-b7a9-4865-bc1c-daa1e9bea939,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-0d971c02-3281-4d48-b4b0-dd0f46ced711,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-e2c32c70-dd98-4576-9d45-b8e3ef1583dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-50745b0d-d084-451e-80b9-b8a3b2072bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-641a6415-afb4-42c4-ba1d-3360b6ff6b32,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-32c2ba95-e9a0-4f28-b61a-cd71a9f104b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-863709037-172.17.0.10-1595562002348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45786,DS-ff496919-da79-4ce2-95b8-72bf73dab183,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-60ec3c66-97bf-4705-a8af-6870863659b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-84ad7daf-b7a9-4865-bc1c-daa1e9bea939,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-0d971c02-3281-4d48-b4b0-dd0f46ced711,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-e2c32c70-dd98-4576-9d45-b8e3ef1583dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-50745b0d-d084-451e-80b9-b8a3b2072bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-641a6415-afb4-42c4-ba1d-3360b6ff6b32,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-32c2ba95-e9a0-4f28-b61a-cd71a9f104b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-3892411-172.17.0.10-1595562043763:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39014,DS-9b20db9b-4ca4-4cd0-8053-521895c3b022,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-9e1eb5b0-e240-4a74-a82c-798f3307f569,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-c4af7e67-6856-4934-ab00-d55a1717c71c,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-0d3e22cc-2b54-40fc-8e5b-793d45696e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-d6b2a297-5c62-4d67-9d30-0832beb36ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-c6816f07-9265-4d36-becb-452fe84183db,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-0b3ac5dc-6b19-4669-ad96-a72af1eb2ada,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-495ce5e4-49cc-4ccd-a30f-35ae3ac49875,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-3892411-172.17.0.10-1595562043763:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39014,DS-9b20db9b-4ca4-4cd0-8053-521895c3b022,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-9e1eb5b0-e240-4a74-a82c-798f3307f569,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-c4af7e67-6856-4934-ab00-d55a1717c71c,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-0d3e22cc-2b54-40fc-8e5b-793d45696e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-d6b2a297-5c62-4d67-9d30-0832beb36ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-c6816f07-9265-4d36-becb-452fe84183db,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-0b3ac5dc-6b19-4669-ad96-a72af1eb2ada,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-495ce5e4-49cc-4ccd-a30f-35ae3ac49875,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-553053010-172.17.0.10-1595562607976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33764,DS-a3f2620f-76a7-45c2-a2f5-4b974c7dbf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-934c77a0-9c95-4754-a94f-d7784dfa5c52,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-ccf7f018-889f-4440-be78-46d58861509e,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-e10b5dd6-c793-429b-ad6c-9466f839ddb3,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-57bc6d7c-c84d-456c-9b6d-6d37b474a9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-421d7bb9-e90e-4eec-9aa6-6a11fb673a32,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-1213c0e6-d423-4c63-9c69-d4a83ab77bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-c4f22725-87d3-415d-895e-ceea3b074db1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-553053010-172.17.0.10-1595562607976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33764,DS-a3f2620f-76a7-45c2-a2f5-4b974c7dbf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-934c77a0-9c95-4754-a94f-d7784dfa5c52,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-ccf7f018-889f-4440-be78-46d58861509e,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-e10b5dd6-c793-429b-ad6c-9466f839ddb3,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-57bc6d7c-c84d-456c-9b6d-6d37b474a9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-421d7bb9-e90e-4eec-9aa6-6a11fb673a32,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-1213c0e6-d423-4c63-9c69-d4a83ab77bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-c4f22725-87d3-415d-895e-ceea3b074db1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-385035165-172.17.0.10-1595562922703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34261,DS-783b505a-bdfa-4a0a-9746-37b29dd94286,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-2e6dd15c-1f09-4db5-9278-322eb466eb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-c1c00fb5-fc3b-4fda-818b-6607eeaf9cad,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-d1da1b2f-6c20-4671-8df0-867053b90514,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-c8976617-c901-4d12-8f2f-5db9b7097b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-11589fb0-4667-48a4-8529-27531cb17e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-6abd705c-586e-4247-89e5-ed5f7ec7ba7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-a49b7a17-fe53-48ef-b22a-10e7a3d774ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-385035165-172.17.0.10-1595562922703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34261,DS-783b505a-bdfa-4a0a-9746-37b29dd94286,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-2e6dd15c-1f09-4db5-9278-322eb466eb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-c1c00fb5-fc3b-4fda-818b-6607eeaf9cad,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-d1da1b2f-6c20-4671-8df0-867053b90514,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-c8976617-c901-4d12-8f2f-5db9b7097b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-11589fb0-4667-48a4-8529-27531cb17e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-6abd705c-586e-4247-89e5-ed5f7ec7ba7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-a49b7a17-fe53-48ef-b22a-10e7a3d774ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-774160531-172.17.0.10-1595563034179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46452,DS-7428377e-7939-419e-ba59-a5a5a2afdd67,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-1dd6fbe8-ddf7-44c4-a12a-a0af8d01743b,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-068f0318-78f1-4676-aa66-f071e1fddbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-101ba932-dddf-43ed-9afd-b69e3ee2caa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-489a3512-6fc2-4025-b1fb-627619dd8190,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-5c7d2bf2-6030-4489-8523-fd373e319b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-e3087673-5589-4229-a7bf-497bb23cef31,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-2cf823cc-5ede-4714-adae-dd2b1911864d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-774160531-172.17.0.10-1595563034179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46452,DS-7428377e-7939-419e-ba59-a5a5a2afdd67,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-1dd6fbe8-ddf7-44c4-a12a-a0af8d01743b,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-068f0318-78f1-4676-aa66-f071e1fddbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-101ba932-dddf-43ed-9afd-b69e3ee2caa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-489a3512-6fc2-4025-b1fb-627619dd8190,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-5c7d2bf2-6030-4489-8523-fd373e319b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-e3087673-5589-4229-a7bf-497bb23cef31,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-2cf823cc-5ede-4714-adae-dd2b1911864d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-339384504-172.17.0.10-1595563158215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46883,DS-aac2fc2f-d647-4ca6-ab0e-ad1f52e81725,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-b73ac5ea-1dff-4ffa-95b4-71bb462b0598,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-dabd13fa-b4d6-4c40-8c27-502f98c53b49,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-219e8aa2-e47c-4a02-931f-317395fe2ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-6a8d4fd3-0cdf-47fb-b44c-1cdcc8e05668,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-8df4bf0d-26b5-4e81-8af1-8af69128dea8,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-5df4216b-2f08-4db1-8c3e-10a1c7a0f437,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-a45a5b0a-97c2-4da7-94cc-55c500c819da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-339384504-172.17.0.10-1595563158215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46883,DS-aac2fc2f-d647-4ca6-ab0e-ad1f52e81725,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-b73ac5ea-1dff-4ffa-95b4-71bb462b0598,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-dabd13fa-b4d6-4c40-8c27-502f98c53b49,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-219e8aa2-e47c-4a02-931f-317395fe2ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-6a8d4fd3-0cdf-47fb-b44c-1cdcc8e05668,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-8df4bf0d-26b5-4e81-8af1-8af69128dea8,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-5df4216b-2f08-4db1-8c3e-10a1c7a0f437,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-a45a5b0a-97c2-4da7-94cc-55c500c819da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2060101586-172.17.0.10-1595563836668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39044,DS-c000e89b-1dda-412c-a9b0-ee5293f506fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-1179466e-b3c4-40c1-b78b-815c94c60542,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-51997dca-7208-48b6-afe0-35ee4f8487d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-f18b0d01-f812-44b1-ab5f-c9ecea1564b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-32709918-6807-46fa-81d2-b9a213b7e8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-2e2ce378-f2da-4892-baa8-d54e381a49c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-db859c2c-312b-438a-8817-02c8ac827fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-eb8519c1-c4f9-47b4-a9ba-71ad005f491e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2060101586-172.17.0.10-1595563836668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39044,DS-c000e89b-1dda-412c-a9b0-ee5293f506fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-1179466e-b3c4-40c1-b78b-815c94c60542,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-51997dca-7208-48b6-afe0-35ee4f8487d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-f18b0d01-f812-44b1-ab5f-c9ecea1564b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-32709918-6807-46fa-81d2-b9a213b7e8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-2e2ce378-f2da-4892-baa8-d54e381a49c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-db859c2c-312b-438a-8817-02c8ac827fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-eb8519c1-c4f9-47b4-a9ba-71ad005f491e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1046511489-172.17.0.10-1595564236217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39594,DS-7abdcf59-732d-4a72-a126-3fba22603b11,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-c0a7c7fe-f650-4d1d-8bac-a4368eb201f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-f388ec55-3478-4305-bea7-1817b50c9295,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-c975a926-0a90-460b-9eae-966ba0bce91e,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-e492e225-0807-40a4-be53-dde7cd83a534,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-0acea311-af1a-41d9-a7f1-ef9881c67cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-feb1ca9f-0115-406f-9482-d753186d2f22,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-54bd661e-f807-4d15-9d40-2cf1c786817b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1046511489-172.17.0.10-1595564236217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39594,DS-7abdcf59-732d-4a72-a126-3fba22603b11,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-c0a7c7fe-f650-4d1d-8bac-a4368eb201f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-f388ec55-3478-4305-bea7-1817b50c9295,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-c975a926-0a90-460b-9eae-966ba0bce91e,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-e492e225-0807-40a4-be53-dde7cd83a534,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-0acea311-af1a-41d9-a7f1-ef9881c67cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-feb1ca9f-0115-406f-9482-d753186d2f22,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-54bd661e-f807-4d15-9d40-2cf1c786817b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-945458999-172.17.0.10-1595564522450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35773,DS-a2b0c901-9ea9-4339-9c15-d9e78fea12fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-811d93d2-a86a-4ad6-8347-6821dda90b22,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-705886f0-b7db-4ccb-b524-51b337a51a80,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-179d2a92-b968-4d82-a0a9-67249785cf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-9694dbc5-2206-4a88-9039-263b979c56f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-e1c3946e-b3fb-42b8-8557-e7a94612c5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-a12a5ee8-3e1e-4941-8142-08e032989b98,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-2834473f-e803-4cad-91b5-42ff6ead0279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-945458999-172.17.0.10-1595564522450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35773,DS-a2b0c901-9ea9-4339-9c15-d9e78fea12fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-811d93d2-a86a-4ad6-8347-6821dda90b22,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-705886f0-b7db-4ccb-b524-51b337a51a80,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-179d2a92-b968-4d82-a0a9-67249785cf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-9694dbc5-2206-4a88-9039-263b979c56f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-e1c3946e-b3fb-42b8-8557-e7a94612c5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-a12a5ee8-3e1e-4941-8142-08e032989b98,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-2834473f-e803-4cad-91b5-42ff6ead0279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708171610-172.17.0.10-1595564694124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40356,DS-fa202e65-ad31-41a0-ac90-c083604608a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-71ec4f30-26ee-41ca-abf6-a619e8d933a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-e0df6b44-15f0-49c8-b123-79aac372c4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-ba18af7d-093f-491e-a547-3955ea75e1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-2dcd3c70-db5a-40fa-9841-3f76a7b72bab,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-8d1a5aa4-34e0-42b6-9352-be3d07949c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-12c215ce-1fa6-4625-981f-1d5003bba4da,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-e5a71639-c806-41c5-899f-012bc3eb8c02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708171610-172.17.0.10-1595564694124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40356,DS-fa202e65-ad31-41a0-ac90-c083604608a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-71ec4f30-26ee-41ca-abf6-a619e8d933a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-e0df6b44-15f0-49c8-b123-79aac372c4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-ba18af7d-093f-491e-a547-3955ea75e1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-2dcd3c70-db5a-40fa-9841-3f76a7b72bab,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-8d1a5aa4-34e0-42b6-9352-be3d07949c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-12c215ce-1fa6-4625-981f-1d5003bba4da,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-e5a71639-c806-41c5-899f-012bc3eb8c02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1052830601-172.17.0.10-1595565304646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33438,DS-9adb0380-fa95-413c-bd92-c8675a6bea99,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-19e1d071-4a94-4ff5-9d51-7bb63a73b1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-cd7a8508-6e68-4f15-bfea-e9aa88beae78,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-87d250a2-4208-4265-b8f6-15e24c52f795,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-4cefac33-2bd2-4126-9b8c-e8360bb8afa0,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-f00a6cd0-4799-4354-82c7-59addff32fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-d0cd5d9c-1552-4b6c-b7cc-e3608a1d2db0,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-0b5411d1-a437-48d4-8b17-fa8df2c41f1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1052830601-172.17.0.10-1595565304646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33438,DS-9adb0380-fa95-413c-bd92-c8675a6bea99,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-19e1d071-4a94-4ff5-9d51-7bb63a73b1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-cd7a8508-6e68-4f15-bfea-e9aa88beae78,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-87d250a2-4208-4265-b8f6-15e24c52f795,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-4cefac33-2bd2-4126-9b8c-e8360bb8afa0,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-f00a6cd0-4799-4354-82c7-59addff32fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-d0cd5d9c-1552-4b6c-b7cc-e3608a1d2db0,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-0b5411d1-a437-48d4-8b17-fa8df2c41f1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5435
