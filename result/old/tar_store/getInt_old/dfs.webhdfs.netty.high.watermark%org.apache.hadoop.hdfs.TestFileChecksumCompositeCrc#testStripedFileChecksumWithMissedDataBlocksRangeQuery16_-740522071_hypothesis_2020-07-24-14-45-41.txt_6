reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-478525573-172.17.0.15-1595602404906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44912,DS-08759a43-0b18-4307-a752-bd0b784e490a,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-0d2fc682-5b9d-4a79-b986-1ad3042e0a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-32595ab6-e363-45ef-9474-803b0c2b11c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-2459c837-5080-478b-8d70-2621d566e5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-5bf0eb0b-9b48-48f4-81c3-d1135127f6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-943b85c1-9f89-4f51-86ed-afef517c5a35,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-9c6806bd-8edb-4e84-9f75-79a792cf52b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-c2d7b794-20d7-4f99-b3b8-4f55f1f2a84a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-478525573-172.17.0.15-1595602404906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44912,DS-08759a43-0b18-4307-a752-bd0b784e490a,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-0d2fc682-5b9d-4a79-b986-1ad3042e0a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-32595ab6-e363-45ef-9474-803b0c2b11c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-2459c837-5080-478b-8d70-2621d566e5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-5bf0eb0b-9b48-48f4-81c3-d1135127f6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-943b85c1-9f89-4f51-86ed-afef517c5a35,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-9c6806bd-8edb-4e84-9f75-79a792cf52b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-c2d7b794-20d7-4f99-b3b8-4f55f1f2a84a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-893525204-172.17.0.15-1595602658417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45730,DS-001556bd-0a05-4cb8-b7f9-9ef81a23c3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-33db719a-8a2b-41e9-90ee-cd89e99a0d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-749826ee-e037-4f2a-9fca-afbd79166e94,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-f81f8af9-1ecb-4721-be12-83de0aae489f,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-b01e7206-723a-42eb-8d78-2692156d7652,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-b4cc834f-d8da-4b50-9819-a8a4fd76b907,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-9298eb56-80d3-439d-87b8-5a2f646146a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-d6dea4ac-9f20-4138-bb10-d097ec3a2b73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-893525204-172.17.0.15-1595602658417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45730,DS-001556bd-0a05-4cb8-b7f9-9ef81a23c3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-33db719a-8a2b-41e9-90ee-cd89e99a0d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-749826ee-e037-4f2a-9fca-afbd79166e94,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-f81f8af9-1ecb-4721-be12-83de0aae489f,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-b01e7206-723a-42eb-8d78-2692156d7652,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-b4cc834f-d8da-4b50-9819-a8a4fd76b907,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-9298eb56-80d3-439d-87b8-5a2f646146a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-d6dea4ac-9f20-4138-bb10-d097ec3a2b73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2068894638-172.17.0.15-1595602728091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33558,DS-35cfdbe1-4c83-48ba-9e88-76cc5b4b6886,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-93453761-eaa4-4d18-8f8b-6ff38f9821fb,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-f8aae22a-e821-441c-81ce-ccfa92607fec,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-f4714a2e-bb0c-4a77-894c-7323648f3320,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-abae7683-ab98-4a31-8355-3968b8dbe407,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-082d4d32-e196-4a61-bb4e-6f576191f90a,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-1c546945-a331-4630-bd99-0fb85b101203,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-980286b1-2571-4152-b75e-d5772626c602,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2068894638-172.17.0.15-1595602728091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33558,DS-35cfdbe1-4c83-48ba-9e88-76cc5b4b6886,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-93453761-eaa4-4d18-8f8b-6ff38f9821fb,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-f8aae22a-e821-441c-81ce-ccfa92607fec,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-f4714a2e-bb0c-4a77-894c-7323648f3320,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-abae7683-ab98-4a31-8355-3968b8dbe407,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-082d4d32-e196-4a61-bb4e-6f576191f90a,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-1c546945-a331-4630-bd99-0fb85b101203,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-980286b1-2571-4152-b75e-d5772626c602,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188617181-172.17.0.15-1595602774285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33692,DS-231859fb-e057-41fd-ba38-ee7282851032,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-3da0bb11-354a-417f-b55b-40668e552dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-67c3f094-13e5-4381-b5df-619cd5c75f95,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-e574ece1-979f-4c57-a190-a3927cfd65a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-e6a8e666-07b2-4f52-930b-e44f02707fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-223e6be4-f6d2-4562-8323-0c91b35858d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-de1bd676-3abc-45c3-831c-7e355b1243b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-1ad45c58-fdba-43b8-b1a0-ce74976bdd44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188617181-172.17.0.15-1595602774285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33692,DS-231859fb-e057-41fd-ba38-ee7282851032,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-3da0bb11-354a-417f-b55b-40668e552dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-67c3f094-13e5-4381-b5df-619cd5c75f95,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-e574ece1-979f-4c57-a190-a3927cfd65a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-e6a8e666-07b2-4f52-930b-e44f02707fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-223e6be4-f6d2-4562-8323-0c91b35858d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-de1bd676-3abc-45c3-831c-7e355b1243b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-1ad45c58-fdba-43b8-b1a0-ce74976bdd44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1468500134-172.17.0.15-1595603067496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37871,DS-7b8125fc-018c-4b9c-99b0-22cffde0c1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-94ca2bc2-18a3-4f6c-9164-26b05ee4f041,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-59a12c29-5249-4493-a76e-9c47b805b1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-6961410e-2d06-479b-9a02-8388648f199b,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-912ae823-42f2-4f86-a6fb-e9cd91d8e36d,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-6abc834a-033c-4f2d-abd0-1c27b4443af4,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-21238f70-c238-412b-9401-93bfae2b9c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-74d88021-a30e-4d06-9bbc-9db10392b1d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1468500134-172.17.0.15-1595603067496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37871,DS-7b8125fc-018c-4b9c-99b0-22cffde0c1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-94ca2bc2-18a3-4f6c-9164-26b05ee4f041,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-59a12c29-5249-4493-a76e-9c47b805b1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-6961410e-2d06-479b-9a02-8388648f199b,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-912ae823-42f2-4f86-a6fb-e9cd91d8e36d,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-6abc834a-033c-4f2d-abd0-1c27b4443af4,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-21238f70-c238-412b-9401-93bfae2b9c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-74d88021-a30e-4d06-9bbc-9db10392b1d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945287912-172.17.0.15-1595604168925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32987,DS-9c11370a-bb1a-4f68-9ab1-0454bca3321a,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-2313827d-da81-49cc-8b03-b7a8ceb1443a,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-209c878f-5609-4e26-8845-de59af15e01b,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-a74a2bf2-c5ff-45ca-a599-bbaf268ae371,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-6c7b8384-3927-4310-b09d-44df8371774c,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-187b6278-a855-4de2-b605-c4484266d9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-dd3a1db2-8bb0-421a-abee-01172d583c31,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-1d67b88e-5889-45a5-a4cc-50ffda1fe9d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945287912-172.17.0.15-1595604168925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32987,DS-9c11370a-bb1a-4f68-9ab1-0454bca3321a,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-2313827d-da81-49cc-8b03-b7a8ceb1443a,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-209c878f-5609-4e26-8845-de59af15e01b,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-a74a2bf2-c5ff-45ca-a599-bbaf268ae371,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-6c7b8384-3927-4310-b09d-44df8371774c,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-187b6278-a855-4de2-b605-c4484266d9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-dd3a1db2-8bb0-421a-abee-01172d583c31,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-1d67b88e-5889-45a5-a4cc-50ffda1fe9d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-503839209-172.17.0.15-1595604266767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42706,DS-68951421-21fb-4e91-9e0f-2745f4ec72fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-5ff7170f-1722-4d75-981f-10dc8c040a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-79bcb27e-0eb4-4e4e-b49e-82234f27dca1,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-b07dd0d3-a927-41bd-85cc-60375b8c5b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-9131272e-6758-46ef-96f2-fcd57b24baea,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-8989e3bd-90b8-4d4a-ae58-01fc88e81a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-bfaaee6b-be49-4e7d-95cb-1b7ae99d5f80,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-ebcdf3d0-73f4-4216-a248-da27f37e9d68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-503839209-172.17.0.15-1595604266767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42706,DS-68951421-21fb-4e91-9e0f-2745f4ec72fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-5ff7170f-1722-4d75-981f-10dc8c040a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-79bcb27e-0eb4-4e4e-b49e-82234f27dca1,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-b07dd0d3-a927-41bd-85cc-60375b8c5b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-9131272e-6758-46ef-96f2-fcd57b24baea,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-8989e3bd-90b8-4d4a-ae58-01fc88e81a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-bfaaee6b-be49-4e7d-95cb-1b7ae99d5f80,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-ebcdf3d0-73f4-4216-a248-da27f37e9d68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156862304-172.17.0.15-1595605016820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43315,DS-97abcd8e-fb66-49fc-bef6-37a13e3f3c27,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-f50ad03b-d638-418d-b157-9b42c8f8248c,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-2ae36b60-e101-4456-b72c-23d3bf631e17,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-e7233949-0a16-4db8-ade5-665eb8f0bc85,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-82dcf4c5-85e1-4bbe-a787-926bd6046a59,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-931a2df7-cc4c-471c-860a-02522c357fba,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-bf6ae7c9-0a80-4b22-976a-528e61bc5c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-1e4ccb29-c602-4e56-9d69-4c7cf4f7b93e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156862304-172.17.0.15-1595605016820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43315,DS-97abcd8e-fb66-49fc-bef6-37a13e3f3c27,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-f50ad03b-d638-418d-b157-9b42c8f8248c,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-2ae36b60-e101-4456-b72c-23d3bf631e17,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-e7233949-0a16-4db8-ade5-665eb8f0bc85,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-82dcf4c5-85e1-4bbe-a787-926bd6046a59,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-931a2df7-cc4c-471c-860a-02522c357fba,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-bf6ae7c9-0a80-4b22-976a-528e61bc5c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-1e4ccb29-c602-4e56-9d69-4c7cf4f7b93e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1094512882-172.17.0.15-1595605092577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38702,DS-008c2ac5-75a7-46ad-872d-a0947c7e19de,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-822027ed-bc29-4b9f-b80f-7c33fa9d8b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-0f8fa98c-269a-4c6e-b9d0-a25281ed7729,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-6f3d4da3-6c50-4dd4-a3df-df10b6a3aa61,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-69e4a480-647c-463b-9256-f4f8f0c0dd66,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-b5c1dc9e-cf2d-4f21-8486-9bc65066efeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-aa420ba5-e173-431f-8331-88c2a6030034,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-0e7274ea-a25a-49a6-ad85-7ce1694b979f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1094512882-172.17.0.15-1595605092577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38702,DS-008c2ac5-75a7-46ad-872d-a0947c7e19de,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-822027ed-bc29-4b9f-b80f-7c33fa9d8b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-0f8fa98c-269a-4c6e-b9d0-a25281ed7729,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-6f3d4da3-6c50-4dd4-a3df-df10b6a3aa61,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-69e4a480-647c-463b-9256-f4f8f0c0dd66,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-b5c1dc9e-cf2d-4f21-8486-9bc65066efeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-aa420ba5-e173-431f-8331-88c2a6030034,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-0e7274ea-a25a-49a6-ad85-7ce1694b979f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458376887-172.17.0.15-1595605585388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39464,DS-683c06fa-710e-498c-b54e-bfa57ed630cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-5a1fe5f4-abfa-4b26-a8e5-66d4bc95296c,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-25975113-ddd2-434f-8478-1f65d09bf54f,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-a1cb6724-7613-45e5-895d-6f9319a1c3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-28e781e8-48e9-4fe7-b7ad-766481d07b65,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-a13bc19b-7a71-48b8-91ee-10b2b481db48,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-14aa53be-905a-42ab-a947-49914628bdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-c81228ae-02ba-454b-9ad6-fc241d7b5870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458376887-172.17.0.15-1595605585388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39464,DS-683c06fa-710e-498c-b54e-bfa57ed630cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-5a1fe5f4-abfa-4b26-a8e5-66d4bc95296c,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-25975113-ddd2-434f-8478-1f65d09bf54f,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-a1cb6724-7613-45e5-895d-6f9319a1c3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-28e781e8-48e9-4fe7-b7ad-766481d07b65,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-a13bc19b-7a71-48b8-91ee-10b2b481db48,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-14aa53be-905a-42ab-a947-49914628bdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-c81228ae-02ba-454b-9ad6-fc241d7b5870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133917024-172.17.0.15-1595605648989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40019,DS-d1da24bb-c5ab-478c-bed8-1357b60dee94,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-99f48dbc-6379-4493-ba3e-a767cd3275f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-2594fa21-03c1-4131-92a4-98f4ae78bac6,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-e97181ee-0947-4b30-afb5-dda5f81cfcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-c7d702e4-e817-4927-bd0e-ac9875998d69,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-a68b563f-edc7-4810-8b60-127006f5435b,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-429992bf-5e6d-4ff2-91ad-075ced5291d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-599a2a9a-3676-4efc-bc52-f33001edc364,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133917024-172.17.0.15-1595605648989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40019,DS-d1da24bb-c5ab-478c-bed8-1357b60dee94,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-99f48dbc-6379-4493-ba3e-a767cd3275f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-2594fa21-03c1-4131-92a4-98f4ae78bac6,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-e97181ee-0947-4b30-afb5-dda5f81cfcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-c7d702e4-e817-4927-bd0e-ac9875998d69,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-a68b563f-edc7-4810-8b60-127006f5435b,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-429992bf-5e6d-4ff2-91ad-075ced5291d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-599a2a9a-3676-4efc-bc52-f33001edc364,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2124459822-172.17.0.15-1595605954106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37183,DS-7db1a2af-f33f-4676-b2f6-d352528f5c71,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-fd4df099-9254-4296-bc61-aaa1d475a291,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-99fbdc94-ef29-4934-be39-b0c3575d1600,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-4372f362-31b5-4034-aebf-38e0b22f5504,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-d9601082-4270-4d0d-9dc5-5c5c2168d48a,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-cf82364b-e738-4ddd-8054-fad18f3859f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-25b34032-53db-4c60-b7d8-bb07e65343e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-abe06e9c-6292-4ce2-bd06-b6bb595a3328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2124459822-172.17.0.15-1595605954106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37183,DS-7db1a2af-f33f-4676-b2f6-d352528f5c71,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-fd4df099-9254-4296-bc61-aaa1d475a291,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-99fbdc94-ef29-4934-be39-b0c3575d1600,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-4372f362-31b5-4034-aebf-38e0b22f5504,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-d9601082-4270-4d0d-9dc5-5c5c2168d48a,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-cf82364b-e738-4ddd-8054-fad18f3859f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-25b34032-53db-4c60-b7d8-bb07e65343e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-abe06e9c-6292-4ce2-bd06-b6bb595a3328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-278995059-172.17.0.15-1595605991975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42238,DS-a417612b-15a6-4ee4-ac73-bc7f19db15ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-001014a6-094f-4b2e-8f17-0c5ba141e5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-7345b1c8-33a9-4e95-a99a-2700136de17a,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-20a5d54a-b76d-4cc5-bf12-82dbc079226e,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-9fd0552d-c762-4f7d-90b6-66498ffbae73,DISK], DatanodeInfoWithStorage[127.0.0.1:46799,DS-4c49ec81-08dc-43db-abe5-342c9543dd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-2656422d-6a9a-4db0-85dc-330d9bc88fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-8049077b-360d-485b-86b2-90509a8528d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-278995059-172.17.0.15-1595605991975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42238,DS-a417612b-15a6-4ee4-ac73-bc7f19db15ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-001014a6-094f-4b2e-8f17-0c5ba141e5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-7345b1c8-33a9-4e95-a99a-2700136de17a,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-20a5d54a-b76d-4cc5-bf12-82dbc079226e,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-9fd0552d-c762-4f7d-90b6-66498ffbae73,DISK], DatanodeInfoWithStorage[127.0.0.1:46799,DS-4c49ec81-08dc-43db-abe5-342c9543dd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-2656422d-6a9a-4db0-85dc-330d9bc88fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-8049077b-360d-485b-86b2-90509a8528d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-49820357-172.17.0.15-1595606135478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41106,DS-82f36eee-ddcd-4be9-9311-dc9c19e3083c,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-b57da45b-21bc-401a-9360-c68ce34a2255,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-f2c9cd36-2da6-4b01-aa62-8beec11b3d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-a19a90e4-c27f-413f-94ef-09eac8fd31e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-c8e3b890-3f19-4aac-b3a2-355aaf11829a,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-f33c5b71-ac85-4472-84fb-1e4b76aa128d,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-7bb271cf-0913-41ee-aecf-7daef3c0ffcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-9f787535-25c2-4c4a-ad0f-dd32ca6b1377,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-49820357-172.17.0.15-1595606135478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41106,DS-82f36eee-ddcd-4be9-9311-dc9c19e3083c,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-b57da45b-21bc-401a-9360-c68ce34a2255,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-f2c9cd36-2da6-4b01-aa62-8beec11b3d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-a19a90e4-c27f-413f-94ef-09eac8fd31e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-c8e3b890-3f19-4aac-b3a2-355aaf11829a,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-f33c5b71-ac85-4472-84fb-1e4b76aa128d,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-7bb271cf-0913-41ee-aecf-7daef3c0ffcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-9f787535-25c2-4c4a-ad0f-dd32ca6b1377,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-838794417-172.17.0.15-1595606241666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39046,DS-9e667918-2671-44e8-be9d-03e6ed87e4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-f3272b04-c029-40e6-a5a8-319c63185176,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-99e7ca49-ce84-444f-91a0-86c98fa7fccb,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-16fa9a25-9388-49a6-b359-193e6553cd65,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-a89d0f9f-e0de-446d-a65c-b31cb91cbce0,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-1e584479-b9d2-41cf-b8bd-af03f98380f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-eb48a4dd-b995-4b5b-b545-d51cfb1014c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-50e745b7-f0e7-41a2-b33d-51a06468d208,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-838794417-172.17.0.15-1595606241666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39046,DS-9e667918-2671-44e8-be9d-03e6ed87e4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-f3272b04-c029-40e6-a5a8-319c63185176,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-99e7ca49-ce84-444f-91a0-86c98fa7fccb,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-16fa9a25-9388-49a6-b359-193e6553cd65,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-a89d0f9f-e0de-446d-a65c-b31cb91cbce0,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-1e584479-b9d2-41cf-b8bd-af03f98380f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-eb48a4dd-b995-4b5b-b545-d51cfb1014c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-50e745b7-f0e7-41a2-b33d-51a06468d208,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757885662-172.17.0.15-1595606273626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40963,DS-0e52abce-4166-42b9-ae9d-d874832a4917,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-270bb105-3ce8-414d-b2e7-44e0af501bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-c91db241-4aaf-4bb0-8dd4-65280a72b1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-6a047530-585a-4043-88ce-8d9188b2a8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-effee4c3-01a0-4ad3-b1e1-2ae64b3f8480,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-f2413f2b-5b48-4356-ae8c-47a025f1611d,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-974e6b7e-d53d-43e9-89c7-43ea98c183b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-3d90a048-58b3-4ccf-962f-70d399d588fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757885662-172.17.0.15-1595606273626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40963,DS-0e52abce-4166-42b9-ae9d-d874832a4917,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-270bb105-3ce8-414d-b2e7-44e0af501bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-c91db241-4aaf-4bb0-8dd4-65280a72b1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-6a047530-585a-4043-88ce-8d9188b2a8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-effee4c3-01a0-4ad3-b1e1-2ae64b3f8480,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-f2413f2b-5b48-4356-ae8c-47a025f1611d,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-974e6b7e-d53d-43e9-89c7-43ea98c183b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-3d90a048-58b3-4ccf-962f-70d399d588fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1790657148-172.17.0.15-1595606885502:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42020,DS-45b52d1b-a551-43f4-b22d-69c393023eae,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-56609ae5-7a6a-455b-886e-4e3cd990329f,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-351373a0-aa31-4df1-a37e-de85db13d069,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-ccd397b2-c7ea-4a9e-a680-d963a49c300c,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-e24cb1c6-fa8a-45b9-b9c9-ca48bf028b86,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-4947c133-2bf3-4022-9189-cba2e42e8437,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-6072e7c8-8ccc-401b-84df-0c534cc54b04,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-63023c9a-2485-4087-8fe4-c0b8d186b6f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1790657148-172.17.0.15-1595606885502:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42020,DS-45b52d1b-a551-43f4-b22d-69c393023eae,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-56609ae5-7a6a-455b-886e-4e3cd990329f,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-351373a0-aa31-4df1-a37e-de85db13d069,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-ccd397b2-c7ea-4a9e-a680-d963a49c300c,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-e24cb1c6-fa8a-45b9-b9c9-ca48bf028b86,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-4947c133-2bf3-4022-9189-cba2e42e8437,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-6072e7c8-8ccc-401b-84df-0c534cc54b04,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-63023c9a-2485-4087-8fe4-c0b8d186b6f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5185
