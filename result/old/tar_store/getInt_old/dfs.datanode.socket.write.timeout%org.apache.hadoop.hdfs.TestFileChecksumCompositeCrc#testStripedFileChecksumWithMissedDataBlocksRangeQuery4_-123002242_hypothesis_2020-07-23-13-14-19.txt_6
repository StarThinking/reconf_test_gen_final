reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809285869-172.17.0.8-1595510105953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35238,DS-79372d95-3d83-47d7-9f4f-803c9c5f7f35,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-77456eaf-5522-4a54-ae98-e826b7f80afc,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-318917e2-c2fb-44eb-9cca-7f6911297a22,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-6ad49b51-f092-4d32-9858-ade1d5b51438,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-1a058c05-11f0-4800-81a7-e79aeeb5d21b,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-82fbe482-021e-4abc-b046-305e45efcc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-df1c198a-58d6-4c81-91d0-092b90283a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-cb1a284a-a2f8-480e-8b6d-a7d20fc9a013,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809285869-172.17.0.8-1595510105953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35238,DS-79372d95-3d83-47d7-9f4f-803c9c5f7f35,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-77456eaf-5522-4a54-ae98-e826b7f80afc,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-318917e2-c2fb-44eb-9cca-7f6911297a22,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-6ad49b51-f092-4d32-9858-ade1d5b51438,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-1a058c05-11f0-4800-81a7-e79aeeb5d21b,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-82fbe482-021e-4abc-b046-305e45efcc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-df1c198a-58d6-4c81-91d0-092b90283a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-cb1a284a-a2f8-480e-8b6d-a7d20fc9a013,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642739497-172.17.0.8-1595510882391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37160,DS-12ea2422-4bba-4764-9452-caa01fadd5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-a45703ea-1911-4451-98bc-740ebe97d262,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-7e946245-1678-418e-9269-aab83ad0024a,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-57d0d247-c51a-4702-a19c-c697798b9de6,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-b1fe9441-6d86-4ab3-b8e8-6a32183c92e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-ce92af86-69c6-49e3-ba6e-c620819c2b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-279ae671-f11e-45b1-a5b9-f8ec3d17ecaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-e4f865fe-3228-41d9-a7c4-fda1f34f9e1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642739497-172.17.0.8-1595510882391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37160,DS-12ea2422-4bba-4764-9452-caa01fadd5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-a45703ea-1911-4451-98bc-740ebe97d262,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-7e946245-1678-418e-9269-aab83ad0024a,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-57d0d247-c51a-4702-a19c-c697798b9de6,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-b1fe9441-6d86-4ab3-b8e8-6a32183c92e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-ce92af86-69c6-49e3-ba6e-c620819c2b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-279ae671-f11e-45b1-a5b9-f8ec3d17ecaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-e4f865fe-3228-41d9-a7c4-fda1f34f9e1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82566303-172.17.0.8-1595510996756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43095,DS-4e97c07d-e385-4fa9-b225-0c7be7f149ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-dcef3ea8-3617-4a69-a2af-2612250b9566,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-8b247db4-53a1-4a6f-8eff-504f297ac2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-5dad3b70-53f3-4240-8aef-f5ec339ffab8,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-1af840fd-9e26-4adc-8dd5-c7773cc76c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-4ab0f417-9715-4d3d-9106-e2741ee127bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-e8137a0a-47d3-4a2a-a56e-a83a96da069d,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-43808a24-d83d-4948-ba83-2ca6a0a775f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82566303-172.17.0.8-1595510996756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43095,DS-4e97c07d-e385-4fa9-b225-0c7be7f149ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-dcef3ea8-3617-4a69-a2af-2612250b9566,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-8b247db4-53a1-4a6f-8eff-504f297ac2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-5dad3b70-53f3-4240-8aef-f5ec339ffab8,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-1af840fd-9e26-4adc-8dd5-c7773cc76c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-4ab0f417-9715-4d3d-9106-e2741ee127bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-e8137a0a-47d3-4a2a-a56e-a83a96da069d,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-43808a24-d83d-4948-ba83-2ca6a0a775f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776891578-172.17.0.8-1595511756973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44166,DS-34ea1044-3430-4ecc-8ab3-759f0ac27a22,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-4ac7ef98-be55-4e24-a4fb-3185e6a34214,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-d4d574c0-4e9d-41b8-bb14-9a95ce4370be,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-bc19b9de-8149-4878-bae0-f5086640015d,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-113b4133-8ade-4153-ad72-6fae4ac2807f,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-551b23c4-654f-45e2-87d2-e7b9ff1d7f26,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-847c57be-218d-4cf2-a3f3-aefd4221f6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-51ee5a5d-be62-4b0e-82dd-728bd6a64cf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776891578-172.17.0.8-1595511756973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44166,DS-34ea1044-3430-4ecc-8ab3-759f0ac27a22,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-4ac7ef98-be55-4e24-a4fb-3185e6a34214,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-d4d574c0-4e9d-41b8-bb14-9a95ce4370be,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-bc19b9de-8149-4878-bae0-f5086640015d,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-113b4133-8ade-4153-ad72-6fae4ac2807f,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-551b23c4-654f-45e2-87d2-e7b9ff1d7f26,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-847c57be-218d-4cf2-a3f3-aefd4221f6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-51ee5a5d-be62-4b0e-82dd-728bd6a64cf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-591175271-172.17.0.8-1595511865234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34354,DS-1955b2bb-7839-4c86-9885-fb55dc69d536,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-4431d60e-93b8-4e27-80be-4af6d8701978,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-7ae3b063-4c4f-4cb7-8870-9de9b2488d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-cbaefcd3-6ac1-4b02-bf99-466e83ddedfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-9bb457cf-1a25-4bc9-baaf-60c305251285,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-857ab05f-7759-4921-bae0-9687d1202088,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-73d25e8e-4184-4d9e-aebb-5b043ab5c1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-48b00971-0d99-4f2c-b7a1-bd230bce48f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-591175271-172.17.0.8-1595511865234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34354,DS-1955b2bb-7839-4c86-9885-fb55dc69d536,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-4431d60e-93b8-4e27-80be-4af6d8701978,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-7ae3b063-4c4f-4cb7-8870-9de9b2488d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-cbaefcd3-6ac1-4b02-bf99-466e83ddedfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-9bb457cf-1a25-4bc9-baaf-60c305251285,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-857ab05f-7759-4921-bae0-9687d1202088,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-73d25e8e-4184-4d9e-aebb-5b043ab5c1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-48b00971-0d99-4f2c-b7a1-bd230bce48f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615413167-172.17.0.8-1595511903134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33415,DS-01678a0e-19c9-4045-beca-6cf3432fb9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-710f0574-0b70-49b3-8a88-34f94e134227,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-e3cedffe-31b4-4799-be58-8dcda12d5bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-da2257c6-cfae-4e26-a905-389ae24d1a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-b2d33cd9-b194-4611-bc86-b4ae8c5b17c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-ebffee8a-ccc0-4f0f-be6d-1542f831c53f,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-fd492b47-6600-4c97-8bec-73eaf05d1fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-350ba857-3212-4c39-91a6-09c61fd31136,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615413167-172.17.0.8-1595511903134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33415,DS-01678a0e-19c9-4045-beca-6cf3432fb9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-710f0574-0b70-49b3-8a88-34f94e134227,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-e3cedffe-31b4-4799-be58-8dcda12d5bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-da2257c6-cfae-4e26-a905-389ae24d1a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-b2d33cd9-b194-4611-bc86-b4ae8c5b17c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-ebffee8a-ccc0-4f0f-be6d-1542f831c53f,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-fd492b47-6600-4c97-8bec-73eaf05d1fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-350ba857-3212-4c39-91a6-09c61fd31136,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-19656149-172.17.0.8-1595512362281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35038,DS-e295cb2b-d65e-4e3f-8d9f-f639ad8fb34e,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-2948e72a-f3d5-4475-b4f7-439ba2c33b55,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-715faeab-e248-4920-a45d-8cce9b2a68a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-06a8d737-2ba0-4eeb-a5de-891da4a2ad2d,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-2d6e147a-6d8e-4f42-aaf5-cc762aaff8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-2d711691-7e4b-41fe-bdb1-a3853567f063,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-61b6c49c-4d47-40a3-98d7-6d8ea76152fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-5201076d-06cb-4ba7-b1a9-128b7be8910c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-19656149-172.17.0.8-1595512362281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35038,DS-e295cb2b-d65e-4e3f-8d9f-f639ad8fb34e,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-2948e72a-f3d5-4475-b4f7-439ba2c33b55,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-715faeab-e248-4920-a45d-8cce9b2a68a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-06a8d737-2ba0-4eeb-a5de-891da4a2ad2d,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-2d6e147a-6d8e-4f42-aaf5-cc762aaff8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-2d711691-7e4b-41fe-bdb1-a3853567f063,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-61b6c49c-4d47-40a3-98d7-6d8ea76152fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-5201076d-06cb-4ba7-b1a9-128b7be8910c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146554491-172.17.0.8-1595512786427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44416,DS-4bfe36cd-d7ad-4406-923c-c242d197bed8,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-4c103231-a49f-4c23-a0c0-2fbc95f7a87c,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-633b1a75-5424-4744-89e9-eb091639143d,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-5dac0dd4-f596-4936-a289-e7a05c5636b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-7225af6e-b90a-4f8b-97d0-8e2e57193edf,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-26800238-31a7-4310-bb83-455a7998a27b,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-d5e88888-1c9d-4ab3-8092-9dfcc90c493e,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-c6e142e1-b525-4a66-93de-915171f5f74d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146554491-172.17.0.8-1595512786427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44416,DS-4bfe36cd-d7ad-4406-923c-c242d197bed8,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-4c103231-a49f-4c23-a0c0-2fbc95f7a87c,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-633b1a75-5424-4744-89e9-eb091639143d,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-5dac0dd4-f596-4936-a289-e7a05c5636b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-7225af6e-b90a-4f8b-97d0-8e2e57193edf,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-26800238-31a7-4310-bb83-455a7998a27b,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-d5e88888-1c9d-4ab3-8092-9dfcc90c493e,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-c6e142e1-b525-4a66-93de-915171f5f74d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650328763-172.17.0.8-1595513028947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44022,DS-9769ad5e-0b40-4db0-8f44-b4b9911f1aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-e240a7ff-448d-47ba-87da-acbd1e8a6a66,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-9a23beb1-997c-47c9-8782-15cc2f1443c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-f4c03b1f-2982-4533-acc3-3097e75e275b,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-fb2322c0-8be1-499f-bad5-a230a8b56050,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-3a23e55b-b3ba-4a6c-a9d7-8d18326df599,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-bc87c83b-f9ad-479e-9228-22111ab773b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-cce3ffb3-a5f8-40f5-b0e2-cb01daf22a80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650328763-172.17.0.8-1595513028947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44022,DS-9769ad5e-0b40-4db0-8f44-b4b9911f1aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-e240a7ff-448d-47ba-87da-acbd1e8a6a66,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-9a23beb1-997c-47c9-8782-15cc2f1443c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-f4c03b1f-2982-4533-acc3-3097e75e275b,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-fb2322c0-8be1-499f-bad5-a230a8b56050,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-3a23e55b-b3ba-4a6c-a9d7-8d18326df599,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-bc87c83b-f9ad-479e-9228-22111ab773b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-cce3ffb3-a5f8-40f5-b0e2-cb01daf22a80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-556423764-172.17.0.8-1595513341908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37668,DS-a8a520fa-7090-4a6d-8ce6-03d39786cc80,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-59465923-1cc5-45bc-8c98-9bd44b82ab9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-8c8678a3-2a3d-4016-a676-7ed1f78b59bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-cc54c684-6572-4be4-93c5-442b4f299f28,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-a8860fd9-2979-4fc5-84f9-04750d29b6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-7da05d16-b913-421c-8358-e6f90c659dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-0df3b147-0a5d-431f-9682-e6fb1c1a39bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-e78bbb8b-d65c-4009-8fd1-b7c9eab886b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-556423764-172.17.0.8-1595513341908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37668,DS-a8a520fa-7090-4a6d-8ce6-03d39786cc80,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-59465923-1cc5-45bc-8c98-9bd44b82ab9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-8c8678a3-2a3d-4016-a676-7ed1f78b59bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-cc54c684-6572-4be4-93c5-442b4f299f28,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-a8860fd9-2979-4fc5-84f9-04750d29b6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-7da05d16-b913-421c-8358-e6f90c659dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-0df3b147-0a5d-431f-9682-e6fb1c1a39bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-e78bbb8b-d65c-4009-8fd1-b7c9eab886b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146901207-172.17.0.8-1595514468474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38328,DS-0389d815-af66-40b9-bd23-08f19e7035d1,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-2abadbf7-4a86-46fb-8434-e49fff34f969,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-97b92706-7f18-4843-b9c2-674cf664b85b,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-1c5c908f-2e0c-47ed-bc67-fdcab98d699a,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-894eac8e-a89b-415e-92c2-5b2f9c49a8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-71d69455-5f29-4809-a047-0559546424eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-1d16bcd1-0db4-4a05-a291-242c1165f214,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-d3e337ed-ce88-4394-952f-8e4860aabb4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146901207-172.17.0.8-1595514468474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38328,DS-0389d815-af66-40b9-bd23-08f19e7035d1,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-2abadbf7-4a86-46fb-8434-e49fff34f969,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-97b92706-7f18-4843-b9c2-674cf664b85b,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-1c5c908f-2e0c-47ed-bc67-fdcab98d699a,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-894eac8e-a89b-415e-92c2-5b2f9c49a8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-71d69455-5f29-4809-a047-0559546424eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-1d16bcd1-0db4-4a05-a291-242c1165f214,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-d3e337ed-ce88-4394-952f-8e4860aabb4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139740486-172.17.0.8-1595515048306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35158,DS-e1d7c28a-48f0-42ef-b054-c6d8c00e92ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-54ad2312-8c67-40e8-b92d-f5747e23f86f,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-b430592e-c53b-4387-917f-42d3d2d194c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-b3845c47-ef98-4967-9163-716c5d52b3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-610c9ca1-f588-4d9b-902b-0a70f9933948,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-6e8083d6-dbbe-416e-b676-0476ce2b161f,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-14ad5d79-5f82-4477-9067-f517b8b43167,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-aa0cbb8c-e999-4ef4-8896-07ece2e5a3a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139740486-172.17.0.8-1595515048306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35158,DS-e1d7c28a-48f0-42ef-b054-c6d8c00e92ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-54ad2312-8c67-40e8-b92d-f5747e23f86f,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-b430592e-c53b-4387-917f-42d3d2d194c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-b3845c47-ef98-4967-9163-716c5d52b3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-610c9ca1-f588-4d9b-902b-0a70f9933948,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-6e8083d6-dbbe-416e-b676-0476ce2b161f,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-14ad5d79-5f82-4477-9067-f517b8b43167,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-aa0cbb8c-e999-4ef4-8896-07ece2e5a3a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560252921-172.17.0.8-1595515165570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45414,DS-f1912751-38de-47e3-9022-a92a802e3823,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-4593ec63-8b4c-4920-b683-4b52f688aae1,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-9765a925-9315-4e0d-80c8-9ba57cc4e4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-9db44785-3cb2-4d87-b3c2-5b2fd5830ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-d714b833-30f5-4ccf-ba3e-6cf07de141c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-7ed5ea5f-e900-4a09-a255-8be9bd483b87,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-72768c59-088a-4fca-92d4-9b6c7ac15f72,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-fe327735-77ae-47f8-8445-c2e60803c121,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560252921-172.17.0.8-1595515165570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45414,DS-f1912751-38de-47e3-9022-a92a802e3823,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-4593ec63-8b4c-4920-b683-4b52f688aae1,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-9765a925-9315-4e0d-80c8-9ba57cc4e4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-9db44785-3cb2-4d87-b3c2-5b2fd5830ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-d714b833-30f5-4ccf-ba3e-6cf07de141c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-7ed5ea5f-e900-4a09-a255-8be9bd483b87,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-72768c59-088a-4fca-92d4-9b6c7ac15f72,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-fe327735-77ae-47f8-8445-c2e60803c121,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507500171-172.17.0.8-1595515354943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35164,DS-c7801f8a-1154-4ede-804e-361fa4b485f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-103acd01-f93b-4ea3-a8d8-b6a198765c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-a40a73a3-f478-4119-8112-eaa422fc2256,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-3be93e63-a764-427e-a277-063ff9ed3f11,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-41ee8c2c-d4d4-4aeb-88b4-891872ac195f,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-28f8f599-e895-4341-aa90-aa46b58eef67,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-35058af9-1f6f-4498-a5ef-5354a1b48828,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-6da5c523-717f-4b59-8a56-68cefa1d1c4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507500171-172.17.0.8-1595515354943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35164,DS-c7801f8a-1154-4ede-804e-361fa4b485f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-103acd01-f93b-4ea3-a8d8-b6a198765c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-a40a73a3-f478-4119-8112-eaa422fc2256,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-3be93e63-a764-427e-a277-063ff9ed3f11,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-41ee8c2c-d4d4-4aeb-88b4-891872ac195f,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-28f8f599-e895-4341-aa90-aa46b58eef67,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-35058af9-1f6f-4498-a5ef-5354a1b48828,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-6da5c523-717f-4b59-8a56-68cefa1d1c4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5658
