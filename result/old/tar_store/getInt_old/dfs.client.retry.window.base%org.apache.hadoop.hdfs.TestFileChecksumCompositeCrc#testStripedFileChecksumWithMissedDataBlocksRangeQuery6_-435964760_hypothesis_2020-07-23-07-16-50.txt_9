reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730749646-172.17.0.15-1595488625204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41551,DS-97d9d13f-1e30-400a-a720-c9630ec7c70b,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-4a8d9d3a-b56c-4f5a-b9d4-1e19933818e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-efa59c04-6f74-4fd7-824e-3df7a28a0939,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-d5a16359-b1c1-469b-8a60-199678ad580e,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-97eb5d8e-4a2b-41dd-beaf-62a0d2e11d22,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-20e81bbc-6d09-4826-b7f4-bf632cd0dff7,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-2a45f275-67e2-4190-abd1-c644d6ed9b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-e4358ca4-7cf0-4cfa-961a-664102e26a7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730749646-172.17.0.15-1595488625204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41551,DS-97d9d13f-1e30-400a-a720-c9630ec7c70b,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-4a8d9d3a-b56c-4f5a-b9d4-1e19933818e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-efa59c04-6f74-4fd7-824e-3df7a28a0939,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-d5a16359-b1c1-469b-8a60-199678ad580e,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-97eb5d8e-4a2b-41dd-beaf-62a0d2e11d22,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-20e81bbc-6d09-4826-b7f4-bf632cd0dff7,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-2a45f275-67e2-4190-abd1-c644d6ed9b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-e4358ca4-7cf0-4cfa-961a-664102e26a7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1180692194-172.17.0.15-1595488778086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38430,DS-e150955f-fb5f-401c-ae2d-0109f517505f,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-a703e432-e9fe-491a-8dc8-5ec74278563d,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-b8ef8b52-1ad7-40c0-aaa4-93d83b7d1e26,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-fa10ce80-17dc-4e4f-b495-1df9e6b0f083,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-f5d023cc-b5bd-40ac-aa37-03eb0daf0631,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-8c02a544-ceee-47ff-94ee-9eb2fd584808,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-82585e1e-8e15-4456-abb1-a6478cd16c79,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-c207d34d-3ce4-42ab-baa3-81e2ae15cb4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1180692194-172.17.0.15-1595488778086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38430,DS-e150955f-fb5f-401c-ae2d-0109f517505f,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-a703e432-e9fe-491a-8dc8-5ec74278563d,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-b8ef8b52-1ad7-40c0-aaa4-93d83b7d1e26,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-fa10ce80-17dc-4e4f-b495-1df9e6b0f083,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-f5d023cc-b5bd-40ac-aa37-03eb0daf0631,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-8c02a544-ceee-47ff-94ee-9eb2fd584808,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-82585e1e-8e15-4456-abb1-a6478cd16c79,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-c207d34d-3ce4-42ab-baa3-81e2ae15cb4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-333701396-172.17.0.15-1595488811251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40991,DS-830e0c87-edcb-4d9d-8d72-51f6b50fe894,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-ca10d03b-6e73-451c-9bbb-aad2658cb0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-16ec2917-2879-403d-9e0f-fbd1254af7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-5a8fa07b-0c08-4e46-8024-c27e19c1b332,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-21a939ac-bcaf-4cc2-a970-1c434f435115,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-caba6897-17f2-4ac3-81b2-133540631757,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-9c8eaf11-ef8a-402e-a4e3-896893ab720d,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-e2ece089-274b-44d5-9d5d-c94b382d6536,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-333701396-172.17.0.15-1595488811251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40991,DS-830e0c87-edcb-4d9d-8d72-51f6b50fe894,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-ca10d03b-6e73-451c-9bbb-aad2658cb0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-16ec2917-2879-403d-9e0f-fbd1254af7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-5a8fa07b-0c08-4e46-8024-c27e19c1b332,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-21a939ac-bcaf-4cc2-a970-1c434f435115,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-caba6897-17f2-4ac3-81b2-133540631757,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-9c8eaf11-ef8a-402e-a4e3-896893ab720d,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-e2ece089-274b-44d5-9d5d-c94b382d6536,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774195824-172.17.0.15-1595489310013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38586,DS-82e76030-b575-45eb-adef-c591287bcebc,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-099635e2-6fa7-424b-a549-626121224383,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-f1cb55b0-40d3-4932-a614-79b2d558ea05,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-ccbf9782-6cde-438b-9915-2520c8078d09,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-bce7e408-644c-43dc-9128-9b0cdcb06d27,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-624d1b24-e6df-4107-b2fc-290b4d09ee19,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-216394fb-32d7-4852-8a09-3df1e66e0ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-37042d26-74bc-40ef-9129-159d8e10c421,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774195824-172.17.0.15-1595489310013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38586,DS-82e76030-b575-45eb-adef-c591287bcebc,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-099635e2-6fa7-424b-a549-626121224383,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-f1cb55b0-40d3-4932-a614-79b2d558ea05,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-ccbf9782-6cde-438b-9915-2520c8078d09,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-bce7e408-644c-43dc-9128-9b0cdcb06d27,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-624d1b24-e6df-4107-b2fc-290b4d09ee19,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-216394fb-32d7-4852-8a09-3df1e66e0ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-37042d26-74bc-40ef-9129-159d8e10c421,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352420596-172.17.0.15-1595489350756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33903,DS-9e10a954-338a-4f87-98f8-cf122cf07ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-3963aaf2-08e7-4e0e-b20f-89a28781abcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-b9dd1263-1299-43fa-8d45-6daffeab0fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-5f6c23d3-ea83-4766-8529-54eaae446544,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-44aa26d0-4bc5-4061-ae35-cffcd523e661,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-487d4243-3741-4f1d-89e2-d8035b2e46f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-78ebe7c2-2eb8-44eb-90e5-fb51ae38e7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-c0897a53-0487-405b-9c19-af34febc36aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352420596-172.17.0.15-1595489350756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33903,DS-9e10a954-338a-4f87-98f8-cf122cf07ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-3963aaf2-08e7-4e0e-b20f-89a28781abcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-b9dd1263-1299-43fa-8d45-6daffeab0fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-5f6c23d3-ea83-4766-8529-54eaae446544,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-44aa26d0-4bc5-4061-ae35-cffcd523e661,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-487d4243-3741-4f1d-89e2-d8035b2e46f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-78ebe7c2-2eb8-44eb-90e5-fb51ae38e7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-c0897a53-0487-405b-9c19-af34febc36aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2033737380-172.17.0.15-1595489455532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39831,DS-65bea840-54d2-450e-96d6-1a2da7465e21,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-15816a4f-71db-468c-b582-28aeef8903f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-6e45585d-630f-4064-8c36-cc12d396e6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-1d97634c-a1a8-41de-8b96-5cee374e5f80,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-4357da54-82f3-471f-b5ed-817abc6b76b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-2c897c5b-c4ec-4756-89cd-d21cf0a71879,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-f8e6069d-3426-48cc-85b7-348be7090b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-24b6cc3c-2744-4fd3-91d3-dbe17e65813b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2033737380-172.17.0.15-1595489455532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39831,DS-65bea840-54d2-450e-96d6-1a2da7465e21,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-15816a4f-71db-468c-b582-28aeef8903f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-6e45585d-630f-4064-8c36-cc12d396e6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-1d97634c-a1a8-41de-8b96-5cee374e5f80,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-4357da54-82f3-471f-b5ed-817abc6b76b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-2c897c5b-c4ec-4756-89cd-d21cf0a71879,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-f8e6069d-3426-48cc-85b7-348be7090b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-24b6cc3c-2744-4fd3-91d3-dbe17e65813b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1490415188-172.17.0.15-1595490031159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41742,DS-936ed98f-9177-4742-bd26-b9e85be65248,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-a4e0921d-a295-433b-a90b-155ed3f770dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-4add9a6d-2ffe-4d7f-af70-4f6193acdf60,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-8db44b31-5ba7-4810-94dc-e3e9946df622,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-c95ea18f-e1da-4b54-a357-a4cc5c01d2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-d7069384-56d3-4265-9c84-c91892d5e43e,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-746dd72c-a2f7-4096-ad21-389056b3d5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-5f27c93e-2668-40de-8a87-abd1b61e1d46,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1490415188-172.17.0.15-1595490031159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41742,DS-936ed98f-9177-4742-bd26-b9e85be65248,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-a4e0921d-a295-433b-a90b-155ed3f770dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-4add9a6d-2ffe-4d7f-af70-4f6193acdf60,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-8db44b31-5ba7-4810-94dc-e3e9946df622,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-c95ea18f-e1da-4b54-a357-a4cc5c01d2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-d7069384-56d3-4265-9c84-c91892d5e43e,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-746dd72c-a2f7-4096-ad21-389056b3d5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-5f27c93e-2668-40de-8a87-abd1b61e1d46,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428657770-172.17.0.15-1595490066105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33796,DS-ad509f45-5271-49ce-bdcb-baa417626d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-04fb1032-3600-4768-a0fa-374c290f0200,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-a2446961-558c-417c-8e32-59a6f79675c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-77380014-4057-4f1d-9476-fe51d9bd99df,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-801dfa87-4125-4246-9025-4d9b2fe7d5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-2b976a8a-f5a9-4e5f-9577-46de7b48d6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-c612de0d-ab93-4172-9594-1656fafc4726,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-f5014f68-493b-4f9f-9c1e-8da653639abe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428657770-172.17.0.15-1595490066105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33796,DS-ad509f45-5271-49ce-bdcb-baa417626d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-04fb1032-3600-4768-a0fa-374c290f0200,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-a2446961-558c-417c-8e32-59a6f79675c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-77380014-4057-4f1d-9476-fe51d9bd99df,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-801dfa87-4125-4246-9025-4d9b2fe7d5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-2b976a8a-f5a9-4e5f-9577-46de7b48d6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-c612de0d-ab93-4172-9594-1656fafc4726,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-f5014f68-493b-4f9f-9c1e-8da653639abe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743526667-172.17.0.15-1595490142797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37999,DS-c2ae3600-47d8-465a-bd53-d84b8dc7c77d,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-1fffa5f4-a188-4c2d-b6ed-3fdd333ebe04,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-0b698acf-de2b-4405-bddf-e8720a8deeca,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-4ee11e29-89f5-4412-bee0-c022daf87ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-7c4fde8e-18e9-4f58-aa6c-20b27b840a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-85e04eaf-fba8-4971-851b-a3f6ed7693da,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-d3334a5c-bcb9-4df6-9cab-742a14c00f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-d06d99bd-d532-42b0-bede-c8fd8bbec76d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743526667-172.17.0.15-1595490142797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37999,DS-c2ae3600-47d8-465a-bd53-d84b8dc7c77d,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-1fffa5f4-a188-4c2d-b6ed-3fdd333ebe04,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-0b698acf-de2b-4405-bddf-e8720a8deeca,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-4ee11e29-89f5-4412-bee0-c022daf87ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-7c4fde8e-18e9-4f58-aa6c-20b27b840a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-85e04eaf-fba8-4971-851b-a3f6ed7693da,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-d3334a5c-bcb9-4df6-9cab-742a14c00f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-d06d99bd-d532-42b0-bede-c8fd8bbec76d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1576211051-172.17.0.15-1595490295724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42184,DS-21ebfcb3-2ec7-4521-8550-6e13486736ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-893e58dc-a8cf-43b2-b84f-419ceceb287e,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-272ad0a9-7615-4ad5-b61f-d6e692a9b2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-05400203-8f6a-4301-80b2-5c645af59ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-948f6dbd-ad9d-4f57-8fb0-13307bf1fe80,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-3d3bc200-4bdd-4666-9808-dcc0c3bea69c,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-219c967c-e284-408b-92a7-91e6c0c32117,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-5558a7f8-d9d8-4bee-9c5e-4b86b28e0eb7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1576211051-172.17.0.15-1595490295724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42184,DS-21ebfcb3-2ec7-4521-8550-6e13486736ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-893e58dc-a8cf-43b2-b84f-419ceceb287e,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-272ad0a9-7615-4ad5-b61f-d6e692a9b2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-05400203-8f6a-4301-80b2-5c645af59ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-948f6dbd-ad9d-4f57-8fb0-13307bf1fe80,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-3d3bc200-4bdd-4666-9808-dcc0c3bea69c,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-219c967c-e284-408b-92a7-91e6c0c32117,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-5558a7f8-d9d8-4bee-9c5e-4b86b28e0eb7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260826124-172.17.0.15-1595490730111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46232,DS-56753e2b-f223-4cd0-9cad-6c86a29588ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-e8450707-8fec-466e-b5d2-76522eba3508,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-52b843af-d21f-4246-88e4-c14c03fafc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-a1405454-03c7-4437-b5a1-bcf822b54da4,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-924c1faa-182a-46da-9631-0c3bf135fa4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-3ff8070a-0aff-44da-a1c0-34ab6d62c20d,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-8987642c-dc8b-4ae1-ad98-65350e1322d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-d138168b-c31a-4914-99de-4121f5fd4503,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260826124-172.17.0.15-1595490730111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46232,DS-56753e2b-f223-4cd0-9cad-6c86a29588ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-e8450707-8fec-466e-b5d2-76522eba3508,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-52b843af-d21f-4246-88e4-c14c03fafc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-a1405454-03c7-4437-b5a1-bcf822b54da4,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-924c1faa-182a-46da-9631-0c3bf135fa4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-3ff8070a-0aff-44da-a1c0-34ab6d62c20d,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-8987642c-dc8b-4ae1-ad98-65350e1322d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-d138168b-c31a-4914-99de-4121f5fd4503,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629666771-172.17.0.15-1595491232163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39449,DS-56eac965-b498-4b33-a385-46c02b2500a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-3ef0806f-b817-45d3-a32a-4f903b3f260a,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-ab695b91-4156-4cb6-8e88-c9cc41913bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-13a7da07-71f4-4024-a25a-0eb947722b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-8063d0f9-893d-44ec-8253-acdbcebad159,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-42d1075b-80ff-4b25-995c-dd1f7962788f,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-64a9f32d-0b82-4521-b196-43895d6717ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-0577e514-7546-46b7-a516-762b952d19dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629666771-172.17.0.15-1595491232163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39449,DS-56eac965-b498-4b33-a385-46c02b2500a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-3ef0806f-b817-45d3-a32a-4f903b3f260a,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-ab695b91-4156-4cb6-8e88-c9cc41913bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-13a7da07-71f4-4024-a25a-0eb947722b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-8063d0f9-893d-44ec-8253-acdbcebad159,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-42d1075b-80ff-4b25-995c-dd1f7962788f,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-64a9f32d-0b82-4521-b196-43895d6717ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-0577e514-7546-46b7-a516-762b952d19dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958753034-172.17.0.15-1595491632203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41298,DS-7605a643-56c4-4c37-bb91-cd8e5bcd1673,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-b786a579-8080-4206-aa45-b11bd1314de5,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-cbacccde-41f7-4419-a5b5-259e71814603,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-55427055-9fe1-47b6-9088-ee31e80bfab8,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-924e7211-a78c-4a8a-83a2-abb9174965aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-b978b449-ffd8-4b09-bd9f-0497b074b128,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-b4cb1a00-bc77-437b-b365-0bf887e63962,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-ee49d09d-9f89-455c-ad8e-517c2e4d50ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958753034-172.17.0.15-1595491632203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41298,DS-7605a643-56c4-4c37-bb91-cd8e5bcd1673,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-b786a579-8080-4206-aa45-b11bd1314de5,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-cbacccde-41f7-4419-a5b5-259e71814603,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-55427055-9fe1-47b6-9088-ee31e80bfab8,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-924e7211-a78c-4a8a-83a2-abb9174965aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-b978b449-ffd8-4b09-bd9f-0497b074b128,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-b4cb1a00-bc77-437b-b365-0bf887e63962,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-ee49d09d-9f89-455c-ad8e-517c2e4d50ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46713645-172.17.0.15-1595491800626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35943,DS-8e4596fe-e9bd-4f1a-b241-353c4dcb671c,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-34a59e15-cfad-4f4a-943b-a9d62a9b54f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-e99ae25e-34d1-49fb-8f66-a72c532b0386,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-69bf3149-06f2-4048-81aa-9a74fc02aba5,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-d78fe0b1-e1df-4c52-af0c-91e565527ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-b8ffd19b-0d06-441f-9f7b-8914c2e114f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-71c8bad8-1636-495f-9f67-85224fc08b79,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-28d1964d-852d-4c34-a9b5-8baa3e02000e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46713645-172.17.0.15-1595491800626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35943,DS-8e4596fe-e9bd-4f1a-b241-353c4dcb671c,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-34a59e15-cfad-4f4a-943b-a9d62a9b54f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-e99ae25e-34d1-49fb-8f66-a72c532b0386,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-69bf3149-06f2-4048-81aa-9a74fc02aba5,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-d78fe0b1-e1df-4c52-af0c-91e565527ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-b8ffd19b-0d06-441f-9f7b-8914c2e114f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-71c8bad8-1636-495f-9f67-85224fc08b79,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-28d1964d-852d-4c34-a9b5-8baa3e02000e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-373844337-172.17.0.15-1595491952340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44969,DS-963f7106-d243-494d-a098-f05b76201b45,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-003bcd24-5dab-45e2-8548-41c54434a3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-68c9a938-0cd0-4a06-8a5d-95f901fc3c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39630,DS-4fab816c-1595-4fa0-8383-733fea203f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-7716890f-7d9c-475e-8ff1-41fc54763831,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-a2ab99bd-6665-44aa-afec-c7ebfe599bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-a16e0a6a-04b1-4c50-b0f4-58f03c12a2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-1aff1388-2dc1-4ae4-8c2a-20735cb5fcf1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-373844337-172.17.0.15-1595491952340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44969,DS-963f7106-d243-494d-a098-f05b76201b45,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-003bcd24-5dab-45e2-8548-41c54434a3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-68c9a938-0cd0-4a06-8a5d-95f901fc3c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39630,DS-4fab816c-1595-4fa0-8383-733fea203f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-7716890f-7d9c-475e-8ff1-41fc54763831,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-a2ab99bd-6665-44aa-afec-c7ebfe599bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-a16e0a6a-04b1-4c50-b0f4-58f03c12a2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-1aff1388-2dc1-4ae4-8c2a-20735cb5fcf1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950401308-172.17.0.15-1595492261881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35626,DS-527b2ca2-347f-4bf2-9e2d-595779ae0ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-c87e4f3e-8eb5-4426-84dd-dea0a1e4479e,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-c6f89950-611d-4bea-97e9-1006b070658e,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-ef23003d-2777-4e2c-aa58-61a29b83b241,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-70b53d0b-2471-4e5a-95b1-3db7eceebe3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-7aba459e-aaff-49a9-9e84-773670eb3ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-8a2be5a1-1c1a-4a5b-82af-0195c9df81a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-816c6266-7c6a-4389-a57e-0d1ba432e992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950401308-172.17.0.15-1595492261881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35626,DS-527b2ca2-347f-4bf2-9e2d-595779ae0ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-c87e4f3e-8eb5-4426-84dd-dea0a1e4479e,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-c6f89950-611d-4bea-97e9-1006b070658e,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-ef23003d-2777-4e2c-aa58-61a29b83b241,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-70b53d0b-2471-4e5a-95b1-3db7eceebe3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-7aba459e-aaff-49a9-9e84-773670eb3ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-8a2be5a1-1c1a-4a5b-82af-0195c9df81a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-816c6266-7c6a-4389-a57e-0d1ba432e992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1508057556-172.17.0.15-1595492299223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43033,DS-939e6711-bbe9-4364-82af-41321b8f55b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-2762259c-38f9-4ccb-bf72-9bee98ed2117,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-186560b6-e9ac-4072-9710-5212fc77c1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-9dcc7e30-048b-4096-8beb-5663b2a5c5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-d71de69c-d605-471b-9826-ff5d3a15c207,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-fa284381-df4a-4e23-ab43-ff52f3aa6dea,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-2d3bcdf8-60dc-4084-9df5-ee23e5d163f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-c5200e56-a4c5-48f9-b167-7e839c4a1af6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1508057556-172.17.0.15-1595492299223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43033,DS-939e6711-bbe9-4364-82af-41321b8f55b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-2762259c-38f9-4ccb-bf72-9bee98ed2117,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-186560b6-e9ac-4072-9710-5212fc77c1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-9dcc7e30-048b-4096-8beb-5663b2a5c5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-d71de69c-d605-471b-9826-ff5d3a15c207,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-fa284381-df4a-4e23-ab43-ff52f3aa6dea,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-2d3bcdf8-60dc-4084-9df5-ee23e5d163f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-c5200e56-a4c5-48f9-b167-7e839c4a1af6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2091176965-172.17.0.15-1595492504305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41973,DS-a2560b61-3ab8-41a9-9a61-6a2a79162faa,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-bf4591ff-0573-4a40-877e-0dbbdc2ecbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-9f2dd2dd-88ff-43f4-9838-0a0e0132f502,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-ad17af05-4de9-48d0-a9b9-a85f8ca1409c,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-1c15c72e-37e1-4306-bc9a-16fc9b398329,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-5036b386-c4c5-4cb8-8bd8-ccb5d5999dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-0556187b-c3aa-43d4-bed0-4ad505a248d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-14814c4c-a9d8-43b4-a458-4e8fea4f6b71,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2091176965-172.17.0.15-1595492504305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41973,DS-a2560b61-3ab8-41a9-9a61-6a2a79162faa,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-bf4591ff-0573-4a40-877e-0dbbdc2ecbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-9f2dd2dd-88ff-43f4-9838-0a0e0132f502,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-ad17af05-4de9-48d0-a9b9-a85f8ca1409c,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-1c15c72e-37e1-4306-bc9a-16fc9b398329,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-5036b386-c4c5-4cb8-8bd8-ccb5d5999dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-0556187b-c3aa-43d4-bed0-4ad505a248d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-14814c4c-a9d8-43b4-a458-4e8fea4f6b71,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288139945-172.17.0.15-1595493046391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35353,DS-c9eb8de8-639b-41b9-906b-8e814efb8e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-ea4bbada-54d9-4e38-a7ac-80eb6da60567,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-cb3dd8dc-e8ac-46e7-965b-33461c75bf3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-8436f5b5-18c9-476e-b82f-32314ac0b2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-4e2bd9c4-8be0-4bff-8521-3b3d4113d525,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-faf046c9-cba2-426a-a648-5d4db875065f,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-2039dd28-4661-4b96-81a3-d26a3ef917cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-d5818544-8028-452b-8040-b576ed7a5cdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288139945-172.17.0.15-1595493046391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35353,DS-c9eb8de8-639b-41b9-906b-8e814efb8e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-ea4bbada-54d9-4e38-a7ac-80eb6da60567,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-cb3dd8dc-e8ac-46e7-965b-33461c75bf3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-8436f5b5-18c9-476e-b82f-32314ac0b2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-4e2bd9c4-8be0-4bff-8521-3b3d4113d525,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-faf046c9-cba2-426a-a648-5d4db875065f,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-2039dd28-4661-4b96-81a3-d26a3ef917cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-d5818544-8028-452b-8040-b576ed7a5cdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707367546-172.17.0.15-1595493292884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40593,DS-5ef755c1-7e7d-46bc-8ad5-5ac46ca46864,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-2d802441-1130-4f6e-91a9-6fb3900a27b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-a564c2df-d0ed-40ca-a2e7-0d45ab267dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-2d679423-a215-42e3-afe5-c6001d76e32c,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-88a2b1c6-fb66-49db-92a8-e33420473059,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-c803eed4-5d2b-4627-a820-5948227c9682,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-8ebd7fd1-39ab-44fd-8263-f14abff839cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-f413c1b1-8d9f-4779-a7ad-7f5755f47f97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707367546-172.17.0.15-1595493292884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40593,DS-5ef755c1-7e7d-46bc-8ad5-5ac46ca46864,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-2d802441-1130-4f6e-91a9-6fb3900a27b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-a564c2df-d0ed-40ca-a2e7-0d45ab267dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-2d679423-a215-42e3-afe5-c6001d76e32c,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-88a2b1c6-fb66-49db-92a8-e33420473059,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-c803eed4-5d2b-4627-a820-5948227c9682,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-8ebd7fd1-39ab-44fd-8263-f14abff839cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-f413c1b1-8d9f-4779-a7ad-7f5755f47f97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1503083541-172.17.0.15-1595493625859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34988,DS-2acdc0df-b2b7-4574-a596-11ae39931554,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-445082b0-97ec-4b01-af86-d168d4538a37,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-02990eac-661e-40ac-b388-02f2799f009a,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-20866476-57b0-4ef0-aa2d-e8bf202aef1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-dac4ea34-bc0b-41ee-9762-1db7330c48cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-7a44a3ca-9d80-44e0-b9fa-f31b25e0cd13,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-b6350684-ba0f-4142-a730-31da1d23eab3,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-f971fc2c-ce04-4355-a628-1cd03929ffc1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1503083541-172.17.0.15-1595493625859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34988,DS-2acdc0df-b2b7-4574-a596-11ae39931554,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-445082b0-97ec-4b01-af86-d168d4538a37,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-02990eac-661e-40ac-b388-02f2799f009a,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-20866476-57b0-4ef0-aa2d-e8bf202aef1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-dac4ea34-bc0b-41ee-9762-1db7330c48cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-7a44a3ca-9d80-44e0-b9fa-f31b25e0cd13,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-b6350684-ba0f-4142-a730-31da1d23eab3,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-f971fc2c-ce04-4355-a628-1cd03929ffc1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1135191209-172.17.0.15-1595493914863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39690,DS-e0a29506-4858-47f2-a451-0b642545b8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-d13ef30e-264b-4440-94ee-84bccc7500b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-6f5d6946-7609-4465-a715-284e7e6cd811,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-df916612-d63c-441f-9a26-3582f5e6e026,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-b69c0c6c-6e80-418d-87a4-c21a94c74342,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-6b8f3d1a-a55f-460b-8fab-a261f6ea1783,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-c717d539-3fe9-4874-b900-23cb635ba3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-8d21e386-f339-4a9c-88bc-472fbca1f02f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1135191209-172.17.0.15-1595493914863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39690,DS-e0a29506-4858-47f2-a451-0b642545b8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-d13ef30e-264b-4440-94ee-84bccc7500b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-6f5d6946-7609-4465-a715-284e7e6cd811,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-df916612-d63c-441f-9a26-3582f5e6e026,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-b69c0c6c-6e80-418d-87a4-c21a94c74342,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-6b8f3d1a-a55f-460b-8fab-a261f6ea1783,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-c717d539-3fe9-4874-b900-23cb635ba3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-8d21e386-f339-4a9c-88bc-472fbca1f02f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611878889-172.17.0.15-1595494389465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35252,DS-1c35d83a-df1b-4660-ace8-85f817ff642b,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-8032acee-b1a8-43bf-b0dd-299a00fcbfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-70b1c3e5-b99f-4a0c-aa0a-28780f99c5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-96a922c8-c079-4254-b792-6a22b936f255,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-4aec5427-d25a-40c3-a66e-2849c4bbf94e,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-0a8a31b3-8c60-4a1d-85b4-7ccc571143da,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-1abad3ec-1ed8-447a-aaf3-dad553c684ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-837c70e3-66cb-4c62-92a0-35f13cd44f88,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611878889-172.17.0.15-1595494389465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35252,DS-1c35d83a-df1b-4660-ace8-85f817ff642b,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-8032acee-b1a8-43bf-b0dd-299a00fcbfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-70b1c3e5-b99f-4a0c-aa0a-28780f99c5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-96a922c8-c079-4254-b792-6a22b936f255,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-4aec5427-d25a-40c3-a66e-2849c4bbf94e,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-0a8a31b3-8c60-4a1d-85b4-7ccc571143da,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-1abad3ec-1ed8-447a-aaf3-dad553c684ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-837c70e3-66cb-4c62-92a0-35f13cd44f88,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5797
