reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219160955-172.17.0.5-1595724577439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45907,DS-4828f764-0a27-4f64-8697-1d82cd33b349,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-16edcd2e-cb1d-4a35-9b61-e06b0460e4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-089a937b-9660-459d-a744-a6f04a5e0fec,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-d2917fda-a753-46d8-8781-ea043772b96f,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-0b98d63c-06aa-4305-a187-8afbb8e8369e,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-8fde9251-00a2-43f4-8fc9-32bcc25ccdce,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-d25a3747-b162-4285-bf13-f6cf0ce311f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-087446b6-7945-4242-a230-6d41acdf9fac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219160955-172.17.0.5-1595724577439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45907,DS-4828f764-0a27-4f64-8697-1d82cd33b349,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-16edcd2e-cb1d-4a35-9b61-e06b0460e4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-089a937b-9660-459d-a744-a6f04a5e0fec,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-d2917fda-a753-46d8-8781-ea043772b96f,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-0b98d63c-06aa-4305-a187-8afbb8e8369e,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-8fde9251-00a2-43f4-8fc9-32bcc25ccdce,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-d25a3747-b162-4285-bf13-f6cf0ce311f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-087446b6-7945-4242-a230-6d41acdf9fac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1431541411-172.17.0.5-1595725617788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42278,DS-ffbc8a13-95d7-4ba3-a547-3aba43727e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-5875fdf0-2fcd-4381-af24-e17a361e9f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-6239ea21-4cf1-45ba-acec-07692d0461ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-f7a96a46-a645-4206-8d46-75d80ce4eeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-33439b94-8ddd-432a-9cfd-1fd6034fa21a,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-4d367145-4fd1-49ee-85fa-ebf2dd362961,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-f5b061d6-7366-484c-a5e2-dbef9b70f080,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-1c6f3bbf-83b5-4b36-9fe8-9c1a97e42357,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1431541411-172.17.0.5-1595725617788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42278,DS-ffbc8a13-95d7-4ba3-a547-3aba43727e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-5875fdf0-2fcd-4381-af24-e17a361e9f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-6239ea21-4cf1-45ba-acec-07692d0461ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-f7a96a46-a645-4206-8d46-75d80ce4eeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-33439b94-8ddd-432a-9cfd-1fd6034fa21a,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-4d367145-4fd1-49ee-85fa-ebf2dd362961,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-f5b061d6-7366-484c-a5e2-dbef9b70f080,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-1c6f3bbf-83b5-4b36-9fe8-9c1a97e42357,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1889912549-172.17.0.5-1595726266037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36210,DS-29d1bff5-6455-48ea-9d03-199ced611d70,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-2a2099ab-a0d1-4d93-8692-ba5e66fccd42,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-21cb609e-1eaf-44ef-8a01-3783219844ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-866057af-50b9-4b04-8f7f-5bbca67e362f,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-be9dc47a-d6ae-4f6d-8f5a-b22e0bd6936a,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-a0f8f60f-9eed-449f-b6d1-51e3aafc192d,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-8fbf5153-69e5-471f-9598-6ff57a71f90b,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-a620b9b8-5d79-4ab3-91fa-178d3f02455d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1889912549-172.17.0.5-1595726266037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36210,DS-29d1bff5-6455-48ea-9d03-199ced611d70,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-2a2099ab-a0d1-4d93-8692-ba5e66fccd42,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-21cb609e-1eaf-44ef-8a01-3783219844ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-866057af-50b9-4b04-8f7f-5bbca67e362f,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-be9dc47a-d6ae-4f6d-8f5a-b22e0bd6936a,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-a0f8f60f-9eed-449f-b6d1-51e3aafc192d,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-8fbf5153-69e5-471f-9598-6ff57a71f90b,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-a620b9b8-5d79-4ab3-91fa-178d3f02455d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-165897888-172.17.0.5-1595726402978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37894,DS-ffb27c0f-c18a-4528-adfc-358fd1301b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-4f439b58-d68e-4596-91b7-8e2d6c8ef9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-5769f147-7fbc-4698-ba13-e6f042f6ba2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-7665b560-9cf0-4f6e-9d33-e92ce56d04e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-36f3a9b5-1ef9-44e9-a80b-c33215a1ab1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-780e5731-f0d6-4280-8462-a91dee93c524,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-4206cdd4-249b-4ca8-b07e-c0c2a35a0fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-805153f6-a5e2-4418-b49a-d4857071665b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-165897888-172.17.0.5-1595726402978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37894,DS-ffb27c0f-c18a-4528-adfc-358fd1301b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-4f439b58-d68e-4596-91b7-8e2d6c8ef9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-5769f147-7fbc-4698-ba13-e6f042f6ba2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-7665b560-9cf0-4f6e-9d33-e92ce56d04e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-36f3a9b5-1ef9-44e9-a80b-c33215a1ab1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-780e5731-f0d6-4280-8462-a91dee93c524,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-4206cdd4-249b-4ca8-b07e-c0c2a35a0fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-805153f6-a5e2-4418-b49a-d4857071665b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157806095-172.17.0.5-1595726538435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44286,DS-3476a886-145c-498e-bd0f-8e3e5a9028e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-3b6313d2-f123-40ba-8131-2ecf5f532a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-c32b1403-b675-4b9f-aebf-72b8f4f83986,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-43728e51-9e00-412e-8d1b-9b8906b8ecc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-91645f92-236e-4ce0-bf78-7edc77cea138,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-8c2ec085-dd3f-4deb-954d-cb1ce5186570,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-8abfd925-7b29-4b36-8a6e-82166a4e4e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-28d0925d-1deb-4bd4-aa0a-a5bb8b962e74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157806095-172.17.0.5-1595726538435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44286,DS-3476a886-145c-498e-bd0f-8e3e5a9028e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-3b6313d2-f123-40ba-8131-2ecf5f532a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-c32b1403-b675-4b9f-aebf-72b8f4f83986,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-43728e51-9e00-412e-8d1b-9b8906b8ecc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-91645f92-236e-4ce0-bf78-7edc77cea138,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-8c2ec085-dd3f-4deb-954d-cb1ce5186570,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-8abfd925-7b29-4b36-8a6e-82166a4e4e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-28d0925d-1deb-4bd4-aa0a-a5bb8b962e74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-742170451-172.17.0.5-1595727137003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42283,DS-c9ae5625-d605-4877-8c1d-fd5a025617b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-48ed8bd5-eb42-4229-9f6f-96fb49eb5469,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-b9866028-890f-4a1d-9fd7-034eeb05c2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-245a5f0d-7438-4776-841c-3269b22fdf48,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-fa004817-38c5-436b-bf39-a71a667e3534,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-a79b453f-91ec-4f36-95de-8f699f7c08ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-f56404e3-abcb-46f2-a204-48ad2e36f727,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-0a08f226-c4b1-479e-95f1-020ddc526dcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-742170451-172.17.0.5-1595727137003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42283,DS-c9ae5625-d605-4877-8c1d-fd5a025617b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-48ed8bd5-eb42-4229-9f6f-96fb49eb5469,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-b9866028-890f-4a1d-9fd7-034eeb05c2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-245a5f0d-7438-4776-841c-3269b22fdf48,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-fa004817-38c5-436b-bf39-a71a667e3534,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-a79b453f-91ec-4f36-95de-8f699f7c08ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-f56404e3-abcb-46f2-a204-48ad2e36f727,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-0a08f226-c4b1-479e-95f1-020ddc526dcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835167829-172.17.0.5-1595727377961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45454,DS-6ccfdf0b-693c-4be3-93c6-20bb254ce643,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-537bf354-14bb-488d-aee6-66fc5f21c1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-28f1e206-186c-47e9-b74b-d4c167207887,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-3b616906-7aaf-43c5-be9a-5b3ed046d292,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-758d8007-2cd4-416e-8bf4-df78aae34af9,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-4350f18a-3952-4209-8c3f-c690737cda46,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-4c33b480-6df5-47c4-830f-8e8108178117,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-d6fe45ec-ebbf-4ecc-95c2-a46baadc9f0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835167829-172.17.0.5-1595727377961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45454,DS-6ccfdf0b-693c-4be3-93c6-20bb254ce643,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-537bf354-14bb-488d-aee6-66fc5f21c1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-28f1e206-186c-47e9-b74b-d4c167207887,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-3b616906-7aaf-43c5-be9a-5b3ed046d292,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-758d8007-2cd4-416e-8bf4-df78aae34af9,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-4350f18a-3952-4209-8c3f-c690737cda46,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-4c33b480-6df5-47c4-830f-8e8108178117,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-d6fe45ec-ebbf-4ecc-95c2-a46baadc9f0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1663115973-172.17.0.5-1595727766970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37930,DS-0e59a1f3-b3bb-4f39-8b3c-0e94ae8abe5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-4a57181b-0f9f-414b-80dd-b919bae62437,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-ae590599-46f0-45d5-aaa5-71d0e3f03fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-8a3fa364-44d9-4d20-a616-ed3862413d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-fac7834a-eea7-453c-aac6-3d32d20bec45,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-907985c2-28dd-4d14-a973-dfcaea6064ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-2925e34e-d05e-41bd-a7e0-dad77d3b58dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-16dc8fbc-463c-4651-ac7a-25f055d98056,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1663115973-172.17.0.5-1595727766970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37930,DS-0e59a1f3-b3bb-4f39-8b3c-0e94ae8abe5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-4a57181b-0f9f-414b-80dd-b919bae62437,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-ae590599-46f0-45d5-aaa5-71d0e3f03fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-8a3fa364-44d9-4d20-a616-ed3862413d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-fac7834a-eea7-453c-aac6-3d32d20bec45,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-907985c2-28dd-4d14-a973-dfcaea6064ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-2925e34e-d05e-41bd-a7e0-dad77d3b58dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-16dc8fbc-463c-4651-ac7a-25f055d98056,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638601299-172.17.0.5-1595728074945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36547,DS-c5003604-dd79-48b7-b303-cf12ad3e1518,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-e535c165-222b-46ec-a7d4-628e0d90a5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-f0ca7920-b9f7-4ecd-a17b-b3749df8901c,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-a0bf805c-d803-4e5e-81cd-96f8a83dbc81,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-884a6aba-bc22-4f53-944d-842e1c154306,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-0d132111-2ade-41b6-a703-9b0823dfc9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-073ceeac-676f-4d14-b62d-51ab3f3f3a94,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-3792d8b4-98c8-484a-987c-d6065d18faa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638601299-172.17.0.5-1595728074945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36547,DS-c5003604-dd79-48b7-b303-cf12ad3e1518,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-e535c165-222b-46ec-a7d4-628e0d90a5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-f0ca7920-b9f7-4ecd-a17b-b3749df8901c,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-a0bf805c-d803-4e5e-81cd-96f8a83dbc81,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-884a6aba-bc22-4f53-944d-842e1c154306,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-0d132111-2ade-41b6-a703-9b0823dfc9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-073ceeac-676f-4d14-b62d-51ab3f3f3a94,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-3792d8b4-98c8-484a-987c-d6065d18faa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1193845839-172.17.0.5-1595728634439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46657,DS-7d5b5d3e-1b1d-4d67-a97e-1d3fbd9b40ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-e741696b-76a9-45ad-9715-acae2ccfe174,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-527a14c2-681e-44f7-ba86-e94a717926a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-d65e5105-b3a6-40db-bc90-305ebd866641,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-66687003-47f1-4a26-8af6-1b0cd892c4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-e50dfc1c-9147-49fa-aa3b-52274cf15605,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-00842fd7-f7fb-4956-aebb-69165c4d980d,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-a69e8283-4904-4d52-8e23-602ad2b1c627,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1193845839-172.17.0.5-1595728634439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46657,DS-7d5b5d3e-1b1d-4d67-a97e-1d3fbd9b40ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-e741696b-76a9-45ad-9715-acae2ccfe174,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-527a14c2-681e-44f7-ba86-e94a717926a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-d65e5105-b3a6-40db-bc90-305ebd866641,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-66687003-47f1-4a26-8af6-1b0cd892c4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-e50dfc1c-9147-49fa-aa3b-52274cf15605,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-00842fd7-f7fb-4956-aebb-69165c4d980d,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-a69e8283-4904-4d52-8e23-602ad2b1c627,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-827821802-172.17.0.5-1595728681910:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37832,DS-027c586c-0dca-4ee4-9b84-608b979f9aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-53e9f968-f497-480d-9e47-3a87928a147e,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-cc2b8561-889d-4dbf-bf9f-7b5be267804a,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-326990e6-1ee2-4297-952d-71b3cb05f6db,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-1545c012-d6ab-44bd-baed-5581a57952b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-48a61252-dece-499e-8826-d9560ae0e5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-94751e08-f1c5-48bc-af74-fd18d86289b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-c81f1887-407e-48ae-be53-6f139e64be7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-827821802-172.17.0.5-1595728681910:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37832,DS-027c586c-0dca-4ee4-9b84-608b979f9aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-53e9f968-f497-480d-9e47-3a87928a147e,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-cc2b8561-889d-4dbf-bf9f-7b5be267804a,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-326990e6-1ee2-4297-952d-71b3cb05f6db,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-1545c012-d6ab-44bd-baed-5581a57952b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-48a61252-dece-499e-8826-d9560ae0e5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-94751e08-f1c5-48bc-af74-fd18d86289b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-c81f1887-407e-48ae-be53-6f139e64be7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057756865-172.17.0.5-1595729542463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41691,DS-01937b26-5d26-4036-a575-a4f3e007e876,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-2c9433b8-08ce-43af-aab1-9896bc8ce125,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-3eb82185-24df-4869-8193-a7f4f101c5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-366cea83-f89b-4b78-86ed-ae4e79bf1011,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-e5ecfd51-73ef-46fb-b081-cc24df1927ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-5d10add5-f985-49d3-9b9e-c514cc4e1a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-746aa5cf-7f90-431d-9b2a-2786a1a36958,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-749a76e8-8336-416e-bbde-41aa64d58e12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057756865-172.17.0.5-1595729542463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41691,DS-01937b26-5d26-4036-a575-a4f3e007e876,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-2c9433b8-08ce-43af-aab1-9896bc8ce125,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-3eb82185-24df-4869-8193-a7f4f101c5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-366cea83-f89b-4b78-86ed-ae4e79bf1011,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-e5ecfd51-73ef-46fb-b081-cc24df1927ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-5d10add5-f985-49d3-9b9e-c514cc4e1a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-746aa5cf-7f90-431d-9b2a-2786a1a36958,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-749a76e8-8336-416e-bbde-41aa64d58e12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1355411186-172.17.0.5-1595729589251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32804,DS-28ae09e4-72da-48a3-894a-e94625caee47,DISK], DatanodeInfoWithStorage[127.0.0.1:41709,DS-1b1f15f5-8557-4d26-91f7-47548a9e0d13,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-ebd4c7ea-f65e-4f45-b750-75674c9aa6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-6b15e760-b0bd-47b0-8068-eae8dc497b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-9bb92ad0-2086-4015-a624-9d9e49320f12,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-a58380e0-75a4-403b-9b95-2f34ee469659,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-b1cfe203-842c-4913-80e2-fb225e48b228,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-0cefefa7-1d0b-43c3-94f6-a01c258a898c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1355411186-172.17.0.5-1595729589251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32804,DS-28ae09e4-72da-48a3-894a-e94625caee47,DISK], DatanodeInfoWithStorage[127.0.0.1:41709,DS-1b1f15f5-8557-4d26-91f7-47548a9e0d13,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-ebd4c7ea-f65e-4f45-b750-75674c9aa6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-6b15e760-b0bd-47b0-8068-eae8dc497b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-9bb92ad0-2086-4015-a624-9d9e49320f12,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-a58380e0-75a4-403b-9b95-2f34ee469659,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-b1cfe203-842c-4913-80e2-fb225e48b228,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-0cefefa7-1d0b-43c3-94f6-a01c258a898c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2099258527-172.17.0.5-1595730103550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39102,DS-8261f4fd-613a-4f34-b148-3f64d14ee8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-93f822bd-037d-4ca2-9716-4e249dc6e11b,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-8c823542-9b38-44aa-b072-1cbea9c951d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-bbc20f8d-469e-4d51-bfd2-a62c2fab87d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-1b6ffb38-2d75-4fed-909a-284b0cba99e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-46b751a9-7721-40be-aabc-274080cad8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-74b38cde-91a5-47c9-8c60-6a7e2bd784a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-517faa6a-af25-4da3-8b43-789386b5094e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2099258527-172.17.0.5-1595730103550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39102,DS-8261f4fd-613a-4f34-b148-3f64d14ee8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-93f822bd-037d-4ca2-9716-4e249dc6e11b,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-8c823542-9b38-44aa-b072-1cbea9c951d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-bbc20f8d-469e-4d51-bfd2-a62c2fab87d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-1b6ffb38-2d75-4fed-909a-284b0cba99e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-46b751a9-7721-40be-aabc-274080cad8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-74b38cde-91a5-47c9-8c60-6a7e2bd784a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-517faa6a-af25-4da3-8b43-789386b5094e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-314056111-172.17.0.5-1595730511258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39217,DS-16ae2450-8fc7-4cc3-a189-44b6646cb289,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-91c189f8-a7b1-4fe2-8815-3a2ccf2f7c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-5df4a876-7d2f-43ed-9de5-c3320fdcb7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-72370696-3f0a-4abe-b233-b350592035ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-9ab79fde-17fd-48d5-a84f-c6fa857cad8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-106c1c0c-9061-4d89-a62c-5c58b3fdcbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-065baa71-6e14-4e73-abb7-962a3db7fa30,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-8c283432-321b-4274-8eba-fa43c55aa650,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-314056111-172.17.0.5-1595730511258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39217,DS-16ae2450-8fc7-4cc3-a189-44b6646cb289,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-91c189f8-a7b1-4fe2-8815-3a2ccf2f7c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-5df4a876-7d2f-43ed-9de5-c3320fdcb7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-72370696-3f0a-4abe-b233-b350592035ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-9ab79fde-17fd-48d5-a84f-c6fa857cad8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-106c1c0c-9061-4d89-a62c-5c58b3fdcbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-065baa71-6e14-4e73-abb7-962a3db7fa30,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-8c283432-321b-4274-8eba-fa43c55aa650,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1127264005-172.17.0.5-1595730763193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34840,DS-d38958b8-986c-49c8-b1b2-b7e34b30222e,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-4a8eff25-d095-45bc-92fd-11de2c30cd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-f50ae147-459f-40ba-ae28-83dba4168ace,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-4bc8aad0-999d-4e77-9101-5f6fd07c9590,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-4eebd799-4a6d-400a-8c68-8a0d1e4dd4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-8334a39c-6f3b-4c8c-867c-7cae10fab605,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-d02e6a6f-8b94-418c-b119-461cea1591e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-3752f126-c688-400d-af21-29cd33dc85e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1127264005-172.17.0.5-1595730763193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34840,DS-d38958b8-986c-49c8-b1b2-b7e34b30222e,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-4a8eff25-d095-45bc-92fd-11de2c30cd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-f50ae147-459f-40ba-ae28-83dba4168ace,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-4bc8aad0-999d-4e77-9101-5f6fd07c9590,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-4eebd799-4a6d-400a-8c68-8a0d1e4dd4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-8334a39c-6f3b-4c8c-867c-7cae10fab605,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-d02e6a6f-8b94-418c-b119-461cea1591e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-3752f126-c688-400d-af21-29cd33dc85e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1825370511-172.17.0.5-1595730809102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41120,DS-5554fdf5-25a0-442c-a704-8773d2aa63c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-be01e114-dbe6-41d4-9de3-54613713250e,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-d26ab424-858f-4e52-b176-3163dfcb89f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-58969d91-968a-43b8-969d-a0d9e97a6c67,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-99cb6922-70f5-4de2-bd40-454e2ddcdcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-77616890-e5b4-4be7-9229-ceb36a4a508e,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-fb9c92da-d25a-46cf-a76e-aa1af4cfcb38,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-94700b2e-88ee-4486-b755-da7f601778ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1825370511-172.17.0.5-1595730809102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41120,DS-5554fdf5-25a0-442c-a704-8773d2aa63c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-be01e114-dbe6-41d4-9de3-54613713250e,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-d26ab424-858f-4e52-b176-3163dfcb89f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-58969d91-968a-43b8-969d-a0d9e97a6c67,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-99cb6922-70f5-4de2-bd40-454e2ddcdcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-77616890-e5b4-4be7-9229-ceb36a4a508e,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-fb9c92da-d25a-46cf-a76e-aa1af4cfcb38,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-94700b2e-88ee-4486-b755-da7f601778ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1929334285-172.17.0.5-1595730940124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42856,DS-78a0246d-6a4f-447c-85f5-731c390d0057,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-29cfd8b9-8f50-4bd8-8c9e-85ce9968fd41,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-ceadcd3d-1e6d-4dfb-9978-317abf66046a,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-790c934c-3500-4a6a-9816-4b170d0ea547,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-6aa36ebb-7222-4d7c-88e2-2d6431755b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-f46ae9c3-cab7-482e-a830-1c6abc5483c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-a104ac84-9ac0-4489-9602-32f935863cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-42567b7c-fc12-4276-8129-1500e40d90cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1929334285-172.17.0.5-1595730940124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42856,DS-78a0246d-6a4f-447c-85f5-731c390d0057,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-29cfd8b9-8f50-4bd8-8c9e-85ce9968fd41,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-ceadcd3d-1e6d-4dfb-9978-317abf66046a,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-790c934c-3500-4a6a-9816-4b170d0ea547,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-6aa36ebb-7222-4d7c-88e2-2d6431755b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-f46ae9c3-cab7-482e-a830-1c6abc5483c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-a104ac84-9ac0-4489-9602-32f935863cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-42567b7c-fc12-4276-8129-1500e40d90cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6789
