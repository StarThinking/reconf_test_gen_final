reconf_parameter: dfs.namenode.reconstruction.pending.timeout-sec
component: hdfs:NameNode
v1: 1
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reconstruction.pending.timeout-sec
component: hdfs:NameNode
v1: 1
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1934525753-172.17.0.13-1595679825280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36902,DS-d42efa46-7d7d-4669-9211-096c0cbbd6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-c6bc415a-78ec-48f5-9f21-edd6cb25c811,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-ad608fa6-5120-44b0-ab07-1829c17833b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-cd57f3a9-0f32-4332-9aa1-1ff0ac143534,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-b945cb35-4d35-4cb6-b651-a1c1451c3e26,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-e3178473-607f-4354-8be3-bd0a1be0e111,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-a9f0c97e-2ec4-4b18-a83a-acd6bb6d6742,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-a42dbd45-bb1f-402b-a866-7abe03b9acb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1934525753-172.17.0.13-1595679825280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36902,DS-d42efa46-7d7d-4669-9211-096c0cbbd6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-c6bc415a-78ec-48f5-9f21-edd6cb25c811,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-ad608fa6-5120-44b0-ab07-1829c17833b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-cd57f3a9-0f32-4332-9aa1-1ff0ac143534,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-b945cb35-4d35-4cb6-b651-a1c1451c3e26,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-e3178473-607f-4354-8be3-bd0a1be0e111,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-a9f0c97e-2ec4-4b18-a83a-acd6bb6d6742,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-a42dbd45-bb1f-402b-a866-7abe03b9acb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reconstruction.pending.timeout-sec
component: hdfs:NameNode
v1: 1
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-480634882-172.17.0.13-1595680507581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40528,DS-897d56ca-efbf-40ae-b7a9-50150d2cd145,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-eaa13c81-4a32-45e8-9185-2c849a972e11,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-c0b1bc85-71f4-47a4-a8e7-824c8b49ea8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-ecc89bcf-2c34-4c1f-8a94-138aa99a2c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-3651abc5-179e-449c-9c65-60d4f37dbcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-0b39a661-353c-4750-bbc1-c9332b970779,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-58c83816-c15b-49ae-a042-1ec057890f39,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-4d8cf50b-8448-4550-ac64-f799e63dc461,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-480634882-172.17.0.13-1595680507581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40528,DS-897d56ca-efbf-40ae-b7a9-50150d2cd145,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-eaa13c81-4a32-45e8-9185-2c849a972e11,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-c0b1bc85-71f4-47a4-a8e7-824c8b49ea8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-ecc89bcf-2c34-4c1f-8a94-138aa99a2c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-3651abc5-179e-449c-9c65-60d4f37dbcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-0b39a661-353c-4750-bbc1-c9332b970779,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-58c83816-c15b-49ae-a042-1ec057890f39,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-4d8cf50b-8448-4550-ac64-f799e63dc461,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reconstruction.pending.timeout-sec
component: hdfs:NameNode
v1: 1
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742445320-172.17.0.13-1595681478412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38689,DS-e23fddf1-ec60-4047-a5c4-d13d81680355,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-46557d95-59c6-4c66-b034-39bb6585c494,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-73326891-710f-4131-a7fd-b4938a9ec9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-e1f8ebd9-de34-49b2-84db-6e5f5b5dbfed,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-b9985491-6cfb-400c-969c-9188e5d3f34b,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-3c145891-77ba-436c-8a61-86b26e718819,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-18a7d472-846e-445c-868b-eddd2fcf7bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-371c88b3-341d-4542-a286-6c3585ef894c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742445320-172.17.0.13-1595681478412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38689,DS-e23fddf1-ec60-4047-a5c4-d13d81680355,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-46557d95-59c6-4c66-b034-39bb6585c494,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-73326891-710f-4131-a7fd-b4938a9ec9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-e1f8ebd9-de34-49b2-84db-6e5f5b5dbfed,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-b9985491-6cfb-400c-969c-9188e5d3f34b,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-3c145891-77ba-436c-8a61-86b26e718819,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-18a7d472-846e-445c-868b-eddd2fcf7bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-371c88b3-341d-4542-a286-6c3585ef894c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reconstruction.pending.timeout-sec
component: hdfs:NameNode
v1: 1
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-771970566-172.17.0.13-1595681618342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45985,DS-68b2b552-7375-4adb-97bc-3b93d51ea43c,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-e9467f03-782d-4cfb-a2f0-bab50170655b,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-4a79c72d-5250-4680-8cbb-768c143b53ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-dd1f9f6a-2f3d-47ac-984f-95bc1cc45d47,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-8585fb55-9246-4d1c-8eeb-26fd46e4d9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-82fecde0-d43e-4be7-bc89-16f98f06e002,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-779f7d2d-b53a-4a2d-a94c-1e1602678f24,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-d9e50752-afa8-4e19-ae26-1e14d320f719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-771970566-172.17.0.13-1595681618342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45985,DS-68b2b552-7375-4adb-97bc-3b93d51ea43c,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-e9467f03-782d-4cfb-a2f0-bab50170655b,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-4a79c72d-5250-4680-8cbb-768c143b53ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-dd1f9f6a-2f3d-47ac-984f-95bc1cc45d47,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-8585fb55-9246-4d1c-8eeb-26fd46e4d9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-82fecde0-d43e-4be7-bc89-16f98f06e002,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-779f7d2d-b53a-4a2d-a94c-1e1602678f24,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-d9e50752-afa8-4e19-ae26-1e14d320f719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reconstruction.pending.timeout-sec
component: hdfs:NameNode
v1: 1
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-306991754-172.17.0.13-1595681733757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37782,DS-494c6f08-a148-4252-a9fa-e07dfd6dba50,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-e6600609-3fd4-4635-82e2-1bdaf9ce3c31,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-f039d661-cf6d-4539-8b64-d7b2c2e95c54,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-309abc44-1ab2-4e92-aad8-e119eedf7da6,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-204d4104-ed3a-4931-b203-65a30d81e079,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-a533f876-b0f4-4086-a439-65ad4cc9b3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-94b82a0a-687b-4622-940a-f9a7d274cc42,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-7c9d8047-e3d6-4604-b9a9-4d27e40188b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-306991754-172.17.0.13-1595681733757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37782,DS-494c6f08-a148-4252-a9fa-e07dfd6dba50,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-e6600609-3fd4-4635-82e2-1bdaf9ce3c31,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-f039d661-cf6d-4539-8b64-d7b2c2e95c54,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-309abc44-1ab2-4e92-aad8-e119eedf7da6,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-204d4104-ed3a-4931-b203-65a30d81e079,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-a533f876-b0f4-4086-a439-65ad4cc9b3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-94b82a0a-687b-4622-940a-f9a7d274cc42,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-7c9d8047-e3d6-4604-b9a9-4d27e40188b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reconstruction.pending.timeout-sec
component: hdfs:NameNode
v1: 1
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77729075-172.17.0.13-1595681848190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42182,DS-5a38db36-8a10-4d59-afa6-7565d7f45c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-e6f0e786-c4ba-4591-be80-554dcb468e62,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-a53bef34-bbb4-4311-bc9f-6995e2b662d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-2c293680-134c-4b0c-9a3a-861923aa44b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-27851ada-000e-47fe-9843-30577b42b891,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-c9d8894d-ba08-488c-984f-3c133b8349f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-485fc5ac-f487-4354-94ab-71cde8279592,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-cd91287f-5b02-401d-9b8c-bb03f4cd13a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77729075-172.17.0.13-1595681848190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42182,DS-5a38db36-8a10-4d59-afa6-7565d7f45c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-e6f0e786-c4ba-4591-be80-554dcb468e62,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-a53bef34-bbb4-4311-bc9f-6995e2b662d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-2c293680-134c-4b0c-9a3a-861923aa44b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-27851ada-000e-47fe-9843-30577b42b891,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-c9d8894d-ba08-488c-984f-3c133b8349f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-485fc5ac-f487-4354-94ab-71cde8279592,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-cd91287f-5b02-401d-9b8c-bb03f4cd13a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reconstruction.pending.timeout-sec
component: hdfs:NameNode
v1: 1
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230034263-172.17.0.13-1595682506180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44376,DS-0c8b2167-3cc3-441d-9853-100b591ed7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-a87fbef6-b06e-4f61-adc9-c8b43b7a3c12,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-1c214acd-e66d-438b-b6f6-96ce03da6d31,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-55ffc4d1-1c8b-4b10-9daa-7fb03c6d45a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-4f0ddf15-b719-40ba-9260-c40118b95c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-bc9fe321-c6ba-4ae7-89a7-29d1d1cce046,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-fea8ea18-36a3-42f8-9e58-411171502c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-a736e651-3e7f-43ec-99f8-4ee9b152725c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230034263-172.17.0.13-1595682506180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44376,DS-0c8b2167-3cc3-441d-9853-100b591ed7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-a87fbef6-b06e-4f61-adc9-c8b43b7a3c12,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-1c214acd-e66d-438b-b6f6-96ce03da6d31,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-55ffc4d1-1c8b-4b10-9daa-7fb03c6d45a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-4f0ddf15-b719-40ba-9260-c40118b95c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-bc9fe321-c6ba-4ae7-89a7-29d1d1cce046,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-fea8ea18-36a3-42f8-9e58-411171502c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-a736e651-3e7f-43ec-99f8-4ee9b152725c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reconstruction.pending.timeout-sec
component: hdfs:NameNode
v1: 1
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1170120490-172.17.0.13-1595683004182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39452,DS-5a4d1464-0336-4dde-ac09-f7d796c6b610,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-0a4bab8d-5379-4e50-be8f-082f9ba31cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-c1522091-dcc1-4cd7-be4b-d571f507017d,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-a384aa9e-a689-4d57-bc40-c9f63c1e56e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-8e62d0b7-7433-44d3-b67e-b34b19379250,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-7001005f-007c-4509-b48d-a21311cef646,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-583cd7f6-88d4-47f4-bc76-87c43e2e9446,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-c4f561dc-b1fc-4e1d-a04f-245472f296b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1170120490-172.17.0.13-1595683004182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39452,DS-5a4d1464-0336-4dde-ac09-f7d796c6b610,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-0a4bab8d-5379-4e50-be8f-082f9ba31cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-c1522091-dcc1-4cd7-be4b-d571f507017d,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-a384aa9e-a689-4d57-bc40-c9f63c1e56e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-8e62d0b7-7433-44d3-b67e-b34b19379250,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-7001005f-007c-4509-b48d-a21311cef646,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-583cd7f6-88d4-47f4-bc76-87c43e2e9446,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-c4f561dc-b1fc-4e1d-a04f-245472f296b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reconstruction.pending.timeout-sec
component: hdfs:NameNode
v1: 1
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1240917681-172.17.0.13-1595683612069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37223,DS-0317d7b0-8b9d-4e0c-9f2e-07aa72cb5dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-87ef2c4f-b233-4403-8d0b-1af0ca49a4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-7827e74d-888f-4f05-8af1-7ec2ab2a6678,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-fd1bbd92-ad46-4ef0-a77f-f0bf85ffecd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-45b91b76-689c-47dd-afce-6e53b9ffda65,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-8ab2b7a3-6600-43a1-a718-2d8c6019c7be,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-b85489c9-e44b-4aa9-9db4-bf4401decd71,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-95df7f1d-b776-4873-9afb-bf850cda1630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1240917681-172.17.0.13-1595683612069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37223,DS-0317d7b0-8b9d-4e0c-9f2e-07aa72cb5dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-87ef2c4f-b233-4403-8d0b-1af0ca49a4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-7827e74d-888f-4f05-8af1-7ec2ab2a6678,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-fd1bbd92-ad46-4ef0-a77f-f0bf85ffecd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-45b91b76-689c-47dd-afce-6e53b9ffda65,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-8ab2b7a3-6600-43a1-a718-2d8c6019c7be,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-b85489c9-e44b-4aa9-9db4-bf4401decd71,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-95df7f1d-b776-4873-9afb-bf850cda1630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reconstruction.pending.timeout-sec
component: hdfs:NameNode
v1: 1
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1689150283-172.17.0.13-1595683644281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38790,DS-abc0e4cb-2570-43a7-81b4-caaeb9f08fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-cda4f939-31bc-4a75-b53b-4ce0fcba06a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-03b50e55-ff88-4f01-9a9c-2189fe2c4d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-4cb80d82-3aba-47a4-8186-51877dca9d57,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-10e6c70b-dc4b-4920-bef7-6ea2a1e6e6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-d64611ab-4404-494d-94d4-af37af89625b,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-50699c4a-1fc3-4416-8d6d-6a5924e38c87,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-623df956-724d-4e13-90ac-9e9cc0fdf4ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1689150283-172.17.0.13-1595683644281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38790,DS-abc0e4cb-2570-43a7-81b4-caaeb9f08fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-cda4f939-31bc-4a75-b53b-4ce0fcba06a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-03b50e55-ff88-4f01-9a9c-2189fe2c4d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-4cb80d82-3aba-47a4-8186-51877dca9d57,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-10e6c70b-dc4b-4920-bef7-6ea2a1e6e6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-d64611ab-4404-494d-94d4-af37af89625b,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-50699c4a-1fc3-4416-8d6d-6a5924e38c87,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-623df956-724d-4e13-90ac-9e9cc0fdf4ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.reconstruction.pending.timeout-sec
component: hdfs:NameNode
v1: 1
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-862280500-172.17.0.13-1595683677533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34730,DS-4711e123-e6d1-4a53-85b0-4bac057b4c26,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-a8b38a1e-076c-4364-98e7-ab04b54297fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-03babf79-1c83-4bec-be90-2616fff699d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-2b3f1ca9-baf9-4832-8bfb-1a0de6026728,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-e44a3aaf-3cd1-4027-be63-cbcb73829b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-9eaa3980-420e-4974-a74b-1df12d3457c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-3bab4d18-56ec-413b-a65a-cb1bc9ace983,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-f6ae1438-fd2f-4f23-b132-45f36ea57a68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-862280500-172.17.0.13-1595683677533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34730,DS-4711e123-e6d1-4a53-85b0-4bac057b4c26,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-a8b38a1e-076c-4364-98e7-ab04b54297fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-03babf79-1c83-4bec-be90-2616fff699d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-2b3f1ca9-baf9-4832-8bfb-1a0de6026728,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-e44a3aaf-3cd1-4027-be63-cbcb73829b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-9eaa3980-420e-4974-a74b-1df12d3457c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-3bab4d18-56ec-413b-a65a-cb1bc9ace983,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-f6ae1438-fd2f-4f23-b132-45f36ea57a68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reconstruction.pending.timeout-sec
component: hdfs:NameNode
v1: 1
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234666202-172.17.0.13-1595683841292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37297,DS-e8605bf8-50dd-4dde-8399-4f8a92cb295a,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-8abd2e95-9e4d-4992-bf3b-6bdcb8c47b33,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-e82daa64-c30f-4112-8cb0-784134248e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-f9e273aa-f01f-42af-b8a4-06705d93c989,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-40c747e7-4efd-4242-804e-5df44434121b,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-f9119c9d-4a9c-420a-99f2-717b0e464076,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-bbc59d17-1377-4e9e-8d7b-4c055f1d65d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-7c5c0439-c848-498e-9b48-962adb66caca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234666202-172.17.0.13-1595683841292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37297,DS-e8605bf8-50dd-4dde-8399-4f8a92cb295a,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-8abd2e95-9e4d-4992-bf3b-6bdcb8c47b33,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-e82daa64-c30f-4112-8cb0-784134248e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-f9e273aa-f01f-42af-b8a4-06705d93c989,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-40c747e7-4efd-4242-804e-5df44434121b,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-f9119c9d-4a9c-420a-99f2-717b0e464076,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-bbc59d17-1377-4e9e-8d7b-4c055f1d65d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-7c5c0439-c848-498e-9b48-962adb66caca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reconstruction.pending.timeout-sec
component: hdfs:NameNode
v1: 1
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822984547-172.17.0.13-1595683945748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34569,DS-64415e83-677b-44aa-9c72-1f83827c0ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-a75dd2b6-dc93-41b6-8a15-4541302f67f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-d4d461d6-c61c-4318-96bd-bd5edfbc89b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-d6aab812-b145-420f-880e-dd2b63238296,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-2b4f885f-c728-45a5-80a6-735337dd888c,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-7c067fe0-1b82-4636-8e4a-1ce3ebff57f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-d6802603-1bf5-4ebc-af09-c1a35287499d,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-9193aa9a-b80d-4f29-a177-52081fc61645,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822984547-172.17.0.13-1595683945748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34569,DS-64415e83-677b-44aa-9c72-1f83827c0ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-a75dd2b6-dc93-41b6-8a15-4541302f67f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-d4d461d6-c61c-4318-96bd-bd5edfbc89b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-d6aab812-b145-420f-880e-dd2b63238296,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-2b4f885f-c728-45a5-80a6-735337dd888c,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-7c067fe0-1b82-4636-8e4a-1ce3ebff57f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-d6802603-1bf5-4ebc-af09-c1a35287499d,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-9193aa9a-b80d-4f29-a177-52081fc61645,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reconstruction.pending.timeout-sec
component: hdfs:NameNode
v1: 1
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1890962004-172.17.0.13-1595684095674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33632,DS-21b694ae-43d9-436f-a679-5b7fa77038b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-74408abc-df18-42f1-bfcf-94308b13c39c,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-462e6662-bc98-429e-9e30-9eb863e16408,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-23a39839-2e82-4a3d-9ea6-d3b3d6963537,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-955553ae-ec96-43ea-996c-1156df5ee510,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-c0c02989-2a16-4fb1-a0ec-e352276c0b24,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-4405add0-6ffb-4157-ba38-1ecb240df51c,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-bf877ab1-6c77-4aa7-8469-06ce2f16e49b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1890962004-172.17.0.13-1595684095674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33632,DS-21b694ae-43d9-436f-a679-5b7fa77038b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-74408abc-df18-42f1-bfcf-94308b13c39c,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-462e6662-bc98-429e-9e30-9eb863e16408,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-23a39839-2e82-4a3d-9ea6-d3b3d6963537,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-955553ae-ec96-43ea-996c-1156df5ee510,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-c0c02989-2a16-4fb1-a0ec-e352276c0b24,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-4405add0-6ffb-4157-ba38-1ecb240df51c,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-bf877ab1-6c77-4aa7-8469-06ce2f16e49b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reconstruction.pending.timeout-sec
component: hdfs:NameNode
v1: 1
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1448932971-172.17.0.13-1595684131975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41459,DS-a3ce3bd2-b2dc-485b-ad17-5ed3fd1f1007,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-3e914a06-bc30-480c-a947-526a9ab3ec44,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-f22384b0-b2dd-4449-bb16-212dc1d5b050,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-fc76aa35-bc13-47b4-866f-b0fae63bf79e,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-abbff5a1-c30d-4456-b87a-9d18f2a26af5,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-9fa49b6a-8b60-4c47-8636-b932bcca56da,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-0e3fba6c-94f4-4131-a506-50eb40514f92,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-c4db404c-70d6-4266-a5f3-93574d8d0e34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1448932971-172.17.0.13-1595684131975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41459,DS-a3ce3bd2-b2dc-485b-ad17-5ed3fd1f1007,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-3e914a06-bc30-480c-a947-526a9ab3ec44,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-f22384b0-b2dd-4449-bb16-212dc1d5b050,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-fc76aa35-bc13-47b4-866f-b0fae63bf79e,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-abbff5a1-c30d-4456-b87a-9d18f2a26af5,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-9fa49b6a-8b60-4c47-8636-b932bcca56da,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-0e3fba6c-94f4-4131-a506-50eb40514f92,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-c4db404c-70d6-4266-a5f3-93574d8d0e34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reconstruction.pending.timeout-sec
component: hdfs:NameNode
v1: 1
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753137178-172.17.0.13-1595684165804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43253,DS-c1b53b9e-b0c5-4e5b-9684-02267b9756c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-d06a934b-39d7-42e9-b6e9-812a6ea3f27b,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-d3061030-8baf-4e77-a795-ae0f9fc24d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-5b504902-e76a-4f06-8e81-c896dad0168d,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-b68fdc1c-3796-473e-87ac-f5e5edb7f9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-e6949071-4c59-412d-bb27-0c7b954c8080,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-d1c9d7aa-4c86-4051-9fb8-065ef8b10a62,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-4a12fb90-26c0-4fb1-8ea6-ad6adda2012a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753137178-172.17.0.13-1595684165804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43253,DS-c1b53b9e-b0c5-4e5b-9684-02267b9756c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-d06a934b-39d7-42e9-b6e9-812a6ea3f27b,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-d3061030-8baf-4e77-a795-ae0f9fc24d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-5b504902-e76a-4f06-8e81-c896dad0168d,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-b68fdc1c-3796-473e-87ac-f5e5edb7f9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-e6949071-4c59-412d-bb27-0c7b954c8080,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-d1c9d7aa-4c86-4051-9fb8-065ef8b10a62,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-4a12fb90-26c0-4fb1-8ea6-ad6adda2012a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reconstruction.pending.timeout-sec
component: hdfs:NameNode
v1: 1
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369473542-172.17.0.13-1595684314344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34003,DS-c7c1a27b-e2dc-49c2-a5b1-7bccc2beb600,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-f3320b91-c186-4f23-8145-be7aede48c24,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-5f314538-8004-43ee-93ad-ba4aa3998d80,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-4bc1c55f-bf3a-4053-9df2-7c7491745969,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-5b4bcabf-1d45-4e92-ba2a-09d0d03d3182,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-56137d1a-a470-4918-b11c-d8040858c6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-fdab92f4-ed96-4f65-8c9b-cbd1d46c74c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-9ea54fed-af53-4352-a9fc-69bc4b82dd4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369473542-172.17.0.13-1595684314344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34003,DS-c7c1a27b-e2dc-49c2-a5b1-7bccc2beb600,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-f3320b91-c186-4f23-8145-be7aede48c24,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-5f314538-8004-43ee-93ad-ba4aa3998d80,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-4bc1c55f-bf3a-4053-9df2-7c7491745969,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-5b4bcabf-1d45-4e92-ba2a-09d0d03d3182,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-56137d1a-a470-4918-b11c-d8040858c6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-fdab92f4-ed96-4f65-8c9b-cbd1d46c74c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-9ea54fed-af53-4352-a9fc-69bc4b82dd4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reconstruction.pending.timeout-sec
component: hdfs:NameNode
v1: 1
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1132595610-172.17.0.13-1595684350251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43667,DS-ad8f7eb3-edb9-49aa-bbe3-ddc3126ca710,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-66b7c1fe-24ac-45e3-adaf-b4c79222ec9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-354c89e4-2719-4d3a-800c-4c01a8ab5c56,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-8f4fd021-d522-4ece-9379-8c3222b38e01,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-d25986e7-74aa-4cc8-b484-24c26c34638d,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-17e2e32e-1e97-4ede-a2a1-063a8bfedb24,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-639915f3-e12c-442d-b997-cd3b02effa34,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-fc1861b7-da41-42bb-9e45-136e1e4d3688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1132595610-172.17.0.13-1595684350251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43667,DS-ad8f7eb3-edb9-49aa-bbe3-ddc3126ca710,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-66b7c1fe-24ac-45e3-adaf-b4c79222ec9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-354c89e4-2719-4d3a-800c-4c01a8ab5c56,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-8f4fd021-d522-4ece-9379-8c3222b38e01,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-d25986e7-74aa-4cc8-b484-24c26c34638d,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-17e2e32e-1e97-4ede-a2a1-063a8bfedb24,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-639915f3-e12c-442d-b997-cd3b02effa34,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-fc1861b7-da41-42bb-9e45-136e1e4d3688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reconstruction.pending.timeout-sec
component: hdfs:NameNode
v1: 1
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529580877-172.17.0.13-1595684383579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41844,DS-16159938-1824-412c-8157-82ee04ec0d72,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-d5f70947-d8fd-4bd8-b991-04ac982eb531,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-76985277-cc45-4969-ad22-0c79c5180548,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-2a50d296-f4d6-428a-8dde-c833d7acc9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-301e42cf-cf43-424c-be91-ae4f23f7972b,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-2fd35f41-11bd-4d52-ae8c-9dbae73b0a65,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-e75dd326-1a46-4067-abed-f75ca1cea197,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-8620ef8e-c9e4-439a-a5f8-f33379bd90f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529580877-172.17.0.13-1595684383579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41844,DS-16159938-1824-412c-8157-82ee04ec0d72,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-d5f70947-d8fd-4bd8-b991-04ac982eb531,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-76985277-cc45-4969-ad22-0c79c5180548,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-2a50d296-f4d6-428a-8dde-c833d7acc9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-301e42cf-cf43-424c-be91-ae4f23f7972b,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-2fd35f41-11bd-4d52-ae8c-9dbae73b0a65,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-e75dd326-1a46-4067-abed-f75ca1cea197,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-8620ef8e-c9e4-439a-a5f8-f33379bd90f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5182
