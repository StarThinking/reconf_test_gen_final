reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-534297241-172.17.0.2-1595503420173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42229,DS-3dcf138c-c914-4be0-9fed-6412a751f282,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-70771c95-8cc1-4c58-9b50-dec7197cd463,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-ea4c6042-a129-4a83-9e62-e7437f8f76a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-9d98e024-d095-4ee8-aece-4a77e22d74e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-86874ab1-bf5f-4372-88b4-ef7db12ae83c,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-06af6da5-20af-4e59-a9cc-8bd32aa57fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-c9003cf1-4bfc-41eb-bdee-f6d8bcc7fbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-76c451c9-9baf-472a-8d45-f749455026b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-534297241-172.17.0.2-1595503420173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42229,DS-3dcf138c-c914-4be0-9fed-6412a751f282,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-70771c95-8cc1-4c58-9b50-dec7197cd463,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-ea4c6042-a129-4a83-9e62-e7437f8f76a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-9d98e024-d095-4ee8-aece-4a77e22d74e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-86874ab1-bf5f-4372-88b4-ef7db12ae83c,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-06af6da5-20af-4e59-a9cc-8bd32aa57fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-c9003cf1-4bfc-41eb-bdee-f6d8bcc7fbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-76c451c9-9baf-472a-8d45-f749455026b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082600263-172.17.0.2-1595503752002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36953,DS-df4ef698-1c54-4e16-a16a-aeea4c7c621c,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-a6d1b770-22f7-4011-8463-740c71e0ca70,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-beb40f5d-fb35-4783-93f3-1ec3d758bd20,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-e3dd1dbd-c5dc-4289-98cf-5af9a781cf14,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-9a89023c-4d92-41aa-b436-d0da75a178ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-0113f15b-50cd-4d48-8c3f-4f41deae2312,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-4a12a36c-d2d8-4043-8b3e-be7bbeb8ce15,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-e3f19387-62e0-47d0-bec8-ce7756f76d04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082600263-172.17.0.2-1595503752002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36953,DS-df4ef698-1c54-4e16-a16a-aeea4c7c621c,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-a6d1b770-22f7-4011-8463-740c71e0ca70,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-beb40f5d-fb35-4783-93f3-1ec3d758bd20,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-e3dd1dbd-c5dc-4289-98cf-5af9a781cf14,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-9a89023c-4d92-41aa-b436-d0da75a178ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-0113f15b-50cd-4d48-8c3f-4f41deae2312,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-4a12a36c-d2d8-4043-8b3e-be7bbeb8ce15,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-e3f19387-62e0-47d0-bec8-ce7756f76d04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508117295-172.17.0.2-1595504644523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42451,DS-e7e93264-cd53-4334-b68e-4034f8009204,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-ba34c30d-9f17-4d9f-8086-d13d46ee4576,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-caf30c16-ed34-49da-aa8d-2deb339777ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-77e69f28-c775-4cdb-8b1f-1efdf5c10e43,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-e4750d98-730b-4775-86a1-f10ab456627f,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-6c3a7d33-8c72-458f-bdb1-9662efe7b5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-08e2268f-4972-4eef-91e0-27ed3d16ad9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-b3c756af-4908-473e-8b0d-defe95b33b05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508117295-172.17.0.2-1595504644523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42451,DS-e7e93264-cd53-4334-b68e-4034f8009204,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-ba34c30d-9f17-4d9f-8086-d13d46ee4576,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-caf30c16-ed34-49da-aa8d-2deb339777ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-77e69f28-c775-4cdb-8b1f-1efdf5c10e43,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-e4750d98-730b-4775-86a1-f10ab456627f,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-6c3a7d33-8c72-458f-bdb1-9662efe7b5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-08e2268f-4972-4eef-91e0-27ed3d16ad9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-b3c756af-4908-473e-8b0d-defe95b33b05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-602816573-172.17.0.2-1595504716709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44016,DS-5b3b0115-10a0-4a69-aff0-cc1da8afc252,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-1299dbcf-88fe-48f7-99f7-6d22d5d97c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-91e68f02-3142-448a-a48c-4298cb9fd4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-97e28858-d896-4e2f-ac30-f0266ae88dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-fcf4c251-161d-4e69-91ae-e9db00052f50,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-5ed46db5-9f4c-477c-a8d3-805166c7898d,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-3c2150ec-621a-4e46-b0f4-2bef63961922,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-2d6c7227-8e62-41fe-aea1-de3f7066f175,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-602816573-172.17.0.2-1595504716709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44016,DS-5b3b0115-10a0-4a69-aff0-cc1da8afc252,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-1299dbcf-88fe-48f7-99f7-6d22d5d97c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-91e68f02-3142-448a-a48c-4298cb9fd4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-97e28858-d896-4e2f-ac30-f0266ae88dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-fcf4c251-161d-4e69-91ae-e9db00052f50,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-5ed46db5-9f4c-477c-a8d3-805166c7898d,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-3c2150ec-621a-4e46-b0f4-2bef63961922,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-2d6c7227-8e62-41fe-aea1-de3f7066f175,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1941212007-172.17.0.2-1595504984982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34426,DS-c7c11258-9223-4e05-b095-159dc6be665b,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-268f2032-e57e-4e5b-bb32-49752b352a53,DISK], DatanodeInfoWithStorage[127.0.0.1:39630,DS-6b8c5940-e044-4214-9810-866564837992,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-a5242e61-3bc9-4abe-9353-13ed0f8b4260,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-ac2b71de-ce11-4e1a-8036-2732947333d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-0917e49e-e5f8-443b-bb00-a5e5c479d4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-d4b6dcee-a416-4e91-b46c-e55e498b51ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-8412cab1-4bf7-4dea-840a-466c73159858,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1941212007-172.17.0.2-1595504984982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34426,DS-c7c11258-9223-4e05-b095-159dc6be665b,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-268f2032-e57e-4e5b-bb32-49752b352a53,DISK], DatanodeInfoWithStorage[127.0.0.1:39630,DS-6b8c5940-e044-4214-9810-866564837992,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-a5242e61-3bc9-4abe-9353-13ed0f8b4260,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-ac2b71de-ce11-4e1a-8036-2732947333d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-0917e49e-e5f8-443b-bb00-a5e5c479d4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-d4b6dcee-a416-4e91-b46c-e55e498b51ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-8412cab1-4bf7-4dea-840a-466c73159858,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1997061338-172.17.0.2-1595505017054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36150,DS-8daf8b4a-c322-43a8-ba14-ca724e651523,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-4ebdf2bf-7b71-44cc-8536-f910e4fde6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-5c649a15-8bec-4e35-8904-128fca20516e,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-6adb7e61-1bf0-410e-bad9-b847233f91a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-2f6e6573-c31e-4d20-a114-260f0019d41f,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-ae2ad852-decc-4642-adc5-588bfed67b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-fc4adc17-ba13-4ef8-8e65-475ccf39ee3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-e30161ab-3524-4dca-b33f-494e1979fbab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1997061338-172.17.0.2-1595505017054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36150,DS-8daf8b4a-c322-43a8-ba14-ca724e651523,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-4ebdf2bf-7b71-44cc-8536-f910e4fde6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-5c649a15-8bec-4e35-8904-128fca20516e,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-6adb7e61-1bf0-410e-bad9-b847233f91a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-2f6e6573-c31e-4d20-a114-260f0019d41f,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-ae2ad852-decc-4642-adc5-588bfed67b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-fc4adc17-ba13-4ef8-8e65-475ccf39ee3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-e30161ab-3524-4dca-b33f-494e1979fbab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124218157-172.17.0.2-1595505172458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44977,DS-bdcb0766-b398-44f4-aaef-9a939bd6c9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-e0d13a36-f03d-4ccb-ad00-774c395e4a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-5d30d2b9-381d-449f-80eb-31bc09d2d021,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-d659e1eb-8f18-4eb1-9140-c0b89d5b99b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-5b2d8d78-0091-40a9-a141-fc6c21870ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-4a7f897c-43af-4f7b-8128-1270e24fff34,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-5715df58-53cb-438b-843d-7fbb200331a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-d50e6837-ad66-4251-8d5d-1512138b4f45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124218157-172.17.0.2-1595505172458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44977,DS-bdcb0766-b398-44f4-aaef-9a939bd6c9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-e0d13a36-f03d-4ccb-ad00-774c395e4a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-5d30d2b9-381d-449f-80eb-31bc09d2d021,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-d659e1eb-8f18-4eb1-9140-c0b89d5b99b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-5b2d8d78-0091-40a9-a141-fc6c21870ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-4a7f897c-43af-4f7b-8128-1270e24fff34,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-5715df58-53cb-438b-843d-7fbb200331a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-d50e6837-ad66-4251-8d5d-1512138b4f45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927633772-172.17.0.2-1595505333444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42522,DS-189aff57-5111-4a6a-8e57-558ddfd6bc99,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-53f49722-1d80-4294-bb18-2674e5ecd8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-c8d4d4e2-8775-408e-aeb1-b6f91ba79ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-41616f14-28d5-459a-8784-ff440f3e119b,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-8c73573e-6dfa-4101-9b31-37926ef16b71,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-679cad65-af1f-47ca-b63d-148319927fac,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-5422f2bd-698a-48bd-92ee-d8b74c9896eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-c8008083-a4f5-4b25-bc6c-3d8c2c438189,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927633772-172.17.0.2-1595505333444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42522,DS-189aff57-5111-4a6a-8e57-558ddfd6bc99,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-53f49722-1d80-4294-bb18-2674e5ecd8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-c8d4d4e2-8775-408e-aeb1-b6f91ba79ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-41616f14-28d5-459a-8784-ff440f3e119b,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-8c73573e-6dfa-4101-9b31-37926ef16b71,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-679cad65-af1f-47ca-b63d-148319927fac,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-5422f2bd-698a-48bd-92ee-d8b74c9896eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-c8008083-a4f5-4b25-bc6c-3d8c2c438189,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959567803-172.17.0.2-1595505525906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40439,DS-b652d0c8-76e0-40ff-ac23-9096d08b7d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-43f87153-b321-4b41-9883-6b121bcc58b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-ea514e00-68ae-451e-9482-918e765031f4,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-d608f3c2-9b26-43da-906b-dd6f553a9b24,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-7727ee9e-6f40-45d6-940e-35bba1a5fc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-5552a533-4806-4a12-abe8-c6bd833561ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-ecfdb822-859f-4938-8545-7fa08ac286e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-68100d17-77f6-41e2-9675-3ec5285864af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959567803-172.17.0.2-1595505525906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40439,DS-b652d0c8-76e0-40ff-ac23-9096d08b7d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-43f87153-b321-4b41-9883-6b121bcc58b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-ea514e00-68ae-451e-9482-918e765031f4,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-d608f3c2-9b26-43da-906b-dd6f553a9b24,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-7727ee9e-6f40-45d6-940e-35bba1a5fc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-5552a533-4806-4a12-abe8-c6bd833561ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-ecfdb822-859f-4938-8545-7fa08ac286e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-68100d17-77f6-41e2-9675-3ec5285864af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-465226629-172.17.0.2-1595505824260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42101,DS-183144b8-0030-4a95-a02a-ae4ef6707976,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-707d4d9a-f906-413f-8b64-b52edeeca1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-add0df3d-f953-4b98-ac09-5b888712cc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-febc361e-94d3-4b08-8b92-e837a9520dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-0934ff88-cd0e-476f-8414-78b32b5aa261,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-e85de0a7-5e37-4dca-bb99-b6074b6b88bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-576fb67f-ec6a-4af3-8a50-8ddbaef488b5,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-a226172c-042e-4713-9a18-cb74c6a80941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-465226629-172.17.0.2-1595505824260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42101,DS-183144b8-0030-4a95-a02a-ae4ef6707976,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-707d4d9a-f906-413f-8b64-b52edeeca1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-add0df3d-f953-4b98-ac09-5b888712cc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-febc361e-94d3-4b08-8b92-e837a9520dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-0934ff88-cd0e-476f-8414-78b32b5aa261,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-e85de0a7-5e37-4dca-bb99-b6074b6b88bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-576fb67f-ec6a-4af3-8a50-8ddbaef488b5,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-a226172c-042e-4713-9a18-cb74c6a80941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1947208974-172.17.0.2-1595506237349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33592,DS-e146fe4f-3d99-49ed-9b68-3c3da8d747ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-3486ded0-5843-48f6-a101-74a0fa4fa164,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-e968d9b9-8179-481c-ba69-259b66a69c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-3bc6074b-c201-4133-a599-1174a9ab4940,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-42c17c48-baa3-4687-ba86-80ad61fdde8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-9fe101b8-f0a8-48a8-a49a-8427114b4b96,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-639cc257-994b-419b-9be5-f28b691cabf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-d7e34f02-e5ae-407d-92b9-ea38fa602c99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1947208974-172.17.0.2-1595506237349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33592,DS-e146fe4f-3d99-49ed-9b68-3c3da8d747ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-3486ded0-5843-48f6-a101-74a0fa4fa164,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-e968d9b9-8179-481c-ba69-259b66a69c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-3bc6074b-c201-4133-a599-1174a9ab4940,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-42c17c48-baa3-4687-ba86-80ad61fdde8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-9fe101b8-f0a8-48a8-a49a-8427114b4b96,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-639cc257-994b-419b-9be5-f28b691cabf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-d7e34f02-e5ae-407d-92b9-ea38fa602c99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-520318083-172.17.0.2-1595506276117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46770,DS-10885d5e-9122-4675-a3e5-12e1160770ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-10fda06d-ae00-4f90-bd79-ad873111adc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-497698d5-e181-41dc-97ba-0b0d306d3b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-cd75f9b6-19f1-47b4-b554-4af887eae7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-8bec53ee-7f59-414b-93fc-a49f3b33a012,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-b72d9bda-3c64-48d5-ad1f-363b89c1244f,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-5aada820-8bd2-4642-86b7-4139480cf7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-2a9844ee-f679-4ad3-a0a6-e5317833be33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-520318083-172.17.0.2-1595506276117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46770,DS-10885d5e-9122-4675-a3e5-12e1160770ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-10fda06d-ae00-4f90-bd79-ad873111adc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-497698d5-e181-41dc-97ba-0b0d306d3b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-cd75f9b6-19f1-47b4-b554-4af887eae7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-8bec53ee-7f59-414b-93fc-a49f3b33a012,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-b72d9bda-3c64-48d5-ad1f-363b89c1244f,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-5aada820-8bd2-4642-86b7-4139480cf7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-2a9844ee-f679-4ad3-a0a6-e5317833be33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393322723-172.17.0.2-1595506316208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45538,DS-8d59032a-8959-491f-9a50-51ea2c0bc985,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-f21f3b4d-469a-4922-8353-66c67a25df0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-dc38f489-b1e0-4e0a-8d8c-0529be73d6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-366d2603-4721-48d7-86e8-6e59be487123,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-9069f557-3714-45d5-943c-37d556de67b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-9277edaf-55c7-4894-befe-b1ef266cd65c,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-ccec0ec3-b15f-4bff-b374-14801b5d78b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-1c0ecad0-951c-486a-a332-e659d412fdf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393322723-172.17.0.2-1595506316208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45538,DS-8d59032a-8959-491f-9a50-51ea2c0bc985,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-f21f3b4d-469a-4922-8353-66c67a25df0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-dc38f489-b1e0-4e0a-8d8c-0529be73d6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-366d2603-4721-48d7-86e8-6e59be487123,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-9069f557-3714-45d5-943c-37d556de67b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-9277edaf-55c7-4894-befe-b1ef266cd65c,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-ccec0ec3-b15f-4bff-b374-14801b5d78b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-1c0ecad0-951c-486a-a332-e659d412fdf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467208862-172.17.0.2-1595507159308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35928,DS-ab34e754-026d-480f-9b92-c01da3e8868c,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-c1ce2969-f2bf-44d4-978b-f5c678d2af77,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-ccd3f810-c288-4c71-b58a-16b25bbd1581,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-475f2d59-a6c2-4be5-9f50-b3b90ec0283e,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-e5a4f29a-3db5-4203-ba43-2da1932e45ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-ca568f2c-b75e-4ffe-8731-3fd64b05019f,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-0d0ca786-5302-4142-a8dc-a5ad6f58d3af,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-f9eb1b3f-8d31-4ce4-a7a8-b2cfc634e138,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467208862-172.17.0.2-1595507159308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35928,DS-ab34e754-026d-480f-9b92-c01da3e8868c,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-c1ce2969-f2bf-44d4-978b-f5c678d2af77,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-ccd3f810-c288-4c71-b58a-16b25bbd1581,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-475f2d59-a6c2-4be5-9f50-b3b90ec0283e,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-e5a4f29a-3db5-4203-ba43-2da1932e45ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-ca568f2c-b75e-4ffe-8731-3fd64b05019f,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-0d0ca786-5302-4142-a8dc-a5ad6f58d3af,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-f9eb1b3f-8d31-4ce4-a7a8-b2cfc634e138,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226736972-172.17.0.2-1595507188264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36512,DS-3786780f-65b4-4380-9544-b6c2218f8123,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-55d1e9d3-71ff-48d5-9cb8-4652546b4c38,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-e480c6f5-9615-4c3d-adeb-17c67d1021e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-070caaab-7726-4679-a36f-c62902a0663f,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-d7394e6c-f0b7-45e2-9aa9-3752b5685313,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-56a2f68d-91a7-41bc-80e0-5f24e897a08a,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-b2c26027-434c-4c4b-a89a-e64167048837,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-f8e9036c-c3ab-4469-9098-962d0c567d67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226736972-172.17.0.2-1595507188264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36512,DS-3786780f-65b4-4380-9544-b6c2218f8123,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-55d1e9d3-71ff-48d5-9cb8-4652546b4c38,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-e480c6f5-9615-4c3d-adeb-17c67d1021e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-070caaab-7726-4679-a36f-c62902a0663f,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-d7394e6c-f0b7-45e2-9aa9-3752b5685313,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-56a2f68d-91a7-41bc-80e0-5f24e897a08a,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-b2c26027-434c-4c4b-a89a-e64167048837,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-f8e9036c-c3ab-4469-9098-962d0c567d67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286028416-172.17.0.2-1595508242341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44617,DS-99d14847-ba11-4cbd-a65f-ffaec66e177a,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-9571f5d4-11e4-4901-9332-9eb82273f815,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-d96a8b59-41cd-4022-9289-0f35a886c80f,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-33be62ae-3ea1-4940-b302-ee5a1b79f1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-fdd079d9-53fa-4ba0-9e52-8d866a5f7087,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-13864864-a6b6-409d-b620-27ec75e59b94,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-18ea8088-c412-4446-b402-571b708fdd96,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-0f0a7776-95f3-4b56-84e1-0e573c52f831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286028416-172.17.0.2-1595508242341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44617,DS-99d14847-ba11-4cbd-a65f-ffaec66e177a,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-9571f5d4-11e4-4901-9332-9eb82273f815,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-d96a8b59-41cd-4022-9289-0f35a886c80f,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-33be62ae-3ea1-4940-b302-ee5a1b79f1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-fdd079d9-53fa-4ba0-9e52-8d866a5f7087,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-13864864-a6b6-409d-b620-27ec75e59b94,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-18ea8088-c412-4446-b402-571b708fdd96,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-0f0a7776-95f3-4b56-84e1-0e573c52f831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278623774-172.17.0.2-1595508324623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33919,DS-ea6cd4aa-dcc6-42b1-90ac-440d590aa24a,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-bdc61cba-b26a-4f67-ba95-bc22db1438eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-cce32b6c-86e1-4a19-b78f-25e45e66e6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-6f63b4e7-9f50-4edc-9ee7-9ae100ee4976,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-82d8847c-8d1e-4115-92bb-8c7152acd213,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-99797d75-e970-4062-b193-7156b4d25abd,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-c6c84906-18f8-4c1e-8abd-046c9eaef0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-a50b5eb6-e535-4476-9051-ab45c3a1b7e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278623774-172.17.0.2-1595508324623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33919,DS-ea6cd4aa-dcc6-42b1-90ac-440d590aa24a,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-bdc61cba-b26a-4f67-ba95-bc22db1438eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-cce32b6c-86e1-4a19-b78f-25e45e66e6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-6f63b4e7-9f50-4edc-9ee7-9ae100ee4976,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-82d8847c-8d1e-4115-92bb-8c7152acd213,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-99797d75-e970-4062-b193-7156b4d25abd,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-c6c84906-18f8-4c1e-8abd-046c9eaef0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-a50b5eb6-e535-4476-9051-ab45c3a1b7e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345518232-172.17.0.2-1595508477599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34520,DS-1ae577c7-bb8e-4f93-9536-c8effb5abd71,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-f4107492-dfb3-4df0-bde9-374e945a5593,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-a3b20be6-5928-44b2-bdfb-ff1573f4e6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-93446dab-7d6c-4b8c-bd34-8d581c92fa93,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-ccaeea78-bfdf-4c32-aabd-3c618688647c,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-c301b877-4237-445c-9dec-edff85701629,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-666bd74f-59ac-4543-9a7e-2b47566be484,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-d6c7110b-e4d2-4f81-865a-00b3b14691db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345518232-172.17.0.2-1595508477599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34520,DS-1ae577c7-bb8e-4f93-9536-c8effb5abd71,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-f4107492-dfb3-4df0-bde9-374e945a5593,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-a3b20be6-5928-44b2-bdfb-ff1573f4e6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-93446dab-7d6c-4b8c-bd34-8d581c92fa93,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-ccaeea78-bfdf-4c32-aabd-3c618688647c,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-c301b877-4237-445c-9dec-edff85701629,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-666bd74f-59ac-4543-9a7e-2b47566be484,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-d6c7110b-e4d2-4f81-865a-00b3b14691db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5621
