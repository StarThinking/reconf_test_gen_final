reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663738746-172.17.0.9-1595570511365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40499,DS-2b04f46a-0951-4bcc-aaf6-ddc453621112,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-654d6184-2c4b-42eb-a4c6-c04e7cfb8dea,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-7511100e-17aa-4054-ace9-e250a0c19273,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-822d3647-a6a4-41b2-bfd2-cff5540e6302,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-276e743f-c4cb-4a6d-9029-7ffc3ab4590c,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-123e2d22-fe2b-44d3-9d27-db3763852697,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-e0b9f833-1ba9-4613-8edf-d03e2453b913,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-234e5641-fd0f-4d7c-9cea-583762c0e199,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663738746-172.17.0.9-1595570511365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40499,DS-2b04f46a-0951-4bcc-aaf6-ddc453621112,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-654d6184-2c4b-42eb-a4c6-c04e7cfb8dea,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-7511100e-17aa-4054-ace9-e250a0c19273,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-822d3647-a6a4-41b2-bfd2-cff5540e6302,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-276e743f-c4cb-4a6d-9029-7ffc3ab4590c,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-123e2d22-fe2b-44d3-9d27-db3763852697,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-e0b9f833-1ba9-4613-8edf-d03e2453b913,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-234e5641-fd0f-4d7c-9cea-583762c0e199,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426604385-172.17.0.9-1595570760856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42917,DS-7e9d645f-bf5f-48dc-a423-0a800759616f,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-3ec7003e-0d65-41b6-b271-1da008785b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-0c5a8cbc-fe68-4348-91bb-c4f22190865e,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-f8a0a6d3-85dd-42d4-b923-751550ac0867,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-dac6ce12-e165-4f3f-bc67-52213b0d09ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-19b265fa-86bb-4539-bff0-e440dc5d4cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-8a0089a2-0d00-4f53-b9b2-0f8af27110be,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-5c313f0c-2bdc-406f-9280-9b31bc54f77b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426604385-172.17.0.9-1595570760856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42917,DS-7e9d645f-bf5f-48dc-a423-0a800759616f,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-3ec7003e-0d65-41b6-b271-1da008785b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-0c5a8cbc-fe68-4348-91bb-c4f22190865e,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-f8a0a6d3-85dd-42d4-b923-751550ac0867,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-dac6ce12-e165-4f3f-bc67-52213b0d09ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-19b265fa-86bb-4539-bff0-e440dc5d4cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-8a0089a2-0d00-4f53-b9b2-0f8af27110be,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-5c313f0c-2bdc-406f-9280-9b31bc54f77b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-179230294-172.17.0.9-1595570949169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33480,DS-92875663-bbb3-44bd-b9b5-50d0b1ea5ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-c38dfc35-99e6-4442-9a14-d2d8bf3d4817,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-7bcd84c3-2910-4c19-bf04-4ff2afcaf727,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-17375fe9-aefb-4bde-b7c1-37a34f4e4426,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-c816b2be-695c-4740-bded-4cd2e67a3afa,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-c3e8f410-0f5a-4f6a-9f5c-e994bf9c1021,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-05e047e0-60a3-4d2f-8ea6-e2daaefb0d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-57a9850d-654e-4475-a3e9-69ca28ec7027,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-179230294-172.17.0.9-1595570949169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33480,DS-92875663-bbb3-44bd-b9b5-50d0b1ea5ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-c38dfc35-99e6-4442-9a14-d2d8bf3d4817,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-7bcd84c3-2910-4c19-bf04-4ff2afcaf727,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-17375fe9-aefb-4bde-b7c1-37a34f4e4426,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-c816b2be-695c-4740-bded-4cd2e67a3afa,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-c3e8f410-0f5a-4f6a-9f5c-e994bf9c1021,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-05e047e0-60a3-4d2f-8ea6-e2daaefb0d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-57a9850d-654e-4475-a3e9-69ca28ec7027,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1125707060-172.17.0.9-1595571058704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39916,DS-de1aec17-bc63-45a6-b487-5895640a27de,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-6f5ea5e6-af99-4bb6-80f4-3f8f3d24da55,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-ca2ce879-eb29-4379-ad2d-2069f2ef87eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-a70bac07-0aab-4bb9-b780-f37743737a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-55d60f76-f72c-43e0-a48e-84262e91c2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-73beadc8-c7f8-4bb7-9ba3-550c654c2bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-ccc8c92a-7c69-4a12-b1b5-02ac9370581b,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-a018d349-f369-4e3d-aa7e-09ec034218b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1125707060-172.17.0.9-1595571058704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39916,DS-de1aec17-bc63-45a6-b487-5895640a27de,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-6f5ea5e6-af99-4bb6-80f4-3f8f3d24da55,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-ca2ce879-eb29-4379-ad2d-2069f2ef87eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-a70bac07-0aab-4bb9-b780-f37743737a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-55d60f76-f72c-43e0-a48e-84262e91c2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-73beadc8-c7f8-4bb7-9ba3-550c654c2bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-ccc8c92a-7c69-4a12-b1b5-02ac9370581b,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-a018d349-f369-4e3d-aa7e-09ec034218b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-38476196-172.17.0.9-1595571237863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43431,DS-7ef80ea7-e30a-493d-bc86-5741c5d40b59,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-c0d45ef5-35dd-4575-bc38-ecce92c16c43,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-65b3ab52-55ce-4a16-8c3b-e6c23646bb52,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-8b13c095-1730-405c-81c9-a7c0d9470aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-d31e9a78-eef4-4dfc-b8db-3f217f752b86,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-45d05b86-3850-41eb-b78d-b1df1671a509,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-a83b25b8-19e7-429e-90c0-55bcf168e470,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-af76a494-1e0b-41e6-9728-49fe91f05df0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-38476196-172.17.0.9-1595571237863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43431,DS-7ef80ea7-e30a-493d-bc86-5741c5d40b59,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-c0d45ef5-35dd-4575-bc38-ecce92c16c43,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-65b3ab52-55ce-4a16-8c3b-e6c23646bb52,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-8b13c095-1730-405c-81c9-a7c0d9470aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-d31e9a78-eef4-4dfc-b8db-3f217f752b86,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-45d05b86-3850-41eb-b78d-b1df1671a509,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-a83b25b8-19e7-429e-90c0-55bcf168e470,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-af76a494-1e0b-41e6-9728-49fe91f05df0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2127814909-172.17.0.9-1595571277681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32991,DS-b3fd4726-1816-4d64-b3e4-639152f60dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-b12c718c-1cd7-42b2-9b96-910ce630269e,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-987a5583-081b-478f-93a9-3a8945deb69f,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-06468014-cef5-4c2d-aa49-04055e596505,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-70870a3c-fc53-4c7c-8ca6-afe13ed8cb61,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-2841ec14-8321-414d-957f-cefab66c7c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-1ed242e7-db46-4aaa-a9eb-c1fdaf84b4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-39f36ba2-2b0d-4366-9685-c73e5ed73adf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2127814909-172.17.0.9-1595571277681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32991,DS-b3fd4726-1816-4d64-b3e4-639152f60dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-b12c718c-1cd7-42b2-9b96-910ce630269e,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-987a5583-081b-478f-93a9-3a8945deb69f,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-06468014-cef5-4c2d-aa49-04055e596505,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-70870a3c-fc53-4c7c-8ca6-afe13ed8cb61,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-2841ec14-8321-414d-957f-cefab66c7c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-1ed242e7-db46-4aaa-a9eb-c1fdaf84b4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-39f36ba2-2b0d-4366-9685-c73e5ed73adf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1527680794-172.17.0.9-1595571386957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34796,DS-41f5acf5-5ece-496f-a533-c88a8fccf0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-41e6759a-d398-415c-9859-e8d1fc7711d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-70cf65ac-12a5-4d6b-b72e-02db6f143228,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-5dd48973-1f27-495c-a4ab-7a859792206d,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-3c28150c-ff51-42ae-a043-1a36f65cb770,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-7a7d01bc-3ead-4f74-be42-9cdd80801e46,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-3a34c143-669b-4694-8479-2a0ca5305be9,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-ceb7e07d-b95c-4756-9776-cc6ac06abe4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1527680794-172.17.0.9-1595571386957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34796,DS-41f5acf5-5ece-496f-a533-c88a8fccf0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-41e6759a-d398-415c-9859-e8d1fc7711d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-70cf65ac-12a5-4d6b-b72e-02db6f143228,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-5dd48973-1f27-495c-a4ab-7a859792206d,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-3c28150c-ff51-42ae-a043-1a36f65cb770,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-7a7d01bc-3ead-4f74-be42-9cdd80801e46,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-3a34c143-669b-4694-8479-2a0ca5305be9,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-ceb7e07d-b95c-4756-9776-cc6ac06abe4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478840951-172.17.0.9-1595571623271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45957,DS-897f240a-48b6-4bf7-bc3d-a3536e52e4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-e8f35bd7-4888-4b40-8f8a-3bade4a31332,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-6a3ce6c5-1e64-4ca5-af7e-b59899a4f854,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-9cdcf40d-6baf-4518-9bbe-5a02f20d663c,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-efcf8004-c67f-4dbd-97f2-fe284679c06a,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-cb0c8a69-e60b-40cb-b3ae-866b66f833ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-402ee1ef-8f0e-493a-8c9e-95b2fa46fb85,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-1434eadf-d9d7-45c0-8016-e4eee616a427,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478840951-172.17.0.9-1595571623271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45957,DS-897f240a-48b6-4bf7-bc3d-a3536e52e4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-e8f35bd7-4888-4b40-8f8a-3bade4a31332,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-6a3ce6c5-1e64-4ca5-af7e-b59899a4f854,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-9cdcf40d-6baf-4518-9bbe-5a02f20d663c,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-efcf8004-c67f-4dbd-97f2-fe284679c06a,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-cb0c8a69-e60b-40cb-b3ae-866b66f833ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-402ee1ef-8f0e-493a-8c9e-95b2fa46fb85,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-1434eadf-d9d7-45c0-8016-e4eee616a427,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524831914-172.17.0.9-1595572873854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42511,DS-bc06f31e-4328-451a-868f-a6c8cbf0b485,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-9f090d7d-29bb-4e60-96be-32ced5bf53fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-c8d4a513-185d-4ce0-8133-00af8bbb3459,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-20848b5c-3ce4-402b-a109-9a13b5b74db5,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-5aa05573-d8f7-48ec-8ecf-dceba95420a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-12156eb5-de37-48b6-998f-da937b0cda5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-365bd30c-abd2-49d9-80b7-5cf715e9ee32,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-6e2dd688-e3ee-4d90-898e-2f8b0b431d90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524831914-172.17.0.9-1595572873854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42511,DS-bc06f31e-4328-451a-868f-a6c8cbf0b485,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-9f090d7d-29bb-4e60-96be-32ced5bf53fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-c8d4a513-185d-4ce0-8133-00af8bbb3459,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-20848b5c-3ce4-402b-a109-9a13b5b74db5,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-5aa05573-d8f7-48ec-8ecf-dceba95420a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-12156eb5-de37-48b6-998f-da937b0cda5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-365bd30c-abd2-49d9-80b7-5cf715e9ee32,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-6e2dd688-e3ee-4d90-898e-2f8b0b431d90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-555995319-172.17.0.9-1595573018931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45508,DS-857f1e73-3cc4-4afe-afc6-108b5128909c,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-5b081984-9e3b-4572-8623-e832978787ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-8ef247a3-09ba-41b2-93a8-d44230b1f395,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-b18b4dc6-8580-4e39-a21c-b41a36395a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-8c60dac8-a0b3-483c-aca7-75babaf59983,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-1ee10949-2fcc-48be-8006-c6ae30d2e85d,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-7100fd3a-dff8-41c4-8d58-d81bf54888c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-dac0fce4-3f3c-4f32-8be6-ce7fffc46da0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-555995319-172.17.0.9-1595573018931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45508,DS-857f1e73-3cc4-4afe-afc6-108b5128909c,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-5b081984-9e3b-4572-8623-e832978787ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-8ef247a3-09ba-41b2-93a8-d44230b1f395,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-b18b4dc6-8580-4e39-a21c-b41a36395a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-8c60dac8-a0b3-483c-aca7-75babaf59983,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-1ee10949-2fcc-48be-8006-c6ae30d2e85d,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-7100fd3a-dff8-41c4-8d58-d81bf54888c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-dac0fce4-3f3c-4f32-8be6-ce7fffc46da0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-719474841-172.17.0.9-1595573452502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36795,DS-202aef34-b689-40b5-abd1-adb3badfa5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-ac226a7c-4876-4ed4-9af7-4247a1f2e005,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-7d4af4a6-cecf-4e81-a951-35c7ba284daf,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-77956513-8606-4568-bb78-eaab270b11f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-e3eee5c2-faef-4041-9f8b-b99801b32654,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-e655762c-e7e4-468f-b431-078d8a7847c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-7d24c7bb-db30-4048-ba65-eb6abcebd33a,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-6945f8cf-8657-4495-9fb5-b270f15f1761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-719474841-172.17.0.9-1595573452502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36795,DS-202aef34-b689-40b5-abd1-adb3badfa5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-ac226a7c-4876-4ed4-9af7-4247a1f2e005,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-7d4af4a6-cecf-4e81-a951-35c7ba284daf,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-77956513-8606-4568-bb78-eaab270b11f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-e3eee5c2-faef-4041-9f8b-b99801b32654,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-e655762c-e7e4-468f-b431-078d8a7847c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-7d24c7bb-db30-4048-ba65-eb6abcebd33a,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-6945f8cf-8657-4495-9fb5-b270f15f1761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170882643-172.17.0.9-1595573489113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34648,DS-1ab93da5-e512-458e-8767-3c73b6998a15,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-5281305b-a155-42f5-a4d8-ad2d4929b8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-1dcf106f-a08e-4c33-8b20-bd92deb84894,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-3c1ae4ff-9384-4161-8ae6-e1ee5acb2661,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-d1bfffb6-81f9-4d4a-b4b3-e560ff2b04ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-1f4258d9-0cb8-46a0-80ae-3826e86a1a13,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-7ed3d2b0-b5b6-4171-ae6b-dd5de10e0ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-dd09aaf6-c437-49f6-99c1-2dd1d70fbfff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170882643-172.17.0.9-1595573489113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34648,DS-1ab93da5-e512-458e-8767-3c73b6998a15,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-5281305b-a155-42f5-a4d8-ad2d4929b8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-1dcf106f-a08e-4c33-8b20-bd92deb84894,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-3c1ae4ff-9384-4161-8ae6-e1ee5acb2661,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-d1bfffb6-81f9-4d4a-b4b3-e560ff2b04ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-1f4258d9-0cb8-46a0-80ae-3826e86a1a13,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-7ed3d2b0-b5b6-4171-ae6b-dd5de10e0ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-dd09aaf6-c437-49f6-99c1-2dd1d70fbfff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438535781-172.17.0.9-1595574005839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36627,DS-d4e2d9a6-c694-44ed-8fa4-6e711c1441ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-d9769d38-e49e-41da-bf35-8304be4f19d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-ae33bbba-7b8b-4c2e-89c1-83bbd78569df,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-df57c8f8-bade-41c4-8629-6be2e6ab192c,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-ec3506f1-8dc0-47f2-9cce-73475239f44d,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-8357ad53-6513-4fc2-81c9-0c9dd62a2cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-e9ee8743-ae19-4186-b90f-a19aa838da35,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-6564af13-eb91-4327-abe9-afebeef947f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438535781-172.17.0.9-1595574005839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36627,DS-d4e2d9a6-c694-44ed-8fa4-6e711c1441ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-d9769d38-e49e-41da-bf35-8304be4f19d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-ae33bbba-7b8b-4c2e-89c1-83bbd78569df,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-df57c8f8-bade-41c4-8629-6be2e6ab192c,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-ec3506f1-8dc0-47f2-9cce-73475239f44d,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-8357ad53-6513-4fc2-81c9-0c9dd62a2cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-e9ee8743-ae19-4186-b90f-a19aa838da35,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-6564af13-eb91-4327-abe9-afebeef947f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116542454-172.17.0.9-1595574401369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37932,DS-dd9426bb-47cf-4f94-af22-ddebd3f20ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-cc5e0d4a-fab4-42e0-9df6-0cef9ce9b1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-56f81192-2acb-473a-8c77-4dc64c99a61a,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-cc25b652-8a9f-40d8-a887-7b3a2c56a91d,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-c7419fb6-3665-46a9-9d2f-d8bac05b3e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-20285a0a-2bbe-4979-8043-1aa6a964262c,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-436eeace-45ae-4ff0-b857-0f686a314fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-e3ecb957-5a63-42e1-bc96-91278bd3c47c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116542454-172.17.0.9-1595574401369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37932,DS-dd9426bb-47cf-4f94-af22-ddebd3f20ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-cc5e0d4a-fab4-42e0-9df6-0cef9ce9b1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-56f81192-2acb-473a-8c77-4dc64c99a61a,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-cc25b652-8a9f-40d8-a887-7b3a2c56a91d,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-c7419fb6-3665-46a9-9d2f-d8bac05b3e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-20285a0a-2bbe-4979-8043-1aa6a964262c,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-436eeace-45ae-4ff0-b857-0f686a314fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-e3ecb957-5a63-42e1-bc96-91278bd3c47c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859495640-172.17.0.9-1595574647551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35437,DS-2f97e5db-84bb-47af-b145-b2ff2c94483b,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-5d830096-1f7b-412e-a373-10ab1d7b9918,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-a1319e34-138d-4bab-9c89-11f14a8031c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-1126b944-1b3c-4172-877d-a682412e9fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-ea895201-d220-4325-8c96-0afb8cc33d99,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-97e49b62-29e3-4692-b1c8-f54ffeca8935,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-0554f250-7a43-4f94-ab37-19147e08bf16,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-cc409d11-b548-48b4-a57f-e51837c3c47a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859495640-172.17.0.9-1595574647551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35437,DS-2f97e5db-84bb-47af-b145-b2ff2c94483b,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-5d830096-1f7b-412e-a373-10ab1d7b9918,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-a1319e34-138d-4bab-9c89-11f14a8031c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-1126b944-1b3c-4172-877d-a682412e9fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-ea895201-d220-4325-8c96-0afb8cc33d99,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-97e49b62-29e3-4692-b1c8-f54ffeca8935,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-0554f250-7a43-4f94-ab37-19147e08bf16,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-cc409d11-b548-48b4-a57f-e51837c3c47a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-651530214-172.17.0.9-1595574675473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33668,DS-07acbe69-7a16-4815-9e39-9b5f8dad12aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-4763cfdc-8a62-44d6-877d-03dc730c80e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-99ec86c7-5bb8-4f1f-a366-a7283613b852,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-fc5fe1ac-01c1-44ec-b3d0-a38065a3c31e,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-a441fa84-0333-4e6d-a3b8-d4fbc2e39946,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-68e94f4a-7028-4ec7-b5d2-aec07a9b6e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-f40dcb55-9ec6-41c4-8831-7ffffb4aa6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-0cd32a76-732d-4437-9ecb-e51f35c6edfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-651530214-172.17.0.9-1595574675473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33668,DS-07acbe69-7a16-4815-9e39-9b5f8dad12aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-4763cfdc-8a62-44d6-877d-03dc730c80e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-99ec86c7-5bb8-4f1f-a366-a7283613b852,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-fc5fe1ac-01c1-44ec-b3d0-a38065a3c31e,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-a441fa84-0333-4e6d-a3b8-d4fbc2e39946,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-68e94f4a-7028-4ec7-b5d2-aec07a9b6e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-f40dcb55-9ec6-41c4-8831-7ffffb4aa6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-0cd32a76-732d-4437-9ecb-e51f35c6edfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288208816-172.17.0.9-1595574962471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43543,DS-f3494e85-7b88-4eb1-995c-4f147da15dee,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-74151abc-0f55-4bfd-afd9-04caf5709548,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-cb023295-2f73-4e87-964a-2723eeb54ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-bfdcce79-209c-4de6-b765-1366922a5af8,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-d1333222-37c6-4cb6-b094-461f5235e947,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-530ff4af-c42b-4e35-aa3c-d18e6f2a314c,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-4384c5f1-cc3f-43b6-9a3b-cff880db8100,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-b1083c0a-0331-4ac9-b330-d05b060bfb45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288208816-172.17.0.9-1595574962471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43543,DS-f3494e85-7b88-4eb1-995c-4f147da15dee,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-74151abc-0f55-4bfd-afd9-04caf5709548,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-cb023295-2f73-4e87-964a-2723eeb54ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-bfdcce79-209c-4de6-b765-1366922a5af8,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-d1333222-37c6-4cb6-b094-461f5235e947,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-530ff4af-c42b-4e35-aa3c-d18e6f2a314c,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-4384c5f1-cc3f-43b6-9a3b-cff880db8100,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-b1083c0a-0331-4ac9-b330-d05b060bfb45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5290
