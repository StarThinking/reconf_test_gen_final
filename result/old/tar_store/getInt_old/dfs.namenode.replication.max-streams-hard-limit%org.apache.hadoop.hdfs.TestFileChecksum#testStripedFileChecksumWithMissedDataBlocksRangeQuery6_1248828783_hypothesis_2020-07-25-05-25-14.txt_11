reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977869559-172.17.0.9-1595654770133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40863,DS-c8a3fad4-8c56-412f-92b7-17ef8a54eff7,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-84925fc0-a117-4a68-bf0b-bce989e57238,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-53bae62d-960f-4232-91c1-4b3411cf94b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-e1a151b7-2f34-4c48-929d-26a60faf43e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-2f3d0b32-e321-4bfb-9b98-12f09af51d26,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-b48f9f24-d488-4f65-be16-5181c3b82e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-00fc5874-49c9-444b-a26a-e557dfb3c8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-3d3268eb-f01a-43ee-9011-0cffbb63bd62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977869559-172.17.0.9-1595654770133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40863,DS-c8a3fad4-8c56-412f-92b7-17ef8a54eff7,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-84925fc0-a117-4a68-bf0b-bce989e57238,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-53bae62d-960f-4232-91c1-4b3411cf94b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-e1a151b7-2f34-4c48-929d-26a60faf43e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-2f3d0b32-e321-4bfb-9b98-12f09af51d26,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-b48f9f24-d488-4f65-be16-5181c3b82e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-00fc5874-49c9-444b-a26a-e557dfb3c8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-3d3268eb-f01a-43ee-9011-0cffbb63bd62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204716865-172.17.0.9-1595654970637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38124,DS-1dab0e4e-5fa0-4e64-ac30-6e2c0e4f3a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-7985dfc6-273d-4878-b9d8-5bf25201a242,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-8db55693-f1ff-473f-9140-d46798120227,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-67490cbd-add6-41f1-adb9-ac860e2f5279,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-e4d16eac-281d-4835-9365-0467a5bf6174,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-b586c44f-f759-4808-bc21-bf31a3671e21,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-f38dccb3-744c-4f88-bc18-1f3dbd4cf99d,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-0d9dbcca-812c-4887-8069-fb139b5044b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204716865-172.17.0.9-1595654970637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38124,DS-1dab0e4e-5fa0-4e64-ac30-6e2c0e4f3a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-7985dfc6-273d-4878-b9d8-5bf25201a242,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-8db55693-f1ff-473f-9140-d46798120227,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-67490cbd-add6-41f1-adb9-ac860e2f5279,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-e4d16eac-281d-4835-9365-0467a5bf6174,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-b586c44f-f759-4808-bc21-bf31a3671e21,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-f38dccb3-744c-4f88-bc18-1f3dbd4cf99d,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-0d9dbcca-812c-4887-8069-fb139b5044b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437665529-172.17.0.9-1595655060468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45488,DS-9ceee58d-c6e4-4f69-a4df-dd0e7e23f250,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-de03ec86-2eed-4f51-b2e3-31e16fa7df96,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-ea7bfae2-594f-4950-97fa-773fbc295d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-c9727fa2-7152-498b-bc2b-525b2638536d,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-ebcb5b29-0e5f-438b-919d-d51f8bbd5208,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-71a585f7-b5aa-462e-a80c-28694267d831,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-025af09f-e431-48af-bb99-27e93c4f98a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-0493007f-cb4d-4467-953d-45177c55b594,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437665529-172.17.0.9-1595655060468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45488,DS-9ceee58d-c6e4-4f69-a4df-dd0e7e23f250,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-de03ec86-2eed-4f51-b2e3-31e16fa7df96,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-ea7bfae2-594f-4950-97fa-773fbc295d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-c9727fa2-7152-498b-bc2b-525b2638536d,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-ebcb5b29-0e5f-438b-919d-d51f8bbd5208,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-71a585f7-b5aa-462e-a80c-28694267d831,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-025af09f-e431-48af-bb99-27e93c4f98a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-0493007f-cb4d-4467-953d-45177c55b594,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635347015-172.17.0.9-1595655124749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32873,DS-8612ebbc-f83c-4c7b-ad81-0bbcbe377c35,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-3c1976b4-e236-479d-b1da-bb01fcdf5b00,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-6815b38a-a4e5-4cec-803b-b50694acdc42,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-f1af2f10-c17b-4de8-b073-430379089c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-4e3cc090-dcac-4154-90ec-6337d146f20c,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-b7dca8c0-6b3f-49b8-8471-c1acafe54b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-459dc72a-e84c-480e-83a8-9581d7b8fb12,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-bde98d2c-2ec3-42a0-847c-d28512b6125d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635347015-172.17.0.9-1595655124749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32873,DS-8612ebbc-f83c-4c7b-ad81-0bbcbe377c35,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-3c1976b4-e236-479d-b1da-bb01fcdf5b00,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-6815b38a-a4e5-4cec-803b-b50694acdc42,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-f1af2f10-c17b-4de8-b073-430379089c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-4e3cc090-dcac-4154-90ec-6337d146f20c,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-b7dca8c0-6b3f-49b8-8471-c1acafe54b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-459dc72a-e84c-480e-83a8-9581d7b8fb12,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-bde98d2c-2ec3-42a0-847c-d28512b6125d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428711138-172.17.0.9-1595655160782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39063,DS-4881eed7-9053-4b8c-9ab3-f6194f433e52,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-295c54bf-4f82-4f26-9139-163d6bc5d22c,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-6a225bfe-525c-4df1-a9c2-9e0d161be606,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-bc610221-5bae-49f8-ac6d-a05a650fd8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-6ef58242-da1f-4035-868c-69de8eadea77,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-b99cf64b-996f-44a8-8caa-a6bf206b6c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-b95fe0da-f130-47a5-beff-10fc41461031,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-f956e989-a7fe-4d11-ac64-f56783818695,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428711138-172.17.0.9-1595655160782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39063,DS-4881eed7-9053-4b8c-9ab3-f6194f433e52,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-295c54bf-4f82-4f26-9139-163d6bc5d22c,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-6a225bfe-525c-4df1-a9c2-9e0d161be606,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-bc610221-5bae-49f8-ac6d-a05a650fd8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-6ef58242-da1f-4035-868c-69de8eadea77,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-b99cf64b-996f-44a8-8caa-a6bf206b6c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-b95fe0da-f130-47a5-beff-10fc41461031,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-f956e989-a7fe-4d11-ac64-f56783818695,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-32041203-172.17.0.9-1595655191199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41311,DS-8efb54bf-0f83-4b88-b977-e64a7071751b,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-069fbfba-6843-4711-9edd-b71dee03a63c,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-b1a94215-6a73-4bfc-9389-36774a3c85d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-618e00f8-9c9d-4e33-9597-d1180735ff42,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-ee3c64ce-bf02-4c7b-9e5e-8218e43aec18,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-758f88cc-3af1-4c23-8c07-48e535d0d022,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-a8064845-244e-43c3-a566-54bdf04a6e45,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-6f3a3fa0-6093-420d-96d8-9ac5391e70c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-32041203-172.17.0.9-1595655191199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41311,DS-8efb54bf-0f83-4b88-b977-e64a7071751b,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-069fbfba-6843-4711-9edd-b71dee03a63c,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-b1a94215-6a73-4bfc-9389-36774a3c85d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-618e00f8-9c9d-4e33-9597-d1180735ff42,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-ee3c64ce-bf02-4c7b-9e5e-8218e43aec18,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-758f88cc-3af1-4c23-8c07-48e535d0d022,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-a8064845-244e-43c3-a566-54bdf04a6e45,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-6f3a3fa0-6093-420d-96d8-9ac5391e70c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-584461402-172.17.0.9-1595655369205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36322,DS-626f6615-eded-4c70-a619-ec0936e918cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-1f23f9c2-df67-4be8-aac3-9a0e8b50b158,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-869b3120-e3a3-473a-a062-f33a48cd5da1,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-2bdfd66c-e7b7-4b38-bc9d-4cb9d6f9149b,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-e6267950-bf00-4a3e-ba3b-4d5e5a70a5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-4d9aa22f-537a-46e0-967c-cfa67c1ec0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-d595cfe3-7409-4361-a4db-46160baeef04,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-647ec7d5-cbd3-4198-9f3a-0997b304cd14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-584461402-172.17.0.9-1595655369205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36322,DS-626f6615-eded-4c70-a619-ec0936e918cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-1f23f9c2-df67-4be8-aac3-9a0e8b50b158,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-869b3120-e3a3-473a-a062-f33a48cd5da1,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-2bdfd66c-e7b7-4b38-bc9d-4cb9d6f9149b,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-e6267950-bf00-4a3e-ba3b-4d5e5a70a5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-4d9aa22f-537a-46e0-967c-cfa67c1ec0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-d595cfe3-7409-4361-a4db-46160baeef04,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-647ec7d5-cbd3-4198-9f3a-0997b304cd14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2111970637-172.17.0.9-1595655424314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41087,DS-18de1d97-3599-43b3-9a63-a997362a1fed,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-586bbc06-6032-451d-a78f-ea9192a844bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-a8bf3459-de7e-4161-8e49-967854cc4baf,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-a66c1651-1d4b-4278-88e7-3a8682f1738c,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-f0a80553-6298-4ae5-93de-e0d35f49bf02,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-9b227a45-fdca-4f72-9a6d-b6d5584276f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-cc3a3663-8c32-45a9-b673-e20dab1d8f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-6ccc3f40-fb36-4981-b85b-591157f0f6f4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2111970637-172.17.0.9-1595655424314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41087,DS-18de1d97-3599-43b3-9a63-a997362a1fed,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-586bbc06-6032-451d-a78f-ea9192a844bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-a8bf3459-de7e-4161-8e49-967854cc4baf,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-a66c1651-1d4b-4278-88e7-3a8682f1738c,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-f0a80553-6298-4ae5-93de-e0d35f49bf02,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-9b227a45-fdca-4f72-9a6d-b6d5584276f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-cc3a3663-8c32-45a9-b673-e20dab1d8f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-6ccc3f40-fb36-4981-b85b-591157f0f6f4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1168856586-172.17.0.9-1595655549588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46434,DS-1fb9112c-391d-4d47-a6bd-194fed140d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-c9ef4708-b91d-477f-8f76-bf2a42d73ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-2cd922ce-fa4d-4a33-8834-2f5d348a8c96,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-f8e96772-781a-4516-83f2-00fb3c6b3e52,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-91b2bd36-a5d6-47d2-a7b4-ea3de0fd1a39,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-1e60e7ff-7888-4173-b245-1c45e004ab54,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-8207bfaa-343b-46c9-9692-db7fc58dfdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-72ce6587-bd25-4747-ba21-83b502b2b842,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1168856586-172.17.0.9-1595655549588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46434,DS-1fb9112c-391d-4d47-a6bd-194fed140d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-c9ef4708-b91d-477f-8f76-bf2a42d73ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-2cd922ce-fa4d-4a33-8834-2f5d348a8c96,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-f8e96772-781a-4516-83f2-00fb3c6b3e52,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-91b2bd36-a5d6-47d2-a7b4-ea3de0fd1a39,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-1e60e7ff-7888-4173-b245-1c45e004ab54,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-8207bfaa-343b-46c9-9692-db7fc58dfdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-72ce6587-bd25-4747-ba21-83b502b2b842,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561563608-172.17.0.9-1595655577847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41382,DS-1bd2be65-73f2-4815-8a08-62503c8995c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-e2a40217-9793-4882-b7f7-984646c1e781,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-1dbda5e7-0f4b-4f95-95ca-096f2a3f132b,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-fc62da22-bb0b-4bc8-b721-d53e1e74fbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-4f506538-4234-498f-9c6a-311dbb5d7fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-a30abfde-168c-49d6-be8c-3240b6aeef3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-f76f0dc4-96d6-40ae-963f-41c379aca427,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-4829d63f-c017-4ed6-b958-1b128bfcd7d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561563608-172.17.0.9-1595655577847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41382,DS-1bd2be65-73f2-4815-8a08-62503c8995c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-e2a40217-9793-4882-b7f7-984646c1e781,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-1dbda5e7-0f4b-4f95-95ca-096f2a3f132b,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-fc62da22-bb0b-4bc8-b721-d53e1e74fbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-4f506538-4234-498f-9c6a-311dbb5d7fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-a30abfde-168c-49d6-be8c-3240b6aeef3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-f76f0dc4-96d6-40ae-963f-41c379aca427,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-4829d63f-c017-4ed6-b958-1b128bfcd7d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695108875-172.17.0.9-1595655601928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36972,DS-489c9b23-353e-4a99-b2b7-c368ec50c67e,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-3fc06ff8-b594-4d89-918f-8bbb6490c0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-07258751-61f9-45ca-833d-14227b564b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-69d363cd-1919-4a62-9125-383f5ad06286,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-9f73f519-e7f3-4f59-ae8e-368b6798a6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-4b424d0c-b887-4c8e-8014-bcfd35f5770a,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-92dcb0a3-f8dd-4ef2-b09c-44a98f1f5b85,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-f947a632-2663-40d1-9024-b2292ad70bf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695108875-172.17.0.9-1595655601928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36972,DS-489c9b23-353e-4a99-b2b7-c368ec50c67e,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-3fc06ff8-b594-4d89-918f-8bbb6490c0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-07258751-61f9-45ca-833d-14227b564b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-69d363cd-1919-4a62-9125-383f5ad06286,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-9f73f519-e7f3-4f59-ae8e-368b6798a6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-4b424d0c-b887-4c8e-8014-bcfd35f5770a,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-92dcb0a3-f8dd-4ef2-b09c-44a98f1f5b85,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-f947a632-2663-40d1-9024-b2292ad70bf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1918397590-172.17.0.9-1595655668333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34075,DS-a8d368d9-d0ac-4d4d-bf01-151159520c78,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-5f716971-7e9d-416c-9ae3-3d00cbfb11f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-2abe5c8b-e0d8-4112-95d2-cdc01622c2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-2232c3a5-8129-4afc-9094-522bf5aef29b,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-c6f3ecdc-4a34-4c5e-9453-b82d5d263c40,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-4633b8c7-6812-4cbf-acc1-6e4326e443cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-2c0e4158-be1a-41e4-a378-b6aa3d514c55,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-b1f45a2c-499c-42f8-aeee-355e14efb153,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1918397590-172.17.0.9-1595655668333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34075,DS-a8d368d9-d0ac-4d4d-bf01-151159520c78,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-5f716971-7e9d-416c-9ae3-3d00cbfb11f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-2abe5c8b-e0d8-4112-95d2-cdc01622c2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-2232c3a5-8129-4afc-9094-522bf5aef29b,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-c6f3ecdc-4a34-4c5e-9453-b82d5d263c40,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-4633b8c7-6812-4cbf-acc1-6e4326e443cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-2c0e4158-be1a-41e4-a378-b6aa3d514c55,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-b1f45a2c-499c-42f8-aeee-355e14efb153,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503494014-172.17.0.9-1595655820160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32828,DS-e7ced77f-f874-45a4-a50c-a2939faf6d05,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-dcd3f7c1-c702-4bcd-bc91-61b17404f6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-240504fc-fa63-4388-b234-8d2d01d88c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-f70de7c8-5ee2-454a-87f0-15920c4db924,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-964af9a1-af97-4799-b8c8-3e92123982dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-12877ef3-3575-4e2d-b1f7-181bdade3143,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-0e9451bf-2be4-45b3-8b5b-d1c474076cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-ad2497f6-d493-4819-91ae-2b72838c323d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503494014-172.17.0.9-1595655820160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32828,DS-e7ced77f-f874-45a4-a50c-a2939faf6d05,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-dcd3f7c1-c702-4bcd-bc91-61b17404f6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-240504fc-fa63-4388-b234-8d2d01d88c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-f70de7c8-5ee2-454a-87f0-15920c4db924,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-964af9a1-af97-4799-b8c8-3e92123982dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-12877ef3-3575-4e2d-b1f7-181bdade3143,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-0e9451bf-2be4-45b3-8b5b-d1c474076cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-ad2497f6-d493-4819-91ae-2b72838c323d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603272998-172.17.0.9-1595655855876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42009,DS-71099409-656c-4d2f-a41f-2c2463e916ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-650097de-bce4-4279-bbb7-08e12b0ec35a,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-14a78ab2-b3ba-4f14-bea7-ea5d532519c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-eba1a476-88df-4229-9b17-255def6dd850,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-95ab59e4-2f99-4995-9af0-04a646bf3236,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-d5058811-d197-414b-ae0b-e2603908131d,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-3f0e4d89-6bd4-486c-8056-f47ad3a4a60a,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-9bda3959-0ada-4e62-baf6-ee29c6f10343,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603272998-172.17.0.9-1595655855876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42009,DS-71099409-656c-4d2f-a41f-2c2463e916ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-650097de-bce4-4279-bbb7-08e12b0ec35a,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-14a78ab2-b3ba-4f14-bea7-ea5d532519c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-eba1a476-88df-4229-9b17-255def6dd850,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-95ab59e4-2f99-4995-9af0-04a646bf3236,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-d5058811-d197-414b-ae0b-e2603908131d,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-3f0e4d89-6bd4-486c-8056-f47ad3a4a60a,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-9bda3959-0ada-4e62-baf6-ee29c6f10343,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060585448-172.17.0.9-1595656043552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37370,DS-5ca18471-be9d-4e29-8c11-0eddb7a7d15e,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-bd11aa81-a629-4c3a-afcb-dae1ce385514,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-3755eb5b-e227-4c51-8180-c5fdbf1c1e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-c333f719-0643-4ca3-b505-2e43b76616b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-f5e9163e-b142-4651-b2cc-f1dd62548ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-22886ebe-c7eb-447c-953f-66d5b3c64f29,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-78883278-f868-4a5d-b462-4f73257c9f21,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-fb2c3213-778c-4eaa-acb2-b83e822d94fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060585448-172.17.0.9-1595656043552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37370,DS-5ca18471-be9d-4e29-8c11-0eddb7a7d15e,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-bd11aa81-a629-4c3a-afcb-dae1ce385514,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-3755eb5b-e227-4c51-8180-c5fdbf1c1e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-c333f719-0643-4ca3-b505-2e43b76616b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-f5e9163e-b142-4651-b2cc-f1dd62548ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-22886ebe-c7eb-447c-953f-66d5b3c64f29,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-78883278-f868-4a5d-b462-4f73257c9f21,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-fb2c3213-778c-4eaa-acb2-b83e822d94fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047621409-172.17.0.9-1595656083150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39002,DS-f98a4d79-6776-4d5a-b1b9-a45536982519,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-139b1cc0-51b1-47d4-aedf-80299a2e5bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-ead0d2ee-c1f1-42da-a803-636b645b99d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-6c230005-d4fe-4b07-9560-ccc4d62138f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-3c8237ee-3455-4560-8992-deca67569352,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-b7cba22c-7d97-4d76-89f4-cc8de9ca71d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-d048e382-478f-4f71-9b99-359781fbb2be,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-0a68ca60-c6f5-4499-83ba-81774c258869,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047621409-172.17.0.9-1595656083150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39002,DS-f98a4d79-6776-4d5a-b1b9-a45536982519,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-139b1cc0-51b1-47d4-aedf-80299a2e5bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-ead0d2ee-c1f1-42da-a803-636b645b99d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-6c230005-d4fe-4b07-9560-ccc4d62138f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-3c8237ee-3455-4560-8992-deca67569352,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-b7cba22c-7d97-4d76-89f4-cc8de9ca71d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-d048e382-478f-4f71-9b99-359781fbb2be,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-0a68ca60-c6f5-4499-83ba-81774c258869,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115360187-172.17.0.9-1595656227816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38006,DS-fe6e5a29-68ef-401b-8228-68334ad5c0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-25d4f323-b7b2-41fa-ab22-c120659d9566,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-0110197f-55bb-4bae-9f1d-561b082f8617,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-ac20e057-ea8e-4c3f-8c47-eb083375e2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-48c23f1f-384c-488b-b4f9-53f30b9f20a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-405a5a96-3e0c-4d1f-bfd3-32ff96223672,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-03f3da81-1708-4160-8acb-437296a279c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-589cb665-3e07-48b2-807e-a73156a50b1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115360187-172.17.0.9-1595656227816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38006,DS-fe6e5a29-68ef-401b-8228-68334ad5c0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-25d4f323-b7b2-41fa-ab22-c120659d9566,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-0110197f-55bb-4bae-9f1d-561b082f8617,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-ac20e057-ea8e-4c3f-8c47-eb083375e2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-48c23f1f-384c-488b-b4f9-53f30b9f20a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-405a5a96-3e0c-4d1f-bfd3-32ff96223672,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-03f3da81-1708-4160-8acb-437296a279c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-589cb665-3e07-48b2-807e-a73156a50b1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-583414749-172.17.0.9-1595656380362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44778,DS-31693ea5-7497-4acd-b413-e61e216e2515,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-17a5d2c4-9f68-424a-9e3f-f08b865898e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-2e46debb-7846-4874-92f9-bd610efa8927,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-607c881b-d53b-4033-ac5e-686facdab0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-c5e25b94-0800-4a51-9590-726beb2d42af,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-3b394985-261d-4482-b9c7-a79e03cffa54,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-c67d9940-cd46-4700-8833-65bfce8f5a39,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-2943bb50-070c-4c2b-883b-cb371f6f8fb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-583414749-172.17.0.9-1595656380362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44778,DS-31693ea5-7497-4acd-b413-e61e216e2515,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-17a5d2c4-9f68-424a-9e3f-f08b865898e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-2e46debb-7846-4874-92f9-bd610efa8927,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-607c881b-d53b-4033-ac5e-686facdab0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-c5e25b94-0800-4a51-9590-726beb2d42af,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-3b394985-261d-4482-b9c7-a79e03cffa54,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-c67d9940-cd46-4700-8833-65bfce8f5a39,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-2943bb50-070c-4c2b-883b-cb371f6f8fb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039089880-172.17.0.9-1595656418124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38134,DS-8d4b25f0-3f00-42d1-89d0-044f62cb7fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-0456cb2e-dc34-4369-a997-a8ec25aa08da,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-419ad3fe-8cb4-4d42-b586-29b6e7665e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-aa773985-b202-411d-ab0d-de33d042b944,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-2ef76f93-0e42-4893-892a-f9a8e6682fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-2769902f-8d8c-4604-81ce-d6e924c92cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-89fe3bc5-137e-4af9-9b69-70c7183bccf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-6e877aca-dcb9-4d83-bb76-8f0d18012864,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039089880-172.17.0.9-1595656418124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38134,DS-8d4b25f0-3f00-42d1-89d0-044f62cb7fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-0456cb2e-dc34-4369-a997-a8ec25aa08da,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-419ad3fe-8cb4-4d42-b586-29b6e7665e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-aa773985-b202-411d-ab0d-de33d042b944,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-2ef76f93-0e42-4893-892a-f9a8e6682fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-2769902f-8d8c-4604-81ce-d6e924c92cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-89fe3bc5-137e-4af9-9b69-70c7183bccf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-6e877aca-dcb9-4d83-bb76-8f0d18012864,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631873228-172.17.0.9-1595656966002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39030,DS-3e988ef0-f648-444e-a2ae-af157a27ac00,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-f81fd4fa-6b9f-4264-83b9-ce2c65a2cb61,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-a83eff75-eebc-453e-b03d-29d5e90a5977,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-dcd03ecb-889d-4c07-aec9-192e19634c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-b5b5aa21-747f-4009-98d1-c7506a353119,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-30b5710f-9857-43cb-8616-a2c4a285ccd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-adfbf2d4-13fa-46cd-8737-26667010263e,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-687c76dd-e9c0-44d9-b4f4-614806630405,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631873228-172.17.0.9-1595656966002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39030,DS-3e988ef0-f648-444e-a2ae-af157a27ac00,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-f81fd4fa-6b9f-4264-83b9-ce2c65a2cb61,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-a83eff75-eebc-453e-b03d-29d5e90a5977,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-dcd03ecb-889d-4c07-aec9-192e19634c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-b5b5aa21-747f-4009-98d1-c7506a353119,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-30b5710f-9857-43cb-8616-a2c4a285ccd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-adfbf2d4-13fa-46cd-8737-26667010263e,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-687c76dd-e9c0-44d9-b4f4-614806630405,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943831519-172.17.0.9-1595657039304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39491,DS-c58e759b-4f9d-4305-95a8-2171a111fc96,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-51f0bc3c-73d0-45f5-bc11-a57d252afcab,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-a50312ad-9d15-49b2-9a4e-63a74e12a0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-d351679d-205f-4b2c-baa7-b0b58a70e61b,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-ba21dc6b-f063-4635-b49f-756f080a84b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-6cbcda78-1739-4d77-80ab-549999d45cba,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-e0056e6d-fcef-495b-9161-7fea88828077,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-b77819e5-4be8-428e-b13e-ec0b506a6a10,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943831519-172.17.0.9-1595657039304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39491,DS-c58e759b-4f9d-4305-95a8-2171a111fc96,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-51f0bc3c-73d0-45f5-bc11-a57d252afcab,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-a50312ad-9d15-49b2-9a4e-63a74e12a0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-d351679d-205f-4b2c-baa7-b0b58a70e61b,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-ba21dc6b-f063-4635-b49f-756f080a84b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-6cbcda78-1739-4d77-80ab-549999d45cba,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-e0056e6d-fcef-495b-9161-7fea88828077,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-b77819e5-4be8-428e-b13e-ec0b506a6a10,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-501501520-172.17.0.9-1595657079263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35340,DS-f0a759f4-7700-471a-98c7-de7e91427942,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-ca784a54-467b-47d7-b380-6409f5612299,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-7aa2d499-84d0-4a5f-844d-ef18250859f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-9560bbb4-5590-42d8-8010-0151636c3755,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-696696c5-1a02-4de5-8057-0cbb7206b493,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-27ce7574-3105-45f2-901d-c3b7fb9eac59,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-79665ff0-94bc-487c-ac63-7561b8239f90,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-3330a033-54fa-4f98-be71-fd791684af4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-501501520-172.17.0.9-1595657079263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35340,DS-f0a759f4-7700-471a-98c7-de7e91427942,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-ca784a54-467b-47d7-b380-6409f5612299,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-7aa2d499-84d0-4a5f-844d-ef18250859f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-9560bbb4-5590-42d8-8010-0151636c3755,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-696696c5-1a02-4de5-8057-0cbb7206b493,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-27ce7574-3105-45f2-901d-c3b7fb9eac59,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-79665ff0-94bc-487c-ac63-7561b8239f90,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-3330a033-54fa-4f98-be71-fd791684af4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1207924090-172.17.0.9-1595657275747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45785,DS-6d7a9230-9442-4803-9fed-2e2ad2a50597,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-fd249d49-d67c-4a2f-9052-d174822c343f,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-f9653cac-9ec6-4352-a6d5-0d053a97fcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-6a41d04c-2e62-41ea-8f46-cf94e803f88b,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-5b0479cd-e0a4-494c-bb84-4d07e19bd601,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-cac52c7c-1b82-4217-b6db-cefaf8979bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-1c5e9f5c-517f-4ae5-b2ef-6ad75fb7530a,DISK], DatanodeInfoWithStorage[127.0.0.1:40389,DS-965fbc45-a033-4147-b85c-1eb6ba067cff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1207924090-172.17.0.9-1595657275747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45785,DS-6d7a9230-9442-4803-9fed-2e2ad2a50597,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-fd249d49-d67c-4a2f-9052-d174822c343f,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-f9653cac-9ec6-4352-a6d5-0d053a97fcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-6a41d04c-2e62-41ea-8f46-cf94e803f88b,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-5b0479cd-e0a4-494c-bb84-4d07e19bd601,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-cac52c7c-1b82-4217-b6db-cefaf8979bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-1c5e9f5c-517f-4ae5-b2ef-6ad75fb7530a,DISK], DatanodeInfoWithStorage[127.0.0.1:40389,DS-965fbc45-a033-4147-b85c-1eb6ba067cff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330071639-172.17.0.9-1595657567708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32797,DS-90ac15db-3718-43ac-bf47-20a91895859b,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-68ab6eb5-f03a-48c5-b290-04443749c3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-8335c4de-19ea-442e-af5b-28112b494d79,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-47d7ca5c-f864-4865-93e5-06eff8a77750,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-cd8fa69d-443d-4488-9df0-c1e136af308a,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-dd436493-cb15-412e-b32b-2e5d65c96217,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-daa96457-63ae-45f4-96ff-e9f8543bf934,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-92cc7549-5f97-499d-82c5-49006f2b2d6b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330071639-172.17.0.9-1595657567708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32797,DS-90ac15db-3718-43ac-bf47-20a91895859b,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-68ab6eb5-f03a-48c5-b290-04443749c3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-8335c4de-19ea-442e-af5b-28112b494d79,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-47d7ca5c-f864-4865-93e5-06eff8a77750,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-cd8fa69d-443d-4488-9df0-c1e136af308a,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-dd436493-cb15-412e-b32b-2e5d65c96217,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-daa96457-63ae-45f4-96ff-e9f8543bf934,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-92cc7549-5f97-499d-82c5-49006f2b2d6b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-103453035-172.17.0.9-1595657692854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42992,DS-4775b33b-246c-4efa-8c79-e45d95f93d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-17672b09-8903-49cd-952d-059618722c83,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-7d83ca8b-1182-4f3c-bdef-4d262306afd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-59d2ed46-7cf5-4ca0-b498-37dca9a759a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-fd24a762-2503-421d-ad46-1a844ed69bea,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-8a12b18d-55d0-463b-b7f7-0c177773af1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-5df5d857-1285-48fc-a88a-a2208e4d10a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-fc36600f-f629-4248-83ad-28b932b62675,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-103453035-172.17.0.9-1595657692854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42992,DS-4775b33b-246c-4efa-8c79-e45d95f93d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-17672b09-8903-49cd-952d-059618722c83,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-7d83ca8b-1182-4f3c-bdef-4d262306afd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-59d2ed46-7cf5-4ca0-b498-37dca9a759a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-fd24a762-2503-421d-ad46-1a844ed69bea,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-8a12b18d-55d0-463b-b7f7-0c177773af1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-5df5d857-1285-48fc-a88a-a2208e4d10a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-fc36600f-f629-4248-83ad-28b932b62675,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10425239-172.17.0.9-1595657730810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45628,DS-caab8735-9f69-42f6-b6a7-41f38f272f75,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-53d1d9fb-9d83-4879-8e92-ae37121769bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-adf7409e-cdf0-48ae-bad9-d7ec6abad6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-6910ff85-3953-4e50-a6ad-089ee8f52dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-8b9474d7-5449-4264-9d3c-b6e074550e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-a895edb0-4fa2-4cca-8ac2-1b37919dd750,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-8fe10fa9-9485-49a8-84fe-695a302c0ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-92eb23b0-abff-4515-946b-ba6f0c0fc027,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10425239-172.17.0.9-1595657730810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45628,DS-caab8735-9f69-42f6-b6a7-41f38f272f75,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-53d1d9fb-9d83-4879-8e92-ae37121769bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-adf7409e-cdf0-48ae-bad9-d7ec6abad6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-6910ff85-3953-4e50-a6ad-089ee8f52dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-8b9474d7-5449-4264-9d3c-b6e074550e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-a895edb0-4fa2-4cca-8ac2-1b37919dd750,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-8fe10fa9-9485-49a8-84fe-695a302c0ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-92eb23b0-abff-4515-946b-ba6f0c0fc027,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796357002-172.17.0.9-1595657844474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44359,DS-7de78165-58b8-4632-9cd4-eda12872d684,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-f1e770cf-62aa-4a7e-971f-70a866887c60,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-8930d8d3-6a1b-42f9-acd7-0e0df58b4fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-2ffa2d8c-b523-432b-a3e0-296eab643bba,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-f9caad8d-f097-4cfd-a313-ac7c6926a31d,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-5541680a-10bd-4ad0-b8b1-07c713509746,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-b164919e-08be-4205-85e9-6f3af4b8706a,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-f00d82d8-3621-4de1-b921-f940547f8dc2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796357002-172.17.0.9-1595657844474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44359,DS-7de78165-58b8-4632-9cd4-eda12872d684,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-f1e770cf-62aa-4a7e-971f-70a866887c60,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-8930d8d3-6a1b-42f9-acd7-0e0df58b4fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-2ffa2d8c-b523-432b-a3e0-296eab643bba,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-f9caad8d-f097-4cfd-a313-ac7c6926a31d,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-5541680a-10bd-4ad0-b8b1-07c713509746,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-b164919e-08be-4205-85e9-6f3af4b8706a,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-f00d82d8-3621-4de1-b921-f940547f8dc2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-435532101-172.17.0.9-1595657878215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45433,DS-3e3076b9-f224-462c-bf90-329c89661435,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-2a7e2e7d-bf65-485b-9592-22cfa4d497d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-7cc69a33-4867-49cf-957f-474a2db7c98c,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-9a6731df-c48f-4684-bd71-5854b34d9aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-ca97ecec-0ef8-4615-9f1b-c01aedfc4cae,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-3f2d7175-3caa-4dec-94fa-aec1aeffc579,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-5fe47286-ac5a-4294-bc0e-5bfb5a925444,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-8ff3a1ff-d2d5-4117-8120-fa52083d559e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-435532101-172.17.0.9-1595657878215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45433,DS-3e3076b9-f224-462c-bf90-329c89661435,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-2a7e2e7d-bf65-485b-9592-22cfa4d497d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-7cc69a33-4867-49cf-957f-474a2db7c98c,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-9a6731df-c48f-4684-bd71-5854b34d9aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-ca97ecec-0ef8-4615-9f1b-c01aedfc4cae,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-3f2d7175-3caa-4dec-94fa-aec1aeffc579,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-5fe47286-ac5a-4294-bc0e-5bfb5a925444,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-8ff3a1ff-d2d5-4117-8120-fa52083d559e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113193942-172.17.0.9-1595657954364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35244,DS-6461b13d-12d0-41d8-8100-e0e8045ea93c,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-d2eb3f4f-0621-4253-b815-c483fce535c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-c9f945a0-d3e7-4e07-b5b2-ca1143fa802e,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-bd02d940-2bab-465f-b5e1-e7ffc23c66bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-54dc1984-aa12-4202-9abc-1db307417c58,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-17a46fcc-b29d-4d04-8e89-a88bf0a2092c,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-bf49c123-1e98-4d4c-9ff4-8fa8b21a9268,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-5ee5b737-7f75-400f-afa1-2200405789e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113193942-172.17.0.9-1595657954364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35244,DS-6461b13d-12d0-41d8-8100-e0e8045ea93c,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-d2eb3f4f-0621-4253-b815-c483fce535c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-c9f945a0-d3e7-4e07-b5b2-ca1143fa802e,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-bd02d940-2bab-465f-b5e1-e7ffc23c66bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-54dc1984-aa12-4202-9abc-1db307417c58,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-17a46fcc-b29d-4d04-8e89-a88bf0a2092c,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-bf49c123-1e98-4d4c-9ff4-8fa8b21a9268,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-5ee5b737-7f75-400f-afa1-2200405789e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-920129551-172.17.0.9-1595658084275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38612,DS-f0137250-2f7b-4f72-8702-d87df7480c07,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-53b4c28a-1000-4c03-a065-434c7da565e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-617a9fa9-a28c-4278-8413-403816d7bcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-4f4e423b-6d78-4930-8c80-82ee7116d837,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-76a8c6e0-9d64-47ca-a41e-31aeda3b8a59,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-9eb5382b-dd97-4770-823c-8037690c8d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-7a288ed1-5b78-4884-8b81-96ac67100990,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-771fe431-2266-4a45-9c06-504edcd7dcf1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-920129551-172.17.0.9-1595658084275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38612,DS-f0137250-2f7b-4f72-8702-d87df7480c07,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-53b4c28a-1000-4c03-a065-434c7da565e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-617a9fa9-a28c-4278-8413-403816d7bcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-4f4e423b-6d78-4930-8c80-82ee7116d837,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-76a8c6e0-9d64-47ca-a41e-31aeda3b8a59,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-9eb5382b-dd97-4770-823c-8037690c8d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-7a288ed1-5b78-4884-8b81-96ac67100990,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-771fe431-2266-4a45-9c06-504edcd7dcf1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560663648-172.17.0.9-1595658225646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34867,DS-22ab3523-6790-4025-abc9-27e1dc452955,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-7784d892-c292-482c-b2f4-e35c9cd8a274,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-c4b43ede-cdec-4370-8d61-a2122323d858,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-dced164e-3749-4d2c-aca9-aba79eef41d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-a3d2aa6f-e3e8-460e-a231-a7ec5f73c5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-3193d39f-b84b-435d-8047-eabbc7136263,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-2ece976b-d271-437d-9ba2-c6161e05a2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-86f293b2-1059-4600-be80-bcea785e8e87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560663648-172.17.0.9-1595658225646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34867,DS-22ab3523-6790-4025-abc9-27e1dc452955,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-7784d892-c292-482c-b2f4-e35c9cd8a274,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-c4b43ede-cdec-4370-8d61-a2122323d858,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-dced164e-3749-4d2c-aca9-aba79eef41d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-a3d2aa6f-e3e8-460e-a231-a7ec5f73c5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-3193d39f-b84b-435d-8047-eabbc7136263,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-2ece976b-d271-437d-9ba2-c6161e05a2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-86f293b2-1059-4600-be80-bcea785e8e87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210115945-172.17.0.9-1595658356233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44088,DS-edb2366f-210c-4bfe-8ec3-de5dcf3e36fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-acb07e94-637f-4d35-8e0e-1666f5678033,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-3dd95474-fb12-42a1-a2d2-7d6505932d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-b077f04a-af0f-4283-960b-6cd387c7be0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-57f41c15-ee67-49f7-8095-05ad89f1b0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-8199ed0f-d677-4503-b6e6-badb1a125e33,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-47f1a53b-133a-45ce-bdc3-e1dc4a1266e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-662866f9-6092-4733-879a-2e32fa4859c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210115945-172.17.0.9-1595658356233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44088,DS-edb2366f-210c-4bfe-8ec3-de5dcf3e36fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-acb07e94-637f-4d35-8e0e-1666f5678033,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-3dd95474-fb12-42a1-a2d2-7d6505932d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-b077f04a-af0f-4283-960b-6cd387c7be0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-57f41c15-ee67-49f7-8095-05ad89f1b0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-8199ed0f-d677-4503-b6e6-badb1a125e33,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-47f1a53b-133a-45ce-bdc3-e1dc4a1266e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-662866f9-6092-4733-879a-2e32fa4859c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572734717-172.17.0.9-1595658429135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36249,DS-6ebc3c40-2052-4ae7-a670-f999f48b0d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-8ed3d2ab-1fdb-4934-a727-6ebc99ef3b49,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-c44c09e6-25cb-4a7e-ac71-7bab8d259c53,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-5e8f28a6-9e70-48d4-aac4-9b468eb120b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-5d48b722-ba01-456d-a354-f60586b0cc83,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-45152348-b635-4106-a3e9-bdd5b295eee0,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-4672f0e5-ab28-47ad-ace1-9abf1bda5d54,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-8ad1d867-4a3f-4f08-8ee2-108751cfd1aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572734717-172.17.0.9-1595658429135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36249,DS-6ebc3c40-2052-4ae7-a670-f999f48b0d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-8ed3d2ab-1fdb-4934-a727-6ebc99ef3b49,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-c44c09e6-25cb-4a7e-ac71-7bab8d259c53,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-5e8f28a6-9e70-48d4-aac4-9b468eb120b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-5d48b722-ba01-456d-a354-f60586b0cc83,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-45152348-b635-4106-a3e9-bdd5b295eee0,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-4672f0e5-ab28-47ad-ace1-9abf1bda5d54,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-8ad1d867-4a3f-4f08-8ee2-108751cfd1aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1081097722-172.17.0.9-1595658537162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34892,DS-69ad8ef7-b80f-403c-9eb2-e7777cd2ee36,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-ce42ab28-c1cd-4eb3-91de-ef352b210a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-47171e91-574a-4a46-988f-2bfca2d82461,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-548699b0-05d9-4e3f-9ad4-e6f2a3442d51,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-382580ef-1760-4b4b-b521-2b29082b7463,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-541c5b98-cd32-418f-a42c-6706296a325e,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-c27500ab-d110-4b86-92e6-5b62ae4d05b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-ca3c215b-31d9-4116-bfa9-79e949436ce2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1081097722-172.17.0.9-1595658537162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34892,DS-69ad8ef7-b80f-403c-9eb2-e7777cd2ee36,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-ce42ab28-c1cd-4eb3-91de-ef352b210a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-47171e91-574a-4a46-988f-2bfca2d82461,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-548699b0-05d9-4e3f-9ad4-e6f2a3442d51,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-382580ef-1760-4b4b-b521-2b29082b7463,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-541c5b98-cd32-418f-a42c-6706296a325e,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-c27500ab-d110-4b86-92e6-5b62ae4d05b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-ca3c215b-31d9-4116-bfa9-79e949436ce2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-402698497-172.17.0.9-1595658667864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42861,DS-0a4ea8cd-826a-49b9-9aee-d0f5e49447c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-9c64fbb8-dda2-4e40-a981-5424ac43dd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-66dd288b-fd6d-4fa1-a0d9-249023323e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-48046e5c-ce7b-429b-817e-c87902d62956,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-ba32882f-6326-4edb-9d0d-0b703fba29d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-12e4ccb4-6b47-41e1-9ec4-5154d1b84f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-8ab651b6-88ee-46f7-b3db-b567bb8bc06e,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-93145284-d105-47c2-b3f7-1ee3e0c9f423,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-402698497-172.17.0.9-1595658667864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42861,DS-0a4ea8cd-826a-49b9-9aee-d0f5e49447c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-9c64fbb8-dda2-4e40-a981-5424ac43dd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-66dd288b-fd6d-4fa1-a0d9-249023323e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-48046e5c-ce7b-429b-817e-c87902d62956,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-ba32882f-6326-4edb-9d0d-0b703fba29d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-12e4ccb4-6b47-41e1-9ec4-5154d1b84f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-8ab651b6-88ee-46f7-b3db-b567bb8bc06e,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-93145284-d105-47c2-b3f7-1ee3e0c9f423,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1162772711-172.17.0.9-1595658771256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34360,DS-462cc0fc-da33-46a8-a0cf-1b7395928915,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-2a96aa79-f2d9-44be-aa53-12492d4ecfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-1fb7b761-ea2f-446c-9e84-815edfbfc23f,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-df4f9b52-f377-4d2c-b278-13df5cd0e528,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-9d9aaf4a-bb00-4a53-97ac-d595e8adcd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-94cee392-dbe0-46ed-afce-31821ff36a08,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-9e6a8ebc-5572-4862-b96b-1a604b30c5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-c110c232-583b-4eee-a4cf-f5d0885aa10b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1162772711-172.17.0.9-1595658771256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34360,DS-462cc0fc-da33-46a8-a0cf-1b7395928915,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-2a96aa79-f2d9-44be-aa53-12492d4ecfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-1fb7b761-ea2f-446c-9e84-815edfbfc23f,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-df4f9b52-f377-4d2c-b278-13df5cd0e528,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-9d9aaf4a-bb00-4a53-97ac-d595e8adcd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-94cee392-dbe0-46ed-afce-31821ff36a08,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-9e6a8ebc-5572-4862-b96b-1a604b30c5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-c110c232-583b-4eee-a4cf-f5d0885aa10b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1778120134-172.17.0.9-1595659001080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46603,DS-49347720-d2cc-4502-8278-9c0a9d630532,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-d373c067-cd17-4135-a585-23a9ba565e94,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-062b622b-40e6-42fa-b8dc-aefe4b9c76f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-c877454d-75ba-4775-bcc7-075bac1c1da3,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-0e5c3bdb-e7b3-446a-8dec-1901ca5bc6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-266bd8c7-b1b6-4476-a21a-3947de30e2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-ad5dd62f-b5d0-4ea5-a569-1152536b5353,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-4f136e7a-d187-43e3-8c9e-83685e1d05e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1778120134-172.17.0.9-1595659001080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46603,DS-49347720-d2cc-4502-8278-9c0a9d630532,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-d373c067-cd17-4135-a585-23a9ba565e94,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-062b622b-40e6-42fa-b8dc-aefe4b9c76f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-c877454d-75ba-4775-bcc7-075bac1c1da3,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-0e5c3bdb-e7b3-446a-8dec-1901ca5bc6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-266bd8c7-b1b6-4476-a21a-3947de30e2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-ad5dd62f-b5d0-4ea5-a569-1152536b5353,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-4f136e7a-d187-43e3-8c9e-83685e1d05e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845257170-172.17.0.9-1595659037052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35422,DS-aeb701c3-6a40-4eb4-93ae-89525b804c01,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-6c8751fb-0cc4-4863-bfc1-ad47d8e539ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-6ea1549c-c2d4-4f46-97f2-fcb94879b9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-2e2f7f7d-b570-4cdb-a657-d40de3bfa935,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-84607b45-50a2-47ac-b446-afe5dd35858a,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-def5229b-2ce5-49f2-b416-eebb8b93afee,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-5f2639e1-3bd1-481f-a523-ef1d201bf4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-761012b0-3d72-4b4b-a703-b25bc3a1f7ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845257170-172.17.0.9-1595659037052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35422,DS-aeb701c3-6a40-4eb4-93ae-89525b804c01,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-6c8751fb-0cc4-4863-bfc1-ad47d8e539ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-6ea1549c-c2d4-4f46-97f2-fcb94879b9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-2e2f7f7d-b570-4cdb-a657-d40de3bfa935,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-84607b45-50a2-47ac-b446-afe5dd35858a,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-def5229b-2ce5-49f2-b416-eebb8b93afee,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-5f2639e1-3bd1-481f-a523-ef1d201bf4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-761012b0-3d72-4b4b-a703-b25bc3a1f7ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274451878-172.17.0.9-1595659209971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36229,DS-770c9a66-0d9c-4ae3-aab4-33d623272b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-a0d1ed2d-52c3-456c-bd19-f9b829e51f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-b72c7e56-c985-4962-8f28-1474866bf533,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-63c087dd-38ef-43df-a153-f391527cee9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-f1d9f412-9c57-4f4c-8db6-fb11f2bcc6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-9e0aa71c-51a7-4dd2-ba61-2b91ba7c635c,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-6a89d294-cd3d-41b4-8bbd-0733d538d270,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-07560865-c8bd-4424-92c7-c3d5d6d538bb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274451878-172.17.0.9-1595659209971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36229,DS-770c9a66-0d9c-4ae3-aab4-33d623272b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-a0d1ed2d-52c3-456c-bd19-f9b829e51f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-b72c7e56-c985-4962-8f28-1474866bf533,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-63c087dd-38ef-43df-a153-f391527cee9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-f1d9f412-9c57-4f4c-8db6-fb11f2bcc6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-9e0aa71c-51a7-4dd2-ba61-2b91ba7c635c,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-6a89d294-cd3d-41b4-8bbd-0733d538d270,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-07560865-c8bd-4424-92c7-c3d5d6d538bb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665588107-172.17.0.9-1595659594101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46527,DS-56bdb33b-6f70-4eef-8419-b7c85702abe9,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-b2893f21-42d2-450c-b206-cb9e269bc9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-92072554-f804-4de5-b61d-d21e4b8111b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-dec87cfd-c7df-44f0-a22b-17bb0ea7c8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-66138b9c-1b59-44fc-9f7a-03f9664e944a,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-7ad39d43-4940-4442-ae9e-12e92510af86,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-2ff30af0-86d1-4188-8b02-b382c963342c,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-76f73536-c211-4a56-8463-9a555fb45856,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665588107-172.17.0.9-1595659594101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46527,DS-56bdb33b-6f70-4eef-8419-b7c85702abe9,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-b2893f21-42d2-450c-b206-cb9e269bc9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-92072554-f804-4de5-b61d-d21e4b8111b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-dec87cfd-c7df-44f0-a22b-17bb0ea7c8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-66138b9c-1b59-44fc-9f7a-03f9664e944a,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-7ad39d43-4940-4442-ae9e-12e92510af86,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-2ff30af0-86d1-4188-8b02-b382c963342c,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-76f73536-c211-4a56-8463-9a555fb45856,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-604339167-172.17.0.9-1595659678695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41607,DS-bb0e193a-9584-4348-b41f-8a7031283567,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-5c698399-1d24-4e22-a5cc-99dd8bd9bfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-870d455b-9603-46fc-975e-5242692ccba5,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-08a88c22-cd11-4534-92b6-38c8ac635787,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-3d580e3d-6e88-48e8-b7ed-b39c656b43c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-f2eb7e10-949e-447e-a421-1cefb4684b50,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-b5a2b976-51bf-4831-94cd-5fcc53c6a7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-3786f373-6152-4c7e-87ae-40cb9fa89fd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-604339167-172.17.0.9-1595659678695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41607,DS-bb0e193a-9584-4348-b41f-8a7031283567,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-5c698399-1d24-4e22-a5cc-99dd8bd9bfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-870d455b-9603-46fc-975e-5242692ccba5,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-08a88c22-cd11-4534-92b6-38c8ac635787,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-3d580e3d-6e88-48e8-b7ed-b39c656b43c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-f2eb7e10-949e-447e-a421-1cefb4684b50,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-b5a2b976-51bf-4831-94cd-5fcc53c6a7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-3786f373-6152-4c7e-87ae-40cb9fa89fd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 100
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126802188-172.17.0.9-1595659891284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44626,DS-2f6bb614-f806-4331-a0cd-8b8fad689056,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-79d42333-76c1-4bf0-8199-e192542e9051,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-27e81df6-5d73-4874-b7ff-e36ca04b4b12,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-f663c1b2-3e37-484c-9491-886491f475de,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-a582a0fa-1cc4-46de-a509-2affc6e287e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-ef769635-a5bb-4c04-a716-b8af4786f03e,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-ab727e09-4e2e-4b0c-bc9c-5909b1925314,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-aed53dfb-57cf-42b7-a0e2-ae0026463100,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126802188-172.17.0.9-1595659891284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44626,DS-2f6bb614-f806-4331-a0cd-8b8fad689056,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-79d42333-76c1-4bf0-8199-e192542e9051,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-27e81df6-5d73-4874-b7ff-e36ca04b4b12,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-f663c1b2-3e37-484c-9491-886491f475de,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-a582a0fa-1cc4-46de-a509-2affc6e287e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-ef769635-a5bb-4c04-a716-b8af4786f03e,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-ab727e09-4e2e-4b0c-bc9c-5909b1925314,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-aed53dfb-57cf-42b7-a0e2-ae0026463100,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 28 out of 50
result: false positive !!!
Total execution time in seconds : 5231
