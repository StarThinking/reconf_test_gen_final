reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1643019309-172.17.0.2-1595590150189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45501,DS-58d4d60f-97a1-4093-a22a-a4da4fa68f98,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-4931ff6f-07dd-4d2a-833f-3b10f1f153f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-7fba7c22-9e0d-4980-bada-293468ef2a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-7b559db3-1e32-4c31-b3ea-a6c0b0960192,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-59a7966d-bf2f-4c93-ad5d-6a1a841daf3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-8dddd49e-0af8-4f31-a1e0-18f4180913b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-9d6c6050-b3cc-464b-a171-654d7308128b,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-f7e33230-d473-4f5a-823e-6bba7abb68b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1643019309-172.17.0.2-1595590150189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45501,DS-58d4d60f-97a1-4093-a22a-a4da4fa68f98,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-4931ff6f-07dd-4d2a-833f-3b10f1f153f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-7fba7c22-9e0d-4980-bada-293468ef2a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-7b559db3-1e32-4c31-b3ea-a6c0b0960192,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-59a7966d-bf2f-4c93-ad5d-6a1a841daf3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-8dddd49e-0af8-4f31-a1e0-18f4180913b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-9d6c6050-b3cc-464b-a171-654d7308128b,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-f7e33230-d473-4f5a-823e-6bba7abb68b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389679921-172.17.0.2-1595590315882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43083,DS-615a59b5-d5ba-4bf6-ad33-60a21584f1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-d22d0b73-d133-4eaf-b7e7-62bc971497e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-cb830692-f97a-492c-aeac-df85a9c1fe1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-3721ea0c-f71d-4b3d-897a-ef1336e92019,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-a962f157-eec7-4a5a-8e6c-ed261ad9dda4,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-12868bb8-6d2c-43d8-a17b-86216c35739b,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-11bdf434-bd70-4022-8f7a-acc0916ab2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-8d919578-da9a-4f69-bfcf-2a0f6b870eaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389679921-172.17.0.2-1595590315882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43083,DS-615a59b5-d5ba-4bf6-ad33-60a21584f1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-d22d0b73-d133-4eaf-b7e7-62bc971497e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-cb830692-f97a-492c-aeac-df85a9c1fe1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-3721ea0c-f71d-4b3d-897a-ef1336e92019,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-a962f157-eec7-4a5a-8e6c-ed261ad9dda4,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-12868bb8-6d2c-43d8-a17b-86216c35739b,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-11bdf434-bd70-4022-8f7a-acc0916ab2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-8d919578-da9a-4f69-bfcf-2a0f6b870eaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1756694862-172.17.0.2-1595590498456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44434,DS-d6dca5b4-ce71-47e0-98a0-89eab8c8fb32,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-e25533f2-135d-4b77-9f8d-9cd6fecf084c,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-a8aa8785-d6fd-46bf-a90f-359dd28a5a59,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-bf692407-ab7d-4364-b3ed-5def2f10b9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-f69a79be-194e-42f3-93e9-55edf8678e53,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-d509db45-e2b1-4ca7-84b4-28278a031419,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-c60996d1-6ac5-4277-9964-cb0fc9d688ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-aafe82b7-49fe-4c6a-bd5a-e90e834ad71e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1756694862-172.17.0.2-1595590498456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44434,DS-d6dca5b4-ce71-47e0-98a0-89eab8c8fb32,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-e25533f2-135d-4b77-9f8d-9cd6fecf084c,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-a8aa8785-d6fd-46bf-a90f-359dd28a5a59,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-bf692407-ab7d-4364-b3ed-5def2f10b9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-f69a79be-194e-42f3-93e9-55edf8678e53,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-d509db45-e2b1-4ca7-84b4-28278a031419,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-c60996d1-6ac5-4277-9964-cb0fc9d688ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-aafe82b7-49fe-4c6a-bd5a-e90e834ad71e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-714785687-172.17.0.2-1595590803008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45084,DS-094dcfed-b6ef-418c-a12d-45fcf19292fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-1445d57e-c423-48e3-bb8a-6fe18f625cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-559ee451-b716-4db2-9bba-195913e84085,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-0a5b789f-3f8d-4c5b-b708-2539754a4f14,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-f1552252-5228-4e73-8856-29b6996389e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-f55f1abc-696c-4987-b82e-f3e747c129c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-da038553-2ced-4f21-9133-343074172552,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-d23bb509-878e-4653-99cf-fd4fdcc92c00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-714785687-172.17.0.2-1595590803008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45084,DS-094dcfed-b6ef-418c-a12d-45fcf19292fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-1445d57e-c423-48e3-bb8a-6fe18f625cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-559ee451-b716-4db2-9bba-195913e84085,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-0a5b789f-3f8d-4c5b-b708-2539754a4f14,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-f1552252-5228-4e73-8856-29b6996389e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-f55f1abc-696c-4987-b82e-f3e747c129c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-da038553-2ced-4f21-9133-343074172552,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-d23bb509-878e-4653-99cf-fd4fdcc92c00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908059253-172.17.0.2-1595591102246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43482,DS-a86ff919-d95e-4232-8c50-2e6b3d06a83c,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-a62bde53-f341-4bdc-bfb7-447360d1e8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-2f43fd57-f089-4c34-be07-594099b333ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-cdbe0318-767f-41a3-b7bd-b026a4a609a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-690b515e-4a11-4e04-a890-6915065f8b99,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-1d6fc1c8-7830-45a7-b3dd-457ea9b5f15f,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-27d47d30-e97f-42a9-8459-75fc7875fc74,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-10054908-6dcd-4961-ab16-20c00478908b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908059253-172.17.0.2-1595591102246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43482,DS-a86ff919-d95e-4232-8c50-2e6b3d06a83c,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-a62bde53-f341-4bdc-bfb7-447360d1e8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-2f43fd57-f089-4c34-be07-594099b333ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-cdbe0318-767f-41a3-b7bd-b026a4a609a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-690b515e-4a11-4e04-a890-6915065f8b99,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-1d6fc1c8-7830-45a7-b3dd-457ea9b5f15f,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-27d47d30-e97f-42a9-8459-75fc7875fc74,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-10054908-6dcd-4961-ab16-20c00478908b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-32911365-172.17.0.2-1595591621963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45793,DS-0ea55b1c-67c7-41bd-87cf-14445bed4df2,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-480d12b7-2f06-407f-8e1c-a492599a38fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-b7b0719b-ab39-418a-92a8-10f5e5a3c68c,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-40cb555f-3387-4fd0-9d2f-0fa456ef3159,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-0f841218-d2d5-4c89-bd2f-1ffa9664afc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-79fb96b9-ea7d-4548-ad03-c86e7753dd29,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-aa2e150d-ab39-4063-bee6-4024eaf8668d,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-ebd21e10-fae3-47bb-bbc2-48f28019ef9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-32911365-172.17.0.2-1595591621963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45793,DS-0ea55b1c-67c7-41bd-87cf-14445bed4df2,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-480d12b7-2f06-407f-8e1c-a492599a38fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-b7b0719b-ab39-418a-92a8-10f5e5a3c68c,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-40cb555f-3387-4fd0-9d2f-0fa456ef3159,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-0f841218-d2d5-4c89-bd2f-1ffa9664afc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-79fb96b9-ea7d-4548-ad03-c86e7753dd29,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-aa2e150d-ab39-4063-bee6-4024eaf8668d,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-ebd21e10-fae3-47bb-bbc2-48f28019ef9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1441918795-172.17.0.2-1595591926192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44389,DS-e0bfa773-e78f-4511-9e59-37159c61b568,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-ada0f931-7b29-44c3-9f1d-ef413074b96d,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-54eb0f3d-211c-47c6-b3a0-6c49c68db36e,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-86a6856f-8a36-4ea2-936a-a105c1f0664f,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-7c507664-b8b4-410b-8dc3-445dfd455e31,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-10927b40-5c9b-4ae0-80ed-ae8e1fae6379,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-e7ca81c1-3b76-4735-8251-a017ed2fe24c,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-6cfdb6e2-0ff8-4c4d-a996-58ca96e69b96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1441918795-172.17.0.2-1595591926192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44389,DS-e0bfa773-e78f-4511-9e59-37159c61b568,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-ada0f931-7b29-44c3-9f1d-ef413074b96d,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-54eb0f3d-211c-47c6-b3a0-6c49c68db36e,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-86a6856f-8a36-4ea2-936a-a105c1f0664f,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-7c507664-b8b4-410b-8dc3-445dfd455e31,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-10927b40-5c9b-4ae0-80ed-ae8e1fae6379,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-e7ca81c1-3b76-4735-8251-a017ed2fe24c,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-6cfdb6e2-0ff8-4c4d-a996-58ca96e69b96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-538521624-172.17.0.2-1595592801782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44123,DS-ebc92e75-8d0a-45ee-9e6f-4422a5e0a9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-b3ff2e12-d993-4e0e-a599-131ef5998fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-10b1f02d-2578-403d-a2a2-cf426d0190e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-28263793-3fba-486b-add0-e9efc076d5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-51350b67-5214-4a7f-8b27-32cbaf9c769f,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-28215dcb-cbef-4491-ae73-6b038f11cc27,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-7707993a-564a-49a5-8029-07229ef61b77,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-2f1cf89e-61ac-4caf-b6d8-1bdf6295411e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-538521624-172.17.0.2-1595592801782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44123,DS-ebc92e75-8d0a-45ee-9e6f-4422a5e0a9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-b3ff2e12-d993-4e0e-a599-131ef5998fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-10b1f02d-2578-403d-a2a2-cf426d0190e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-28263793-3fba-486b-add0-e9efc076d5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-51350b67-5214-4a7f-8b27-32cbaf9c769f,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-28215dcb-cbef-4491-ae73-6b038f11cc27,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-7707993a-564a-49a5-8029-07229ef61b77,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-2f1cf89e-61ac-4caf-b6d8-1bdf6295411e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-313127934-172.17.0.2-1595592876683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40210,DS-014ac193-0593-4a3a-a1fb-4ab94313fe87,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-60f14a34-6436-49cb-abd5-d2d982d8a35d,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-ee6e440e-52e8-4db6-9284-0c0e93895535,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-1dd0bee4-c296-4684-9a03-a3a703bfc95d,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-ea89fac2-17a6-4579-ad3a-ba24eb898330,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-011917e4-f771-409a-9fd9-a7e06c58848d,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-c15401ef-6975-4e31-a1a5-2439d02501db,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-84541950-da4f-4497-a0c9-b82d9c1a1d8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-313127934-172.17.0.2-1595592876683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40210,DS-014ac193-0593-4a3a-a1fb-4ab94313fe87,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-60f14a34-6436-49cb-abd5-d2d982d8a35d,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-ee6e440e-52e8-4db6-9284-0c0e93895535,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-1dd0bee4-c296-4684-9a03-a3a703bfc95d,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-ea89fac2-17a6-4579-ad3a-ba24eb898330,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-011917e4-f771-409a-9fd9-a7e06c58848d,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-c15401ef-6975-4e31-a1a5-2439d02501db,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-84541950-da4f-4497-a0c9-b82d9c1a1d8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767261960-172.17.0.2-1595592965017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40944,DS-147feaab-61ad-40cb-b70e-a54a0463e4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-1a3fce08-2ad2-45c9-a5e2-39d9b82062a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-d82c5644-02af-46a8-9cf8-557979262810,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-2abe81c6-85a8-4c00-9b2d-c283198353a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-8800122b-4881-4705-8562-ee10520b4427,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-d0a6c354-e3ad-409e-a60b-55e15574ac0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-63349305-b5c3-4dba-964e-8f8ace0a99a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-298fa3bd-e804-4b43-940b-630392cb84e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767261960-172.17.0.2-1595592965017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40944,DS-147feaab-61ad-40cb-b70e-a54a0463e4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-1a3fce08-2ad2-45c9-a5e2-39d9b82062a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-d82c5644-02af-46a8-9cf8-557979262810,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-2abe81c6-85a8-4c00-9b2d-c283198353a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-8800122b-4881-4705-8562-ee10520b4427,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-d0a6c354-e3ad-409e-a60b-55e15574ac0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-63349305-b5c3-4dba-964e-8f8ace0a99a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-298fa3bd-e804-4b43-940b-630392cb84e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1495729643-172.17.0.2-1595593003962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42968,DS-0786e79f-10be-477a-8494-68b15a3f9946,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-3fe834a8-624d-4915-9935-9d7ed2d02bde,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-c6d7271e-e327-41c4-9df2-9505b88c2dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-652bc9e0-2101-4083-98d1-b0c42edde8be,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-e81b9930-5501-4b57-bd44-cb04de0c0574,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-c6764059-eb98-4be5-b293-2d12dd73ebd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-23bc1532-ec07-4caf-b7c0-ba4f920d9974,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-e0fe8746-f78f-4187-85a7-3863ade283f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1495729643-172.17.0.2-1595593003962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42968,DS-0786e79f-10be-477a-8494-68b15a3f9946,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-3fe834a8-624d-4915-9935-9d7ed2d02bde,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-c6d7271e-e327-41c4-9df2-9505b88c2dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-652bc9e0-2101-4083-98d1-b0c42edde8be,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-e81b9930-5501-4b57-bd44-cb04de0c0574,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-c6764059-eb98-4be5-b293-2d12dd73ebd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-23bc1532-ec07-4caf-b7c0-ba4f920d9974,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-e0fe8746-f78f-4187-85a7-3863ade283f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-881169858-172.17.0.2-1595594150624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43989,DS-be903ff7-1610-468a-b487-68ba0ed58f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-9b120853-51b7-406d-a80d-d037eb4bff24,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-7dcedb70-1b3e-4de4-94e3-2605926fa4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-e0aabce8-1945-40ee-b196-d8217af032c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-52796564-74a8-4232-a342-44d5849e0f34,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-528eee83-5e23-4271-a4e6-08fa7378f2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-fa089c06-7ddc-401c-bad0-eda2f3067b63,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-ff22796f-087c-45eb-845c-9678965dceca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-881169858-172.17.0.2-1595594150624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43989,DS-be903ff7-1610-468a-b487-68ba0ed58f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-9b120853-51b7-406d-a80d-d037eb4bff24,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-7dcedb70-1b3e-4de4-94e3-2605926fa4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-e0aabce8-1945-40ee-b196-d8217af032c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-52796564-74a8-4232-a342-44d5849e0f34,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-528eee83-5e23-4271-a4e6-08fa7378f2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-fa089c06-7ddc-401c-bad0-eda2f3067b63,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-ff22796f-087c-45eb-845c-9678965dceca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5661
