reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-153883257-172.17.0.2-1595519618436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45782,DS-e1727f43-552f-4f05-b7bc-3ab746f8817d,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-c417e57a-b128-478c-9cab-9401f465ee38,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-cc3f2c11-184d-42dd-9eea-98c917057e53,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-33774c88-9e0f-4139-8a5e-b5f6ea484af9,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-4e4e7fea-7188-4921-9ad8-33d048af17d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-b3c58d6e-6353-4917-9b9f-305d07f4f06d,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-756219cf-6aac-4c55-a1ca-9c69f6b44868,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-1237d669-5ce1-4e59-bf66-50aacca41198,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-153883257-172.17.0.2-1595519618436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45782,DS-e1727f43-552f-4f05-b7bc-3ab746f8817d,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-c417e57a-b128-478c-9cab-9401f465ee38,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-cc3f2c11-184d-42dd-9eea-98c917057e53,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-33774c88-9e0f-4139-8a5e-b5f6ea484af9,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-4e4e7fea-7188-4921-9ad8-33d048af17d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-b3c58d6e-6353-4917-9b9f-305d07f4f06d,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-756219cf-6aac-4c55-a1ca-9c69f6b44868,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-1237d669-5ce1-4e59-bf66-50aacca41198,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530523493-172.17.0.2-1595520137314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44737,DS-fdfde6be-0e5e-4935-80b7-aedbcfd54ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-8a0b3fe3-f347-4f9e-80a3-cd010632f222,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-4474168c-098e-4091-a527-5e59686b9128,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-d009caaf-3697-4893-933e-372685cfaf00,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-484552bd-26fe-4c5f-8aeb-a0745862a210,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-662ac35f-af5b-4975-ae2b-0f49b7c5ab9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-44de50ea-8753-4258-b60b-27a5172cbd27,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-ede0fc9b-3eb7-41a5-9293-ddaba6a5d81c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530523493-172.17.0.2-1595520137314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44737,DS-fdfde6be-0e5e-4935-80b7-aedbcfd54ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-8a0b3fe3-f347-4f9e-80a3-cd010632f222,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-4474168c-098e-4091-a527-5e59686b9128,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-d009caaf-3697-4893-933e-372685cfaf00,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-484552bd-26fe-4c5f-8aeb-a0745862a210,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-662ac35f-af5b-4975-ae2b-0f49b7c5ab9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-44de50ea-8753-4258-b60b-27a5172cbd27,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-ede0fc9b-3eb7-41a5-9293-ddaba6a5d81c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-22617455-172.17.0.2-1595520400035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34769,DS-6a154211-0505-4863-b313-416eb8ee34a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-30d48a37-2a56-40d2-b05b-a78a01c529a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-7f2cd811-1040-4914-9885-0caf62ce2d63,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-6fc60c68-d1f3-480f-b58d-03436d867cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-5e7bbc2a-cc01-4bb7-b49d-044cf31fee3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-26ad19df-4a1f-4e70-bd81-f6d6884f1f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-f8393607-742a-4679-9ef3-5bb5f502599d,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-f502c9c9-4031-4db1-a676-8a36910802ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-22617455-172.17.0.2-1595520400035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34769,DS-6a154211-0505-4863-b313-416eb8ee34a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-30d48a37-2a56-40d2-b05b-a78a01c529a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-7f2cd811-1040-4914-9885-0caf62ce2d63,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-6fc60c68-d1f3-480f-b58d-03436d867cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-5e7bbc2a-cc01-4bb7-b49d-044cf31fee3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-26ad19df-4a1f-4e70-bd81-f6d6884f1f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-f8393607-742a-4679-9ef3-5bb5f502599d,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-f502c9c9-4031-4db1-a676-8a36910802ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1265943420-172.17.0.2-1595520825266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43943,DS-e77cb4fb-566e-4ea3-9012-3aa76b282e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-552526e9-f8cc-4aa7-bf28-b439213959fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-43e38610-c42d-4ed8-a255-c7268ca9ddb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-a77c8d85-978b-43cf-a416-089d009bc3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-cf9f7cb3-17cd-46a7-b288-eb44d51b14f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-37e6f651-0aa1-46a9-bb3a-982242b0b50c,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-facfdf54-1447-448d-b1f3-17c5f73b1537,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-06943aef-33c4-40eb-bb98-0093e2402232,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1265943420-172.17.0.2-1595520825266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43943,DS-e77cb4fb-566e-4ea3-9012-3aa76b282e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-552526e9-f8cc-4aa7-bf28-b439213959fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-43e38610-c42d-4ed8-a255-c7268ca9ddb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-a77c8d85-978b-43cf-a416-089d009bc3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-cf9f7cb3-17cd-46a7-b288-eb44d51b14f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-37e6f651-0aa1-46a9-bb3a-982242b0b50c,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-facfdf54-1447-448d-b1f3-17c5f73b1537,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-06943aef-33c4-40eb-bb98-0093e2402232,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-47647906-172.17.0.2-1595520900228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36219,DS-274ae5b0-5b7c-4853-a259-8da62babfe40,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-d721f9aa-a5ff-4a36-957a-45704c62c979,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-80d0da87-9076-4fbb-9d6e-3cb628e3a838,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-9b72f0d3-9a9c-4391-a824-b25788c881a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-9a74e637-721e-4079-90f6-c1d5578a4a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-14eee9ab-ffa9-4305-97b0-75255ee59353,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-69a31e63-fa59-48b9-b897-d2e204397239,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-0dcfa02f-19eb-4687-b10a-3b2710114b79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-47647906-172.17.0.2-1595520900228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36219,DS-274ae5b0-5b7c-4853-a259-8da62babfe40,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-d721f9aa-a5ff-4a36-957a-45704c62c979,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-80d0da87-9076-4fbb-9d6e-3cb628e3a838,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-9b72f0d3-9a9c-4391-a824-b25788c881a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-9a74e637-721e-4079-90f6-c1d5578a4a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-14eee9ab-ffa9-4305-97b0-75255ee59353,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-69a31e63-fa59-48b9-b897-d2e204397239,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-0dcfa02f-19eb-4687-b10a-3b2710114b79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1652774548-172.17.0.2-1595521541955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37764,DS-067d5d67-7570-4985-ab0a-95b99fb7ebc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-1248de82-9848-4563-b008-3185ea96c4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-f6b81169-97cf-4e15-b69b-ad78c870324a,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-14bc2f96-fe63-4b54-8c06-24a0fedfd944,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-b7c51135-e049-4226-ba45-0b4a299f9833,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-cae63710-5f7f-4825-b902-3532cf1c4193,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-f8cbc927-7234-4d4a-aa96-da58503afd34,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-ad1478bc-b3e2-445c-9b08-ab6b2f3b7e39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1652774548-172.17.0.2-1595521541955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37764,DS-067d5d67-7570-4985-ab0a-95b99fb7ebc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-1248de82-9848-4563-b008-3185ea96c4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-f6b81169-97cf-4e15-b69b-ad78c870324a,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-14bc2f96-fe63-4b54-8c06-24a0fedfd944,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-b7c51135-e049-4226-ba45-0b4a299f9833,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-cae63710-5f7f-4825-b902-3532cf1c4193,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-f8cbc927-7234-4d4a-aa96-da58503afd34,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-ad1478bc-b3e2-445c-9b08-ab6b2f3b7e39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1191932126-172.17.0.2-1595522554739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37482,DS-2bb5a968-58b5-4607-a640-293bca45f35f,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-e5954484-bbe6-4261-92ce-a71b4d05936c,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-8d6ac0bd-d29a-475f-8d6f-b99af44a14f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-8bed69dd-04ab-4d6c-9eda-1cb04bbd24b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-c706b446-0588-44de-a739-9e73267682cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-27c8d5cc-406c-4a69-aacb-10b5916ba654,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-6f5d6a29-7aef-41d8-9bb3-05903f087354,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-9e38aa24-e3c9-4f44-b2b7-7e137fc4b078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1191932126-172.17.0.2-1595522554739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37482,DS-2bb5a968-58b5-4607-a640-293bca45f35f,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-e5954484-bbe6-4261-92ce-a71b4d05936c,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-8d6ac0bd-d29a-475f-8d6f-b99af44a14f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-8bed69dd-04ab-4d6c-9eda-1cb04bbd24b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-c706b446-0588-44de-a739-9e73267682cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-27c8d5cc-406c-4a69-aacb-10b5916ba654,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-6f5d6a29-7aef-41d8-9bb3-05903f087354,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-9e38aa24-e3c9-4f44-b2b7-7e137fc4b078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-875686055-172.17.0.2-1595522785881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46302,DS-9d99c8fd-1a9b-43bc-b127-a2ac5c4cc729,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-0d04894c-fb70-4ac6-aed8-9958c5909398,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-007179e5-3767-4888-81b9-b109d2b7eb16,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-e61b0063-291c-490b-b28f-eea9ca3be83c,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-0fc50547-3dd1-4f21-b21a-cbbade705a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-0477d513-ba3a-4214-8753-0779e3e87c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-d4b1d22e-7bfc-4fa4-be80-f8dd6fb5aacc,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-1e599136-24b7-497c-a33d-630751f72531,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-875686055-172.17.0.2-1595522785881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46302,DS-9d99c8fd-1a9b-43bc-b127-a2ac5c4cc729,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-0d04894c-fb70-4ac6-aed8-9958c5909398,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-007179e5-3767-4888-81b9-b109d2b7eb16,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-e61b0063-291c-490b-b28f-eea9ca3be83c,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-0fc50547-3dd1-4f21-b21a-cbbade705a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-0477d513-ba3a-4214-8753-0779e3e87c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-d4b1d22e-7bfc-4fa4-be80-f8dd6fb5aacc,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-1e599136-24b7-497c-a33d-630751f72531,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-343741922-172.17.0.2-1595522920298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34612,DS-96a74ace-d980-474a-8a76-df053f452a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-cd879b6e-c0cc-41bf-9067-db3d867f6bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-a22b750d-f627-411b-bca4-98f5ab0a47af,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-af67c13f-d7ce-420f-bede-0c8545bd23a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-10e442ca-06c5-4c2d-ae6f-94a1442ab7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-11891607-79c6-433d-a805-f79064afe294,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-31275201-b758-4c2c-8770-ee59573eb84e,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-7cd82050-e32c-49f7-8184-b1244510f9b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-343741922-172.17.0.2-1595522920298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34612,DS-96a74ace-d980-474a-8a76-df053f452a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-cd879b6e-c0cc-41bf-9067-db3d867f6bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-a22b750d-f627-411b-bca4-98f5ab0a47af,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-af67c13f-d7ce-420f-bede-0c8545bd23a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-10e442ca-06c5-4c2d-ae6f-94a1442ab7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-11891607-79c6-433d-a805-f79064afe294,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-31275201-b758-4c2c-8770-ee59573eb84e,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-7cd82050-e32c-49f7-8184-b1244510f9b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1317391614-172.17.0.2-1595523087957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36331,DS-03bc311e-9039-4cc2-bf3a-525a14f5b098,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-3d7ee377-83af-4e64-949c-e5ae0c232a81,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-abb6a8ef-1af8-4832-9ed4-7e771a1da31a,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-8cc15778-7629-4d51-8db6-cba1fa47cd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-86371999-b72a-4b76-a799-6c4ff976ae51,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-05bd14ee-9967-45a9-b0b6-57332affd26d,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-a694b3d7-ed3e-4440-ab8c-08a2030d7116,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-d9314027-2203-4785-886b-0e35a4c24ac8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1317391614-172.17.0.2-1595523087957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36331,DS-03bc311e-9039-4cc2-bf3a-525a14f5b098,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-3d7ee377-83af-4e64-949c-e5ae0c232a81,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-abb6a8ef-1af8-4832-9ed4-7e771a1da31a,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-8cc15778-7629-4d51-8db6-cba1fa47cd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-86371999-b72a-4b76-a799-6c4ff976ae51,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-05bd14ee-9967-45a9-b0b6-57332affd26d,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-a694b3d7-ed3e-4440-ab8c-08a2030d7116,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-d9314027-2203-4785-886b-0e35a4c24ac8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1577644260-172.17.0.2-1595523349407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33676,DS-15a243ca-79bd-4b9c-955b-2d902b371998,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-9736ef3c-4c63-4485-9845-d562379db44e,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-349e81d7-d0b8-4932-90f4-5fdebb47d4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-04f5ecea-519e-4eb5-b48c-f6c258a4e236,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-17585a2b-60f5-4bda-a8c0-3c5461cf58b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-06485198-a40b-4a3c-9c99-b8d7b3e5a078,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-4b32ef2e-50b5-4268-971f-baa56757d2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-ac57e93d-7978-4486-b9c7-98bbc703b4bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1577644260-172.17.0.2-1595523349407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33676,DS-15a243ca-79bd-4b9c-955b-2d902b371998,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-9736ef3c-4c63-4485-9845-d562379db44e,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-349e81d7-d0b8-4932-90f4-5fdebb47d4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-04f5ecea-519e-4eb5-b48c-f6c258a4e236,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-17585a2b-60f5-4bda-a8c0-3c5461cf58b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-06485198-a40b-4a3c-9c99-b8d7b3e5a078,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-4b32ef2e-50b5-4268-971f-baa56757d2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-ac57e93d-7978-4486-b9c7-98bbc703b4bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1559976223-172.17.0.2-1595523739381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43391,DS-84291931-cec8-4893-9098-de4788c1633d,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-e7cea426-e583-44b0-a2a7-d9ee93ee2159,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-2b8c54cd-7463-457a-8707-b5bee4c3489c,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-ce131508-e939-4b51-94cd-b694943f68c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-d9ba0a1e-a3a8-4292-b423-5627e6f06c76,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-f6f348f3-9fe4-4f6d-b4eb-b37a133a661f,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-1bc2e6b4-4054-4eb0-b62a-de8c63ffa348,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-d3a38661-7c7c-4e3c-8b4c-132e323a70f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1559976223-172.17.0.2-1595523739381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43391,DS-84291931-cec8-4893-9098-de4788c1633d,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-e7cea426-e583-44b0-a2a7-d9ee93ee2159,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-2b8c54cd-7463-457a-8707-b5bee4c3489c,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-ce131508-e939-4b51-94cd-b694943f68c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-d9ba0a1e-a3a8-4292-b423-5627e6f06c76,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-f6f348f3-9fe4-4f6d-b4eb-b37a133a661f,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-1bc2e6b4-4054-4eb0-b62a-de8c63ffa348,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-d3a38661-7c7c-4e3c-8b4c-132e323a70f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-997940277-172.17.0.2-1595524074696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38148,DS-283b0f53-d4bb-414d-bd50-6cd3542cab92,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-58525476-6962-433f-a0b9-e70ef0be810c,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-f1201841-7b76-49fb-955e-1c35c88d10d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-73d00dcc-5582-44fb-9691-8f040acfa493,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-53825a99-c0a2-4a9c-8425-06e465d95f21,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-9db7dc38-da94-4431-8d01-59808c365609,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-dc6424c1-fa7d-4241-ab9b-50a462dd03e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-f2c6999e-02ad-498a-b793-7ef544ec3a0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-997940277-172.17.0.2-1595524074696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38148,DS-283b0f53-d4bb-414d-bd50-6cd3542cab92,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-58525476-6962-433f-a0b9-e70ef0be810c,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-f1201841-7b76-49fb-955e-1c35c88d10d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-73d00dcc-5582-44fb-9691-8f040acfa493,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-53825a99-c0a2-4a9c-8425-06e465d95f21,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-9db7dc38-da94-4431-8d01-59808c365609,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-dc6424c1-fa7d-4241-ab9b-50a462dd03e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-f2c6999e-02ad-498a-b793-7ef544ec3a0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-975809462-172.17.0.2-1595524297616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36289,DS-74012564-448a-44e1-81e4-6787d6a20ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-e69df2ee-e661-415c-926d-22ad0632659d,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-2b9647c3-36d9-4424-b36d-c068cf2619af,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-3158b327-a7ea-494b-a3c4-c2f8ebfbfd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-abb61f06-b1ff-4839-89d9-aec044315f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-518fba3d-59b5-4a65-9399-0a098d0f345e,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-f6ea1897-d2d2-4b30-babc-4a3399fdbcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-d246cd0f-cd62-4424-b14c-fb832318790e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-975809462-172.17.0.2-1595524297616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36289,DS-74012564-448a-44e1-81e4-6787d6a20ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-e69df2ee-e661-415c-926d-22ad0632659d,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-2b9647c3-36d9-4424-b36d-c068cf2619af,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-3158b327-a7ea-494b-a3c4-c2f8ebfbfd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-abb61f06-b1ff-4839-89d9-aec044315f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-518fba3d-59b5-4a65-9399-0a098d0f345e,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-f6ea1897-d2d2-4b30-babc-4a3399fdbcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-d246cd0f-cd62-4424-b14c-fb832318790e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-68767010-172.17.0.2-1595524434912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32821,DS-971a6d83-b5aa-4f81-a8bb-654ef064d40e,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-8ccea5de-6559-422e-902c-f7b57b1a7b77,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-8306d5d7-e015-493d-8547-af969120a2da,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-4efe7bac-d70f-4dd8-ba61-70af5d7bfc24,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-5b5b7a8c-1b66-42dd-9f00-5114c1e1a397,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-2809de0a-62ce-4bd4-949a-71ba70e30e97,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-10bcaa11-2acd-47a2-935e-756e2c77c293,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-13c7f368-058a-4637-801c-0aaccb0325fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-68767010-172.17.0.2-1595524434912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32821,DS-971a6d83-b5aa-4f81-a8bb-654ef064d40e,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-8ccea5de-6559-422e-902c-f7b57b1a7b77,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-8306d5d7-e015-493d-8547-af969120a2da,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-4efe7bac-d70f-4dd8-ba61-70af5d7bfc24,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-5b5b7a8c-1b66-42dd-9f00-5114c1e1a397,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-2809de0a-62ce-4bd4-949a-71ba70e30e97,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-10bcaa11-2acd-47a2-935e-756e2c77c293,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-13c7f368-058a-4637-801c-0aaccb0325fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822568009-172.17.0.2-1595524753819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45390,DS-5183b438-5b5c-49a3-ad60-65e59b6df92f,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-cd83c127-4694-45d4-90fe-b0ec0d33584e,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-498f5dec-8826-4d24-a244-7d5fe4fdf3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-79c56a6b-c1b4-47e0-aa3c-9f453278db87,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-95efaafa-7c36-461f-9ecb-2af749771803,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-4ecb1b56-c850-4d53-afca-81e65b84b2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-2482fc07-62a9-4f21-9c2f-d3fea05dc3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-69364754-3795-4c9d-b897-10b5937f87c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822568009-172.17.0.2-1595524753819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45390,DS-5183b438-5b5c-49a3-ad60-65e59b6df92f,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-cd83c127-4694-45d4-90fe-b0ec0d33584e,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-498f5dec-8826-4d24-a244-7d5fe4fdf3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-79c56a6b-c1b4-47e0-aa3c-9f453278db87,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-95efaafa-7c36-461f-9ecb-2af749771803,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-4ecb1b56-c850-4d53-afca-81e65b84b2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-2482fc07-62a9-4f21-9c2f-d3fea05dc3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-69364754-3795-4c9d-b897-10b5937f87c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1669487001-172.17.0.2-1595524790746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33618,DS-055b4cce-08e3-48da-86ec-80d778ebe7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-ba9ae8fe-3c7c-44d6-8c94-fac1d86bc268,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-90a4c723-d8e2-41e2-9ef4-4e4df367a261,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-3c95e42b-46b6-4ec1-a9b9-6e0325e68a25,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-3a759627-1169-4b9b-85d4-18f5f88f2d01,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-ea18e093-f5a6-4780-95cc-2e4f72b69b07,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-42ff2bdd-dc08-4497-a5e8-773906d7f447,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-a83d336b-2a7a-46ff-a5b9-ca7ab6800039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1669487001-172.17.0.2-1595524790746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33618,DS-055b4cce-08e3-48da-86ec-80d778ebe7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-ba9ae8fe-3c7c-44d6-8c94-fac1d86bc268,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-90a4c723-d8e2-41e2-9ef4-4e4df367a261,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-3c95e42b-46b6-4ec1-a9b9-6e0325e68a25,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-3a759627-1169-4b9b-85d4-18f5f88f2d01,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-ea18e093-f5a6-4780-95cc-2e4f72b69b07,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-42ff2bdd-dc08-4497-a5e8-773906d7f447,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-a83d336b-2a7a-46ff-a5b9-ca7ab6800039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5289
