reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-613690329-172.17.0.16-1595534835339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42908,DS-3c883f8f-d64c-4595-931e-50f14e9b38e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-07165e1b-a0a1-4f25-ac99-8aebcd6b97f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-f91bad57-bbf8-45e7-9561-4689f8ef7221,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-80917d96-9f7a-4aef-9a15-f167fa6b4c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-daa9be37-04ad-4bcb-bf3e-404608000599,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-3e2f45d1-c254-46dd-b86b-55ff4891e841,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-0c7fd05f-03b2-4ca0-9959-08c3f7fb024f,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-1a1597c5-19b4-458d-9930-349feb7116cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-613690329-172.17.0.16-1595534835339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42908,DS-3c883f8f-d64c-4595-931e-50f14e9b38e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-07165e1b-a0a1-4f25-ac99-8aebcd6b97f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-f91bad57-bbf8-45e7-9561-4689f8ef7221,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-80917d96-9f7a-4aef-9a15-f167fa6b4c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-daa9be37-04ad-4bcb-bf3e-404608000599,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-3e2f45d1-c254-46dd-b86b-55ff4891e841,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-0c7fd05f-03b2-4ca0-9959-08c3f7fb024f,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-1a1597c5-19b4-458d-9930-349feb7116cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1616131849-172.17.0.16-1595534898684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34766,DS-b11d6f8a-bf06-476e-affa-b03a033514b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-1e6a00a3-81ec-4ef4-8b20-c0f19f259f64,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-69b09ce2-cc3c-4a21-bdb5-08df4032116a,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-2ac6b4d0-74df-4990-bdda-46234ab28c20,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-8669ff1d-9739-4bb6-a5f8-134702f18b35,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-bc08f647-5e7f-462a-9bc7-177ed176fd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-d79682b2-6423-4f6d-ae2c-b2cfc0d9d596,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-66ccefaa-c68a-4e67-89a0-b796d256285b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1616131849-172.17.0.16-1595534898684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34766,DS-b11d6f8a-bf06-476e-affa-b03a033514b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-1e6a00a3-81ec-4ef4-8b20-c0f19f259f64,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-69b09ce2-cc3c-4a21-bdb5-08df4032116a,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-2ac6b4d0-74df-4990-bdda-46234ab28c20,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-8669ff1d-9739-4bb6-a5f8-134702f18b35,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-bc08f647-5e7f-462a-9bc7-177ed176fd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-d79682b2-6423-4f6d-ae2c-b2cfc0d9d596,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-66ccefaa-c68a-4e67-89a0-b796d256285b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1441473870-172.17.0.16-1595535053332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39144,DS-43054242-b0ff-4c5d-832f-83a0aaf69396,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-f1be5a99-a9ca-4bc5-b60b-5a730bbb425b,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-9c82972a-cbd0-43f6-a6bc-37fadb1d3f50,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-a61ce71a-6544-4478-8d78-e642a6e889d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-adf879e4-7d80-40bc-a109-49ec57189d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-f3e59c47-7b2c-4261-8936-09d3b146b2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-ab89f91e-1b0d-4bcd-800d-01cdcef2836b,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-9bf1e4d5-0f65-4e1e-b2dd-48b14342a387,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1441473870-172.17.0.16-1595535053332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39144,DS-43054242-b0ff-4c5d-832f-83a0aaf69396,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-f1be5a99-a9ca-4bc5-b60b-5a730bbb425b,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-9c82972a-cbd0-43f6-a6bc-37fadb1d3f50,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-a61ce71a-6544-4478-8d78-e642a6e889d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-adf879e4-7d80-40bc-a109-49ec57189d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-f3e59c47-7b2c-4261-8936-09d3b146b2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-ab89f91e-1b0d-4bcd-800d-01cdcef2836b,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-9bf1e4d5-0f65-4e1e-b2dd-48b14342a387,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2065200305-172.17.0.16-1595535081055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39855,DS-34b171ef-ad66-4517-915a-54ccd29aa85f,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-63b138b8-6ba5-40f8-bf1a-2b321b5be529,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-3a7eae07-271d-4ec1-bbe8-a163542ec97c,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-5316f500-b1a8-40b2-8f43-95c7070eb22d,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-1d526dbd-a3e7-47e3-ba1f-132094b76864,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-6d4262d8-5d68-48ac-86a2-3f301c11c8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-75389a5c-27d6-41a7-b3e4-9d7c321073f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-5486e4a8-d51a-4ff1-bc77-de6dd71434e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2065200305-172.17.0.16-1595535081055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39855,DS-34b171ef-ad66-4517-915a-54ccd29aa85f,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-63b138b8-6ba5-40f8-bf1a-2b321b5be529,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-3a7eae07-271d-4ec1-bbe8-a163542ec97c,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-5316f500-b1a8-40b2-8f43-95c7070eb22d,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-1d526dbd-a3e7-47e3-ba1f-132094b76864,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-6d4262d8-5d68-48ac-86a2-3f301c11c8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-75389a5c-27d6-41a7-b3e4-9d7c321073f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-5486e4a8-d51a-4ff1-bc77-de6dd71434e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-606133676-172.17.0.16-1595535110212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36620,DS-f0ec3dc4-2449-4ecb-9389-b75131aea062,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-2d5349e5-09ea-41e3-9d64-5e5fdfe30597,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-654cb6e2-5de2-474a-9bb5-411c87477e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-69403132-0c8e-4ec6-9d8c-23014d8caa27,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-2648b6e0-650e-4d53-b60d-2beb66e22a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-20fd5fdc-c6a5-411c-99d0-9b58e11fbffa,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-cab921ec-b356-4383-8ede-a0d706de92b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-1f9bfa28-7181-4df9-bc61-1f32b8cfe15b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-606133676-172.17.0.16-1595535110212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36620,DS-f0ec3dc4-2449-4ecb-9389-b75131aea062,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-2d5349e5-09ea-41e3-9d64-5e5fdfe30597,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-654cb6e2-5de2-474a-9bb5-411c87477e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-69403132-0c8e-4ec6-9d8c-23014d8caa27,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-2648b6e0-650e-4d53-b60d-2beb66e22a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-20fd5fdc-c6a5-411c-99d0-9b58e11fbffa,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-cab921ec-b356-4383-8ede-a0d706de92b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-1f9bfa28-7181-4df9-bc61-1f32b8cfe15b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-166950106-172.17.0.16-1595535936543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45241,DS-76f681bc-ee52-476d-9326-e609ed3c2bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-42f3f8cc-c6d4-40cb-9280-896287b649ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-e673727d-836e-41de-b193-80fff7a76bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-6ff8658e-7401-4665-b6e7-85522119af9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-ca6d7c5e-aea9-4c55-adcc-b04e7b873280,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-3a757cb5-d3c9-4111-a344-de2b67fc462f,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-ad02a189-490e-46b4-8627-7dbde951a98c,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-069e25ab-0968-4d87-afb8-c9cc093bceb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-166950106-172.17.0.16-1595535936543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45241,DS-76f681bc-ee52-476d-9326-e609ed3c2bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-42f3f8cc-c6d4-40cb-9280-896287b649ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-e673727d-836e-41de-b193-80fff7a76bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-6ff8658e-7401-4665-b6e7-85522119af9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-ca6d7c5e-aea9-4c55-adcc-b04e7b873280,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-3a757cb5-d3c9-4111-a344-de2b67fc462f,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-ad02a189-490e-46b4-8627-7dbde951a98c,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-069e25ab-0968-4d87-afb8-c9cc093bceb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2099195843-172.17.0.16-1595536079674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42252,DS-0b8411f1-f590-4ba4-8d1d-89aee4c032bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-6864dc9d-8dae-43df-a49f-18f697d631be,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-379c1a8c-c0bb-4cb9-9730-637860f68c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-42f6ad6b-68bd-42e6-8043-7337d0b5d4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-2bae7ce1-e902-4a37-9cf7-c7b525124afd,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-b1fde0ab-3fa7-416c-8bd0-3f4b180a0e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-c618c906-29c0-4d6b-ad2d-9fb40030e020,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-35ed0ef1-fffb-4f0c-a5af-c8929e834268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2099195843-172.17.0.16-1595536079674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42252,DS-0b8411f1-f590-4ba4-8d1d-89aee4c032bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-6864dc9d-8dae-43df-a49f-18f697d631be,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-379c1a8c-c0bb-4cb9-9730-637860f68c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-42f6ad6b-68bd-42e6-8043-7337d0b5d4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-2bae7ce1-e902-4a37-9cf7-c7b525124afd,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-b1fde0ab-3fa7-416c-8bd0-3f4b180a0e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-c618c906-29c0-4d6b-ad2d-9fb40030e020,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-35ed0ef1-fffb-4f0c-a5af-c8929e834268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1518426999-172.17.0.16-1595536442660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39918,DS-853ec6e8-db8b-4fdd-95dc-8f7ae09e1e37,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-da32f161-0207-4f98-a562-61b75a4b16f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-0ae7ff04-351f-4c60-95d4-0e53d38463cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-38f12312-471f-491c-ac82-384877058190,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-6d8df8b9-9c43-4d33-948e-a6deb8557289,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-d54384d8-ac27-4ed2-bb91-e92a8be8e083,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-bc00f6d3-cfad-487d-bd05-c69a9f21ec16,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-9a902bd1-8951-421f-8c4b-2ba6c26fc8b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1518426999-172.17.0.16-1595536442660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39918,DS-853ec6e8-db8b-4fdd-95dc-8f7ae09e1e37,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-da32f161-0207-4f98-a562-61b75a4b16f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-0ae7ff04-351f-4c60-95d4-0e53d38463cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-38f12312-471f-491c-ac82-384877058190,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-6d8df8b9-9c43-4d33-948e-a6deb8557289,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-d54384d8-ac27-4ed2-bb91-e92a8be8e083,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-bc00f6d3-cfad-487d-bd05-c69a9f21ec16,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-9a902bd1-8951-421f-8c4b-2ba6c26fc8b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-458162677-172.17.0.16-1595536477557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46399,DS-efa92e70-b0d3-4eb8-851a-36b66a1298c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-fd963691-ea13-4724-86cd-3888fcf310dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-c96269e1-5b8e-4b91-9dac-b72d86f2cd96,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-b40f27dd-d35a-4fbb-b7ca-a49fb05987d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-699cc280-e090-485a-a75a-108a308e5067,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-16324d17-601f-4600-b203-a2f8bd1ee61c,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-574fb913-b90e-40cd-9c87-a3450e5d597c,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-fe7a3a94-ba96-4baf-b89c-052c55c1dbf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-458162677-172.17.0.16-1595536477557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46399,DS-efa92e70-b0d3-4eb8-851a-36b66a1298c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-fd963691-ea13-4724-86cd-3888fcf310dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-c96269e1-5b8e-4b91-9dac-b72d86f2cd96,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-b40f27dd-d35a-4fbb-b7ca-a49fb05987d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-699cc280-e090-485a-a75a-108a308e5067,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-16324d17-601f-4600-b203-a2f8bd1ee61c,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-574fb913-b90e-40cd-9c87-a3450e5d597c,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-fe7a3a94-ba96-4baf-b89c-052c55c1dbf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667511831-172.17.0.16-1595537609625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35886,DS-b83d0ce1-852f-49d9-9afe-6d6116417b45,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-7a3bc7ac-910b-4900-818f-85d3b4eae2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-52508182-a48e-414b-b067-c57ae5a662bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-12765b46-f203-4451-a73a-95e95e461fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-9329efdc-638a-4b93-af9e-b66688bf62bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-63bd8ea8-b722-4fcf-b9cd-c2651843b1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-8d9bbdd6-dfd4-4c6f-a0b5-d5d8889cf34f,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-dd42166c-eaa5-4aaa-9bb9-e3118c5a727d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667511831-172.17.0.16-1595537609625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35886,DS-b83d0ce1-852f-49d9-9afe-6d6116417b45,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-7a3bc7ac-910b-4900-818f-85d3b4eae2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-52508182-a48e-414b-b067-c57ae5a662bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-12765b46-f203-4451-a73a-95e95e461fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-9329efdc-638a-4b93-af9e-b66688bf62bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-63bd8ea8-b722-4fcf-b9cd-c2651843b1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-8d9bbdd6-dfd4-4c6f-a0b5-d5d8889cf34f,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-dd42166c-eaa5-4aaa-9bb9-e3118c5a727d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822872720-172.17.0.16-1595537714912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44607,DS-1b39eb9b-888f-40c5-8444-7cd16c09599c,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-0cff90a5-32d5-4547-b88c-afba66aef231,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-ad2884f3-649b-4409-a0f1-5ad85f5e5522,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-7e1fc7a4-d89a-4759-bbc7-9e88d437a8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36241,DS-9fca1db1-6311-429d-96af-b183176999d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-1969a21d-6cb8-4433-bc45-fedd1290aa94,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-12d1f1d1-59a2-4f19-9e33-e3c2281b6be2,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-9273b64f-9ba9-4580-9170-371ba9765e69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822872720-172.17.0.16-1595537714912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44607,DS-1b39eb9b-888f-40c5-8444-7cd16c09599c,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-0cff90a5-32d5-4547-b88c-afba66aef231,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-ad2884f3-649b-4409-a0f1-5ad85f5e5522,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-7e1fc7a4-d89a-4759-bbc7-9e88d437a8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36241,DS-9fca1db1-6311-429d-96af-b183176999d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-1969a21d-6cb8-4433-bc45-fedd1290aa94,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-12d1f1d1-59a2-4f19-9e33-e3c2281b6be2,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-9273b64f-9ba9-4580-9170-371ba9765e69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807994169-172.17.0.16-1595537752077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38187,DS-36d91246-0b26-47d6-8a38-457297eece65,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-e1461ccd-96a2-4046-aad6-f7e38675bbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-53599c75-dac3-4885-8c63-b724274b7461,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-1c978591-a623-4783-bab4-e6495c049cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-60a84025-6b18-4f3b-8132-b737e8118c75,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-2e5c161f-86c5-4299-86bb-aac7c2c4140f,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-a03cc7df-17df-46db-aa22-1b8418702a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-db358296-1cc4-4029-a087-2dc55e321e12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807994169-172.17.0.16-1595537752077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38187,DS-36d91246-0b26-47d6-8a38-457297eece65,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-e1461ccd-96a2-4046-aad6-f7e38675bbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-53599c75-dac3-4885-8c63-b724274b7461,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-1c978591-a623-4783-bab4-e6495c049cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-60a84025-6b18-4f3b-8132-b737e8118c75,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-2e5c161f-86c5-4299-86bb-aac7c2c4140f,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-a03cc7df-17df-46db-aa22-1b8418702a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-db358296-1cc4-4029-a087-2dc55e321e12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-944250858-172.17.0.16-1595538063397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46280,DS-fba0123a-60d4-4e2b-b54c-99e39e5af472,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-3331d200-788a-4468-a1ed-35edf4be2e56,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-5b3510e3-32d6-46e8-ba21-295b0bc4c7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-ed8f8b61-7127-4583-9551-b6a7588ac22e,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-aaa56630-19cc-4e2c-9976-1ac09bf3e71a,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-9711dacb-83d8-4515-b4ce-dde313169478,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-f905ef23-44a5-41bf-b275-5f55666bda1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-38af5713-0e72-46ac-9fb1-7c512cf2893b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-944250858-172.17.0.16-1595538063397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46280,DS-fba0123a-60d4-4e2b-b54c-99e39e5af472,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-3331d200-788a-4468-a1ed-35edf4be2e56,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-5b3510e3-32d6-46e8-ba21-295b0bc4c7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-ed8f8b61-7127-4583-9551-b6a7588ac22e,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-aaa56630-19cc-4e2c-9976-1ac09bf3e71a,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-9711dacb-83d8-4515-b4ce-dde313169478,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-f905ef23-44a5-41bf-b275-5f55666bda1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-38af5713-0e72-46ac-9fb1-7c512cf2893b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1733559739-172.17.0.16-1595538697071:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34857,DS-9889343d-0854-4d54-9913-19eeed243308,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-8e075bfb-b42b-481a-8785-3360637d2c59,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-d0eafebc-ce12-4e41-a8be-ac47af6b5a96,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-a168b434-6c0e-418b-aca9-21eb743d7afc,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-f6076e9c-b231-4a52-9c37-560eb268bd17,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-93371a40-3c49-44ef-b83a-407b66a5cdee,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-57f25cb1-7bfe-4d17-8d49-aa0f54e3d262,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-6318c489-2d4c-417c-b582-7bf473f24b71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1733559739-172.17.0.16-1595538697071:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34857,DS-9889343d-0854-4d54-9913-19eeed243308,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-8e075bfb-b42b-481a-8785-3360637d2c59,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-d0eafebc-ce12-4e41-a8be-ac47af6b5a96,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-a168b434-6c0e-418b-aca9-21eb743d7afc,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-f6076e9c-b231-4a52-9c37-560eb268bd17,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-93371a40-3c49-44ef-b83a-407b66a5cdee,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-57f25cb1-7bfe-4d17-8d49-aa0f54e3d262,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-6318c489-2d4c-417c-b582-7bf473f24b71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1103487518-172.17.0.16-1595539063185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38133,DS-af34f8c8-a846-4abe-be69-a304b55b9a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-fae90736-2512-4b03-bb1a-c36c15faeb45,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-b9ef9a80-8828-452e-b027-e05d69e4a893,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-26bec42d-33b8-4f77-a5b7-1dc378e1b212,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-0664ecf5-af83-4481-bc0c-944b67913519,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-6bbfc414-a8db-4cdb-9e2a-052bed087503,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-ab00b646-f2e0-433f-9020-a05014011938,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-12bd93d3-c45d-42bf-836b-456e3ff6c2a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1103487518-172.17.0.16-1595539063185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38133,DS-af34f8c8-a846-4abe-be69-a304b55b9a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-fae90736-2512-4b03-bb1a-c36c15faeb45,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-b9ef9a80-8828-452e-b027-e05d69e4a893,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-26bec42d-33b8-4f77-a5b7-1dc378e1b212,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-0664ecf5-af83-4481-bc0c-944b67913519,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-6bbfc414-a8db-4cdb-9e2a-052bed087503,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-ab00b646-f2e0-433f-9020-a05014011938,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-12bd93d3-c45d-42bf-836b-456e3ff6c2a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1724739399-172.17.0.16-1595539233288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35317,DS-2aa8ec48-c483-4c02-997d-46628834435a,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-8b29d6a2-e11f-46dc-ac1f-8b811dce8e69,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-aa1716ab-97f1-445a-a34f-c3ec74e6238f,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-95cf95be-859a-4b16-a284-fa257962ffc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-888f8df2-0de1-4cbc-99a4-efe093d2f9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-8073bcdd-83e0-4980-a620-f193730453fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-40c5a91b-f49e-4286-be9c-8a3a17d2e0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-0180f0f3-0365-4a3c-a10b-0f83535da8d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1724739399-172.17.0.16-1595539233288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35317,DS-2aa8ec48-c483-4c02-997d-46628834435a,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-8b29d6a2-e11f-46dc-ac1f-8b811dce8e69,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-aa1716ab-97f1-445a-a34f-c3ec74e6238f,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-95cf95be-859a-4b16-a284-fa257962ffc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-888f8df2-0de1-4cbc-99a4-efe093d2f9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-8073bcdd-83e0-4980-a620-f193730453fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-40c5a91b-f49e-4286-be9c-8a3a17d2e0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-0180f0f3-0365-4a3c-a10b-0f83535da8d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1333361360-172.17.0.16-1595539265456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37716,DS-6ad84676-13ef-4915-9f1e-e39d0ef209e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-918a7a95-b05d-4443-b4b8-e5169ff3ec40,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-409a2dd8-c2ae-4716-8400-ec3f7d9c3585,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-b1384754-cf02-47ac-abd0-fe11413ea1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-8e54ec6d-2ec8-4f8d-9e37-9e181f80d8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-8bb065c5-8d30-42c6-ab89-d850418cc786,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-2df7ea0d-9cb5-4b26-a367-ee9296ce9aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-08e66dd8-cf16-4678-af4b-282e6fd3b439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1333361360-172.17.0.16-1595539265456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37716,DS-6ad84676-13ef-4915-9f1e-e39d0ef209e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-918a7a95-b05d-4443-b4b8-e5169ff3ec40,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-409a2dd8-c2ae-4716-8400-ec3f7d9c3585,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-b1384754-cf02-47ac-abd0-fe11413ea1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-8e54ec6d-2ec8-4f8d-9e37-9e181f80d8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-8bb065c5-8d30-42c6-ab89-d850418cc786,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-2df7ea0d-9cb5-4b26-a367-ee9296ce9aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-08e66dd8-cf16-4678-af4b-282e6fd3b439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2050970280-172.17.0.16-1595539304077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41951,DS-5b37b2f3-e2cb-4f7a-8377-45e6955fe7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-64fe801f-d193-41b9-8877-782ada338524,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-f61443ec-5a1d-4f41-b6fc-1bd73b65755f,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-87c509c0-8013-463e-a624-085649568b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-ccf73dd2-2ba2-4adc-b86a-e31670032f99,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-6907bd3e-9e41-4f50-a2ef-8c5203be01bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-9fbc104a-c804-477e-abde-9d03a859495f,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-0358bd7c-5958-41b0-8b04-3a8d920149d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2050970280-172.17.0.16-1595539304077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41951,DS-5b37b2f3-e2cb-4f7a-8377-45e6955fe7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-64fe801f-d193-41b9-8877-782ada338524,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-f61443ec-5a1d-4f41-b6fc-1bd73b65755f,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-87c509c0-8013-463e-a624-085649568b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-ccf73dd2-2ba2-4adc-b86a-e31670032f99,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-6907bd3e-9e41-4f50-a2ef-8c5203be01bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-9fbc104a-c804-477e-abde-9d03a859495f,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-0358bd7c-5958-41b0-8b04-3a8d920149d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369137459-172.17.0.16-1595539797063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42459,DS-771d5222-0b87-4c87-9a85-f12e2d27b09b,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-715d2741-8e36-4016-bae1-d9ed0bc04385,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-a5eea977-0a5e-4df9-aca9-4be79a52c3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-e0f0dd68-6a2b-4a4a-ae39-6cb14e62e112,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-8d9fd8cd-f12f-46fa-b94a-d2c9726511c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-0ac025dc-3252-495a-871d-79246397af02,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-74f27a13-0b63-4af8-94f4-6de8ece8face,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-7b60aff1-3207-4709-929a-3446d10d18b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369137459-172.17.0.16-1595539797063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42459,DS-771d5222-0b87-4c87-9a85-f12e2d27b09b,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-715d2741-8e36-4016-bae1-d9ed0bc04385,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-a5eea977-0a5e-4df9-aca9-4be79a52c3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-e0f0dd68-6a2b-4a4a-ae39-6cb14e62e112,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-8d9fd8cd-f12f-46fa-b94a-d2c9726511c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-0ac025dc-3252-495a-871d-79246397af02,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-74f27a13-0b63-4af8-94f4-6de8ece8face,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-7b60aff1-3207-4709-929a-3446d10d18b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5264
