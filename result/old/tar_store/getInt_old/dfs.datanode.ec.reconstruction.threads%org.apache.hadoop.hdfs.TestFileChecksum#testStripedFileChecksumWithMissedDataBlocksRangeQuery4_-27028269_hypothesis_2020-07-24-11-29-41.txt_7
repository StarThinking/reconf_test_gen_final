reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1242434693-172.17.0.7-1595590393249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40821,DS-860921ee-4fe9-4dd5-9983-0216cddfc43c,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-b46b8d28-8819-4434-9f95-d30906a21e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-b9c469e2-a012-4b7f-ae22-14f5d8d699ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-5b0af261-3d6f-442f-919c-86ec8a0dfc83,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-c5eaa185-879b-4342-9e69-b7125c022ace,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-fb6bd59b-0b9d-449b-a3fd-9cc8345f9c63,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-a42b2c18-83b5-48c6-8296-9ad0a31bfb54,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-d47d1248-d6de-4535-a60e-e3f82bd80c38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1242434693-172.17.0.7-1595590393249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40821,DS-860921ee-4fe9-4dd5-9983-0216cddfc43c,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-b46b8d28-8819-4434-9f95-d30906a21e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-b9c469e2-a012-4b7f-ae22-14f5d8d699ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-5b0af261-3d6f-442f-919c-86ec8a0dfc83,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-c5eaa185-879b-4342-9e69-b7125c022ace,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-fb6bd59b-0b9d-449b-a3fd-9cc8345f9c63,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-a42b2c18-83b5-48c6-8296-9ad0a31bfb54,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-d47d1248-d6de-4535-a60e-e3f82bd80c38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1807928630-172.17.0.7-1595590434759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38269,DS-96875ea6-d597-4357-9c13-565f40f158a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-c2d64a45-128e-4fe1-b498-156fdc84591b,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-49cd96b4-2de2-46ab-b57e-44781cf3fb43,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-65168538-ed98-44f1-9ff0-5096fd189979,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-3f7396e6-094d-4c66-bd48-cce3837dc464,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-c32f3cb8-b2b4-4a51-89c0-042589ea9326,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-d6530a15-ee28-44a9-84ea-682794083441,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-53c27af5-ee17-4608-b48d-45056f882bb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1807928630-172.17.0.7-1595590434759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38269,DS-96875ea6-d597-4357-9c13-565f40f158a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-c2d64a45-128e-4fe1-b498-156fdc84591b,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-49cd96b4-2de2-46ab-b57e-44781cf3fb43,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-65168538-ed98-44f1-9ff0-5096fd189979,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-3f7396e6-094d-4c66-bd48-cce3837dc464,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-c32f3cb8-b2b4-4a51-89c0-042589ea9326,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-d6530a15-ee28-44a9-84ea-682794083441,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-53c27af5-ee17-4608-b48d-45056f882bb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654677781-172.17.0.7-1595590864972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43436,DS-25c483d5-8328-4758-b727-6cacac756b27,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-3b053d82-3e92-40e0-927e-4e30e98b803b,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-cee58844-23bd-4547-91eb-f8c912562d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-9a93972b-7d64-4544-a7cc-e8b4152c4710,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-e90b9f4e-4a3e-4bec-9125-3bc010f0b851,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-e629dbdb-c899-4687-9b3a-9b91a10c3d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-37fd7fbc-4788-4d41-af1e-6a17ab7ced88,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-a8fd2b98-478e-42f9-855e-e13180199e4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654677781-172.17.0.7-1595590864972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43436,DS-25c483d5-8328-4758-b727-6cacac756b27,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-3b053d82-3e92-40e0-927e-4e30e98b803b,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-cee58844-23bd-4547-91eb-f8c912562d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-9a93972b-7d64-4544-a7cc-e8b4152c4710,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-e90b9f4e-4a3e-4bec-9125-3bc010f0b851,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-e629dbdb-c899-4687-9b3a-9b91a10c3d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-37fd7fbc-4788-4d41-af1e-6a17ab7ced88,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-a8fd2b98-478e-42f9-855e-e13180199e4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133787912-172.17.0.7-1595591405101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37865,DS-8e567497-9343-493f-a589-1d68396c88de,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-cf66dff8-0517-488c-a2de-8ef34685066e,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-18432945-dd6e-4e88-92db-382e82d5f17c,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-578e0ff9-0a8f-4199-9544-8ec7c751b003,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-0316874f-b9ca-49eb-8c40-2ea6f4293152,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-342ebe48-4f5f-4149-8723-7a2cc34c30a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-0bbf137f-7387-49cc-9f02-4dec18146079,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-9610b5e3-e790-426e-8c16-a44d61801c05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133787912-172.17.0.7-1595591405101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37865,DS-8e567497-9343-493f-a589-1d68396c88de,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-cf66dff8-0517-488c-a2de-8ef34685066e,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-18432945-dd6e-4e88-92db-382e82d5f17c,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-578e0ff9-0a8f-4199-9544-8ec7c751b003,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-0316874f-b9ca-49eb-8c40-2ea6f4293152,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-342ebe48-4f5f-4149-8723-7a2cc34c30a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-0bbf137f-7387-49cc-9f02-4dec18146079,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-9610b5e3-e790-426e-8c16-a44d61801c05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-61559791-172.17.0.7-1595591817802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34819,DS-54d5677e-bf90-41f6-8838-828008c9e1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-60aecb95-1baf-4dac-acfd-6dd5056a8a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-2ddca83a-9e23-47d5-b9ea-e3740f0f7b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-06e65f6f-d0a3-4492-9b41-7378791dbeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-0005d254-dbbb-4179-93c5-f4c3caf74c98,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-e605dfa9-5e25-4445-aba8-c7ac3163b8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-3bf576e4-de33-4137-b22f-34e5b2d7f1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-dec26ac8-b9df-430d-901f-485aecdb1768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-61559791-172.17.0.7-1595591817802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34819,DS-54d5677e-bf90-41f6-8838-828008c9e1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-60aecb95-1baf-4dac-acfd-6dd5056a8a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-2ddca83a-9e23-47d5-b9ea-e3740f0f7b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-06e65f6f-d0a3-4492-9b41-7378791dbeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-0005d254-dbbb-4179-93c5-f4c3caf74c98,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-e605dfa9-5e25-4445-aba8-c7ac3163b8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-3bf576e4-de33-4137-b22f-34e5b2d7f1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-dec26ac8-b9df-430d-901f-485aecdb1768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582400111-172.17.0.7-1595592587078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41049,DS-b11c350e-5cbe-4fe5-b844-acc1cb37f4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-9b0876bc-a6ea-41e1-a38a-c5c4e758a4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-f227c5b6-5040-42e5-9a24-13fa2c973394,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-10c1414a-2031-4112-8658-2c2f30896773,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-e33a1c02-769c-4e33-9f78-402d06b67600,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-827bfbaa-5a60-4995-921f-caa435fd9906,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-a26fc65b-86ce-4ded-8959-64d94c8b51ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-2796303f-4144-4ff3-88ec-ebad1553ea46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582400111-172.17.0.7-1595592587078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41049,DS-b11c350e-5cbe-4fe5-b844-acc1cb37f4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-9b0876bc-a6ea-41e1-a38a-c5c4e758a4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-f227c5b6-5040-42e5-9a24-13fa2c973394,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-10c1414a-2031-4112-8658-2c2f30896773,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-e33a1c02-769c-4e33-9f78-402d06b67600,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-827bfbaa-5a60-4995-921f-caa435fd9906,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-a26fc65b-86ce-4ded-8959-64d94c8b51ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-2796303f-4144-4ff3-88ec-ebad1553ea46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1918235653-172.17.0.7-1595592622187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43735,DS-1740e3a4-d8e7-4d20-801e-2966815016b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-62b04968-2ba6-4e4d-a1dd-38e1d768a94f,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-c4ecb754-5f8a-462b-b848-53748f1e8536,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-129e7b83-2289-4a00-b98a-76824bad04c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-7538904c-2456-4d06-a25c-1ed075e5af4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-82c80d1f-bf4f-4cbe-8589-43abede44607,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-45186094-ebd9-451b-a5de-a16a9dacb30f,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-128decd2-cb41-484d-bfb5-06c1f01a3943,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1918235653-172.17.0.7-1595592622187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43735,DS-1740e3a4-d8e7-4d20-801e-2966815016b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-62b04968-2ba6-4e4d-a1dd-38e1d768a94f,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-c4ecb754-5f8a-462b-b848-53748f1e8536,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-129e7b83-2289-4a00-b98a-76824bad04c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-7538904c-2456-4d06-a25c-1ed075e5af4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-82c80d1f-bf4f-4cbe-8589-43abede44607,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-45186094-ebd9-451b-a5de-a16a9dacb30f,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-128decd2-cb41-484d-bfb5-06c1f01a3943,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942077292-172.17.0.7-1595592687468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43605,DS-283818c6-d11e-4be3-a41b-11fbb0e7cd20,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-475092cf-0940-4879-9134-6eb988805d17,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-89b4f715-d331-4b9e-9419-3e9297949766,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-c7ff8d9b-4b72-49e9-a0d8-74a5576104ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-96e01b84-0ccb-416a-b9b6-1667939f1009,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-fbec04c7-ddb6-4c85-b94c-987448f544f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-600935e4-149f-4ed1-b7df-039d36c8b225,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-b053fcf9-f5bf-45aa-92d2-7ccbed926d44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942077292-172.17.0.7-1595592687468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43605,DS-283818c6-d11e-4be3-a41b-11fbb0e7cd20,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-475092cf-0940-4879-9134-6eb988805d17,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-89b4f715-d331-4b9e-9419-3e9297949766,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-c7ff8d9b-4b72-49e9-a0d8-74a5576104ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-96e01b84-0ccb-416a-b9b6-1667939f1009,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-fbec04c7-ddb6-4c85-b94c-987448f544f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-600935e4-149f-4ed1-b7df-039d36c8b225,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-b053fcf9-f5bf-45aa-92d2-7ccbed926d44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1716798792-172.17.0.7-1595593516235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40181,DS-956cd0e1-6ef2-445f-99cf-e97d1b18b35e,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-4ad8fcf4-4463-404d-a1a8-082720ff2d14,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-fd1fac46-122d-4da9-8266-b77bfff91a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-e3cd1dad-cd12-4079-b67c-41f2f515cabf,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-2bc3ec3f-0c73-4806-92fb-27a2175cd79a,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-4fdb1cd3-9f19-42a5-ac18-8e92cd026e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-7b88161c-7f20-4c4d-9190-e144f0f1030d,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-09c0eb70-b698-4d43-b3c2-85f9b5a687ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1716798792-172.17.0.7-1595593516235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40181,DS-956cd0e1-6ef2-445f-99cf-e97d1b18b35e,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-4ad8fcf4-4463-404d-a1a8-082720ff2d14,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-fd1fac46-122d-4da9-8266-b77bfff91a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-e3cd1dad-cd12-4079-b67c-41f2f515cabf,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-2bc3ec3f-0c73-4806-92fb-27a2175cd79a,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-4fdb1cd3-9f19-42a5-ac18-8e92cd026e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-7b88161c-7f20-4c4d-9190-e144f0f1030d,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-09c0eb70-b698-4d43-b3c2-85f9b5a687ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758172515-172.17.0.7-1595593696528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33986,DS-fadd1940-2213-4d04-b304-cc6b66993e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-041c9229-981a-4777-bb22-628a7d8e3aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-c7609f92-11e3-45ae-9fbe-075050e3dd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-6a957c03-0eb5-4e4b-9649-26887d590be7,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-4dd33fa3-7a39-41b9-92a3-a91e73cf859b,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-d82a7585-1138-4b14-ae00-4b26c7d647fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-dc29fdc1-2e24-4313-b40f-44b05f3b9a33,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-c909a378-6a3d-4a27-a1da-61a7259dd389,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758172515-172.17.0.7-1595593696528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33986,DS-fadd1940-2213-4d04-b304-cc6b66993e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-041c9229-981a-4777-bb22-628a7d8e3aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-c7609f92-11e3-45ae-9fbe-075050e3dd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-6a957c03-0eb5-4e4b-9649-26887d590be7,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-4dd33fa3-7a39-41b9-92a3-a91e73cf859b,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-d82a7585-1138-4b14-ae00-4b26c7d647fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-dc29fdc1-2e24-4313-b40f-44b05f3b9a33,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-c909a378-6a3d-4a27-a1da-61a7259dd389,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-333852373-172.17.0.7-1595593943453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34483,DS-91fb42f6-8e25-4536-bdad-c67bd9296dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-af6f50d3-f669-4f67-8427-5e6d8edf1a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-1b0e9c31-406d-44f3-9485-347e659f173d,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-e08f5395-04e7-4d57-9ec0-11573b7d184c,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-a2406e70-c29d-481a-aa7e-9a302f0d0eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-af3a8208-be75-407a-9584-935484437f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-57c0d53a-db7c-4529-870a-d72f673eeb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-13013472-2181-4bf5-b8ab-7d5e09c0a5ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-333852373-172.17.0.7-1595593943453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34483,DS-91fb42f6-8e25-4536-bdad-c67bd9296dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-af6f50d3-f669-4f67-8427-5e6d8edf1a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-1b0e9c31-406d-44f3-9485-347e659f173d,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-e08f5395-04e7-4d57-9ec0-11573b7d184c,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-a2406e70-c29d-481a-aa7e-9a302f0d0eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-af3a8208-be75-407a-9584-935484437f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-57c0d53a-db7c-4529-870a-d72f673eeb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-13013472-2181-4bf5-b8ab-7d5e09c0a5ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34438432-172.17.0.7-1595594149281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38030,DS-da0ee59b-6f32-4195-927f-8897ad4a1768,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-16137a24-5937-4f33-9181-c67983fd5b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-869480a2-6f80-48fc-b5cd-e595216c4c81,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-bfb87482-ddb8-4f97-be4c-519daee43e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-c03ad864-b5f5-4460-adf4-b72448936125,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-d528a897-d3e4-446a-9a6b-47850694dafe,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-e1355c4a-35a0-4a37-b753-c11f80d78339,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-2dd879c2-27d2-42c1-b64a-fc3fe6bb86cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34438432-172.17.0.7-1595594149281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38030,DS-da0ee59b-6f32-4195-927f-8897ad4a1768,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-16137a24-5937-4f33-9181-c67983fd5b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-869480a2-6f80-48fc-b5cd-e595216c4c81,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-bfb87482-ddb8-4f97-be4c-519daee43e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-c03ad864-b5f5-4460-adf4-b72448936125,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-d528a897-d3e4-446a-9a6b-47850694dafe,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-e1355c4a-35a0-4a37-b753-c11f80d78339,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-2dd879c2-27d2-42c1-b64a-fc3fe6bb86cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176310718-172.17.0.7-1595594290828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41918,DS-80eb5b32-935c-48b5-929c-779325535fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-805e0427-812c-46bb-ae38-b9512064ea69,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-570943cd-be46-442e-8913-5b43c4a8197c,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-4b663c7d-b2dc-401d-a71f-b5e61cf6f6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-78152eb1-32c5-4d4b-9812-386638d3765e,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-5b17f902-ea79-4607-91cc-185adda89d39,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-b7db633b-ebab-46a8-a29e-b73dcc1ddbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-6b834a73-b135-4a8d-83a1-9a197b181b20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176310718-172.17.0.7-1595594290828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41918,DS-80eb5b32-935c-48b5-929c-779325535fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-805e0427-812c-46bb-ae38-b9512064ea69,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-570943cd-be46-442e-8913-5b43c4a8197c,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-4b663c7d-b2dc-401d-a71f-b5e61cf6f6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-78152eb1-32c5-4d4b-9812-386638d3765e,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-5b17f902-ea79-4607-91cc-185adda89d39,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-b7db633b-ebab-46a8-a29e-b73dcc1ddbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-6b834a73-b135-4a8d-83a1-9a197b181b20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560299294-172.17.0.7-1595594325805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36817,DS-52652e54-af05-4be7-9da7-fc05da7bfb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-f4f0236f-4461-487b-afc3-a436da8c7830,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-ae9ec9d7-60d1-4718-882f-fe32f75793aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-75c0948d-8ce5-4d98-aabf-5c56f43f97bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-b7d2e39a-9a46-40b2-9808-8b740764158b,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-cd78b04f-9e7d-4ee6-a574-63fd42e5c614,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-033d22d0-14db-4016-a103-0c2f81bd03ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-2b0721e0-140b-4636-81b1-372245eb174b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560299294-172.17.0.7-1595594325805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36817,DS-52652e54-af05-4be7-9da7-fc05da7bfb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-f4f0236f-4461-487b-afc3-a436da8c7830,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-ae9ec9d7-60d1-4718-882f-fe32f75793aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-75c0948d-8ce5-4d98-aabf-5c56f43f97bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-b7d2e39a-9a46-40b2-9808-8b740764158b,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-cd78b04f-9e7d-4ee6-a574-63fd42e5c614,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-033d22d0-14db-4016-a103-0c2f81bd03ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-2b0721e0-140b-4636-81b1-372245eb174b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440179086-172.17.0.7-1595594390354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43757,DS-a0ccb8b0-cca6-4e10-8f18-d3fc16045ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-4830fed1-f4aa-418f-920f-8b8998163b95,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-83cf7ba6-e69e-492e-894f-f7844c7d4a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-450c1ea5-57dd-4bfc-bd7b-85dfe96dc68d,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-7920b00f-2132-4743-a9e8-8c0f281ddb29,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-246c2e61-ad69-4791-9d1d-9b3fe9e691d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-8b01d4d4-8e3a-4bf0-ad3e-23cad5aa276e,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-5f626561-8eb2-40c7-81f5-4e6bce14c082,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440179086-172.17.0.7-1595594390354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43757,DS-a0ccb8b0-cca6-4e10-8f18-d3fc16045ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-4830fed1-f4aa-418f-920f-8b8998163b95,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-83cf7ba6-e69e-492e-894f-f7844c7d4a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-450c1ea5-57dd-4bfc-bd7b-85dfe96dc68d,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-7920b00f-2132-4743-a9e8-8c0f281ddb29,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-246c2e61-ad69-4791-9d1d-9b3fe9e691d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-8b01d4d4-8e3a-4bf0-ad3e-23cad5aa276e,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-5f626561-8eb2-40c7-81f5-4e6bce14c082,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471377461-172.17.0.7-1595594456991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33800,DS-70513f3e-903e-4143-a243-447d7c63b8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-2583c366-b573-414c-8b29-6e563735059c,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-7e245b6c-c988-4f56-bea1-ef37d1865bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-e428c898-b9e6-416e-b4d2-9c6bd922aedc,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-924bd0b9-6cc3-4743-8037-034af937563c,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-43c43e36-2e81-452e-affb-2c1d68123cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-f2415170-78f5-43a7-a252-9526f8e3f152,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-3459e6e8-28e6-4e51-a929-c09ba61044e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471377461-172.17.0.7-1595594456991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33800,DS-70513f3e-903e-4143-a243-447d7c63b8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-2583c366-b573-414c-8b29-6e563735059c,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-7e245b6c-c988-4f56-bea1-ef37d1865bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-e428c898-b9e6-416e-b4d2-9c6bd922aedc,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-924bd0b9-6cc3-4743-8037-034af937563c,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-43c43e36-2e81-452e-affb-2c1d68123cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-f2415170-78f5-43a7-a252-9526f8e3f152,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-3459e6e8-28e6-4e51-a929-c09ba61044e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854126149-172.17.0.7-1595594524646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43152,DS-37ddfe45-07d1-4926-8da8-20b6a8559906,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-dd86ca09-6844-45a1-bbfa-f0e8df2b8ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-a74c3ae5-001c-431b-ab28-1de042da4d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-f8a2d5c1-8926-40f5-9fe9-46983f3bc4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-819c8364-3f0c-43c4-81e6-83960184230c,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-98bb0724-3f29-4065-b669-2d23ceff1d89,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-239a8ad6-9b8a-49c0-bf69-b54aaca3c585,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-85c5302e-252d-4009-8720-c78464083d15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854126149-172.17.0.7-1595594524646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43152,DS-37ddfe45-07d1-4926-8da8-20b6a8559906,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-dd86ca09-6844-45a1-bbfa-f0e8df2b8ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-a74c3ae5-001c-431b-ab28-1de042da4d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-f8a2d5c1-8926-40f5-9fe9-46983f3bc4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-819c8364-3f0c-43c4-81e6-83960184230c,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-98bb0724-3f29-4065-b669-2d23ceff1d89,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-239a8ad6-9b8a-49c0-bf69-b54aaca3c585,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-85c5302e-252d-4009-8720-c78464083d15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577145242-172.17.0.7-1595594587043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40139,DS-673980e4-fb41-4d1e-933e-57246ecc6bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-206f8ee4-8e04-43f4-a97b-ced84c034997,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-87fa30e2-8b09-46e9-b7f1-b77bc504143e,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-289d73e7-b016-4b0b-ad06-3f2c0bdbfa82,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-636b6360-9975-4666-a7aa-3a2d1bf3c712,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-39764377-69a3-4ec2-9fd1-945c9b8141a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-29b7d360-2d81-4eed-9429-a676dce83c72,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-211c067f-c50b-4d7d-a93d-8eafcb12f57f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577145242-172.17.0.7-1595594587043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40139,DS-673980e4-fb41-4d1e-933e-57246ecc6bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-206f8ee4-8e04-43f4-a97b-ced84c034997,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-87fa30e2-8b09-46e9-b7f1-b77bc504143e,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-289d73e7-b016-4b0b-ad06-3f2c0bdbfa82,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-636b6360-9975-4666-a7aa-3a2d1bf3c712,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-39764377-69a3-4ec2-9fd1-945c9b8141a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-29b7d360-2d81-4eed-9429-a676dce83c72,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-211c067f-c50b-4d7d-a93d-8eafcb12f57f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-684206663-172.17.0.7-1595594656050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41567,DS-40cae257-8e6c-4bf7-bfae-fa84d9fb7840,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-6976cb69-3a03-4f43-8114-9583fed0974a,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-4667c666-5b95-4257-af3b-c0027e5fff17,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-c2b46b91-c592-4b29-a3ac-5ed975ab9eae,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-5fdf7050-f9a4-44eb-a3b2-cbc9f4453562,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-2d249275-5a18-4213-a9d8-2ebc9999b643,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-5576ff61-06e9-4fa3-91c3-0f266c4b3e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-5d81f4e0-3214-4af0-a5f4-d43466efa5a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-684206663-172.17.0.7-1595594656050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41567,DS-40cae257-8e6c-4bf7-bfae-fa84d9fb7840,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-6976cb69-3a03-4f43-8114-9583fed0974a,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-4667c666-5b95-4257-af3b-c0027e5fff17,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-c2b46b91-c592-4b29-a3ac-5ed975ab9eae,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-5fdf7050-f9a4-44eb-a3b2-cbc9f4453562,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-2d249275-5a18-4213-a9d8-2ebc9999b643,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-5576ff61-06e9-4fa3-91c3-0f266c4b3e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-5d81f4e0-3214-4af0-a5f4-d43466efa5a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1300909047-172.17.0.7-1595595003469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45218,DS-cb43106f-d12e-4a50-8297-9372ed90ff47,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-e6b18e6a-edb4-4d4c-a602-23c68fe31777,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-c47a6281-e9ce-4198-981a-d5cb51934171,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-45321906-5ae3-4d38-ac5f-7caf5f200a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-375384e5-0c7f-425b-b41d-8080abd3848a,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-6f0c679a-658b-4811-8aac-77e5ce91a4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-fb7c8072-fc9a-497c-b4fe-d936598660a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-378ac871-2097-4ef0-9cbc-343b1fc382ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1300909047-172.17.0.7-1595595003469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45218,DS-cb43106f-d12e-4a50-8297-9372ed90ff47,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-e6b18e6a-edb4-4d4c-a602-23c68fe31777,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-c47a6281-e9ce-4198-981a-d5cb51934171,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-45321906-5ae3-4d38-ac5f-7caf5f200a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-375384e5-0c7f-425b-b41d-8080abd3848a,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-6f0c679a-658b-4811-8aac-77e5ce91a4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-fb7c8072-fc9a-497c-b4fe-d936598660a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-378ac871-2097-4ef0-9cbc-343b1fc382ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5121
