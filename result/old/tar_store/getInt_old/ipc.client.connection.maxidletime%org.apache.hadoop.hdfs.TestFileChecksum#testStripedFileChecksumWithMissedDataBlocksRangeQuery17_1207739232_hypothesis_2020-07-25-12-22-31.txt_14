reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994109745-172.17.0.21-1595679978650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34668,DS-8b4f3227-247c-458a-ab83-52e968ec05ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-04c83c04-23bc-4a59-8624-83e12568845d,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-1fa9aa37-6eb5-4394-8b8c-8e43717a6391,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-a26d3ff2-b995-494d-ae96-1e0f8b9f5392,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-3b2e6363-cfd5-4bbf-bb82-16ad7228e8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-8b51a215-2a60-4e95-a172-367de746d522,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-9e4661a6-6588-46fb-9ca5-b291bebf6e64,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-d5d5b489-080b-479e-aa5f-4635e433564c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994109745-172.17.0.21-1595679978650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34668,DS-8b4f3227-247c-458a-ab83-52e968ec05ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-04c83c04-23bc-4a59-8624-83e12568845d,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-1fa9aa37-6eb5-4394-8b8c-8e43717a6391,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-a26d3ff2-b995-494d-ae96-1e0f8b9f5392,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-3b2e6363-cfd5-4bbf-bb82-16ad7228e8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-8b51a215-2a60-4e95-a172-367de746d522,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-9e4661a6-6588-46fb-9ca5-b291bebf6e64,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-d5d5b489-080b-479e-aa5f-4635e433564c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-672522416-172.17.0.21-1595680170186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39180,DS-0f6ba8c6-f47c-4d96-bf7d-949de7ee73bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-9cc97ec8-db19-4b81-b1dd-316f40cf5cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-701c2438-f609-4c4e-b127-44801dbc4b22,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-e1bb6a10-57b1-4277-b60d-c20595bcfec5,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-8980174c-5777-4047-96ae-422f76b547a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-f43c5feb-11c9-4cb2-a966-d80ae4871952,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-445353f5-39e3-44cd-8e22-ba98ce4eb286,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-5cfdd62e-f163-47a3-80d6-b7ca566fe199,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-672522416-172.17.0.21-1595680170186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39180,DS-0f6ba8c6-f47c-4d96-bf7d-949de7ee73bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-9cc97ec8-db19-4b81-b1dd-316f40cf5cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-701c2438-f609-4c4e-b127-44801dbc4b22,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-e1bb6a10-57b1-4277-b60d-c20595bcfec5,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-8980174c-5777-4047-96ae-422f76b547a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-f43c5feb-11c9-4cb2-a966-d80ae4871952,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-445353f5-39e3-44cd-8e22-ba98ce4eb286,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-5cfdd62e-f163-47a3-80d6-b7ca566fe199,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1671854145-172.17.0.21-1595680264794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37378,DS-c68c2a5b-033d-408a-85a0-777bb73697b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-f8f30ab6-df56-410b-bd3e-e50c24ebfbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-79900220-69d6-4e5f-ae7b-72a3e20c3888,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-70a0fd80-7ec5-4ecb-9a63-c6f29a1ff130,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-8eda50e5-3cac-48b4-935c-c51ff580455e,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-2a946b47-871e-415c-9c92-3d8fd12f8905,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-77794505-e8b9-4d36-ac4a-8f1320c26f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-67bf801b-28e0-405e-99dd-1bdc16dfa340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1671854145-172.17.0.21-1595680264794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37378,DS-c68c2a5b-033d-408a-85a0-777bb73697b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-f8f30ab6-df56-410b-bd3e-e50c24ebfbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-79900220-69d6-4e5f-ae7b-72a3e20c3888,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-70a0fd80-7ec5-4ecb-9a63-c6f29a1ff130,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-8eda50e5-3cac-48b4-935c-c51ff580455e,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-2a946b47-871e-415c-9c92-3d8fd12f8905,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-77794505-e8b9-4d36-ac4a-8f1320c26f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-67bf801b-28e0-405e-99dd-1bdc16dfa340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1038124050-172.17.0.21-1595680760150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38365,DS-885ea2bf-6c6d-4cba-8134-7f70ba224086,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-39415ec3-ec98-4b17-ab1d-6caffad83e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-a32eb2e5-8fd8-4443-96bf-dfcac42ea735,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-272cd589-5445-43e9-b07e-b4f1bd8b05cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-771d1d0a-7c18-469d-8c5b-6f96f05a5d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-cdd782c3-9582-4eca-8403-b375144798e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-2bf339d9-5f13-4058-9d30-4964c386f391,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-c663af2a-5537-4e85-8d2a-4255ddb1be0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1038124050-172.17.0.21-1595680760150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38365,DS-885ea2bf-6c6d-4cba-8134-7f70ba224086,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-39415ec3-ec98-4b17-ab1d-6caffad83e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-a32eb2e5-8fd8-4443-96bf-dfcac42ea735,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-272cd589-5445-43e9-b07e-b4f1bd8b05cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-771d1d0a-7c18-469d-8c5b-6f96f05a5d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-cdd782c3-9582-4eca-8403-b375144798e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-2bf339d9-5f13-4058-9d30-4964c386f391,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-c663af2a-5537-4e85-8d2a-4255ddb1be0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-105482876-172.17.0.21-1595680957739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46384,DS-2de7177e-7b7c-46ae-ae4a-557ae7ed83a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-37036554-4d5f-4cd5-aae4-7047aebf5bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-cf625bde-0e06-4b08-b762-b06c4df97129,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-f613fee1-ad28-40e4-8324-c11b4d462c84,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-975c74f7-800d-4829-9692-a81975044737,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-d689e462-b466-4e3a-95b3-112d70d6cfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-941a66ac-b731-40d4-90b6-d4ad2c4d004d,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-9642a160-69bb-4d73-bf5f-c88e93f49626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-105482876-172.17.0.21-1595680957739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46384,DS-2de7177e-7b7c-46ae-ae4a-557ae7ed83a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-37036554-4d5f-4cd5-aae4-7047aebf5bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-cf625bde-0e06-4b08-b762-b06c4df97129,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-f613fee1-ad28-40e4-8324-c11b4d462c84,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-975c74f7-800d-4829-9692-a81975044737,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-d689e462-b466-4e3a-95b3-112d70d6cfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-941a66ac-b731-40d4-90b6-d4ad2c4d004d,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-9642a160-69bb-4d73-bf5f-c88e93f49626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1696111956-172.17.0.21-1595681492538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33757,DS-93bc8871-bd9d-41f2-aeb1-43df737f035a,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-24c352a0-951c-4d02-bb48-bbbf2a7c2645,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-8210187a-cab5-41ea-b0c0-0c989ba0569d,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-fdb4503d-18c7-4a43-ae73-836b61fde201,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-237bd73c-f96d-4d6a-b252-4f46421deae2,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-0080843b-1bec-48cc-8847-319b21c28e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-1e37c8e5-89c2-4294-81f1-efea56e4529e,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-4e3cd257-f356-4424-97f9-9e7391ae57cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1696111956-172.17.0.21-1595681492538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33757,DS-93bc8871-bd9d-41f2-aeb1-43df737f035a,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-24c352a0-951c-4d02-bb48-bbbf2a7c2645,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-8210187a-cab5-41ea-b0c0-0c989ba0569d,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-fdb4503d-18c7-4a43-ae73-836b61fde201,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-237bd73c-f96d-4d6a-b252-4f46421deae2,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-0080843b-1bec-48cc-8847-319b21c28e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-1e37c8e5-89c2-4294-81f1-efea56e4529e,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-4e3cd257-f356-4424-97f9-9e7391ae57cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1211146047-172.17.0.21-1595681623832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34188,DS-498766d1-727c-45c2-92fc-7c14ca85c7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-c0f71117-6429-4eaf-a1ee-3d36882ca161,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-cfd34050-0194-49fe-957d-e9b947853e53,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-0728f9d7-9884-4248-acf5-10ec04d43812,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-c5018468-87ef-44f4-9f3f-538caca634cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-b47761a5-624d-4320-a645-0248957bddc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-c5e311c8-81d0-4dc4-b2a4-2487dbb6816c,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-d1ceb9e0-eb3e-46eb-99eb-d23ed57abbef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1211146047-172.17.0.21-1595681623832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34188,DS-498766d1-727c-45c2-92fc-7c14ca85c7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-c0f71117-6429-4eaf-a1ee-3d36882ca161,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-cfd34050-0194-49fe-957d-e9b947853e53,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-0728f9d7-9884-4248-acf5-10ec04d43812,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-c5018468-87ef-44f4-9f3f-538caca634cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-b47761a5-624d-4320-a645-0248957bddc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-c5e311c8-81d0-4dc4-b2a4-2487dbb6816c,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-d1ceb9e0-eb3e-46eb-99eb-d23ed57abbef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957010402-172.17.0.21-1595681836488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36367,DS-f590bb72-f66e-47ba-ba9d-16f57cc99864,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-5b15aafd-7f2e-4e7b-af68-177a4bb09991,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-5dfe4cf9-d48e-48f1-8102-074e1edf35f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-f6042305-a1ca-49d6-a1a5-4840e02eac98,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-0176e3b2-c0cf-49db-86e9-2d77c5bf313d,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-3dce6872-f50c-495b-86e8-c664c874e766,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-d4bbf418-b15b-4866-bd63-aa2af233ec32,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-b3f13c1f-b4bc-4d68-af51-911d729a96ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957010402-172.17.0.21-1595681836488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36367,DS-f590bb72-f66e-47ba-ba9d-16f57cc99864,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-5b15aafd-7f2e-4e7b-af68-177a4bb09991,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-5dfe4cf9-d48e-48f1-8102-074e1edf35f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-f6042305-a1ca-49d6-a1a5-4840e02eac98,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-0176e3b2-c0cf-49db-86e9-2d77c5bf313d,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-3dce6872-f50c-495b-86e8-c664c874e766,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-d4bbf418-b15b-4866-bd63-aa2af233ec32,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-b3f13c1f-b4bc-4d68-af51-911d729a96ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1767017430-172.17.0.21-1595682456024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43717,DS-98f76dd7-1aa5-427b-a694-5bbc0e2c5c27,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-578ac656-bbf2-4685-b5c6-13c561882224,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-3b05ca5b-3553-4ada-b359-85ce11b8f8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-8f6527ca-0b92-4939-9494-7c5f3c5dfde4,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-7e4c24b6-889d-48f8-aade-5bc0068f17e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-4f4622c5-5201-4f93-b575-f340a26fb899,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-1526e803-ce78-4883-b91c-68666b413e18,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-8f81b43b-12b3-48c9-b1a7-4be780399b60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1767017430-172.17.0.21-1595682456024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43717,DS-98f76dd7-1aa5-427b-a694-5bbc0e2c5c27,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-578ac656-bbf2-4685-b5c6-13c561882224,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-3b05ca5b-3553-4ada-b359-85ce11b8f8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-8f6527ca-0b92-4939-9494-7c5f3c5dfde4,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-7e4c24b6-889d-48f8-aade-5bc0068f17e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-4f4622c5-5201-4f93-b575-f340a26fb899,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-1526e803-ce78-4883-b91c-68666b413e18,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-8f81b43b-12b3-48c9-b1a7-4be780399b60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-240249002-172.17.0.21-1595682619497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36611,DS-624d8a23-3abf-4226-b459-44709019a0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-30331aaa-a0a8-4e97-829b-bd223c63be5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-0153288c-bea9-46d5-af33-6faff36a49b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-dd5aabbc-70d9-4fee-bf13-af887563592b,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-f0be3dbd-3a36-4ab6-8bee-7a1773698623,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-4f192c4f-431c-499c-ac3f-ce804344a355,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-82577969-1177-4917-a330-a74b13aafbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-c475ac30-9c2f-4de0-ae60-3f22f18e01eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-240249002-172.17.0.21-1595682619497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36611,DS-624d8a23-3abf-4226-b459-44709019a0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-30331aaa-a0a8-4e97-829b-bd223c63be5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-0153288c-bea9-46d5-af33-6faff36a49b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-dd5aabbc-70d9-4fee-bf13-af887563592b,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-f0be3dbd-3a36-4ab6-8bee-7a1773698623,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-4f192c4f-431c-499c-ac3f-ce804344a355,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-82577969-1177-4917-a330-a74b13aafbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-c475ac30-9c2f-4de0-ae60-3f22f18e01eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1912196518-172.17.0.21-1595683750036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39957,DS-01daa0c0-90e6-4eb6-82c4-fb2d5c9a7019,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-f1f64eb1-1563-4b1e-8950-8ae29fbe6585,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-1d75bf51-2422-498c-8d56-97e0d49d35a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-1f3252d3-9fd3-42df-b5a0-ca2a13f707bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-21305ff7-e5d7-40c8-b9b7-32a247bc1296,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-ffaf75a8-507a-4316-9103-b41697154327,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-ec6198c3-5e7f-41d6-ac8a-850470f2b9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-1ef34439-42a6-4e1b-9bcc-9ba4498ca28a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1912196518-172.17.0.21-1595683750036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39957,DS-01daa0c0-90e6-4eb6-82c4-fb2d5c9a7019,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-f1f64eb1-1563-4b1e-8950-8ae29fbe6585,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-1d75bf51-2422-498c-8d56-97e0d49d35a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-1f3252d3-9fd3-42df-b5a0-ca2a13f707bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-21305ff7-e5d7-40c8-b9b7-32a247bc1296,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-ffaf75a8-507a-4316-9103-b41697154327,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-ec6198c3-5e7f-41d6-ac8a-850470f2b9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-1ef34439-42a6-4e1b-9bcc-9ba4498ca28a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-145716339-172.17.0.21-1595683818775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37099,DS-9980c21b-265d-4990-ac90-5caadfd68abd,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-54368ecb-e0ad-4bcb-9f88-3248cc0c08a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-0d906039-2ec6-4026-a524-bf759226d754,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-2a48423b-5186-498d-b037-3c3c4be870b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-cdbb8904-3229-48e2-ad23-203628a41c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-0b0ca7c5-9d5f-4fee-b531-4e6b6450f0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-a50273fd-c267-4d93-9877-3ffa7152fbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-b2b230ba-a9d9-4e84-9180-be15debb581a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-145716339-172.17.0.21-1595683818775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37099,DS-9980c21b-265d-4990-ac90-5caadfd68abd,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-54368ecb-e0ad-4bcb-9f88-3248cc0c08a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-0d906039-2ec6-4026-a524-bf759226d754,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-2a48423b-5186-498d-b037-3c3c4be870b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-cdbb8904-3229-48e2-ad23-203628a41c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-0b0ca7c5-9d5f-4fee-b531-4e6b6450f0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-a50273fd-c267-4d93-9877-3ffa7152fbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-b2b230ba-a9d9-4e84-9180-be15debb581a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-864122139-172.17.0.21-1595683919498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42353,DS-8ab91620-0583-4b6e-a67c-4bda704fcd64,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-a1083167-d5aa-428c-8f5a-528189425807,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-042b32fe-8637-4c7d-8552-d1f937d79485,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-c981ac7b-4658-4733-92cb-317cbbe6cc41,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-74e611c6-b2e9-4c07-8f44-f07086befc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-482de1b7-1745-4122-8a3f-4fb23aef3dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-9104af83-b9b5-4294-ad20-8f3137d5ef67,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-3d908853-92d1-4578-bc34-2e2596aaffc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-864122139-172.17.0.21-1595683919498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42353,DS-8ab91620-0583-4b6e-a67c-4bda704fcd64,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-a1083167-d5aa-428c-8f5a-528189425807,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-042b32fe-8637-4c7d-8552-d1f937d79485,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-c981ac7b-4658-4733-92cb-317cbbe6cc41,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-74e611c6-b2e9-4c07-8f44-f07086befc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-482de1b7-1745-4122-8a3f-4fb23aef3dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-9104af83-b9b5-4294-ad20-8f3137d5ef67,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-3d908853-92d1-4578-bc34-2e2596aaffc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1412660185-172.17.0.21-1595683949331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37175,DS-e8c9266a-6db0-4600-9c31-862248c72033,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-a60e0ea9-09c2-4994-9b0f-58f5b0bd49cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-c1332593-59ed-4af0-9edf-b5423d2abf72,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-279648d5-bb2a-493b-8c1b-2be7cfb70831,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-dfab4d19-6f4e-45f6-b3d7-1fbb0f0ee7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-1c9dba23-479a-413d-9239-63a90f3ae2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-e26017a0-e8a7-4434-8719-2ed200f96d58,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-65227397-c154-468f-9f7d-7fce00326e17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1412660185-172.17.0.21-1595683949331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37175,DS-e8c9266a-6db0-4600-9c31-862248c72033,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-a60e0ea9-09c2-4994-9b0f-58f5b0bd49cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-c1332593-59ed-4af0-9edf-b5423d2abf72,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-279648d5-bb2a-493b-8c1b-2be7cfb70831,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-dfab4d19-6f4e-45f6-b3d7-1fbb0f0ee7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-1c9dba23-479a-413d-9239-63a90f3ae2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-e26017a0-e8a7-4434-8719-2ed200f96d58,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-65227397-c154-468f-9f7d-7fce00326e17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-96720354-172.17.0.21-1595684080396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43914,DS-a87f0424-444b-4a95-8a19-8450693bd84b,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-80112ac4-7ea5-48ec-9535-aede28feec4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-080440e6-815d-4630-86ac-f0144d0514c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-91dd1429-6165-4c8b-af1b-306ab634cfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-8a640b49-4a7a-4f5d-94e8-cbeb3741924b,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-acea01b5-5de6-4d7e-b004-99cd06168b44,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-fcd41dbd-bde7-4cf0-ac38-cf9153bb2143,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-44ebd670-a4a9-418c-ba81-051a60ac1df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-96720354-172.17.0.21-1595684080396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43914,DS-a87f0424-444b-4a95-8a19-8450693bd84b,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-80112ac4-7ea5-48ec-9535-aede28feec4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-080440e6-815d-4630-86ac-f0144d0514c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-91dd1429-6165-4c8b-af1b-306ab634cfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-8a640b49-4a7a-4f5d-94e8-cbeb3741924b,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-acea01b5-5de6-4d7e-b004-99cd06168b44,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-fcd41dbd-bde7-4cf0-ac38-cf9153bb2143,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-44ebd670-a4a9-418c-ba81-051a60ac1df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676464886-172.17.0.21-1595684178988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33514,DS-4d77aa4f-9150-48d2-972b-7ff3b7a2c2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-9d2816be-d599-421c-87e7-575840028156,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-74904e26-46c1-4056-b467-cc2377f7bcf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-082939a9-af37-451f-9a57-c4d37a73c44a,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-b7783a2c-03e6-4875-8099-12975a33ce94,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-cfe2afbc-b9bb-4634-8cfe-e4630a9fd776,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-e48a77f9-0800-41c8-be76-d4cb4a1d88f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-3aa6130c-1129-4d77-9b6f-847d74086cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676464886-172.17.0.21-1595684178988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33514,DS-4d77aa4f-9150-48d2-972b-7ff3b7a2c2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-9d2816be-d599-421c-87e7-575840028156,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-74904e26-46c1-4056-b467-cc2377f7bcf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-082939a9-af37-451f-9a57-c4d37a73c44a,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-b7783a2c-03e6-4875-8099-12975a33ce94,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-cfe2afbc-b9bb-4634-8cfe-e4630a9fd776,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-e48a77f9-0800-41c8-be76-d4cb4a1d88f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-3aa6130c-1129-4d77-9b6f-847d74086cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-763232645-172.17.0.21-1595684484627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46215,DS-19c43618-cc48-45ca-ab45-adfa283a9ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-a383c7a7-10a4-4727-a1b4-9843dbb61eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-520f51bb-7cd5-476a-91bb-9c9aeac7bbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-f7a6db16-3582-4c7c-ba51-ed72ec4ce196,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-de78a54f-a7fa-4832-abcb-2a5f05c9228b,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-301ce1cd-7ea5-4de2-8b12-c74edd24c28f,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-00157630-b5dc-42a0-9297-356c92a9ffe2,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-9895f463-f28c-44ee-98cd-e60e5bd1c9b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-763232645-172.17.0.21-1595684484627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46215,DS-19c43618-cc48-45ca-ab45-adfa283a9ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-a383c7a7-10a4-4727-a1b4-9843dbb61eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-520f51bb-7cd5-476a-91bb-9c9aeac7bbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-f7a6db16-3582-4c7c-ba51-ed72ec4ce196,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-de78a54f-a7fa-4832-abcb-2a5f05c9228b,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-301ce1cd-7ea5-4de2-8b12-c74edd24c28f,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-00157630-b5dc-42a0-9297-356c92a9ffe2,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-9895f463-f28c-44ee-98cd-e60e5bd1c9b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1356545973-172.17.0.21-1595684582247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33249,DS-f15314f8-ed81-4348-b03a-3930ca3cb904,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-185717ca-ae62-48d8-88c0-2ac46ab9aba9,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-28731690-65fc-490d-8a8d-58216628d670,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-aebb78f7-7242-48d2-80f0-2ab16b8db3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-080ea20e-97f5-4e62-ba7b-3fd8e98d3bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-b67f7b8a-e979-444c-8741-c9a8b9e63966,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-42634b4e-ae47-4f99-8285-193c563a6bba,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-ea76223f-a860-4f61-8189-24b0e347c49d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1356545973-172.17.0.21-1595684582247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33249,DS-f15314f8-ed81-4348-b03a-3930ca3cb904,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-185717ca-ae62-48d8-88c0-2ac46ab9aba9,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-28731690-65fc-490d-8a8d-58216628d670,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-aebb78f7-7242-48d2-80f0-2ab16b8db3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-080ea20e-97f5-4e62-ba7b-3fd8e98d3bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-b67f7b8a-e979-444c-8741-c9a8b9e63966,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-42634b4e-ae47-4f99-8285-193c563a6bba,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-ea76223f-a860-4f61-8189-24b0e347c49d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331618578-172.17.0.21-1595684683827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44574,DS-3df882cb-52ff-40d9-96e7-162276153a97,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-18ba3c46-e904-420b-93f6-6c3a3e3cb9af,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-82406cea-1348-482d-96f6-d692b240987a,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-7830ec20-f513-4e6e-a2d9-76b05232d9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-1d6ba020-19e2-4701-868e-08ae0563d874,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-71e890eb-97d6-4035-8c61-20374a68072d,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-bb1c6c8c-e284-424e-9c3e-db8d952cf23e,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-d8851ba5-8ed5-4725-8dc7-4b0f6cf5c587,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331618578-172.17.0.21-1595684683827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44574,DS-3df882cb-52ff-40d9-96e7-162276153a97,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-18ba3c46-e904-420b-93f6-6c3a3e3cb9af,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-82406cea-1348-482d-96f6-d692b240987a,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-7830ec20-f513-4e6e-a2d9-76b05232d9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-1d6ba020-19e2-4701-868e-08ae0563d874,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-71e890eb-97d6-4035-8c61-20374a68072d,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-bb1c6c8c-e284-424e-9c3e-db8d952cf23e,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-d8851ba5-8ed5-4725-8dc7-4b0f6cf5c587,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: might be true error
Total execution time in seconds : 5014
