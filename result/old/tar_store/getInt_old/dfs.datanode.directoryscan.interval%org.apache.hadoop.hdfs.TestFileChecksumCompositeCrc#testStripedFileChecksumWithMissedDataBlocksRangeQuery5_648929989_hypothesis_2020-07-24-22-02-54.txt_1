reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323486114-172.17.0.2-1595628584235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44799,DS-f6fe3cc6-a3be-4b4e-92fc-a75d88d539c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-0af50be8-2e91-490c-ae60-1c6c0df9d63e,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-882b7c62-5008-4839-878a-820bafe37ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-15802843-746c-42c2-856f-b680a1798192,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-b893e930-aa5a-47b1-b9d1-f0a684ca35a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-866192a1-d6de-4859-b9d1-0133303e68d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-6783e953-984d-4a7f-84ee-da7df4fd0f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-e471f1c1-9d4a-4713-93fa-7a2a99363f30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323486114-172.17.0.2-1595628584235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44799,DS-f6fe3cc6-a3be-4b4e-92fc-a75d88d539c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-0af50be8-2e91-490c-ae60-1c6c0df9d63e,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-882b7c62-5008-4839-878a-820bafe37ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-15802843-746c-42c2-856f-b680a1798192,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-b893e930-aa5a-47b1-b9d1-f0a684ca35a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-866192a1-d6de-4859-b9d1-0133303e68d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-6783e953-984d-4a7f-84ee-da7df4fd0f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-e471f1c1-9d4a-4713-93fa-7a2a99363f30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1925972320-172.17.0.2-1595629500600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34509,DS-f89c4a29-5b77-4f9e-ba7c-4454afb7af1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-9a4abd87-392f-46c3-8247-5eb101981931,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-71aef03f-5499-4c0c-9780-141de1dc6da5,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-ed7ee81b-b6d6-4bb8-8e73-dfff784573d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-0f1f128a-dfcb-47fd-9e01-8af3d5b81719,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-bfc3a071-a25f-4cde-9211-85b4fd84193a,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-790827de-3702-4003-9805-a8782f0bdca4,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-4a8beed0-fbbc-4330-a541-fe3790f4d53f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1925972320-172.17.0.2-1595629500600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34509,DS-f89c4a29-5b77-4f9e-ba7c-4454afb7af1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-9a4abd87-392f-46c3-8247-5eb101981931,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-71aef03f-5499-4c0c-9780-141de1dc6da5,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-ed7ee81b-b6d6-4bb8-8e73-dfff784573d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-0f1f128a-dfcb-47fd-9e01-8af3d5b81719,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-bfc3a071-a25f-4cde-9211-85b4fd84193a,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-790827de-3702-4003-9805-a8782f0bdca4,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-4a8beed0-fbbc-4330-a541-fe3790f4d53f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193342728-172.17.0.2-1595629596097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42494,DS-b614be39-1202-4cd3-b9dc-c07913844412,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-7756693f-79ef-4d5b-b187-8367c58f5471,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-27565821-0edf-4c7a-b9b3-2c43be4a9ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-ba487940-ad25-4b5f-926a-ef087391d261,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-f5659b3b-7e92-40f6-bf7a-b163cd0e1673,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-cc2e6998-cd31-412d-bf13-12c2a657ca25,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-7f99010a-7c4d-4a56-876c-f9df20be9be4,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-f11af36b-04ef-494e-9936-be153a0815b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193342728-172.17.0.2-1595629596097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42494,DS-b614be39-1202-4cd3-b9dc-c07913844412,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-7756693f-79ef-4d5b-b187-8367c58f5471,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-27565821-0edf-4c7a-b9b3-2c43be4a9ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-ba487940-ad25-4b5f-926a-ef087391d261,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-f5659b3b-7e92-40f6-bf7a-b163cd0e1673,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-cc2e6998-cd31-412d-bf13-12c2a657ca25,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-7f99010a-7c4d-4a56-876c-f9df20be9be4,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-f11af36b-04ef-494e-9936-be153a0815b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145231090-172.17.0.2-1595630987968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42521,DS-bff212dd-b86b-4cf8-bd83-259c9076b368,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-8c5c7fdf-1ed4-4145-aaa6-82c6a732a21f,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-6971bba4-c425-484f-ab24-ec744a80df78,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-e5ceab63-01c2-4312-8d1a-68fb53e9550f,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-946d83c7-01d2-49b7-a691-9b0372f2e74b,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-80fb4882-04ed-4c92-b650-262c6fe75748,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-bf0d28d6-f1e2-4112-af44-f4aababf1077,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-f252b79c-b157-4af1-a0d2-68c9c0e68c7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145231090-172.17.0.2-1595630987968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42521,DS-bff212dd-b86b-4cf8-bd83-259c9076b368,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-8c5c7fdf-1ed4-4145-aaa6-82c6a732a21f,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-6971bba4-c425-484f-ab24-ec744a80df78,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-e5ceab63-01c2-4312-8d1a-68fb53e9550f,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-946d83c7-01d2-49b7-a691-9b0372f2e74b,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-80fb4882-04ed-4c92-b650-262c6fe75748,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-bf0d28d6-f1e2-4112-af44-f4aababf1077,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-f252b79c-b157-4af1-a0d2-68c9c0e68c7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137759283-172.17.0.2-1595631071571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36300,DS-5d937aaf-b156-4df9-b6ee-2509c34ab167,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-70f28c74-58f0-4a3d-856f-9fe58f78eafe,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-5d576b8b-9896-45a1-bc3b-b6bf7e5112b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-b26cd1da-ad9d-4607-89d5-148f70a2f90f,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-98e517a8-5801-415e-aead-946c0ee194d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-573ba822-51cf-429a-95bb-4294a8020931,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-509ae801-9862-448f-8d17-cecc10778dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-8f967772-0372-48b8-8d80-e5f8e367fc94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137759283-172.17.0.2-1595631071571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36300,DS-5d937aaf-b156-4df9-b6ee-2509c34ab167,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-70f28c74-58f0-4a3d-856f-9fe58f78eafe,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-5d576b8b-9896-45a1-bc3b-b6bf7e5112b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-b26cd1da-ad9d-4607-89d5-148f70a2f90f,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-98e517a8-5801-415e-aead-946c0ee194d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-573ba822-51cf-429a-95bb-4294a8020931,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-509ae801-9862-448f-8d17-cecc10778dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-8f967772-0372-48b8-8d80-e5f8e367fc94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318289451-172.17.0.2-1595631412001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41196,DS-348f39a2-72da-4746-8c68-c2ecdebea523,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-1d93f5c9-d49d-4c28-8f8c-27deecec3d00,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-5a6c5456-d6b9-4d34-a242-15c079afcc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-4afce99c-f188-41c4-9465-f3888773e879,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-d82b863c-b0b3-4d13-a4a2-a3da1f3049c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-b61d7ad4-12a8-40fd-9a2e-c615f5daff7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-edd8f67c-370f-4f5a-a04c-ca10680a4d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-fffc0d6e-d649-46ec-a469-194e974313af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318289451-172.17.0.2-1595631412001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41196,DS-348f39a2-72da-4746-8c68-c2ecdebea523,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-1d93f5c9-d49d-4c28-8f8c-27deecec3d00,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-5a6c5456-d6b9-4d34-a242-15c079afcc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-4afce99c-f188-41c4-9465-f3888773e879,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-d82b863c-b0b3-4d13-a4a2-a3da1f3049c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-b61d7ad4-12a8-40fd-9a2e-c615f5daff7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-edd8f67c-370f-4f5a-a04c-ca10680a4d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-fffc0d6e-d649-46ec-a469-194e974313af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012290273-172.17.0.2-1595631677516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44937,DS-561a212a-83b0-4146-93b4-ae370d8ab1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-9c1fb171-5ae0-4268-9f96-525457431022,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-0779dee1-2629-4aca-978a-23c510b8ee1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-49450e44-525b-40c6-9af4-108b1a86419d,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-97e23f61-b387-4a8a-8840-5722ad4550fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-cca267e5-35f1-46db-8ddb-34eaf2764c17,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-2c3dfacd-5ea0-4044-a13f-35dc17b42719,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-55680917-32ea-48ec-8650-3c30bba2db33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012290273-172.17.0.2-1595631677516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44937,DS-561a212a-83b0-4146-93b4-ae370d8ab1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-9c1fb171-5ae0-4268-9f96-525457431022,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-0779dee1-2629-4aca-978a-23c510b8ee1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-49450e44-525b-40c6-9af4-108b1a86419d,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-97e23f61-b387-4a8a-8840-5722ad4550fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-cca267e5-35f1-46db-8ddb-34eaf2764c17,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-2c3dfacd-5ea0-4044-a13f-35dc17b42719,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-55680917-32ea-48ec-8650-3c30bba2db33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-133877063-172.17.0.2-1595632592010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36473,DS-a0742775-e11f-405f-aeed-4d91da85c87a,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-a7b06704-c5b8-41a0-a52a-1d268418b66c,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-fe416d32-55b1-4a89-a429-3aa812a8e8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-59fa2e0e-4174-4cfd-ab1c-45bad372a4af,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-e3377d91-86dc-42a2-b04a-3a7a6bf61580,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-ec4788c5-9c1c-4ee6-9119-3e86b7da2450,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-a6723aa7-af4b-4ded-8e1d-ba2a3c293d56,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-bbde7d96-7c45-4fc8-a6fb-4fc601ef640e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-133877063-172.17.0.2-1595632592010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36473,DS-a0742775-e11f-405f-aeed-4d91da85c87a,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-a7b06704-c5b8-41a0-a52a-1d268418b66c,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-fe416d32-55b1-4a89-a429-3aa812a8e8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-59fa2e0e-4174-4cfd-ab1c-45bad372a4af,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-e3377d91-86dc-42a2-b04a-3a7a6bf61580,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-ec4788c5-9c1c-4ee6-9119-3e86b7da2450,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-a6723aa7-af4b-4ded-8e1d-ba2a3c293d56,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-bbde7d96-7c45-4fc8-a6fb-4fc601ef640e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852260248-172.17.0.2-1595633198240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37458,DS-4f50faab-6727-480a-82f8-69c164538428,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-ebfda76e-8a75-4c92-a0a9-d250f12b6e28,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-0bcb8c56-5b5f-424e-9c6f-c3458736b7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-9a0cdad3-9a33-49c8-8d3e-cc25c0f1780d,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-af091ca0-30cc-4838-9157-074341a79f74,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-ad271361-5739-4c92-9e32-20f656bc15a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-84119bf4-8b99-4db3-83b0-bfa7497446e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-0c6aa953-3f53-4ec3-b400-230971d58f0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852260248-172.17.0.2-1595633198240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37458,DS-4f50faab-6727-480a-82f8-69c164538428,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-ebfda76e-8a75-4c92-a0a9-d250f12b6e28,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-0bcb8c56-5b5f-424e-9c6f-c3458736b7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-9a0cdad3-9a33-49c8-8d3e-cc25c0f1780d,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-af091ca0-30cc-4838-9157-074341a79f74,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-ad271361-5739-4c92-9e32-20f656bc15a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-84119bf4-8b99-4db3-83b0-bfa7497446e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-0c6aa953-3f53-4ec3-b400-230971d58f0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-490540688-172.17.0.2-1595633351888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41206,DS-12615b75-2ff6-4a7e-a248-c87cd23ab12b,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-57a6eaa8-a065-4244-babc-ec5332556b05,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-a7a4a775-1474-49b0-8e5b-0cb5e18eacd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-71556ea6-6dff-451e-8a17-60cc1342c88f,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-541fa29b-d433-4b88-9cf7-c6512e47117a,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-7e94e505-5953-40ab-b653-15d253f2c54b,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-8f6f1074-7028-42e2-9b1c-8616c4150a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-0fea859e-b52b-44e8-b3e1-522c88ebc6fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-490540688-172.17.0.2-1595633351888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41206,DS-12615b75-2ff6-4a7e-a248-c87cd23ab12b,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-57a6eaa8-a065-4244-babc-ec5332556b05,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-a7a4a775-1474-49b0-8e5b-0cb5e18eacd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-71556ea6-6dff-451e-8a17-60cc1342c88f,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-541fa29b-d433-4b88-9cf7-c6512e47117a,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-7e94e505-5953-40ab-b653-15d253f2c54b,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-8f6f1074-7028-42e2-9b1c-8616c4150a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-0fea859e-b52b-44e8-b3e1-522c88ebc6fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230913322-172.17.0.2-1595633599265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37486,DS-2e5063a0-f90f-41ba-be76-4d15955bc357,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-7e390055-081c-42af-934b-ecb437472b26,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-204d50ed-778b-4f50-800e-d850b0118bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-7afd2abe-df69-4417-b66b-8a4efdfdb757,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-049bd0ba-2134-4e6b-871e-5872c471aef1,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-56a0ecb4-841e-4924-9dfc-9a03e2a422a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-9fa7adef-aebd-4bc9-b53f-916cef30f24e,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-609f82a4-1b52-446d-9851-cdb0b8b12a0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230913322-172.17.0.2-1595633599265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37486,DS-2e5063a0-f90f-41ba-be76-4d15955bc357,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-7e390055-081c-42af-934b-ecb437472b26,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-204d50ed-778b-4f50-800e-d850b0118bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-7afd2abe-df69-4417-b66b-8a4efdfdb757,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-049bd0ba-2134-4e6b-871e-5872c471aef1,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-56a0ecb4-841e-4924-9dfc-9a03e2a422a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-9fa7adef-aebd-4bc9-b53f-916cef30f24e,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-609f82a4-1b52-446d-9851-cdb0b8b12a0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2066094255-172.17.0.2-1595633687241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34171,DS-298602f9-86dd-40f2-9f8a-22611f2d6001,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-39e559ae-0374-42f7-bb56-5d0dab9e3bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-d5e0ffc4-28eb-4c91-b87f-92c5bac60925,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-26d5de26-916c-462f-9d47-9724a30ab6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-0b2292a7-04c7-4bff-a639-e9b68d19619b,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-40872c89-ecf7-4efb-8d67-c20e34e1dee3,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-00e0b1f6-52e2-4e7c-a737-9a2452260db0,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-7c2b5bb5-d835-4c1d-81d8-731f04f091f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2066094255-172.17.0.2-1595633687241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34171,DS-298602f9-86dd-40f2-9f8a-22611f2d6001,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-39e559ae-0374-42f7-bb56-5d0dab9e3bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-d5e0ffc4-28eb-4c91-b87f-92c5bac60925,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-26d5de26-916c-462f-9d47-9724a30ab6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-0b2292a7-04c7-4bff-a639-e9b68d19619b,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-40872c89-ecf7-4efb-8d67-c20e34e1dee3,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-00e0b1f6-52e2-4e7c-a737-9a2452260db0,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-7c2b5bb5-d835-4c1d-81d8-731f04f091f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356597982-172.17.0.2-1595634178571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35752,DS-67f78819-2b59-4a6f-86f9-56d114c9750d,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-f9ceb2b5-9b1a-4991-a564-f38b605924b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-90e36ea6-3e53-4579-8a09-f4aa952da68d,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-f6b73a0e-d1bb-4f21-9c11-db3e2ad716cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-c363254c-37b6-4a9c-9fd9-b369c922ab06,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-1d2e5ec2-6c3f-4cfc-a205-edfd6f7eee0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-16f89894-c281-45f1-b4c9-d79f86f8f8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-1f625443-4047-4b07-88cc-632f33d44934,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356597982-172.17.0.2-1595634178571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35752,DS-67f78819-2b59-4a6f-86f9-56d114c9750d,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-f9ceb2b5-9b1a-4991-a564-f38b605924b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-90e36ea6-3e53-4579-8a09-f4aa952da68d,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-f6b73a0e-d1bb-4f21-9c11-db3e2ad716cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-c363254c-37b6-4a9c-9fd9-b369c922ab06,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-1d2e5ec2-6c3f-4cfc-a205-edfd6f7eee0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-16f89894-c281-45f1-b4c9-d79f86f8f8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-1f625443-4047-4b07-88cc-632f33d44934,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 10s
v2: 21600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892386976-172.17.0.2-1595634310007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42656,DS-2f7ac955-076c-427f-ac97-1308b63a659c,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-b25e9192-36e0-453d-9c3d-6abce7653620,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-7b7ffe89-abac-4f87-8ee8-5f75f9321fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-f328333f-57d5-4d02-85bb-eaae3d7c81a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-aab3c9a4-2115-48ea-b381-576f777dab49,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-0eac0f85-41b9-4176-9883-74b2edb1947a,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-16a7ea05-161a-4a6e-8a88-255a24dca733,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-b2253f91-198c-4ba9-b66b-06b5d6ab136e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892386976-172.17.0.2-1595634310007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42656,DS-2f7ac955-076c-427f-ac97-1308b63a659c,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-b25e9192-36e0-453d-9c3d-6abce7653620,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-7b7ffe89-abac-4f87-8ee8-5f75f9321fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-f328333f-57d5-4d02-85bb-eaae3d7c81a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-aab3c9a4-2115-48ea-b381-576f777dab49,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-0eac0f85-41b9-4176-9883-74b2edb1947a,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-16a7ea05-161a-4a6e-8a88-255a24dca733,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-b2253f91-198c-4ba9-b66b-06b5d6ab136e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6787
