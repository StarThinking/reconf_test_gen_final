reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691272943-172.17.0.12-1595530994501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37517,DS-49fa3620-91c4-486a-a802-466d95d05414,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-465085ce-f6f4-45f3-8d2e-4e9c3d1c31ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-4c2ac2c2-6523-425c-a0c3-aec05a3e839c,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-c3440018-c817-45f4-bec5-f19cd01eb64f,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-d5b60126-9a86-4340-82d3-7cff3928259b,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-45d3fb42-ff6f-413e-94ad-d2974f4f69c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-219cbb63-a2d4-4991-bfbe-9685fe34f615,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-d43ac690-6fad-4c01-9e72-a1d8d8b59f0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691272943-172.17.0.12-1595530994501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37517,DS-49fa3620-91c4-486a-a802-466d95d05414,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-465085ce-f6f4-45f3-8d2e-4e9c3d1c31ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-4c2ac2c2-6523-425c-a0c3-aec05a3e839c,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-c3440018-c817-45f4-bec5-f19cd01eb64f,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-d5b60126-9a86-4340-82d3-7cff3928259b,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-45d3fb42-ff6f-413e-94ad-d2974f4f69c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-219cbb63-a2d4-4991-bfbe-9685fe34f615,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-d43ac690-6fad-4c01-9e72-a1d8d8b59f0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1831790722-172.17.0.12-1595531058844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35673,DS-ebc899ea-bf14-4dda-bee4-88c27b4e25a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-6af8b3e5-ddc5-4d86-abcb-aef1e7048235,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-467bbacc-9191-402b-a319-5a69607957d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-a91996bc-b360-48d6-b456-52a53a1fd319,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-35ab8e32-ba6f-4b31-b2df-eff7bef76bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-0573794a-dfee-4759-b0a8-6b058bca5e00,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-1fda486e-ebe3-4cc2-a9e3-83c86bd20532,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-e57f9a8c-59df-496a-a5af-4732d2d87db4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1831790722-172.17.0.12-1595531058844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35673,DS-ebc899ea-bf14-4dda-bee4-88c27b4e25a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-6af8b3e5-ddc5-4d86-abcb-aef1e7048235,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-467bbacc-9191-402b-a319-5a69607957d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-a91996bc-b360-48d6-b456-52a53a1fd319,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-35ab8e32-ba6f-4b31-b2df-eff7bef76bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-0573794a-dfee-4759-b0a8-6b058bca5e00,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-1fda486e-ebe3-4cc2-a9e3-83c86bd20532,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-e57f9a8c-59df-496a-a5af-4732d2d87db4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523968424-172.17.0.12-1595531285759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35456,DS-0f07ad15-b565-49da-83b5-3d2cd4484e09,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-711063c8-c905-4ac6-a879-5c9454e1199e,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-b072c574-cb14-4582-af19-a06424176bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-6f21b89a-510b-4210-87b5-95194a41775e,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-40f8c5e6-ff27-479c-a6ea-b34a726419dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-077a7af4-e7ee-43c8-a041-5679cebb4a27,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-f8098584-e696-429f-a3c9-3b4926df4e19,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-1ef6ca2f-1d7e-4e7d-81fc-67b9213e9169,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523968424-172.17.0.12-1595531285759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35456,DS-0f07ad15-b565-49da-83b5-3d2cd4484e09,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-711063c8-c905-4ac6-a879-5c9454e1199e,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-b072c574-cb14-4582-af19-a06424176bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-6f21b89a-510b-4210-87b5-95194a41775e,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-40f8c5e6-ff27-479c-a6ea-b34a726419dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-077a7af4-e7ee-43c8-a041-5679cebb4a27,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-f8098584-e696-429f-a3c9-3b4926df4e19,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-1ef6ca2f-1d7e-4e7d-81fc-67b9213e9169,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-128229294-172.17.0.12-1595531360693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38022,DS-37c8646b-3308-4687-a73e-07eb15d51077,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-fe8c41ec-0258-413a-beef-cd721bd1e4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-84b752ab-9eec-45db-962c-aab74c64abaf,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-8848fa98-dc07-4f14-bcde-157c5a61500c,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-2cf385a4-a62c-4c64-93e5-36cc5f905c06,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-c6e3c3b7-68dd-4435-a1fc-6ad126578e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-3c9bd9d2-a84d-41ad-b446-f151012b1aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-d42a9386-712a-4b0c-afc7-670b8527bccb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-128229294-172.17.0.12-1595531360693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38022,DS-37c8646b-3308-4687-a73e-07eb15d51077,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-fe8c41ec-0258-413a-beef-cd721bd1e4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-84b752ab-9eec-45db-962c-aab74c64abaf,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-8848fa98-dc07-4f14-bcde-157c5a61500c,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-2cf385a4-a62c-4c64-93e5-36cc5f905c06,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-c6e3c3b7-68dd-4435-a1fc-6ad126578e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-3c9bd9d2-a84d-41ad-b446-f151012b1aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-d42a9386-712a-4b0c-afc7-670b8527bccb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697599915-172.17.0.12-1595531709538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37094,DS-c5f9baa8-783d-4d89-93b8-2d96db309b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-fbbb0147-40ee-4c40-b7d4-30d9ff902d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-e266d14a-d935-42b4-b5a8-8833feea761c,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-50c9db20-a8a2-403c-906e-9e8e1f820f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-5f42be30-0a12-4549-a034-56dc647c09d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-54502d40-fc0a-4a65-ba72-635c6ab7b68d,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-8d823327-0fd4-4775-bd2b-73c1f4b4ab1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-7390f0c9-cfd6-4045-bd07-eec55dd64650,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697599915-172.17.0.12-1595531709538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37094,DS-c5f9baa8-783d-4d89-93b8-2d96db309b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-fbbb0147-40ee-4c40-b7d4-30d9ff902d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-e266d14a-d935-42b4-b5a8-8833feea761c,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-50c9db20-a8a2-403c-906e-9e8e1f820f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-5f42be30-0a12-4549-a034-56dc647c09d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-54502d40-fc0a-4a65-ba72-635c6ab7b68d,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-8d823327-0fd4-4775-bd2b-73c1f4b4ab1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-7390f0c9-cfd6-4045-bd07-eec55dd64650,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349806893-172.17.0.12-1595532381452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35934,DS-bf98fb48-3543-4010-b529-9a4c36a74da1,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-ef1add93-5559-46c8-9a46-e7f5a488736c,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-bba706db-8b45-4fb5-b802-07cd2d490e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-934f9fbd-1299-475f-8014-9328f590866a,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-eace5d06-15c6-4b0a-ab5c-d79a1d900198,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-b0b29efe-5910-4ae2-af60-6f0a3cdac195,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-e70aa513-5170-4ce8-a97a-b11f9ed86bff,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-7e80cca0-e3c8-4eda-ba30-33647218868e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349806893-172.17.0.12-1595532381452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35934,DS-bf98fb48-3543-4010-b529-9a4c36a74da1,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-ef1add93-5559-46c8-9a46-e7f5a488736c,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-bba706db-8b45-4fb5-b802-07cd2d490e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-934f9fbd-1299-475f-8014-9328f590866a,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-eace5d06-15c6-4b0a-ab5c-d79a1d900198,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-b0b29efe-5910-4ae2-af60-6f0a3cdac195,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-e70aa513-5170-4ce8-a97a-b11f9ed86bff,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-7e80cca0-e3c8-4eda-ba30-33647218868e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-746249945-172.17.0.12-1595532532557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36905,DS-10e0a73f-d885-4f13-a1f6-d224eb645e36,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-137c4f51-08de-48eb-9145-707476f42c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-fcbb7c05-83b1-4514-ae27-6bfcc306cd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-d46411a6-5a2e-4a84-bc9b-8f0f43517a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-12616b7a-f4ce-4a5d-a997-cfde5cac4143,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-4e526830-2c7a-4b7f-b066-a586bf0d4902,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-3ea8cf3d-948d-43a3-a062-768c9c17a91e,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-78e7126e-43e7-4816-8064-93c859de3dc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-746249945-172.17.0.12-1595532532557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36905,DS-10e0a73f-d885-4f13-a1f6-d224eb645e36,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-137c4f51-08de-48eb-9145-707476f42c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-fcbb7c05-83b1-4514-ae27-6bfcc306cd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-d46411a6-5a2e-4a84-bc9b-8f0f43517a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-12616b7a-f4ce-4a5d-a997-cfde5cac4143,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-4e526830-2c7a-4b7f-b066-a586bf0d4902,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-3ea8cf3d-948d-43a3-a062-768c9c17a91e,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-78e7126e-43e7-4816-8064-93c859de3dc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154419781-172.17.0.12-1595533246012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39477,DS-50118254-d567-423c-bc84-f01b351c33ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-9ef96b87-a98e-41b8-97df-3151dffeaab5,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-3eec2d88-f05d-4cd4-b26b-ece09d19e2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-dadbf72b-dc75-475f-b86a-3c20c7232d48,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-c7cc0ba3-33cc-453a-ae22-8eb27e1d033a,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-a1c21dc2-3056-4c21-9ac3-ec2dd9b0b566,DISK], DatanodeInfoWithStorage[127.0.0.1:43379,DS-c2c123ca-a4ee-48b0-8ed2-e4af1fb4844c,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-e02f36e5-6f1a-4146-b6c6-0e17b3b9ef4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154419781-172.17.0.12-1595533246012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39477,DS-50118254-d567-423c-bc84-f01b351c33ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-9ef96b87-a98e-41b8-97df-3151dffeaab5,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-3eec2d88-f05d-4cd4-b26b-ece09d19e2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-dadbf72b-dc75-475f-b86a-3c20c7232d48,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-c7cc0ba3-33cc-453a-ae22-8eb27e1d033a,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-a1c21dc2-3056-4c21-9ac3-ec2dd9b0b566,DISK], DatanodeInfoWithStorage[127.0.0.1:43379,DS-c2c123ca-a4ee-48b0-8ed2-e4af1fb4844c,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-e02f36e5-6f1a-4146-b6c6-0e17b3b9ef4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-848862665-172.17.0.12-1595533321548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37875,DS-bb252d47-036f-424e-a643-7ac846f89837,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-77cf6df6-7cbf-4bea-8622-f7594e55810e,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-f025d13f-0e15-4793-a561-0e5596b33ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-f0295f6a-08ba-419e-b70a-09f78340ecc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-58f54838-f9cf-4376-a331-ba2d63b60bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-b0472c02-8167-4937-9dfd-ff221dcc7f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-ab501064-ffea-4f27-8c23-44f8abb78c79,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-c8db3140-8629-42c5-b304-d6a23835638c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-848862665-172.17.0.12-1595533321548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37875,DS-bb252d47-036f-424e-a643-7ac846f89837,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-77cf6df6-7cbf-4bea-8622-f7594e55810e,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-f025d13f-0e15-4793-a561-0e5596b33ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-f0295f6a-08ba-419e-b70a-09f78340ecc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-58f54838-f9cf-4376-a331-ba2d63b60bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-b0472c02-8167-4937-9dfd-ff221dcc7f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-ab501064-ffea-4f27-8c23-44f8abb78c79,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-c8db3140-8629-42c5-b304-d6a23835638c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-176374341-172.17.0.12-1595533560804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36607,DS-f3431c3a-b730-4e41-ac28-a0fc463b3822,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-4cfd09dc-40c8-412f-a33d-08c98be4980a,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-55b75593-2dd3-4fff-9509-ba766687846e,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-8c5beb77-ab87-40eb-a991-fe4fb1f7a5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-934d5cd6-eadc-449f-952e-f0cc5b76800a,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-550feda9-bf21-4313-80da-68c82dbefbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-ce7a87a2-102e-4562-a369-7168aac6e4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-9d9c89d4-d38d-4c71-9e52-9c363bdbff30,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-176374341-172.17.0.12-1595533560804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36607,DS-f3431c3a-b730-4e41-ac28-a0fc463b3822,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-4cfd09dc-40c8-412f-a33d-08c98be4980a,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-55b75593-2dd3-4fff-9509-ba766687846e,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-8c5beb77-ab87-40eb-a991-fe4fb1f7a5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-934d5cd6-eadc-449f-952e-f0cc5b76800a,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-550feda9-bf21-4313-80da-68c82dbefbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-ce7a87a2-102e-4562-a369-7168aac6e4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-9d9c89d4-d38d-4c71-9e52-9c363bdbff30,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-140311207-172.17.0.12-1595533680263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39401,DS-61bea36c-d239-4c83-bc0c-85ac6f0aad82,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-02849677-9978-46dd-b0dd-c6630a245706,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-0064bbe4-5364-4e4c-b4a5-fd2050e32cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-f66b662d-1d27-48d2-80fd-baf3f696b8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-a4387bf9-3bd2-4147-a9e0-31aa47254d39,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-641cd567-ca90-4f8d-a2a1-e844aa8c3de3,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-e7000db4-ce09-424a-9686-56b6dc9c6595,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-de576c45-964f-4a82-88b8-983e5aacb85d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-140311207-172.17.0.12-1595533680263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39401,DS-61bea36c-d239-4c83-bc0c-85ac6f0aad82,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-02849677-9978-46dd-b0dd-c6630a245706,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-0064bbe4-5364-4e4c-b4a5-fd2050e32cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-f66b662d-1d27-48d2-80fd-baf3f696b8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-a4387bf9-3bd2-4147-a9e0-31aa47254d39,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-641cd567-ca90-4f8d-a2a1-e844aa8c3de3,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-e7000db4-ce09-424a-9686-56b6dc9c6595,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-de576c45-964f-4a82-88b8-983e5aacb85d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-458016379-172.17.0.12-1595533837514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36371,DS-3e10a33c-8062-48dc-80eb-3eb5395eca69,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-f44664e3-cbc0-4ad7-9b3a-867ebc4a068b,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-46fca658-3c0e-4fb2-b77c-49a9fafef66d,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-2c6c1082-43ec-4a9c-aa00-dc9d7f875188,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-8e51db97-70ed-4c01-becc-319d4b8085e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-d96503c4-47f6-4a16-b2e9-71cc1c3625b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-3f3ffb40-cb99-4a2f-87a4-d7a5cce70d99,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-834c426a-e2aa-47a5-8b1d-72e1a5924b03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-458016379-172.17.0.12-1595533837514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36371,DS-3e10a33c-8062-48dc-80eb-3eb5395eca69,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-f44664e3-cbc0-4ad7-9b3a-867ebc4a068b,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-46fca658-3c0e-4fb2-b77c-49a9fafef66d,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-2c6c1082-43ec-4a9c-aa00-dc9d7f875188,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-8e51db97-70ed-4c01-becc-319d4b8085e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-d96503c4-47f6-4a16-b2e9-71cc1c3625b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-3f3ffb40-cb99-4a2f-87a4-d7a5cce70d99,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-834c426a-e2aa-47a5-8b1d-72e1a5924b03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-736256653-172.17.0.12-1595534236577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40466,DS-7d5fe56d-a6bd-400b-b6b7-b53812df3050,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-e8ae1324-a884-496b-bcc0-02192351c898,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-7ff84426-c63e-4a0e-841d-19299cb88ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-eef3cd27-c0ca-456d-8e52-c83e45bab9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-680c3251-53a0-43fc-b0cf-a23367cbf028,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-7632c5ab-0ab8-4039-ab44-29faf63cd06d,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-0e59514f-0491-47ff-b6e4-77613f9bf2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-db87f948-51d1-4085-9ed9-34514d0a0f1a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-736256653-172.17.0.12-1595534236577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40466,DS-7d5fe56d-a6bd-400b-b6b7-b53812df3050,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-e8ae1324-a884-496b-bcc0-02192351c898,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-7ff84426-c63e-4a0e-841d-19299cb88ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-eef3cd27-c0ca-456d-8e52-c83e45bab9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-680c3251-53a0-43fc-b0cf-a23367cbf028,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-7632c5ab-0ab8-4039-ab44-29faf63cd06d,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-0e59514f-0491-47ff-b6e4-77613f9bf2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-db87f948-51d1-4085-9ed9-34514d0a0f1a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-447213693-172.17.0.12-1595534295452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42769,DS-8d38f334-f87d-4f2e-b213-1f33a8dbc792,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-1d8dff11-a186-47bb-aa9d-29223a518496,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-4365d743-7cfd-4c11-8c0c-edb05a243cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-e35bf292-390d-45f7-b492-56044b5097d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-70678043-559e-427d-9ea7-b4dbf734fb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-fc369913-a9e8-4f31-a2ef-9cce30befe74,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-d9d04fc0-85c9-4ca4-8c16-a137d8f4fb53,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-f87ca4ec-266f-4c51-bbba-b0accfa66017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-447213693-172.17.0.12-1595534295452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42769,DS-8d38f334-f87d-4f2e-b213-1f33a8dbc792,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-1d8dff11-a186-47bb-aa9d-29223a518496,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-4365d743-7cfd-4c11-8c0c-edb05a243cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-e35bf292-390d-45f7-b492-56044b5097d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-70678043-559e-427d-9ea7-b4dbf734fb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-fc369913-a9e8-4f31-a2ef-9cce30befe74,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-d9d04fc0-85c9-4ca4-8c16-a137d8f4fb53,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-f87ca4ec-266f-4c51-bbba-b0accfa66017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-681895906-172.17.0.12-1595534396008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39001,DS-260ab7d0-fc94-4384-bf08-ea3b55f42f71,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-a6160e3c-9b3b-4374-958f-b10ef3647668,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-b98d98c3-56f2-49f7-8eb9-a6761613962c,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-fb19289f-9e4c-4cd1-aa59-4a50fadf1e39,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-7449da39-ba2b-42ec-adcb-921e88d9b738,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-ae0e149f-2fe3-491e-82f0-e2dae050c207,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-5fe5367c-fdea-4f43-bc28-ca7fd5906d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-b59164bb-80e4-4083-a7c8-a5fcd3281b7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-681895906-172.17.0.12-1595534396008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39001,DS-260ab7d0-fc94-4384-bf08-ea3b55f42f71,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-a6160e3c-9b3b-4374-958f-b10ef3647668,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-b98d98c3-56f2-49f7-8eb9-a6761613962c,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-fb19289f-9e4c-4cd1-aa59-4a50fadf1e39,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-7449da39-ba2b-42ec-adcb-921e88d9b738,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-ae0e149f-2fe3-491e-82f0-e2dae050c207,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-5fe5367c-fdea-4f43-bc28-ca7fd5906d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-b59164bb-80e4-4083-a7c8-a5fcd3281b7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511760019-172.17.0.12-1595534432339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40123,DS-f4c1abda-fa5a-4dee-b4c6-5b19f80c5fca,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-8d9861d7-36ee-419a-8e75-0b0fc4a35bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-71e3f475-837c-47ac-a485-42e0803eb064,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-5eefd02d-6e1d-41d3-8592-7f73a4b927f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-faf379d1-2e6a-4a65-8097-857c5c3eb48f,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-6f3c4aa9-3515-4737-aad3-5530d12e164a,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-49c0b1c9-3091-4368-9c51-ff6ed62934dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-6db99b16-e704-4e1d-8f24-6a942a0d1050,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511760019-172.17.0.12-1595534432339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40123,DS-f4c1abda-fa5a-4dee-b4c6-5b19f80c5fca,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-8d9861d7-36ee-419a-8e75-0b0fc4a35bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-71e3f475-837c-47ac-a485-42e0803eb064,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-5eefd02d-6e1d-41d3-8592-7f73a4b927f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-faf379d1-2e6a-4a65-8097-857c5c3eb48f,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-6f3c4aa9-3515-4737-aad3-5530d12e164a,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-49c0b1c9-3091-4368-9c51-ff6ed62934dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-6db99b16-e704-4e1d-8f24-6a942a0d1050,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-466658667-172.17.0.12-1595534499311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42051,DS-3492e78e-7dae-4536-b979-0e166e6fd3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-89ad347c-82a4-433b-b2c7-f6191b718a15,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-ef85fb63-c8bb-4fea-9f06-947c664e8d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-d9105056-0957-489f-a354-379442edd865,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-6421aa82-b709-466a-86ba-60bfb080896b,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-19294c28-4b03-4ab1-9bbc-81b5c0e77055,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-d416c65e-c61f-4115-96d7-6285e61a4df5,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-bf2e896e-ed70-4dff-a3c6-c5c9fbc36c5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-466658667-172.17.0.12-1595534499311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42051,DS-3492e78e-7dae-4536-b979-0e166e6fd3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-89ad347c-82a4-433b-b2c7-f6191b718a15,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-ef85fb63-c8bb-4fea-9f06-947c664e8d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-d9105056-0957-489f-a354-379442edd865,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-6421aa82-b709-466a-86ba-60bfb080896b,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-19294c28-4b03-4ab1-9bbc-81b5c0e77055,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-d416c65e-c61f-4115-96d7-6285e61a4df5,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-bf2e896e-ed70-4dff-a3c6-c5c9fbc36c5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-890133593-172.17.0.12-1595534868796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36580,DS-f00abfd7-7fcf-4404-94cc-2f5a926e041c,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-5d761b2e-c9de-4cc0-93c5-b13b50829350,DISK], DatanodeInfoWithStorage[127.0.0.1:33514,DS-4afed711-b1c6-4649-b685-0c7daf6bea1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-85bc15c0-ca26-46b0-b4dc-804189472142,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-b39762c9-f478-42ff-b28e-2bf9677c594c,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-c607e000-0c3d-4402-9838-9032f7ba4e74,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-e0ec2afd-6f9f-4658-ac2d-8ec7aea80153,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-44416d0d-dd77-44bd-9235-94d8ec70f8e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-890133593-172.17.0.12-1595534868796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36580,DS-f00abfd7-7fcf-4404-94cc-2f5a926e041c,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-5d761b2e-c9de-4cc0-93c5-b13b50829350,DISK], DatanodeInfoWithStorage[127.0.0.1:33514,DS-4afed711-b1c6-4649-b685-0c7daf6bea1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-85bc15c0-ca26-46b0-b4dc-804189472142,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-b39762c9-f478-42ff-b28e-2bf9677c594c,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-c607e000-0c3d-4402-9838-9032f7ba4e74,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-e0ec2afd-6f9f-4658-ac2d-8ec7aea80153,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-44416d0d-dd77-44bd-9235-94d8ec70f8e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934701139-172.17.0.12-1595534941678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40686,DS-f1481e4c-4615-413e-858e-667997828544,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-fb6bbb94-7d40-4776-bc61-46806c4e213d,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-7c470934-d647-4177-8127-3b7a38e121e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-c48a51d0-7732-4091-8cf7-53f856568c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-20ba0cb2-0840-464c-b907-9565c24cae04,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-0fb934fa-fc3f-47ae-92fe-7b365473f7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-9e47e07c-8052-4340-885c-08c89c103d10,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-d2bbc311-36d6-4a59-867a-8eb4b8981749,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934701139-172.17.0.12-1595534941678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40686,DS-f1481e4c-4615-413e-858e-667997828544,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-fb6bbb94-7d40-4776-bc61-46806c4e213d,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-7c470934-d647-4177-8127-3b7a38e121e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-c48a51d0-7732-4091-8cf7-53f856568c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-20ba0cb2-0840-464c-b907-9565c24cae04,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-0fb934fa-fc3f-47ae-92fe-7b365473f7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-9e47e07c-8052-4340-885c-08c89c103d10,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-d2bbc311-36d6-4a59-867a-8eb4b8981749,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107977654-172.17.0.12-1595534968636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44218,DS-e99935ef-eaad-4683-affe-e11b0a461859,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-4c503a90-3acf-4ab9-955a-d0baa30f0ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-8b0de030-eb03-45ab-b709-7792c3e2d80b,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-dc2d7175-fb64-40bc-918f-26d96702e085,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-271866c2-28c1-4220-b098-6412f3bf8795,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-d905e3f6-f074-4274-af3e-4df587c279aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-df68b313-c8ce-48b2-8ac8-c8d0dc3fb0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-d460cc7d-c291-490c-acce-faff62ff393b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107977654-172.17.0.12-1595534968636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44218,DS-e99935ef-eaad-4683-affe-e11b0a461859,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-4c503a90-3acf-4ab9-955a-d0baa30f0ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-8b0de030-eb03-45ab-b709-7792c3e2d80b,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-dc2d7175-fb64-40bc-918f-26d96702e085,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-271866c2-28c1-4220-b098-6412f3bf8795,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-d905e3f6-f074-4274-af3e-4df587c279aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-df68b313-c8ce-48b2-8ac8-c8d0dc3fb0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-d460cc7d-c291-490c-acce-faff62ff393b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258432185-172.17.0.12-1595535040128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40243,DS-454eeaf4-93de-4351-ba7b-bdfd5c50ea8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-22c63709-7050-4c4d-97d9-3905430e512f,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-aad241e7-fda3-4fbc-8040-1cd593fc8cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-2cf40866-e5bd-4a15-98c2-d7e8474e83ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-3e024a9f-cf25-4d35-83a6-6c41ef45fe83,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-fd69e217-63cd-42ff-a44e-a42acbe120b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-b5e66c49-5113-4bf1-8c2e-cf3745620746,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-0f582eba-ef41-484b-b427-842874d4991f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258432185-172.17.0.12-1595535040128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40243,DS-454eeaf4-93de-4351-ba7b-bdfd5c50ea8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-22c63709-7050-4c4d-97d9-3905430e512f,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-aad241e7-fda3-4fbc-8040-1cd593fc8cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-2cf40866-e5bd-4a15-98c2-d7e8474e83ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-3e024a9f-cf25-4d35-83a6-6c41ef45fe83,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-fd69e217-63cd-42ff-a44e-a42acbe120b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-b5e66c49-5113-4bf1-8c2e-cf3745620746,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-0f582eba-ef41-484b-b427-842874d4991f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1164677280-172.17.0.12-1595535117350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40837,DS-d4930bac-11e4-4c39-8f8c-4a27d7191a65,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-bcc1a498-d0d9-4e2b-946f-7920c2668e71,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-062d9bde-f409-4b49-b153-32a43d2e6ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-6de13cae-c897-4f5c-bddc-a34485f10a80,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-baa368d2-b60c-4eb1-8c41-c72ec56fe757,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-31b4211d-25d6-4e29-95db-6dea25a99c79,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-74ae80f0-d38d-400c-8e5c-cbaa84e661d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-f1881488-0fd7-498f-a576-5ef4fd861e74,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1164677280-172.17.0.12-1595535117350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40837,DS-d4930bac-11e4-4c39-8f8c-4a27d7191a65,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-bcc1a498-d0d9-4e2b-946f-7920c2668e71,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-062d9bde-f409-4b49-b153-32a43d2e6ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-6de13cae-c897-4f5c-bddc-a34485f10a80,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-baa368d2-b60c-4eb1-8c41-c72ec56fe757,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-31b4211d-25d6-4e29-95db-6dea25a99c79,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-74ae80f0-d38d-400c-8e5c-cbaa84e661d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-f1881488-0fd7-498f-a576-5ef4fd861e74,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1858322766-172.17.0.12-1595535375054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44671,DS-b44dfca2-d716-4294-9b91-9cda5e41482d,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-36df2568-6e07-42c9-bf7a-edb30f7d4fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-177aae5e-6cfa-4127-9dec-0e308462ef4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-cf99e280-b5cb-486b-a7e0-9d71c2ca80d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-a3144a16-cb18-4385-a6a0-1d43f19a6b30,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-054d6421-537d-4e60-bd92-34bd57b4f11a,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-d45ef5eb-ef32-418a-86c8-fa8a11061a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-cc0ad962-5907-4c7f-a80d-a048543986d7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1858322766-172.17.0.12-1595535375054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44671,DS-b44dfca2-d716-4294-9b91-9cda5e41482d,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-36df2568-6e07-42c9-bf7a-edb30f7d4fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-177aae5e-6cfa-4127-9dec-0e308462ef4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-cf99e280-b5cb-486b-a7e0-9d71c2ca80d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-a3144a16-cb18-4385-a6a0-1d43f19a6b30,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-054d6421-537d-4e60-bd92-34bd57b4f11a,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-d45ef5eb-ef32-418a-86c8-fa8a11061a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-cc0ad962-5907-4c7f-a80d-a048543986d7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1801769594-172.17.0.12-1595535838970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42148,DS-6148c34e-5796-4a54-abce-10d15fd858d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-f63e6e4a-4a7c-49a4-811b-013e4390bd74,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-37e181d7-9d9d-4384-a851-e8ea7a500c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-2c52f6fd-5636-40d2-bedc-2a06581aabd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-75458c44-253a-49d4-b1df-19cb9a0c94a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-20182d34-e5e2-461e-bfd0-8dbb1b3cacfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-e2ad2a4c-a799-41c8-a72c-2977daec6131,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-ceca204c-43d1-45ad-8459-d1b7477e2076,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1801769594-172.17.0.12-1595535838970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42148,DS-6148c34e-5796-4a54-abce-10d15fd858d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-f63e6e4a-4a7c-49a4-811b-013e4390bd74,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-37e181d7-9d9d-4384-a851-e8ea7a500c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-2c52f6fd-5636-40d2-bedc-2a06581aabd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-75458c44-253a-49d4-b1df-19cb9a0c94a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-20182d34-e5e2-461e-bfd0-8dbb1b3cacfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-e2ad2a4c-a799-41c8-a72c-2977daec6131,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-ceca204c-43d1-45ad-8459-d1b7477e2076,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117315087-172.17.0.12-1595535874333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43484,DS-1997d033-9f91-45cc-9ec9-42f0895e8d25,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-25590dbd-1159-40a3-95c3-8bc4c2e293f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-1fc0619c-7ce4-4c0e-8858-43fbf531c552,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-b2d471a9-5948-4f93-b146-d3a2e0230a85,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-bcdf208a-2c18-4317-be0e-d04c62da2a45,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-f441aea4-b54e-4c71-80a4-049badefd549,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-75008350-dcf7-4801-b136-75ce88756149,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-c19db7a6-bd93-4298-8a24-7e5f66164d05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117315087-172.17.0.12-1595535874333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43484,DS-1997d033-9f91-45cc-9ec9-42f0895e8d25,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-25590dbd-1159-40a3-95c3-8bc4c2e293f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-1fc0619c-7ce4-4c0e-8858-43fbf531c552,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-b2d471a9-5948-4f93-b146-d3a2e0230a85,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-bcdf208a-2c18-4317-be0e-d04c62da2a45,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-f441aea4-b54e-4c71-80a4-049badefd549,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-75008350-dcf7-4801-b136-75ce88756149,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-c19db7a6-bd93-4298-8a24-7e5f66164d05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008199386-172.17.0.12-1595536075310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46545,DS-9710695c-beb3-46c0-a081-27f0d6647e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-884a4588-a25f-43ec-bc6b-28dfd48e2665,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-a7addb60-f884-4f45-af29-64cf323494c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-c7dce153-9a41-4d43-999e-37db3c764578,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-c357b2ea-48d3-4ab5-8845-4c2ea7871df8,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-d42072c4-793e-48bc-9b00-158ecd0ed5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-2ce7d3f8-2c8b-4fd3-bc93-3c7b74a2978b,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-b0718ebc-7977-4a9d-85b1-37059d4a625c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008199386-172.17.0.12-1595536075310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46545,DS-9710695c-beb3-46c0-a081-27f0d6647e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-884a4588-a25f-43ec-bc6b-28dfd48e2665,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-a7addb60-f884-4f45-af29-64cf323494c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-c7dce153-9a41-4d43-999e-37db3c764578,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-c357b2ea-48d3-4ab5-8845-4c2ea7871df8,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-d42072c4-793e-48bc-9b00-158ecd0ed5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-2ce7d3f8-2c8b-4fd3-bc93-3c7b74a2978b,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-b0718ebc-7977-4a9d-85b1-37059d4a625c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584328359-172.17.0.12-1595536418145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38678,DS-9a12112e-c31f-4277-b69c-6ee425509613,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-65f95c21-10a4-4a1a-bc70-033e0a930b51,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-04f5a96d-855c-4ffa-b2d9-7f4d24f7570d,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-b05b6dd2-ac45-4c12-8346-6a198bc987d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-01cc6e45-241d-4458-a164-9d2a5653007c,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-1f3c36aa-6778-4ab9-b175-99bf590996b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-6f3468c8-dfa0-4330-8247-fdaf9f6ffa0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-f7b37c77-b3d2-4981-87d2-d842e05d7cb6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584328359-172.17.0.12-1595536418145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38678,DS-9a12112e-c31f-4277-b69c-6ee425509613,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-65f95c21-10a4-4a1a-bc70-033e0a930b51,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-04f5a96d-855c-4ffa-b2d9-7f4d24f7570d,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-b05b6dd2-ac45-4c12-8346-6a198bc987d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-01cc6e45-241d-4458-a164-9d2a5653007c,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-1f3c36aa-6778-4ab9-b175-99bf590996b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-6f3468c8-dfa0-4330-8247-fdaf9f6ffa0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-f7b37c77-b3d2-4981-87d2-d842e05d7cb6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5500
