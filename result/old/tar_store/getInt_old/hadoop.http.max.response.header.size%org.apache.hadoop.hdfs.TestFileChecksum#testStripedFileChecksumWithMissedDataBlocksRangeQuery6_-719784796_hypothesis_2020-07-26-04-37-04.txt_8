reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-905807300-172.17.0.13-1595738599759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38773,DS-98966fed-5abb-4c34-a7a2-ae32d6e28343,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-70d96f66-c02b-44a9-bda0-6675ff4d9b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-94663d10-fa10-4b83-b984-312a01a8d809,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-8739b0b1-db5c-43b7-b5d6-8e38dc7fbc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-56321918-f20c-487c-9ab1-baa62e8c92b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-f5ca141b-9f4d-42ac-a66a-43ec35938047,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-741ba91f-8e25-47f9-b5d3-a198aa8e1e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-35f30a67-5a08-48f4-a305-7ee4be72eca3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-905807300-172.17.0.13-1595738599759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38773,DS-98966fed-5abb-4c34-a7a2-ae32d6e28343,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-70d96f66-c02b-44a9-bda0-6675ff4d9b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-94663d10-fa10-4b83-b984-312a01a8d809,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-8739b0b1-db5c-43b7-b5d6-8e38dc7fbc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-56321918-f20c-487c-9ab1-baa62e8c92b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-f5ca141b-9f4d-42ac-a66a-43ec35938047,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-741ba91f-8e25-47f9-b5d3-a198aa8e1e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-35f30a67-5a08-48f4-a305-7ee4be72eca3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647868621-172.17.0.13-1595738685391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38394,DS-0b221e71-48dd-43e1-aad8-52f0bb2cc876,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-4131fc5b-ef15-48b4-8745-28b36bb61531,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-badb300e-ee1c-4fb2-a138-10a75806294b,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-e7ef6182-d2d8-48fb-9e3c-e900b289f774,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-2bc10079-2183-4228-94a4-4962cb5be2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-820be788-3c2b-4a0d-9078-e8d287057bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-aa4a7032-a5bf-4b96-be23-80ef927cde68,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-4833ade6-43e2-4fbb-9c5b-46f9f53e55fd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647868621-172.17.0.13-1595738685391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38394,DS-0b221e71-48dd-43e1-aad8-52f0bb2cc876,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-4131fc5b-ef15-48b4-8745-28b36bb61531,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-badb300e-ee1c-4fb2-a138-10a75806294b,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-e7ef6182-d2d8-48fb-9e3c-e900b289f774,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-2bc10079-2183-4228-94a4-4962cb5be2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-820be788-3c2b-4a0d-9078-e8d287057bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-aa4a7032-a5bf-4b96-be23-80ef927cde68,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-4833ade6-43e2-4fbb-9c5b-46f9f53e55fd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969237683-172.17.0.13-1595739075267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41161,DS-59420c4f-6654-458e-b46d-862418cfce73,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-1a495ac7-2695-4213-a2c3-141ff168d4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-571a0f3d-2f8c-4a73-a754-e791ee4c5089,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-f93b9f91-bfbb-493c-a452-8ed45106a300,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-9de32ab8-9e78-447b-95b3-10165d44bfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-92655dd7-70cf-4a0f-962a-9ef3facde4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-d1e99bc4-f0df-4fdd-851d-81c2f52c6aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-383e1e2b-6a5e-43eb-8326-658231ae370e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969237683-172.17.0.13-1595739075267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41161,DS-59420c4f-6654-458e-b46d-862418cfce73,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-1a495ac7-2695-4213-a2c3-141ff168d4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-571a0f3d-2f8c-4a73-a754-e791ee4c5089,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-f93b9f91-bfbb-493c-a452-8ed45106a300,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-9de32ab8-9e78-447b-95b3-10165d44bfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-92655dd7-70cf-4a0f-962a-9ef3facde4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-d1e99bc4-f0df-4fdd-851d-81c2f52c6aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-383e1e2b-6a5e-43eb-8326-658231ae370e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832398655-172.17.0.13-1595739181050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34791,DS-3fd12f2c-81a6-4895-8e7f-83b9e5de6ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-f390a7b4-b973-4f4e-b37a-9669a093c3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-2af24885-5fca-459a-bb97-2296dab31a13,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-cce085a3-aaec-4d88-8959-094f765071ef,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-1cc73e7b-bdeb-4c2e-aec2-3a76c54f6c45,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-bf50cc6c-6ee8-4b68-ae4e-1816110c931a,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-6428dc26-748e-4999-860a-714f6bc790ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-cdad60b7-7fb9-4bd6-9898-4fb1f5d0a5e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832398655-172.17.0.13-1595739181050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34791,DS-3fd12f2c-81a6-4895-8e7f-83b9e5de6ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-f390a7b4-b973-4f4e-b37a-9669a093c3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-2af24885-5fca-459a-bb97-2296dab31a13,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-cce085a3-aaec-4d88-8959-094f765071ef,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-1cc73e7b-bdeb-4c2e-aec2-3a76c54f6c45,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-bf50cc6c-6ee8-4b68-ae4e-1816110c931a,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-6428dc26-748e-4999-860a-714f6bc790ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-cdad60b7-7fb9-4bd6-9898-4fb1f5d0a5e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-271468001-172.17.0.13-1595739316392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40614,DS-768561c8-9db6-4643-a44e-28110d6d0517,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-035f3e64-749c-4570-b38d-f1b0addaad0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-85a2c5a6-28e2-495f-9429-7b86a70b68c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-683eb454-4bd5-441c-a525-2cccb34c0a89,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-d8607680-1716-4dd5-b0de-77d5cae09b90,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-cafe2cd9-7f5c-41c1-962e-d5bdb1890eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-4f97cd88-94cb-42a2-9712-fdf6758af6af,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-f1548a2c-d37b-432f-a0af-a99c1cd0655e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-271468001-172.17.0.13-1595739316392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40614,DS-768561c8-9db6-4643-a44e-28110d6d0517,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-035f3e64-749c-4570-b38d-f1b0addaad0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-85a2c5a6-28e2-495f-9429-7b86a70b68c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-683eb454-4bd5-441c-a525-2cccb34c0a89,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-d8607680-1716-4dd5-b0de-77d5cae09b90,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-cafe2cd9-7f5c-41c1-962e-d5bdb1890eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-4f97cd88-94cb-42a2-9712-fdf6758af6af,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-f1548a2c-d37b-432f-a0af-a99c1cd0655e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071081548-172.17.0.13-1595739589348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41868,DS-97837712-c99b-4b68-9797-dc3f0032e487,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-b07af9db-68f3-4ad6-94db-106c964a8fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-dfdd6c5d-8235-4cdd-8789-8d05c666562d,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-b1a21476-38d3-4ac3-a6b5-037ed028d666,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-baae2f06-e6db-49bd-bc3a-aebd5e0c5788,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-365125b8-37ad-4b55-9fd6-632cadfd1466,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-e86f9b7f-4f2c-4d34-a552-aac13ab08f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-107a82fd-26c8-4a83-8c2c-326a2b0dfb61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071081548-172.17.0.13-1595739589348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41868,DS-97837712-c99b-4b68-9797-dc3f0032e487,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-b07af9db-68f3-4ad6-94db-106c964a8fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-dfdd6c5d-8235-4cdd-8789-8d05c666562d,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-b1a21476-38d3-4ac3-a6b5-037ed028d666,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-baae2f06-e6db-49bd-bc3a-aebd5e0c5788,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-365125b8-37ad-4b55-9fd6-632cadfd1466,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-e86f9b7f-4f2c-4d34-a552-aac13ab08f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-107a82fd-26c8-4a83-8c2c-326a2b0dfb61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553198093-172.17.0.13-1595739663102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35278,DS-c89657d4-27ff-4aa3-89e3-b3c6497fc481,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-35ecc5dc-cfe0-4318-9dba-8307d1d246a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-e3052b4f-bab0-43fe-8ede-6f0e7e931ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-5436d403-276a-4952-85ca-ec003c648563,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-38ba5662-1cb2-4d10-a61d-cb61f2be709a,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-6190c0a3-b78d-4b88-81b1-19f85ab3aad3,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-eb7d6e0a-e079-4c55-9027-a2ab4d541073,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-06d9aa52-a670-44fb-8671-2818aa573fd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553198093-172.17.0.13-1595739663102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35278,DS-c89657d4-27ff-4aa3-89e3-b3c6497fc481,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-35ecc5dc-cfe0-4318-9dba-8307d1d246a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-e3052b4f-bab0-43fe-8ede-6f0e7e931ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-5436d403-276a-4952-85ca-ec003c648563,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-38ba5662-1cb2-4d10-a61d-cb61f2be709a,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-6190c0a3-b78d-4b88-81b1-19f85ab3aad3,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-eb7d6e0a-e079-4c55-9027-a2ab4d541073,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-06d9aa52-a670-44fb-8671-2818aa573fd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407979415-172.17.0.13-1595739748536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42541,DS-02ddaaa0-369e-4e0c-9023-f0498b3e1cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-963690bb-ae95-490e-b3ff-507094eea0af,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-760a33a8-df04-4229-a6f2-b419b1ff517f,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-48c12624-b18f-412f-af05-6b8f372881d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-dd373260-a24e-4164-9f88-356a60e3a47c,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-2423f394-4ef9-4bae-8535-fa992fa56e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-2a8be95a-2e6b-4474-aa57-235cbdb2b0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-4567963d-4032-4d28-9089-118e8dcde6a7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407979415-172.17.0.13-1595739748536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42541,DS-02ddaaa0-369e-4e0c-9023-f0498b3e1cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-963690bb-ae95-490e-b3ff-507094eea0af,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-760a33a8-df04-4229-a6f2-b419b1ff517f,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-48c12624-b18f-412f-af05-6b8f372881d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-dd373260-a24e-4164-9f88-356a60e3a47c,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-2423f394-4ef9-4bae-8535-fa992fa56e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-2a8be95a-2e6b-4474-aa57-235cbdb2b0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-4567963d-4032-4d28-9089-118e8dcde6a7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308742505-172.17.0.13-1595739787090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37843,DS-798fd99d-b553-4c60-9b81-618346ec77ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-608055e1-639b-4b0e-ac71-1e612db9ac33,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-9a9237ae-d6ff-436d-aff7-3bef5f1f8003,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-50782b07-619f-4018-b276-e36e3aa2e14a,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-3119754f-ea20-4a8f-a614-425812e481c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-360e4597-2ad6-4415-ac2e-8a7aa270b74e,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-0b689896-f62d-4d7f-8481-9bedc212c4de,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-d03f88ad-44d9-43fa-b157-2b80bcad9932,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308742505-172.17.0.13-1595739787090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37843,DS-798fd99d-b553-4c60-9b81-618346ec77ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-608055e1-639b-4b0e-ac71-1e612db9ac33,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-9a9237ae-d6ff-436d-aff7-3bef5f1f8003,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-50782b07-619f-4018-b276-e36e3aa2e14a,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-3119754f-ea20-4a8f-a614-425812e481c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-360e4597-2ad6-4415-ac2e-8a7aa270b74e,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-0b689896-f62d-4d7f-8481-9bedc212c4de,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-d03f88ad-44d9-43fa-b157-2b80bcad9932,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047768514-172.17.0.13-1595739902249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43087,DS-31e56d44-711f-4143-bdcb-d5fc40b3b335,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-21d16e44-6f22-4398-ae27-4b2c0f445461,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-3afd28ea-8917-4e20-a866-3ece38c48aad,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-47ce78e2-f510-41be-a29d-02965cd5eb94,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-bf4e9b3d-8694-43e2-b0cc-92a1cc6238f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-a9aab0f7-6fea-4bb8-832b-0b34d96bb5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-93715a0d-1412-4388-96e1-6c056570140f,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-a7fd137c-7543-4c58-bfc0-37015e5799de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047768514-172.17.0.13-1595739902249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43087,DS-31e56d44-711f-4143-bdcb-d5fc40b3b335,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-21d16e44-6f22-4398-ae27-4b2c0f445461,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-3afd28ea-8917-4e20-a866-3ece38c48aad,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-47ce78e2-f510-41be-a29d-02965cd5eb94,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-bf4e9b3d-8694-43e2-b0cc-92a1cc6238f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-a9aab0f7-6fea-4bb8-832b-0b34d96bb5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-93715a0d-1412-4388-96e1-6c056570140f,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-a7fd137c-7543-4c58-bfc0-37015e5799de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112240355-172.17.0.13-1595740128046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38435,DS-34a3c58e-bdf9-4265-a123-6783991d52bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-ebc01117-5341-45e1-97d2-5745369f9144,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-0e283f0c-de22-41af-845c-fb29e3092962,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-41a159e4-087c-46f8-88f5-04bb3fed852b,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-27b53b8c-c7ff-41f3-8147-48e37b4da668,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-3e625454-93ba-4fdb-84b4-4ad021fafda6,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-c756dbba-0e28-420a-b20b-65179a9cd427,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-f3269293-317d-4f52-999b-e9077ea716b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112240355-172.17.0.13-1595740128046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38435,DS-34a3c58e-bdf9-4265-a123-6783991d52bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-ebc01117-5341-45e1-97d2-5745369f9144,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-0e283f0c-de22-41af-845c-fb29e3092962,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-41a159e4-087c-46f8-88f5-04bb3fed852b,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-27b53b8c-c7ff-41f3-8147-48e37b4da668,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-3e625454-93ba-4fdb-84b4-4ad021fafda6,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-c756dbba-0e28-420a-b20b-65179a9cd427,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-f3269293-317d-4f52-999b-e9077ea716b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2063107156-172.17.0.13-1595740176948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38951,DS-15ccdbe9-4714-40cd-8b47-6751f34e4b12,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-43d7d5cd-8329-4bbd-80f1-67b720339890,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-4d70a6a2-59cc-48d1-99c0-7ce14b61b27c,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-daf6f2d9-3789-467d-974d-6f6b0a5c1382,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-56ad7846-1f47-41ba-88af-e33bb2d1b7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-a6f1264f-8d56-4c97-9b4c-b54757e31db0,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-70394c85-5719-4bb2-9d6c-d5c753376ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-3959355e-072a-4c41-a1d9-da525e94fc82,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2063107156-172.17.0.13-1595740176948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38951,DS-15ccdbe9-4714-40cd-8b47-6751f34e4b12,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-43d7d5cd-8329-4bbd-80f1-67b720339890,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-4d70a6a2-59cc-48d1-99c0-7ce14b61b27c,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-daf6f2d9-3789-467d-974d-6f6b0a5c1382,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-56ad7846-1f47-41ba-88af-e33bb2d1b7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-a6f1264f-8d56-4c97-9b4c-b54757e31db0,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-70394c85-5719-4bb2-9d6c-d5c753376ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-3959355e-072a-4c41-a1d9-da525e94fc82,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019120742-172.17.0.13-1595740415072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44609,DS-30adc465-a100-48df-a795-3fba42c866fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-e0529ffa-edbf-47cb-ac4d-d722df6f0bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-ff004a87-150d-4de5-8489-0fdd439b26c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-f43a48b2-6bb6-4866-8799-c01f1c65b5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-005cb8d7-4e5b-4968-baa0-0094ed49764b,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-d1418251-bb70-431d-9cd1-b81d475671db,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-c2ec0c42-f268-4963-a608-542085376f84,DISK], DatanodeInfoWithStorage[127.0.0.1:39047,DS-1ae8325f-8c39-49f5-9c56-421139f10eed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019120742-172.17.0.13-1595740415072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44609,DS-30adc465-a100-48df-a795-3fba42c866fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-e0529ffa-edbf-47cb-ac4d-d722df6f0bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-ff004a87-150d-4de5-8489-0fdd439b26c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-f43a48b2-6bb6-4866-8799-c01f1c65b5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-005cb8d7-4e5b-4968-baa0-0094ed49764b,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-d1418251-bb70-431d-9cd1-b81d475671db,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-c2ec0c42-f268-4963-a608-542085376f84,DISK], DatanodeInfoWithStorage[127.0.0.1:39047,DS-1ae8325f-8c39-49f5-9c56-421139f10eed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1506119726-172.17.0.13-1595740546474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45348,DS-a3109968-47dc-4c13-9c47-ab2cf650585b,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-ae8e97c9-2cac-4f9c-8c34-02aee3a2ab94,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-95d9f9e6-aad4-457d-93b6-394ed4e9d32a,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-b19bd4fe-67a1-4894-ae40-ce5a8e56072b,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-26cd03aa-9f89-4358-a15c-bb3146c43797,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-40d469f5-0458-428f-80e2-b4d1db9fd923,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-028261a7-9d6e-4e60-a69f-dcca12850a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-f3fab265-c70c-4ff5-a321-e1433c36d803,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1506119726-172.17.0.13-1595740546474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45348,DS-a3109968-47dc-4c13-9c47-ab2cf650585b,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-ae8e97c9-2cac-4f9c-8c34-02aee3a2ab94,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-95d9f9e6-aad4-457d-93b6-394ed4e9d32a,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-b19bd4fe-67a1-4894-ae40-ce5a8e56072b,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-26cd03aa-9f89-4358-a15c-bb3146c43797,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-40d469f5-0458-428f-80e2-b4d1db9fd923,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-028261a7-9d6e-4e60-a69f-dcca12850a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-f3fab265-c70c-4ff5-a321-e1433c36d803,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950247029-172.17.0.13-1595740610044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44362,DS-20cdb781-32ef-4e82-97a1-969916a457a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-0afdb850-1b1b-40a4-b127-1a6dce2ab135,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-5c31a0c5-12d2-4f1f-95fe-bfb6fdc47422,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-5f4ce8d1-ff8c-4578-b60a-bdb40732f139,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-b4cd6386-2a5a-46cd-af98-47b82923aec5,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-cf9cfcd6-afe1-4840-8871-2fbbfef9a198,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-86449ada-4d7a-48ba-84cc-ee4d1896fd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-3b6fb2d2-24db-4a85-a2b9-277bc976aa70,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950247029-172.17.0.13-1595740610044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44362,DS-20cdb781-32ef-4e82-97a1-969916a457a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-0afdb850-1b1b-40a4-b127-1a6dce2ab135,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-5c31a0c5-12d2-4f1f-95fe-bfb6fdc47422,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-5f4ce8d1-ff8c-4578-b60a-bdb40732f139,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-b4cd6386-2a5a-46cd-af98-47b82923aec5,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-cf9cfcd6-afe1-4840-8871-2fbbfef9a198,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-86449ada-4d7a-48ba-84cc-ee4d1896fd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-3b6fb2d2-24db-4a85-a2b9-277bc976aa70,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434509919-172.17.0.13-1595740656013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42484,DS-13933762-36aa-4918-a003-ed53cfee8caa,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-1ac55d3c-85f3-4fb1-81f9-cf8ab186a2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-1550e8c9-b4a7-4899-bfde-daa76ab62adb,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-cca40d53-76d1-4811-a634-e71c0f10584c,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-bb582125-f224-4bab-ab8b-007caeb2ea52,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-6085b262-da22-42fd-8ce8-7dbb3c5d9a34,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-b302937c-ce4c-4b1b-a08d-ffb92d1153cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-e66afd4e-3685-4c96-8848-fcad15bedd92,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434509919-172.17.0.13-1595740656013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42484,DS-13933762-36aa-4918-a003-ed53cfee8caa,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-1ac55d3c-85f3-4fb1-81f9-cf8ab186a2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-1550e8c9-b4a7-4899-bfde-daa76ab62adb,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-cca40d53-76d1-4811-a634-e71c0f10584c,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-bb582125-f224-4bab-ab8b-007caeb2ea52,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-6085b262-da22-42fd-8ce8-7dbb3c5d9a34,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-b302937c-ce4c-4b1b-a08d-ffb92d1153cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-e66afd4e-3685-4c96-8848-fcad15bedd92,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764543179-172.17.0.13-1595741056582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45416,DS-400dd50d-2349-401c-b491-c8e9b4ee57fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-e1b84d35-9200-4fd0-b83d-69725e6dcdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-63534884-186e-44f9-96a4-9b530a8a25c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-6bf6ba64-930f-44ef-b3ee-e020cf070b41,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-83404695-32ca-462c-9956-e41c1f068bba,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-069cb3e7-0d18-4c38-908f-5343d7bac09b,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-8180cb83-b5fc-4aa9-b6e1-388dd2d8b327,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-71617eec-4c38-4dcd-8d52-c895e7e8b545,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764543179-172.17.0.13-1595741056582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45416,DS-400dd50d-2349-401c-b491-c8e9b4ee57fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-e1b84d35-9200-4fd0-b83d-69725e6dcdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-63534884-186e-44f9-96a4-9b530a8a25c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-6bf6ba64-930f-44ef-b3ee-e020cf070b41,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-83404695-32ca-462c-9956-e41c1f068bba,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-069cb3e7-0d18-4c38-908f-5343d7bac09b,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-8180cb83-b5fc-4aa9-b6e1-388dd2d8b327,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-71617eec-4c38-4dcd-8d52-c895e7e8b545,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115407242-172.17.0.13-1595741134083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43476,DS-a6bc4cb5-5588-4723-847c-73b744170edd,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-757e7ee2-5462-4a54-a1d6-3b6b70abfc71,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-82a43c06-2705-4e6f-b9e4-35c1def4c634,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-e1d53de2-b4e9-4245-84a4-109c41a11f83,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-1c09b0a6-425e-4ca6-bfa6-56c98f44aba2,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-f28a472e-9ae5-4ca5-bfd7-1ff9478bbfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-65f421ba-7d36-4ccb-abb0-d295d0dfebde,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-35a5dac2-0b54-450f-a41b-a6a06af04130,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115407242-172.17.0.13-1595741134083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43476,DS-a6bc4cb5-5588-4723-847c-73b744170edd,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-757e7ee2-5462-4a54-a1d6-3b6b70abfc71,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-82a43c06-2705-4e6f-b9e4-35c1def4c634,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-e1d53de2-b4e9-4245-84a4-109c41a11f83,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-1c09b0a6-425e-4ca6-bfa6-56c98f44aba2,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-f28a472e-9ae5-4ca5-bfd7-1ff9478bbfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-65f421ba-7d36-4ccb-abb0-d295d0dfebde,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-35a5dac2-0b54-450f-a41b-a6a06af04130,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1686211150-172.17.0.13-1595741175390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39066,DS-b408ec24-e0e9-47a0-8ca5-88291911fa78,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-3b88d747-fb55-42a6-b5d2-10a7d23b8c94,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-c37aabf5-a7a6-4ecb-b627-a638a157bccd,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-a4716f39-d4bd-42ff-9fe6-22e52b35d507,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-8ab95516-fa59-43e8-bce0-2d17c29a1999,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-d7fda04a-0092-4007-9940-d1f4d83c5689,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-d0046aa8-d29c-4fde-9ea7-3696aca0e97f,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-cb8cbe89-04e2-4606-a899-b270598b8cc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1686211150-172.17.0.13-1595741175390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39066,DS-b408ec24-e0e9-47a0-8ca5-88291911fa78,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-3b88d747-fb55-42a6-b5d2-10a7d23b8c94,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-c37aabf5-a7a6-4ecb-b627-a638a157bccd,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-a4716f39-d4bd-42ff-9fe6-22e52b35d507,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-8ab95516-fa59-43e8-bce0-2d17c29a1999,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-d7fda04a-0092-4007-9940-d1f4d83c5689,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-d0046aa8-d29c-4fde-9ea7-3696aca0e97f,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-cb8cbe89-04e2-4606-a899-b270598b8cc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384258933-172.17.0.13-1595741224003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46762,DS-8675d8e6-48ea-4048-b6c1-51e1b8a7b0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-9e614990-9574-4e52-b3b9-1c0c3844a29e,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-a6bb1932-7329-4f7c-bc91-6d0534a96d97,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-8532f53a-e4d1-4a44-ab1d-0923b6c3d079,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-ab0aa349-e3ec-44f6-8816-7f08c3ddbca0,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-df2e4040-0892-48cc-a2e2-9ec6da495e94,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-c52747b7-29ca-41f4-9906-ee611368e1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-ca465117-57f1-42e0-afe2-119122d5d783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384258933-172.17.0.13-1595741224003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46762,DS-8675d8e6-48ea-4048-b6c1-51e1b8a7b0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-9e614990-9574-4e52-b3b9-1c0c3844a29e,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-a6bb1932-7329-4f7c-bc91-6d0534a96d97,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-8532f53a-e4d1-4a44-ab1d-0923b6c3d079,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-ab0aa349-e3ec-44f6-8816-7f08c3ddbca0,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-df2e4040-0892-48cc-a2e2-9ec6da495e94,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-c52747b7-29ca-41f4-9906-ee611368e1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-ca465117-57f1-42e0-afe2-119122d5d783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662563439-172.17.0.13-1595741410382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40546,DS-6f282bd3-61af-4ad7-9854-19ce30a7d24f,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-baee7b98-d750-42f0-a168-91cfef9e99d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-c08f153b-0f22-4f80-8f07-eb3f767ab06f,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-5899f847-6b86-4575-906f-ac475aa546b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-a0e513ed-2d7b-4aaf-9748-8979cf416ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-ce92d62d-b55a-4505-8765-e97e64dc2b78,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-6e955083-5f00-4179-b5a5-2baeef3c4a43,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-16b12089-cd17-4948-9bbd-91bfb26df05b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662563439-172.17.0.13-1595741410382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40546,DS-6f282bd3-61af-4ad7-9854-19ce30a7d24f,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-baee7b98-d750-42f0-a168-91cfef9e99d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-c08f153b-0f22-4f80-8f07-eb3f767ab06f,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-5899f847-6b86-4575-906f-ac475aa546b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-a0e513ed-2d7b-4aaf-9748-8979cf416ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-ce92d62d-b55a-4505-8765-e97e64dc2b78,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-6e955083-5f00-4179-b5a5-2baeef3c4a43,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-16b12089-cd17-4948-9bbd-91bfb26df05b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983756606-172.17.0.13-1595741538090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44048,DS-33487f58-3228-4003-842b-9d62c5c458a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-284715e8-bcef-4472-8040-60dfcf570a66,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-78e88dd1-cf0d-4893-a714-539de706becc,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-8fe4c53a-7dd2-4096-9874-adb9797b9ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-a8a6e706-c38c-4661-a59d-8faa9210273c,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-ddf11b4a-8ab0-4776-bae7-50af90ff426e,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-3bc6566f-39ad-44ce-892f-81eb273483d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-e8ab7fc8-53c4-4fa9-8e0e-a032b2810c7d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983756606-172.17.0.13-1595741538090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44048,DS-33487f58-3228-4003-842b-9d62c5c458a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-284715e8-bcef-4472-8040-60dfcf570a66,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-78e88dd1-cf0d-4893-a714-539de706becc,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-8fe4c53a-7dd2-4096-9874-adb9797b9ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-a8a6e706-c38c-4661-a59d-8faa9210273c,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-ddf11b4a-8ab0-4776-bae7-50af90ff426e,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-3bc6566f-39ad-44ce-892f-81eb273483d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-e8ab7fc8-53c4-4fa9-8e0e-a032b2810c7d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455455189-172.17.0.13-1595741631733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43197,DS-46bf68f5-8845-46cf-bc9f-555f0d6d9f63,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-fed56ecc-d7b7-4628-bab3-deb2567ee820,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-09ba3682-7031-4173-a23f-0be05efe6b05,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-8f3f3c8f-e94a-4ad8-960b-bf433b2ace34,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-4ecf695c-9b11-4355-bb4b-f76a6ccf12af,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-b15951e5-0d32-4cde-b02a-8cd922f60cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-a578e37d-0967-4e67-8da5-98eab948405b,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-d683de6e-12db-4b89-9dd5-a08dd53da961,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455455189-172.17.0.13-1595741631733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43197,DS-46bf68f5-8845-46cf-bc9f-555f0d6d9f63,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-fed56ecc-d7b7-4628-bab3-deb2567ee820,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-09ba3682-7031-4173-a23f-0be05efe6b05,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-8f3f3c8f-e94a-4ad8-960b-bf433b2ace34,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-4ecf695c-9b11-4355-bb4b-f76a6ccf12af,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-b15951e5-0d32-4cde-b02a-8cd922f60cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-a578e37d-0967-4e67-8da5-98eab948405b,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-d683de6e-12db-4b89-9dd5-a08dd53da961,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619569790-172.17.0.13-1595741936226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40144,DS-5498c62d-6f48-4ef9-9601-5faece2169dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-61bd636d-831e-47ea-89ef-ec62e5a2f6af,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-0317edce-1408-4157-9ac7-104c855a476d,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-c218a1dc-90ed-4343-b036-379864d8634c,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-5f433262-ac88-4208-9d69-e10e882de5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-b564839b-80df-46ce-a6ac-3949ee05a04b,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-b5a8082d-306e-42e0-8968-b563acc6bb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-ec4c867b-aab4-4838-8c72-ee7d57bed311,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619569790-172.17.0.13-1595741936226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40144,DS-5498c62d-6f48-4ef9-9601-5faece2169dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-61bd636d-831e-47ea-89ef-ec62e5a2f6af,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-0317edce-1408-4157-9ac7-104c855a476d,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-c218a1dc-90ed-4343-b036-379864d8634c,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-5f433262-ac88-4208-9d69-e10e882de5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-b564839b-80df-46ce-a6ac-3949ee05a04b,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-b5a8082d-306e-42e0-8968-b563acc6bb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-ec4c867b-aab4-4838-8c72-ee7d57bed311,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008304146-172.17.0.13-1595742069363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39785,DS-901e3ad5-b0ed-4bc7-9d44-2c12a9d3b412,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-4c145fc6-6050-4073-8e5b-be4bca944535,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-45f63f47-1a6f-46f0-87cd-e74155f0c2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-5fb3af34-6a9b-48f3-9931-d6b1f4d822a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-654a8ff2-951d-4729-9379-7f3e5cac1017,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-09e5ee0b-6034-4f0c-8b73-4df92187eb84,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-6e962934-97d5-469f-a403-2875ca57b7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-347e0488-552b-422b-b788-4983abeae13f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008304146-172.17.0.13-1595742069363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39785,DS-901e3ad5-b0ed-4bc7-9d44-2c12a9d3b412,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-4c145fc6-6050-4073-8e5b-be4bca944535,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-45f63f47-1a6f-46f0-87cd-e74155f0c2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-5fb3af34-6a9b-48f3-9931-d6b1f4d822a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-654a8ff2-951d-4729-9379-7f3e5cac1017,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-09e5ee0b-6034-4f0c-8b73-4df92187eb84,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-6e962934-97d5-469f-a403-2875ca57b7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-347e0488-552b-422b-b788-4983abeae13f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-990941226-172.17.0.13-1595742441201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43470,DS-d9809efc-da9c-4866-8af6-5102c2baacef,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-58cb278d-67de-4ce0-9763-4d2b0e8e1b10,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-cb0be75f-76e4-4e8a-9f37-a9bc8d4ce253,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-c19fc06f-a529-49a4-8305-2e8830384914,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-79b02bcd-fa92-413e-a61a-5de092df76ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-bf72c21b-a952-4ea3-98bf-d4921e3e9971,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-d8872da0-3caf-48db-827f-b0c0c8ea51da,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-0acbc40a-9c48-4e47-aaa5-5c4ac74378e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-990941226-172.17.0.13-1595742441201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43470,DS-d9809efc-da9c-4866-8af6-5102c2baacef,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-58cb278d-67de-4ce0-9763-4d2b0e8e1b10,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-cb0be75f-76e4-4e8a-9f37-a9bc8d4ce253,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-c19fc06f-a529-49a4-8305-2e8830384914,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-79b02bcd-fa92-413e-a61a-5de092df76ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-bf72c21b-a952-4ea3-98bf-d4921e3e9971,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-d8872da0-3caf-48db-827f-b0c0c8ea51da,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-0acbc40a-9c48-4e47-aaa5-5c4ac74378e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127017476-172.17.0.13-1595742583538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37500,DS-68242144-ef51-4318-81a5-e5ba2b1ce6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-b9ddd3dc-9ecf-46bc-a37b-f0a62cdd0ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-065d7bcc-5063-48f4-8516-cd03a712a300,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-08703f83-500e-4eb7-9b43-9f0a52e609b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-4cfa12e7-569c-46dc-8df9-e9bd4be8a1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-5875185f-a599-4c34-9bf1-1a5db7c6ff89,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-a83160c7-1fe3-4721-a563-e727ba5cb13f,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-3ed74307-2341-4b8a-82c6-fc01c864bd0d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127017476-172.17.0.13-1595742583538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37500,DS-68242144-ef51-4318-81a5-e5ba2b1ce6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-b9ddd3dc-9ecf-46bc-a37b-f0a62cdd0ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-065d7bcc-5063-48f4-8516-cd03a712a300,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-08703f83-500e-4eb7-9b43-9f0a52e609b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-4cfa12e7-569c-46dc-8df9-e9bd4be8a1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-5875185f-a599-4c34-9bf1-1a5db7c6ff89,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-a83160c7-1fe3-4721-a563-e727ba5cb13f,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-3ed74307-2341-4b8a-82c6-fc01c864bd0d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1217637188-172.17.0.13-1595742617535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46345,DS-64d62d35-53da-4c40-bb83-af0612b82b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-85b12d8c-ac79-41c5-91d6-49200d61bd82,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-da2adfcc-49f3-4a8a-aeb7-4f24d8a8b9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-933cd5e6-20b6-440d-b9a7-f9299fdd5dea,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-75aa8256-3db6-4c9e-81b6-8df435e3df0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-b255207f-7610-433c-9b6e-62848f39f15e,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-11c6c37a-2768-48e7-bf8e-bdc51e238440,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-692b459f-10f7-45ba-837b-5b1e232a9bde,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1217637188-172.17.0.13-1595742617535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46345,DS-64d62d35-53da-4c40-bb83-af0612b82b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-85b12d8c-ac79-41c5-91d6-49200d61bd82,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-da2adfcc-49f3-4a8a-aeb7-4f24d8a8b9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-933cd5e6-20b6-440d-b9a7-f9299fdd5dea,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-75aa8256-3db6-4c9e-81b6-8df435e3df0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-b255207f-7610-433c-9b6e-62848f39f15e,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-11c6c37a-2768-48e7-bf8e-bdc51e238440,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-692b459f-10f7-45ba-837b-5b1e232a9bde,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917318342-172.17.0.13-1595742738500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39199,DS-19588531-634c-4e40-8644-0e490d6c9243,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-c9c52b81-16e1-4615-83c5-c23976ff0f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-c1602de0-f428-4920-a8a8-09a76d2afb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-35e1f79a-7388-46c2-95fc-2031d9cf349f,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-48578a44-0ba7-475c-96ac-846a2ae58ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-baeb72f8-c36a-41eb-b8cc-636433a83075,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-5df2492e-a873-484c-9f24-64847a1e6e02,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-f7e31f96-afb1-4440-8638-2f29d202c967,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917318342-172.17.0.13-1595742738500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39199,DS-19588531-634c-4e40-8644-0e490d6c9243,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-c9c52b81-16e1-4615-83c5-c23976ff0f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-c1602de0-f428-4920-a8a8-09a76d2afb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-35e1f79a-7388-46c2-95fc-2031d9cf349f,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-48578a44-0ba7-475c-96ac-846a2ae58ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-baeb72f8-c36a-41eb-b8cc-636433a83075,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-5df2492e-a873-484c-9f24-64847a1e6e02,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-f7e31f96-afb1-4440-8638-2f29d202c967,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051543455-172.17.0.13-1595743599482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37869,DS-32e3999d-3616-4533-8a45-fc3ed1cf5d86,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-0b13d44c-6452-4228-a9e9-9e9e22cd2cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-e4fe643f-27eb-4ecc-ae21-0ac9ea9af726,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-4cefeeb3-4993-4503-a899-4f8ccb512e95,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-cd6770e4-1e70-4487-a6c0-a51ee62ab2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-9d78174a-b2ed-4e5f-81ca-19c5063a2a94,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-8552e940-6f24-437f-864e-540477cbba1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-c5ffb673-302c-4621-ab4c-c964f14775a5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051543455-172.17.0.13-1595743599482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37869,DS-32e3999d-3616-4533-8a45-fc3ed1cf5d86,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-0b13d44c-6452-4228-a9e9-9e9e22cd2cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-e4fe643f-27eb-4ecc-ae21-0ac9ea9af726,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-4cefeeb3-4993-4503-a899-4f8ccb512e95,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-cd6770e4-1e70-4487-a6c0-a51ee62ab2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-9d78174a-b2ed-4e5f-81ca-19c5063a2a94,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-8552e940-6f24-437f-864e-540477cbba1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-c5ffb673-302c-4621-ab4c-c964f14775a5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991005653-172.17.0.13-1595743818868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46639,DS-6e75c040-1c63-4587-9c82-fc4a8ad19c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-53df32c2-1f69-4773-8200-13488c64fba7,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-094ed375-9685-4249-be0e-78df0009890c,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-1c3d91d1-b35a-4b78-b074-7cf205bdeede,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-67106284-91c2-440f-aef5-8ef75f91b699,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-048b2bde-4ba6-4a68-909c-dae7fff69830,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-46aca788-8c7c-4a93-9023-b9c57a8bf4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-92a8f4cd-1247-4e88-973f-4008cf445455,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991005653-172.17.0.13-1595743818868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46639,DS-6e75c040-1c63-4587-9c82-fc4a8ad19c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-53df32c2-1f69-4773-8200-13488c64fba7,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-094ed375-9685-4249-be0e-78df0009890c,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-1c3d91d1-b35a-4b78-b074-7cf205bdeede,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-67106284-91c2-440f-aef5-8ef75f91b699,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-048b2bde-4ba6-4a68-909c-dae7fff69830,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-46aca788-8c7c-4a93-9023-b9c57a8bf4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-92a8f4cd-1247-4e88-973f-4008cf445455,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182325483-172.17.0.13-1595744092282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42391,DS-70abef01-4d3b-4c28-967a-833d7672759e,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-33c1b6dd-f9c8-4c5b-be9f-90af4abe9d23,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-4d1dedbb-2058-4c45-989c-963ff01c22e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-94b2159d-cdb6-4aed-aead-7001e25968a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-81ee3b67-db09-472e-84c5-0dd3d0016bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-b6d2640a-4121-4ff7-902d-98c20d98f847,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-7351f3ba-41e5-4bd8-8ba3-7354e60ff56d,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-dc81026a-5585-4b6e-9610-1336cacec445,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182325483-172.17.0.13-1595744092282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42391,DS-70abef01-4d3b-4c28-967a-833d7672759e,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-33c1b6dd-f9c8-4c5b-be9f-90af4abe9d23,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-4d1dedbb-2058-4c45-989c-963ff01c22e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-94b2159d-cdb6-4aed-aead-7001e25968a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-81ee3b67-db09-472e-84c5-0dd3d0016bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-b6d2640a-4121-4ff7-902d-98c20d98f847,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-7351f3ba-41e5-4bd8-8ba3-7354e60ff56d,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-dc81026a-5585-4b6e-9610-1336cacec445,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655655762-172.17.0.13-1595744174540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36136,DS-cf30c5c5-78bf-4efe-ad70-79eb1a28a9db,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-ce1ac822-8ed0-4b45-ba39-bbf3c276b279,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-801082b7-0508-4473-a72a-0ef51ae4e5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-6063c8eb-8fb0-481e-bd3b-51257ebe8b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-20475041-26f2-437d-9ce0-ea21e7316139,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-2a13ed56-38dc-4d25-8061-ca03655f468f,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-bab2e648-69b5-4820-b5df-42f70740c141,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-6db8a6e1-cdde-45e8-bd69-45b79896c47e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655655762-172.17.0.13-1595744174540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36136,DS-cf30c5c5-78bf-4efe-ad70-79eb1a28a9db,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-ce1ac822-8ed0-4b45-ba39-bbf3c276b279,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-801082b7-0508-4473-a72a-0ef51ae4e5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-6063c8eb-8fb0-481e-bd3b-51257ebe8b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-20475041-26f2-437d-9ce0-ea21e7316139,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-2a13ed56-38dc-4d25-8061-ca03655f468f,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-bab2e648-69b5-4820-b5df-42f70740c141,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-6db8a6e1-cdde-45e8-bd69-45b79896c47e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-416604193-172.17.0.13-1595744533571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43233,DS-8538a761-01e2-43de-b90b-f3870f84285e,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-e7c4afdd-2336-43f1-a780-c8a6f75a780d,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-7c3f3303-c535-4c65-a5f5-31bdd5479f10,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-e8adc06c-7f88-484f-9be8-794fc98dd4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-5fb09ad4-736a-4a47-bb24-a79c2ce0aedb,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-95da8fbc-aebd-46e0-b6af-487060d4089e,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-670573c3-167e-4a55-85bc-f521f5ce31a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-861b4061-0b91-413f-8d07-610672a36947,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-416604193-172.17.0.13-1595744533571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43233,DS-8538a761-01e2-43de-b90b-f3870f84285e,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-e7c4afdd-2336-43f1-a780-c8a6f75a780d,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-7c3f3303-c535-4c65-a5f5-31bdd5479f10,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-e8adc06c-7f88-484f-9be8-794fc98dd4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-5fb09ad4-736a-4a47-bb24-a79c2ce0aedb,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-95da8fbc-aebd-46e0-b6af-487060d4089e,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-670573c3-167e-4a55-85bc-f521f5ce31a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-861b4061-0b91-413f-8d07-610672a36947,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388969485-172.17.0.13-1595744711574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38331,DS-136bf83b-ff3f-4fa2-a670-9520367c6226,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-cbb66897-a5b9-4bac-943c-a3a417258e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-107c282a-77ca-43e5-a698-e4b4bb6a9a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-16435db4-ce52-4f2c-bb6f-2607d972a948,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-8229b3ae-5391-4ef3-899c-b2dabdae6de8,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-8ceab8d5-49b9-4932-a92c-6f11af4e9754,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-c9e17dc7-e3fc-41ba-b520-821c2bbe1507,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-32062a7d-a599-4771-a34e-1a20dfc53ef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388969485-172.17.0.13-1595744711574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38331,DS-136bf83b-ff3f-4fa2-a670-9520367c6226,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-cbb66897-a5b9-4bac-943c-a3a417258e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-107c282a-77ca-43e5-a698-e4b4bb6a9a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-16435db4-ce52-4f2c-bb6f-2607d972a948,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-8229b3ae-5391-4ef3-899c-b2dabdae6de8,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-8ceab8d5-49b9-4932-a92c-6f11af4e9754,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-c9e17dc7-e3fc-41ba-b520-821c2bbe1507,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-32062a7d-a599-4771-a34e-1a20dfc53ef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 23 out of 50
result: false positive !!!
Total execution time in seconds : 6640
