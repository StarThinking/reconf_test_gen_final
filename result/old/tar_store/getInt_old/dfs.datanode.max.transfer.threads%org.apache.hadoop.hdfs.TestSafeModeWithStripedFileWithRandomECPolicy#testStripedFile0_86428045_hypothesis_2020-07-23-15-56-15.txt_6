reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 4096
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestSafeModeWithStripedFileWithRandomECPolicy#testStripedFile0
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 4096
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestSafeModeWithStripedFileWithRandomECPolicy#testStripedFile0
reconfPoint: -1
result: -1
failureMessage: Data streamers failed while creating new block streams: [#8: failed, blk_-9223372036854775752_1003, #1: failed, blk_-9223372036854775759_1003, #0: failed, blk_-9223372036854775760_1003, #10: failed, blk_-9223372036854775750_1003, #7: failed, blk_-9223372036854775753_1003]. There are not enough healthy streamers.
stackTrace: java.io.IOException: Data streamers failed while creating new block streams: [#8: failed, blk_-9223372036854775752_1003, #1: failed, blk_-9223372036854775759_1003, #0: failed, blk_-9223372036854775760_1003, #10: failed, blk_-9223372036854775750_1003, #7: failed, blk_-9223372036854775753_1003]. There are not enough healthy streamers.
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamerFailures(DFSStripedOutputStream.java:651)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.writeChunk(DFSStripedOutputStream.java:567)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunks(FSOutputSummer.java:217)
	at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:125)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:111)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:57)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:96)
	at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:865)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.doTest(TestSafeModeWithStripedFile.java:122)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.testStripedFile0(TestSafeModeWithStripedFile.java:91)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
	Suppressed: java.io.IOException: Failed: the number of failed blocks = 8 > the number of parity blocks = 4
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamers(DFSStripedOutputStream.java:396)
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamerFailures(DFSStripedOutputStream.java:624)
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1188)
		at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
		at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
		at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
		at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:866)
		... 13 more



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 4096
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestSafeModeWithStripedFileWithRandomECPolicy#testStripedFile0
reconfPoint: -1
result: -1
failureMessage: Data streamers failed while creating new block streams: [#7: failed, blk_-9223372036854775753_1003, #2: failed, blk_-9223372036854775758_1003, #0: failed, blk_-9223372036854775760_1003, #1: failed, blk_-9223372036854775759_1003]. There are not enough healthy streamers.
stackTrace: java.io.IOException: Data streamers failed while creating new block streams: [#7: failed, blk_-9223372036854775753_1003, #2: failed, blk_-9223372036854775758_1003, #0: failed, blk_-9223372036854775760_1003, #1: failed, blk_-9223372036854775759_1003]. There are not enough healthy streamers.
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamerFailures(DFSStripedOutputStream.java:651)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.writeChunk(DFSStripedOutputStream.java:567)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunks(FSOutputSummer.java:217)
	at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:125)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:111)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:57)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:96)
	at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:865)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.doTest(TestSafeModeWithStripedFile.java:122)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.testStripedFile0(TestSafeModeWithStripedFile.java:91)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
	Suppressed: java.io.IOException: Failed: the number of failed blocks = 5 > the number of parity blocks = 3
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamers(DFSStripedOutputStream.java:396)
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamerFailures(DFSStripedOutputStream.java:624)
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1188)
		at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
		at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
		at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
		at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:866)
		... 13 more



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 4096
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestSafeModeWithStripedFileWithRandomECPolicy#testStripedFile0
reconfPoint: -1
result: -1
failureMessage: Data streamers failed while creating new block streams: [#4: failed, blk_-9223372036854775756_1003, #1: failed, blk_-9223372036854775759_1003, #10: failed, blk_-9223372036854775750_1003, #6: failed, blk_-9223372036854775754_1003, #11: failed, blk_-9223372036854775749_1003, #2: failed, blk_-9223372036854775758_1003, #7: failed, blk_-9223372036854775753_1003, #8: failed, blk_-9223372036854775752_1003, #3: failed, blk_-9223372036854775757_1003]. There are not enough healthy streamers.
stackTrace: java.io.IOException: Data streamers failed while creating new block streams: [#4: failed, blk_-9223372036854775756_1003, #1: failed, blk_-9223372036854775759_1003, #10: failed, blk_-9223372036854775750_1003, #6: failed, blk_-9223372036854775754_1003, #11: failed, blk_-9223372036854775749_1003, #2: failed, blk_-9223372036854775758_1003, #7: failed, blk_-9223372036854775753_1003, #8: failed, blk_-9223372036854775752_1003, #3: failed, blk_-9223372036854775757_1003]. There are not enough healthy streamers.
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamerFailures(DFSStripedOutputStream.java:651)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.writeChunk(DFSStripedOutputStream.java:567)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunks(FSOutputSummer.java:217)
	at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:125)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:111)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:57)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:96)
	at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:865)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.doTest(TestSafeModeWithStripedFile.java:122)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.testStripedFile0(TestSafeModeWithStripedFile.java:91)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
	Suppressed: java.io.IOException: Failed: the number of failed blocks = 11 > the number of parity blocks = 4
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamers(DFSStripedOutputStream.java:396)
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamerFailures(DFSStripedOutputStream.java:624)
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1188)
		at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
		at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
		at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
		at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:866)
		... 13 more



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 4096
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestSafeModeWithStripedFileWithRandomECPolicy#testStripedFile0
reconfPoint: -1
result: -1
failureMessage: Data streamers failed while creating new block streams: [#10: failed, blk_-9223372036854775750_1003, #5: failed, blk_-9223372036854775755_1003, #4: failed, blk_-9223372036854775756_1003, #11: failed, blk_-9223372036854775749_1003, #1: failed, blk_-9223372036854775759_1003, #2: failed, blk_-9223372036854775758_1003, #3: failed, blk_-9223372036854775757_1003, #7: failed, blk_-9223372036854775753_1003, #8: failed, blk_-9223372036854775752_1003, #6: failed, blk_-9223372036854775754_1003, #9: failed, blk_-9223372036854775751_1003]. There are not enough healthy streamers.
stackTrace: java.io.IOException: Data streamers failed while creating new block streams: [#10: failed, blk_-9223372036854775750_1003, #5: failed, blk_-9223372036854775755_1003, #4: failed, blk_-9223372036854775756_1003, #11: failed, blk_-9223372036854775749_1003, #1: failed, blk_-9223372036854775759_1003, #2: failed, blk_-9223372036854775758_1003, #3: failed, blk_-9223372036854775757_1003, #7: failed, blk_-9223372036854775753_1003, #8: failed, blk_-9223372036854775752_1003, #6: failed, blk_-9223372036854775754_1003, #9: failed, blk_-9223372036854775751_1003]. There are not enough healthy streamers.
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamerFailures(DFSStripedOutputStream.java:651)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.writeChunk(DFSStripedOutputStream.java:567)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunks(FSOutputSummer.java:217)
	at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:125)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:111)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:57)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:96)
	at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:865)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.doTest(TestSafeModeWithStripedFile.java:122)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.testStripedFile0(TestSafeModeWithStripedFile.java:91)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 4096
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestSafeModeWithStripedFileWithRandomECPolicy#testStripedFile0
reconfPoint: -1
result: -1
failureMessage: Data streamers failed while creating new block streams: [#6: failed, blk_-9223372036854775754_1003, #3: failed, blk_-9223372036854775757_1003, #7: failed, blk_-9223372036854775753_1003, #1: failed, blk_-9223372036854775759_1003, #5: failed, blk_-9223372036854775755_1003, #0: failed, blk_-9223372036854775760_1003, #11: failed, blk_-9223372036854775749_1003, #4: failed, blk_-9223372036854775756_1003, #12: failed, blk_-9223372036854775748_1003, #8: failed, blk_-9223372036854775752_1003, #2: failed, blk_-9223372036854775758_1003, #9: failed, blk_-9223372036854775751_1003]. There are not enough healthy streamers.
stackTrace: java.io.IOException: Data streamers failed while creating new block streams: [#6: failed, blk_-9223372036854775754_1003, #3: failed, blk_-9223372036854775757_1003, #7: failed, blk_-9223372036854775753_1003, #1: failed, blk_-9223372036854775759_1003, #5: failed, blk_-9223372036854775755_1003, #0: failed, blk_-9223372036854775760_1003, #11: failed, blk_-9223372036854775749_1003, #4: failed, blk_-9223372036854775756_1003, #12: failed, blk_-9223372036854775748_1003, #8: failed, blk_-9223372036854775752_1003, #2: failed, blk_-9223372036854775758_1003, #9: failed, blk_-9223372036854775751_1003]. There are not enough healthy streamers.
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamerFailures(DFSStripedOutputStream.java:651)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.writeChunk(DFSStripedOutputStream.java:567)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunks(FSOutputSummer.java:217)
	at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:125)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:111)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:57)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:96)
	at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:865)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.doTest(TestSafeModeWithStripedFile.java:122)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.testStripedFile0(TestSafeModeWithStripedFile.java:91)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
	Suppressed: java.io.IOException: Failed: the number of failed blocks = 13 > the number of parity blocks = 4
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamers(DFSStripedOutputStream.java:396)
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamerFailures(DFSStripedOutputStream.java:624)
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1188)
		at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
		at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
		at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
		at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:866)
		... 13 more



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 4096
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestSafeModeWithStripedFileWithRandomECPolicy#testStripedFile0
reconfPoint: -1
result: -1
failureMessage: Data streamers failed while creating new block streams: [#8: failed, blk_-9223372036854775752_1003, #5: failed, blk_-9223372036854775755_1003, #12: failed, blk_-9223372036854775748_1003, #9: failed, blk_-9223372036854775751_1003, #10: failed, blk_-9223372036854775750_1003, #11: failed, blk_-9223372036854775749_1003]. There are not enough healthy streamers.
stackTrace: java.io.IOException: Data streamers failed while creating new block streams: [#8: failed, blk_-9223372036854775752_1003, #5: failed, blk_-9223372036854775755_1003, #12: failed, blk_-9223372036854775748_1003, #9: failed, blk_-9223372036854775751_1003, #10: failed, blk_-9223372036854775750_1003, #11: failed, blk_-9223372036854775749_1003]. There are not enough healthy streamers.
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamerFailures(DFSStripedOutputStream.java:651)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.writeChunk(DFSStripedOutputStream.java:567)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunks(FSOutputSummer.java:217)
	at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:125)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:111)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:57)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:96)
	at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:865)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.doTest(TestSafeModeWithStripedFile.java:122)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.testStripedFile0(TestSafeModeWithStripedFile.java:91)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
	Suppressed: java.io.IOException: Failed: the number of failed blocks = 7 > the number of parity blocks = 4
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamers(DFSStripedOutputStream.java:396)
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamerFailures(DFSStripedOutputStream.java:624)
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1188)
		at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
		at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
		at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
		at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:866)
		... 13 more



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 4096
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestSafeModeWithStripedFileWithRandomECPolicy#testStripedFile0
reconfPoint: -1
result: -1
failureMessage: Data streamers failed while creating new block streams: [#0: failed, blk_-9223372036854775760_1003, #7: failed, blk_-9223372036854775753_1003, #2: failed, blk_-9223372036854775758_1003, #5: failed, blk_-9223372036854775755_1003, #3: failed, blk_-9223372036854775757_1003, #11: failed, blk_-9223372036854775749_1003]. There are not enough healthy streamers.
stackTrace: java.io.IOException: Data streamers failed while creating new block streams: [#0: failed, blk_-9223372036854775760_1003, #7: failed, blk_-9223372036854775753_1003, #2: failed, blk_-9223372036854775758_1003, #5: failed, blk_-9223372036854775755_1003, #3: failed, blk_-9223372036854775757_1003, #11: failed, blk_-9223372036854775749_1003]. There are not enough healthy streamers.
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamerFailures(DFSStripedOutputStream.java:651)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.writeChunk(DFSStripedOutputStream.java:567)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunks(FSOutputSummer.java:217)
	at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:125)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:111)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:57)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:96)
	at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:865)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.doTest(TestSafeModeWithStripedFile.java:122)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.testStripedFile0(TestSafeModeWithStripedFile.java:91)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
	Suppressed: java.io.IOException: Failed: the number of failed blocks = 8 > the number of parity blocks = 4
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamers(DFSStripedOutputStream.java:396)
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamerFailures(DFSStripedOutputStream.java:624)
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1188)
		at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
		at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
		at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
		at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:866)
		... 13 more



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 4096
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestSafeModeWithStripedFileWithRandomECPolicy#testStripedFile0
reconfPoint: -1
result: -1
failureMessage: Data streamers failed while creating new block streams: [#4: failed, blk_-9223372036854775756_1003, #9: failed, blk_-9223372036854775751_1003, #10: failed, blk_-9223372036854775750_1003, #6: failed, blk_-9223372036854775754_1003, #3: failed, blk_-9223372036854775757_1003, #11: failed, blk_-9223372036854775749_1003, #7: failed, blk_-9223372036854775753_1003, #8: failed, blk_-9223372036854775752_1003, #0: failed, blk_-9223372036854775760_1003, #5: failed, blk_-9223372036854775755_1003, #1: failed, blk_-9223372036854775759_1003]. There are not enough healthy streamers.
stackTrace: java.io.IOException: Data streamers failed while creating new block streams: [#4: failed, blk_-9223372036854775756_1003, #9: failed, blk_-9223372036854775751_1003, #10: failed, blk_-9223372036854775750_1003, #6: failed, blk_-9223372036854775754_1003, #3: failed, blk_-9223372036854775757_1003, #11: failed, blk_-9223372036854775749_1003, #7: failed, blk_-9223372036854775753_1003, #8: failed, blk_-9223372036854775752_1003, #0: failed, blk_-9223372036854775760_1003, #5: failed, blk_-9223372036854775755_1003, #1: failed, blk_-9223372036854775759_1003]. There are not enough healthy streamers.
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamerFailures(DFSStripedOutputStream.java:651)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.writeChunk(DFSStripedOutputStream.java:567)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunks(FSOutputSummer.java:217)
	at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:125)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:111)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:57)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:96)
	at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:865)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.doTest(TestSafeModeWithStripedFile.java:122)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.testStripedFile0(TestSafeModeWithStripedFile.java:91)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
	Suppressed: java.io.IOException: Failed: the number of failed blocks = 13 > the number of parity blocks = 4
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamers(DFSStripedOutputStream.java:396)
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamerFailures(DFSStripedOutputStream.java:624)
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1188)
		at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
		at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
		at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
		at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:866)
		... 13 more



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 4096
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestSafeModeWithStripedFileWithRandomECPolicy#testStripedFile0
reconfPoint: -1
result: -1
failureMessage: Data streamers failed while creating new block streams: [#2: failed, blk_-9223372036854775774_1002, #5: failed, blk_-9223372036854775771_1002, #1: failed, blk_-9223372036854775775_1002, #3: failed, blk_-9223372036854775773_1002, #6: failed, blk_-9223372036854775770_1002, #4: failed, blk_-9223372036854775772_1002, #0: failed, blk_-9223372036854775776_1002]. There are not enough healthy streamers.
stackTrace: java.io.IOException: Data streamers failed while creating new block streams: [#2: failed, blk_-9223372036854775774_1002, #5: failed, blk_-9223372036854775771_1002, #1: failed, blk_-9223372036854775775_1002, #3: failed, blk_-9223372036854775773_1002, #6: failed, blk_-9223372036854775770_1002, #4: failed, blk_-9223372036854775772_1002, #0: failed, blk_-9223372036854775776_1002]. There are not enough healthy streamers.
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamerFailures(DFSStripedOutputStream.java:651)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.writeChunk(DFSStripedOutputStream.java:567)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunks(FSOutputSummer.java:217)
	at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:125)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:111)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:57)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:96)
	at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:865)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.doTest(TestSafeModeWithStripedFile.java:122)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.testStripedFile0(TestSafeModeWithStripedFile.java:91)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
	Suppressed: org.apache.hadoop.io.MultipleIOException: 9 exceptions [java.io.EOFException: Unexpected EOF while trying to read response from server, java.io.IOException: Connection reset by peer, java.io.EOFException: Unexpected EOF while trying to read response from server, java.io.EOFException: Unexpected EOF while trying to read response from server, java.io.EOFException: Unexpected EOF while trying to read response from server, java.io.EOFException: Unexpected EOF while trying to read response from server, java.io.EOFException: Unexpected EOF while trying to read response from server, java.io.IOException: Failed to get parity block, index=7, java.io.IOException: Failed to get parity block, index=8]
		at org.apache.hadoop.io.MultipleIOException.createIOException(MultipleIOException.java:53)
		at org.apache.hadoop.io.MultipleIOException$Builder.build(MultipleIOException.java:77)
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1167)
		at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
		at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
		at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
		at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:866)
		... 13 more



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 4096
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestSafeModeWithStripedFileWithRandomECPolicy#testStripedFile0
reconfPoint: -1
result: -1
failureMessage: Data streamers failed while creating new block streams: [#5: failed, blk_-9223372036854775755_1003, #0: failed, blk_-9223372036854775760_1003, #1: failed, blk_-9223372036854775759_1003, #8: failed, blk_-9223372036854775752_1003, #3: failed, blk_-9223372036854775757_1003, #6: failed, blk_-9223372036854775754_1003, #4: failed, blk_-9223372036854775756_1003, #10: failed, blk_-9223372036854775750_1003, #2: failed, blk_-9223372036854775758_1003, #9: failed, blk_-9223372036854775751_1003, #7: failed, blk_-9223372036854775753_1003]. There are not enough healthy streamers.
stackTrace: java.io.IOException: Data streamers failed while creating new block streams: [#5: failed, blk_-9223372036854775755_1003, #0: failed, blk_-9223372036854775760_1003, #1: failed, blk_-9223372036854775759_1003, #8: failed, blk_-9223372036854775752_1003, #3: failed, blk_-9223372036854775757_1003, #6: failed, blk_-9223372036854775754_1003, #4: failed, blk_-9223372036854775756_1003, #10: failed, blk_-9223372036854775750_1003, #2: failed, blk_-9223372036854775758_1003, #9: failed, blk_-9223372036854775751_1003, #7: failed, blk_-9223372036854775753_1003]. There are not enough healthy streamers.
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamerFailures(DFSStripedOutputStream.java:651)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.writeChunk(DFSStripedOutputStream.java:567)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunks(FSOutputSummer.java:217)
	at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:125)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:111)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:57)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:96)
	at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:865)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.doTest(TestSafeModeWithStripedFile.java:122)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.testStripedFile0(TestSafeModeWithStripedFile.java:91)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 4096
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestSafeModeWithStripedFileWithRandomECPolicy#testStripedFile0
reconfPoint: -1
result: -1
failureMessage: Data streamers failed while creating new block streams: [#8: failed, blk_-9223372036854775752_1003, #9: failed, blk_-9223372036854775751_1003, #0: failed, blk_-9223372036854775760_1003, #10: failed, blk_-9223372036854775750_1003, #3: failed, blk_-9223372036854775757_1003, #7: failed, blk_-9223372036854775753_1003, #4: failed, blk_-9223372036854775756_1003, #5: failed, blk_-9223372036854775755_1003]. There are not enough healthy streamers.
stackTrace: java.io.IOException: Data streamers failed while creating new block streams: [#8: failed, blk_-9223372036854775752_1003, #9: failed, blk_-9223372036854775751_1003, #0: failed, blk_-9223372036854775760_1003, #10: failed, blk_-9223372036854775750_1003, #3: failed, blk_-9223372036854775757_1003, #7: failed, blk_-9223372036854775753_1003, #4: failed, blk_-9223372036854775756_1003, #5: failed, blk_-9223372036854775755_1003]. There are not enough healthy streamers.
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamerFailures(DFSStripedOutputStream.java:651)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.writeChunk(DFSStripedOutputStream.java:567)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunks(FSOutputSummer.java:217)
	at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:125)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:111)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:57)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:96)
	at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:865)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.doTest(TestSafeModeWithStripedFile.java:122)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.testStripedFile0(TestSafeModeWithStripedFile.java:91)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
	Suppressed: java.io.IOException: Failed: the number of failed blocks = 10 > the number of parity blocks = 4
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamers(DFSStripedOutputStream.java:396)
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamerFailures(DFSStripedOutputStream.java:624)
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1188)
		at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
		at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
		at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
		at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:866)
		... 13 more



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 4096
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestSafeModeWithStripedFileWithRandomECPolicy#testStripedFile0
reconfPoint: -1
result: -1
failureMessage: Data streamers failed while creating new block streams: [#9: failed, blk_-9223372036854775751_1003, #10: failed, blk_-9223372036854775750_1003, #1: failed, blk_-9223372036854775759_1003]. There are not enough healthy streamers.
stackTrace: java.io.IOException: Data streamers failed while creating new block streams: [#9: failed, blk_-9223372036854775751_1003, #10: failed, blk_-9223372036854775750_1003, #1: failed, blk_-9223372036854775759_1003]. There are not enough healthy streamers.
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamerFailures(DFSStripedOutputStream.java:651)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.writeChunk(DFSStripedOutputStream.java:567)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunks(FSOutputSummer.java:217)
	at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:125)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:111)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:57)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:96)
	at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:865)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.doTest(TestSafeModeWithStripedFile.java:122)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.testStripedFile0(TestSafeModeWithStripedFile.java:91)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
	Suppressed: java.io.IOException: Failed: the number of failed blocks = 5 > the number of parity blocks = 4
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamers(DFSStripedOutputStream.java:396)
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamerFailures(DFSStripedOutputStream.java:624)
		at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1188)
		at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
		at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
		at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
		at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:866)
		... 13 more



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5421
