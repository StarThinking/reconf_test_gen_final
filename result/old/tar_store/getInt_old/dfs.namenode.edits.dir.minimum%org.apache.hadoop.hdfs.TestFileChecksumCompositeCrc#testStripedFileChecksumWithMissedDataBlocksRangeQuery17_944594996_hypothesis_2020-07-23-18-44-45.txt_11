reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953370663-172.17.0.5-1595529899904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42076,DS-74f30b50-83a6-450e-9601-551dade184bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-4aa94b07-adcc-4e74-9753-a64d4d284c18,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-ece3a934-931e-48db-8d41-2e0c1169324c,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-e668c134-be0c-42fd-9c68-8d4220752611,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-a3daca74-0fd8-4db7-97f9-35d3bcafc157,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-af64bd4b-e001-4ced-b4f8-fe46e5f725c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-a5179856-01a4-4789-9684-67a2dcd53992,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-33c69aac-0eca-4cb5-ba31-f8a7a4969fe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953370663-172.17.0.5-1595529899904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42076,DS-74f30b50-83a6-450e-9601-551dade184bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-4aa94b07-adcc-4e74-9753-a64d4d284c18,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-ece3a934-931e-48db-8d41-2e0c1169324c,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-e668c134-be0c-42fd-9c68-8d4220752611,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-a3daca74-0fd8-4db7-97f9-35d3bcafc157,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-af64bd4b-e001-4ced-b4f8-fe46e5f725c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-a5179856-01a4-4789-9684-67a2dcd53992,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-33c69aac-0eca-4cb5-ba31-f8a7a4969fe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2033755391-172.17.0.5-1595530343999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43776,DS-014c36f6-8382-47fe-b9e5-6e42d7fb8726,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-a9cae652-f3fe-4b48-8d80-ed771fa06268,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-3484742c-d919-49dd-a47d-6230013ef5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-1804f870-14bc-4494-9747-813fa59ee162,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-04374283-a6cd-430a-bb95-29a6bd2db76b,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-ec766d8e-6c14-444f-8eee-c100eb5ca8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-232e5bb3-19c2-4ca8-b080-5ba736dcb799,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-427bbc32-41de-4b38-b028-c5d806f7b72b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2033755391-172.17.0.5-1595530343999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43776,DS-014c36f6-8382-47fe-b9e5-6e42d7fb8726,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-a9cae652-f3fe-4b48-8d80-ed771fa06268,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-3484742c-d919-49dd-a47d-6230013ef5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-1804f870-14bc-4494-9747-813fa59ee162,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-04374283-a6cd-430a-bb95-29a6bd2db76b,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-ec766d8e-6c14-444f-8eee-c100eb5ca8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-232e5bb3-19c2-4ca8-b080-5ba736dcb799,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-427bbc32-41de-4b38-b028-c5d806f7b72b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-902752530-172.17.0.5-1595530843882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35994,DS-099c3467-109f-48a9-8f93-8ad79a6da648,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-fcc5ca2b-587e-44aa-b316-fa49c77367ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-2c81a928-4919-491a-8d72-2c5bb680e8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-9243fa3a-543f-44c3-beca-a7276b1eb8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-47549d2e-368f-4b09-b3b3-ae171ae4047a,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-9e1429cc-0947-4402-974f-4e46a54adaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-710c1844-4a58-49f2-aad9-74995ba7368d,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-ddeae44e-245c-45a6-84fc-bc4e1ec240cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-902752530-172.17.0.5-1595530843882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35994,DS-099c3467-109f-48a9-8f93-8ad79a6da648,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-fcc5ca2b-587e-44aa-b316-fa49c77367ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-2c81a928-4919-491a-8d72-2c5bb680e8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-9243fa3a-543f-44c3-beca-a7276b1eb8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-47549d2e-368f-4b09-b3b3-ae171ae4047a,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-9e1429cc-0947-4402-974f-4e46a54adaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-710c1844-4a58-49f2-aad9-74995ba7368d,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-ddeae44e-245c-45a6-84fc-bc4e1ec240cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1578749801-172.17.0.5-1595530916359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34117,DS-715dcfa2-664c-4aca-9b43-9581fdd7b8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-d9ecd7af-b66c-4288-8c88-270dce2988c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-000a5b92-1be0-4bec-82ac-e53798f32219,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-38db0a2c-ae23-4b68-ab22-5b7cb265d5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-5a8d2f0d-16e6-4858-aef2-ffae566707b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-266ec030-46a3-4b80-81ea-bdd967120c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-74b8635c-f2df-4f10-92f0-eb3c71d4d9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-99eed531-5c83-4a0f-80d4-dc33aff66909,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1578749801-172.17.0.5-1595530916359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34117,DS-715dcfa2-664c-4aca-9b43-9581fdd7b8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-d9ecd7af-b66c-4288-8c88-270dce2988c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-000a5b92-1be0-4bec-82ac-e53798f32219,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-38db0a2c-ae23-4b68-ab22-5b7cb265d5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-5a8d2f0d-16e6-4858-aef2-ffae566707b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-266ec030-46a3-4b80-81ea-bdd967120c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-74b8635c-f2df-4f10-92f0-eb3c71d4d9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-99eed531-5c83-4a0f-80d4-dc33aff66909,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-109904692-172.17.0.5-1595531073975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44887,DS-eee757d3-0482-40ab-a149-cf929d46f45a,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-8a168d92-59be-4f13-a071-47a53aa2f433,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-6997075d-6663-480e-a71b-2ec1a4ef8bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-1af0bfb4-cc7d-460e-9f6e-c25a9abeffb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-46b74b75-682b-45f3-a502-0de039ed47f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-6648175d-bb2b-44d5-93c0-3e84b294144b,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-aef6e9a1-dc6a-4b47-9d98-e0d5f69a9f57,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-036c2860-0858-4a50-8725-91772aac5956,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-109904692-172.17.0.5-1595531073975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44887,DS-eee757d3-0482-40ab-a149-cf929d46f45a,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-8a168d92-59be-4f13-a071-47a53aa2f433,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-6997075d-6663-480e-a71b-2ec1a4ef8bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-1af0bfb4-cc7d-460e-9f6e-c25a9abeffb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-46b74b75-682b-45f3-a502-0de039ed47f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-6648175d-bb2b-44d5-93c0-3e84b294144b,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-aef6e9a1-dc6a-4b47-9d98-e0d5f69a9f57,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-036c2860-0858-4a50-8725-91772aac5956,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-618683800-172.17.0.5-1595531189010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42962,DS-55dceaef-4864-4b2f-8cb9-536766a055b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-44444c23-22c8-4927-adad-3de1216fe29a,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-abd70a17-1344-45d1-827e-a15bbd97a571,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-6afb3752-ee62-4c71-a75c-fb790772db5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-35cf253c-b5c1-4178-8179-53be67fee88e,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-220de5eb-36f0-4861-887a-63fda5c90e37,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-23f09594-ddeb-4952-a8a0-e649fd6c8e18,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-b81f7e5d-6270-4153-ab02-a6c3d9c125c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-618683800-172.17.0.5-1595531189010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42962,DS-55dceaef-4864-4b2f-8cb9-536766a055b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-44444c23-22c8-4927-adad-3de1216fe29a,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-abd70a17-1344-45d1-827e-a15bbd97a571,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-6afb3752-ee62-4c71-a75c-fb790772db5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-35cf253c-b5c1-4178-8179-53be67fee88e,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-220de5eb-36f0-4861-887a-63fda5c90e37,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-23f09594-ddeb-4952-a8a0-e649fd6c8e18,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-b81f7e5d-6270-4153-ab02-a6c3d9c125c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1286429447-172.17.0.5-1595531259581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36418,DS-97226025-c9bc-4331-a8e4-61372cad4005,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-cc573b0b-5896-4f99-9c99-bbc2eca62ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-f8366253-1699-4022-9b2b-73e623af1351,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-42be27a2-e6be-4b2d-811d-df70cc63bee8,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-914cc9e4-93d9-4b2b-bdd5-01cf4e745b34,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-60250dd4-bc96-44cd-a538-62b85c934e00,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-be04f031-80c6-4336-9c11-c320634634f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-9b391de1-963d-4a2b-b803-70ed022f6350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1286429447-172.17.0.5-1595531259581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36418,DS-97226025-c9bc-4331-a8e4-61372cad4005,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-cc573b0b-5896-4f99-9c99-bbc2eca62ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-f8366253-1699-4022-9b2b-73e623af1351,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-42be27a2-e6be-4b2d-811d-df70cc63bee8,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-914cc9e4-93d9-4b2b-bdd5-01cf4e745b34,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-60250dd4-bc96-44cd-a538-62b85c934e00,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-be04f031-80c6-4336-9c11-c320634634f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-9b391de1-963d-4a2b-b803-70ed022f6350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-804310643-172.17.0.5-1595531549352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37775,DS-4f77fad7-4f22-4080-a529-3a1ccae21ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-3c9e690d-29d5-4c9a-8e8a-a34554c8e770,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-7a013d19-c899-4348-baff-1ba009d7243c,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-ce23f893-d426-490b-b805-891af5ba20ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-b6e201fc-34de-4c6a-981f-5df0229e9556,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-f7d08186-8d82-46c3-a39a-5bd23735ef28,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-a7a9c943-4260-4e5c-a989-61d76054f4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-ecc52aa7-8de7-43af-b729-7a35a6ed7780,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-804310643-172.17.0.5-1595531549352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37775,DS-4f77fad7-4f22-4080-a529-3a1ccae21ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-3c9e690d-29d5-4c9a-8e8a-a34554c8e770,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-7a013d19-c899-4348-baff-1ba009d7243c,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-ce23f893-d426-490b-b805-891af5ba20ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-b6e201fc-34de-4c6a-981f-5df0229e9556,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-f7d08186-8d82-46c3-a39a-5bd23735ef28,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-a7a9c943-4260-4e5c-a989-61d76054f4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-ecc52aa7-8de7-43af-b729-7a35a6ed7780,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-827088560-172.17.0.5-1595531584349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33835,DS-6c015118-e398-4ad5-8ca2-b4c090a2e3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-748e0461-69ad-456f-afca-ac96c8986813,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-a8924fe7-f1a4-4df9-a9fb-02f2689feb75,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-da9a4622-470c-4bb1-b4bc-1ac558f4041d,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-58ac4e96-3321-4c83-8e2e-914e967e4a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-67225066-8b44-4f53-8447-293456be1520,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-a0fcfe8e-62bb-4f99-bdbd-056239c83e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-abeb6401-1720-45ca-b6bb-fc06a632f1b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-827088560-172.17.0.5-1595531584349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33835,DS-6c015118-e398-4ad5-8ca2-b4c090a2e3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-748e0461-69ad-456f-afca-ac96c8986813,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-a8924fe7-f1a4-4df9-a9fb-02f2689feb75,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-da9a4622-470c-4bb1-b4bc-1ac558f4041d,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-58ac4e96-3321-4c83-8e2e-914e967e4a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-67225066-8b44-4f53-8447-293456be1520,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-a0fcfe8e-62bb-4f99-bdbd-056239c83e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-abeb6401-1720-45ca-b6bb-fc06a632f1b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1898516415-172.17.0.5-1595531657457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42135,DS-cc27c1d3-af5c-436a-95ac-401c956ce652,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-f6f1da45-9b88-4c06-9566-74c445a4d361,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-0ca602c4-f4be-4d76-ac76-7dafe266df6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-5007c8c2-ec56-47db-b602-7f362a9a5270,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-e3fe2b80-afab-4917-b37b-575160311ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-8f778ff7-787f-44f5-a1af-de96997f5047,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-1d55644d-8c53-429b-bef4-81a851be6385,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-b3dc3e1d-8403-4e0d-bee6-1bc29f49737e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1898516415-172.17.0.5-1595531657457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42135,DS-cc27c1d3-af5c-436a-95ac-401c956ce652,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-f6f1da45-9b88-4c06-9566-74c445a4d361,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-0ca602c4-f4be-4d76-ac76-7dafe266df6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-5007c8c2-ec56-47db-b602-7f362a9a5270,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-e3fe2b80-afab-4917-b37b-575160311ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-8f778ff7-787f-44f5-a1af-de96997f5047,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-1d55644d-8c53-429b-bef4-81a851be6385,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-b3dc3e1d-8403-4e0d-bee6-1bc29f49737e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1103718229-172.17.0.5-1595531801906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42538,DS-3966db80-2994-4bfe-9524-97fe99aa3ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-7f4cdf9e-2094-4e47-a7b2-7b824f5ef91e,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-5a12288b-cee6-40a2-a8ad-c6ae6b6f3057,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-1ed71afd-d1a4-459a-8e8c-6b8bdf1f1e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-3df2ad6c-8dd4-4b76-91de-bb67aa283b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-5e1adf4f-f1a4-44fd-9405-59f051fb2208,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-c481b562-f63c-4023-805b-3d626553da6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-f26d6e53-3e75-4443-adae-66795f691d2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1103718229-172.17.0.5-1595531801906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42538,DS-3966db80-2994-4bfe-9524-97fe99aa3ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-7f4cdf9e-2094-4e47-a7b2-7b824f5ef91e,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-5a12288b-cee6-40a2-a8ad-c6ae6b6f3057,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-1ed71afd-d1a4-459a-8e8c-6b8bdf1f1e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-3df2ad6c-8dd4-4b76-91de-bb67aa283b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-5e1adf4f-f1a4-44fd-9405-59f051fb2208,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-c481b562-f63c-4023-805b-3d626553da6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-f26d6e53-3e75-4443-adae-66795f691d2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308086419-172.17.0.5-1595531873705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37539,DS-c05c2d7f-e863-4ec2-a9d5-39f4a8a0b54d,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-467f9742-879f-42ee-9864-9c72563fe87f,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-41ac0f9f-2928-4f9b-8270-ef1dccc6a24b,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-c2424f9a-f536-4fbe-bf71-f1fac4267260,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-aa20348b-40ef-4b86-afbb-e2f056c60aae,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-98e7683c-c279-4bf3-b3e0-f60cf3aad60d,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-95819d97-2e0d-4017-a2ab-52c814cf96ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-57b636dc-2ec3-40a9-ba7f-7df4ba7d190b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308086419-172.17.0.5-1595531873705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37539,DS-c05c2d7f-e863-4ec2-a9d5-39f4a8a0b54d,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-467f9742-879f-42ee-9864-9c72563fe87f,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-41ac0f9f-2928-4f9b-8270-ef1dccc6a24b,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-c2424f9a-f536-4fbe-bf71-f1fac4267260,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-aa20348b-40ef-4b86-afbb-e2f056c60aae,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-98e7683c-c279-4bf3-b3e0-f60cf3aad60d,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-95819d97-2e0d-4017-a2ab-52c814cf96ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-57b636dc-2ec3-40a9-ba7f-7df4ba7d190b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-196457431-172.17.0.5-1595531906975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34183,DS-ada0687d-51ab-422f-a489-01a32b1355e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-8071b1ed-877a-4de8-8100-5883c5ca5f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-2b6d825b-717a-4dba-bc50-862630c485c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-ec5c2e7c-385c-41f4-9731-1b6bb73b9822,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-34607029-7102-445b-8eac-a5e084b639f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-42932376-156c-4906-8833-3e80d1edb6be,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-4e86cfc3-418d-4884-872b-97ddffb8e551,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-0b7cb55e-f318-4f5e-8b1e-84bcc7de5cbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-196457431-172.17.0.5-1595531906975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34183,DS-ada0687d-51ab-422f-a489-01a32b1355e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-8071b1ed-877a-4de8-8100-5883c5ca5f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-2b6d825b-717a-4dba-bc50-862630c485c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-ec5c2e7c-385c-41f4-9731-1b6bb73b9822,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-34607029-7102-445b-8eac-a5e084b639f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-42932376-156c-4906-8833-3e80d1edb6be,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-4e86cfc3-418d-4884-872b-97ddffb8e551,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-0b7cb55e-f318-4f5e-8b1e-84bcc7de5cbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-784954321-172.17.0.5-1595532778751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37546,DS-886dbe73-ff5b-46a0-8a83-245a19fa95d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-13aa4a67-1b00-415c-aead-9499d0803ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-f6565358-a29d-4e30-a66d-b0ab4d70df3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-e014dd38-5d59-4a3a-bce4-76521efd434b,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-4e9005b3-2dac-4416-b2e7-3b62cf9c6144,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-8deb13c4-9647-44ce-9608-3323fff6274a,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-b8f7c181-5848-4a91-a38c-fcba680c7276,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-36b59c15-d3bf-4f0e-b46c-2319d1383274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-784954321-172.17.0.5-1595532778751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37546,DS-886dbe73-ff5b-46a0-8a83-245a19fa95d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-13aa4a67-1b00-415c-aead-9499d0803ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-f6565358-a29d-4e30-a66d-b0ab4d70df3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-e014dd38-5d59-4a3a-bce4-76521efd434b,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-4e9005b3-2dac-4416-b2e7-3b62cf9c6144,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-8deb13c4-9647-44ce-9608-3323fff6274a,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-b8f7c181-5848-4a91-a38c-fcba680c7276,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-36b59c15-d3bf-4f0e-b46c-2319d1383274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-419383403-172.17.0.5-1595533483611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32976,DS-1456204b-ba62-4c57-a15a-366246606a09,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-d63c313c-63f1-4b4c-85cd-5f2ece4a20d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-1a6cdee7-5ca8-4a40-86c5-8d858e27f73a,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-8f3b60c0-f49f-4a7f-91ff-f72669ad7c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-7aa77edd-95aa-4f2b-847f-24a463f1f796,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-a1524817-6039-4d7e-913f-6a817332a0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-132dd3f5-34a6-44c4-bd24-f0443252931b,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-d6d7f99f-d1c7-4270-b2f8-85abd26717c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-419383403-172.17.0.5-1595533483611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32976,DS-1456204b-ba62-4c57-a15a-366246606a09,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-d63c313c-63f1-4b4c-85cd-5f2ece4a20d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-1a6cdee7-5ca8-4a40-86c5-8d858e27f73a,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-8f3b60c0-f49f-4a7f-91ff-f72669ad7c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-7aa77edd-95aa-4f2b-847f-24a463f1f796,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-a1524817-6039-4d7e-913f-6a817332a0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-132dd3f5-34a6-44c4-bd24-f0443252931b,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-d6d7f99f-d1c7-4270-b2f8-85abd26717c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1863627638-172.17.0.5-1595534201366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34065,DS-4d471ab8-070c-4cfd-b678-73b5bbbd9c71,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-f59fb850-7ac6-4456-8db6-32ab12cabd06,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-a68beea3-bd64-4d19-9179-1b90bdaf17e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-180e418c-cc23-4ef7-8156-3c9a2ddb0982,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-63813348-2f24-4ed8-98f9-880fe29e9775,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-e0d6bfa9-ad58-4cd0-a478-a8fa42c8d84e,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-dd908b86-515f-4615-bced-485a8cab401e,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-5874dc05-6a03-46fc-9747-8bb3c1f0f880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1863627638-172.17.0.5-1595534201366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34065,DS-4d471ab8-070c-4cfd-b678-73b5bbbd9c71,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-f59fb850-7ac6-4456-8db6-32ab12cabd06,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-a68beea3-bd64-4d19-9179-1b90bdaf17e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-180e418c-cc23-4ef7-8156-3c9a2ddb0982,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-63813348-2f24-4ed8-98f9-880fe29e9775,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-e0d6bfa9-ad58-4cd0-a478-a8fa42c8d84e,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-dd908b86-515f-4615-bced-485a8cab401e,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-5874dc05-6a03-46fc-9747-8bb3c1f0f880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1248678798-172.17.0.5-1595534601822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46228,DS-1c6b5c2d-5d90-48f0-95e1-e70cf98ad324,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-2f9993aa-d7c9-4bd9-88a3-17bee80a774a,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-46c55e28-1484-4a85-b180-791034dbd9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-abd96ea6-a629-491d-b428-31aacc1ecf88,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-0f0d21e3-f34d-4d27-a57b-7a75291341f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-0a07a740-359f-4f33-bac5-84d14c581574,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-2dd25beb-4f07-48aa-b309-ce7a68a99598,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-bdd9e038-f1cf-4925-bd92-6fa4531d2775,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1248678798-172.17.0.5-1595534601822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46228,DS-1c6b5c2d-5d90-48f0-95e1-e70cf98ad324,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-2f9993aa-d7c9-4bd9-88a3-17bee80a774a,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-46c55e28-1484-4a85-b180-791034dbd9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-abd96ea6-a629-491d-b428-31aacc1ecf88,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-0f0d21e3-f34d-4d27-a57b-7a75291341f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-0a07a740-359f-4f33-bac5-84d14c581574,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-2dd25beb-4f07-48aa-b309-ce7a68a99598,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-bdd9e038-f1cf-4925-bd92-6fa4531d2775,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970138998-172.17.0.5-1595534638146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34619,DS-afa49028-9131-4fe4-9b22-1d6c1be937db,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-f2dca5db-05e2-462e-a27c-1f33f3946c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-2c9381b3-e646-4ade-a50a-0d10ce004327,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-f139c5b4-41e7-46d1-b3f3-2001f0e5d06e,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-4eaff310-8226-4f8e-ba6b-7a6a0fd92c98,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-19ec1be2-f50a-4bc9-bc17-0b7ac36c4440,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-8e6601a9-2fcb-4701-adcd-1058e27dfd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-01886fc7-e3e8-44dd-b4fd-610c48a7e92d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970138998-172.17.0.5-1595534638146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34619,DS-afa49028-9131-4fe4-9b22-1d6c1be937db,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-f2dca5db-05e2-462e-a27c-1f33f3946c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-2c9381b3-e646-4ade-a50a-0d10ce004327,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-f139c5b4-41e7-46d1-b3f3-2001f0e5d06e,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-4eaff310-8226-4f8e-ba6b-7a6a0fd92c98,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-19ec1be2-f50a-4bc9-bc17-0b7ac36c4440,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-8e6601a9-2fcb-4701-adcd-1058e27dfd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-01886fc7-e3e8-44dd-b4fd-610c48a7e92d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-384296770-172.17.0.5-1595534948139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37266,DS-eec3cc08-866c-42c7-a277-c5c4e7aa2a22,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-e93bf74f-47ce-42c9-a482-ffbf8197369c,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-85d070c0-aed1-4dd3-bc1a-b5949d7c7749,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-e1c27815-f8aa-4e81-a9a9-d1cf0a470955,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-4046d4de-82e7-4646-af24-ba7624df2d63,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-057fae84-fa73-4fc2-a8a5-fb0049daf04a,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-ea50bba7-3b41-40b6-9384-396ed983c0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-409dfbb5-0867-473d-89ab-455d1ca777f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-384296770-172.17.0.5-1595534948139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37266,DS-eec3cc08-866c-42c7-a277-c5c4e7aa2a22,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-e93bf74f-47ce-42c9-a482-ffbf8197369c,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-85d070c0-aed1-4dd3-bc1a-b5949d7c7749,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-e1c27815-f8aa-4e81-a9a9-d1cf0a470955,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-4046d4de-82e7-4646-af24-ba7624df2d63,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-057fae84-fa73-4fc2-a8a5-fb0049daf04a,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-ea50bba7-3b41-40b6-9384-396ed983c0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-409dfbb5-0867-473d-89ab-455d1ca777f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5185
