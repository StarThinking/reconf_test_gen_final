reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631716984-172.17.0.20-1595743029617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36613,DS-92f9673c-f9ff-4747-86f1-5e278eba1d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-c7d423ae-fdc0-4902-b795-92855898bd50,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-89625bdf-716a-45fb-a581-2f358b44dbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-791b954d-4230-41f3-a0fd-7df8ea180e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-7eb8bfb0-f0ec-48ac-b33d-5da5bd68e5db,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-739f3779-9d98-4ebe-80ce-34937a34bf5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-d747e03e-c867-4e6c-b4b9-fcfa4c0fef26,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-7db0ceed-50fe-4d78-8163-e21878d03805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631716984-172.17.0.20-1595743029617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36613,DS-92f9673c-f9ff-4747-86f1-5e278eba1d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-c7d423ae-fdc0-4902-b795-92855898bd50,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-89625bdf-716a-45fb-a581-2f358b44dbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-791b954d-4230-41f3-a0fd-7df8ea180e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-7eb8bfb0-f0ec-48ac-b33d-5da5bd68e5db,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-739f3779-9d98-4ebe-80ce-34937a34bf5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-d747e03e-c867-4e6c-b4b9-fcfa4c0fef26,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-7db0ceed-50fe-4d78-8163-e21878d03805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287586363-172.17.0.20-1595743264347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38916,DS-37fe010b-7e57-40fc-98ed-34d7c06e14d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-7488581f-8815-470e-80ca-3462b9aca321,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-1b8e1e57-6c00-4346-8920-41ccfe7fdb37,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-cb2e30a8-33c2-4be5-9b42-6ec98a6921f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-aa45bdfd-cd19-4dd8-b2b2-ef96a6ed6de7,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-b60a3b9f-bee6-4088-a6ba-02b51fa31d89,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-fa1b78ed-eade-402c-b542-9f44f623fc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-2da8589b-37d7-4522-80c8-9f21f1f9e44a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287586363-172.17.0.20-1595743264347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38916,DS-37fe010b-7e57-40fc-98ed-34d7c06e14d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-7488581f-8815-470e-80ca-3462b9aca321,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-1b8e1e57-6c00-4346-8920-41ccfe7fdb37,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-cb2e30a8-33c2-4be5-9b42-6ec98a6921f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-aa45bdfd-cd19-4dd8-b2b2-ef96a6ed6de7,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-b60a3b9f-bee6-4088-a6ba-02b51fa31d89,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-fa1b78ed-eade-402c-b542-9f44f623fc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-2da8589b-37d7-4522-80c8-9f21f1f9e44a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258233452-172.17.0.20-1595743612817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44714,DS-8d374e6c-5dcb-4aaa-bd5a-61a22b7f99f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-f11df62f-5e21-4f37-af8b-f1963d946137,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-b90bb165-fb60-474b-99b6-cff691ebd214,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-afb46db0-dfb3-4d70-b179-aab21482cc21,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-478c004c-e782-4328-a87a-1ff06cbac4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-c768c74c-a315-42bc-a4e3-5e19e8618ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-4419040a-ab87-48c7-a239-4958c2ebd7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-22b2d0b6-9f90-49c7-b8f5-0be00cbe1a18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258233452-172.17.0.20-1595743612817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44714,DS-8d374e6c-5dcb-4aaa-bd5a-61a22b7f99f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-f11df62f-5e21-4f37-af8b-f1963d946137,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-b90bb165-fb60-474b-99b6-cff691ebd214,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-afb46db0-dfb3-4d70-b179-aab21482cc21,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-478c004c-e782-4328-a87a-1ff06cbac4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-c768c74c-a315-42bc-a4e3-5e19e8618ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-4419040a-ab87-48c7-a239-4958c2ebd7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-22b2d0b6-9f90-49c7-b8f5-0be00cbe1a18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503538017-172.17.0.20-1595744692736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43140,DS-34215670-68af-4dca-8eca-8bdbe7481137,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-829b44bf-fa5c-4cb4-af68-44822af619a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-af5b250a-b176-4106-a525-afe13dec0d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-7512ba6e-262e-42ea-841c-f1c0a6778399,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-9fb12b4d-5888-4d8d-ac62-c46bb234c905,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-645b2000-9896-4303-b342-ce7eecf6d121,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-5bb0a311-a7e4-48c8-b548-52dfa619b664,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-1c6968e2-5445-4de3-a454-80c1c909e006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503538017-172.17.0.20-1595744692736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43140,DS-34215670-68af-4dca-8eca-8bdbe7481137,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-829b44bf-fa5c-4cb4-af68-44822af619a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-af5b250a-b176-4106-a525-afe13dec0d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-7512ba6e-262e-42ea-841c-f1c0a6778399,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-9fb12b4d-5888-4d8d-ac62-c46bb234c905,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-645b2000-9896-4303-b342-ce7eecf6d121,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-5bb0a311-a7e4-48c8-b548-52dfa619b664,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-1c6968e2-5445-4de3-a454-80c1c909e006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1874478127-172.17.0.20-1595744917914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37565,DS-5ad72af5-c408-4769-9b2e-8bb17155d2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-3d2b94e9-1ca0-47d5-9ce7-ee6128a64906,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-ed957db6-ba4f-4a69-b1e6-6212989d1d78,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-b4736ea6-9f89-4066-9f45-d8bac48486a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-7c77e055-174d-4ed5-96b7-dc29e6815051,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-628dd10e-5152-4153-8ff6-0a21549af50e,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-29fc0da1-ed0e-4b17-9436-59aa8ef8130b,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-327a72eb-3fff-4868-9aa3-540c735fc03f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1874478127-172.17.0.20-1595744917914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37565,DS-5ad72af5-c408-4769-9b2e-8bb17155d2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-3d2b94e9-1ca0-47d5-9ce7-ee6128a64906,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-ed957db6-ba4f-4a69-b1e6-6212989d1d78,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-b4736ea6-9f89-4066-9f45-d8bac48486a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-7c77e055-174d-4ed5-96b7-dc29e6815051,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-628dd10e-5152-4153-8ff6-0a21549af50e,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-29fc0da1-ed0e-4b17-9436-59aa8ef8130b,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-327a72eb-3fff-4868-9aa3-540c735fc03f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053173976-172.17.0.20-1595745013376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42885,DS-760f2a89-4a23-42b1-983d-8390afa6c020,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-522514dc-e3be-4dea-b0c7-b70b2a5679ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-1cd23a35-97ca-49ea-97e7-70e4e2e0b157,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-6775e297-79d4-4255-ac89-214c8a266c11,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-a872170a-73c1-4043-a083-3b714f90a50c,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-f0ff04c7-5dd4-43f7-8eae-a267c0ecc98b,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-366e793a-f6eb-4886-bbdc-47d42085f98c,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-68574605-2859-4ca9-840a-87de715eb4d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053173976-172.17.0.20-1595745013376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42885,DS-760f2a89-4a23-42b1-983d-8390afa6c020,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-522514dc-e3be-4dea-b0c7-b70b2a5679ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-1cd23a35-97ca-49ea-97e7-70e4e2e0b157,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-6775e297-79d4-4255-ac89-214c8a266c11,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-a872170a-73c1-4043-a083-3b714f90a50c,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-f0ff04c7-5dd4-43f7-8eae-a267c0ecc98b,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-366e793a-f6eb-4886-bbdc-47d42085f98c,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-68574605-2859-4ca9-840a-87de715eb4d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151698671-172.17.0.20-1595745451616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46528,DS-255afb10-6f12-4006-8dc3-9ef329f6905b,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-2831499f-4e2c-4c8f-a78e-809b0fc13f63,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-732e2397-ea8a-4756-b356-fadb5fa3b392,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-bd7d54d5-9d5d-4ce7-8fe8-eea0c8d194e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-75e23107-34cc-4440-b757-6c8940886388,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-78a01eec-237b-4a08-8360-6a610cf2de19,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-288f8590-8b4d-4b20-92e0-f612df21c99a,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-6e5da10e-ae62-4bbc-9542-dc4497d76626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151698671-172.17.0.20-1595745451616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46528,DS-255afb10-6f12-4006-8dc3-9ef329f6905b,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-2831499f-4e2c-4c8f-a78e-809b0fc13f63,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-732e2397-ea8a-4756-b356-fadb5fa3b392,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-bd7d54d5-9d5d-4ce7-8fe8-eea0c8d194e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-75e23107-34cc-4440-b757-6c8940886388,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-78a01eec-237b-4a08-8360-6a610cf2de19,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-288f8590-8b4d-4b20-92e0-f612df21c99a,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-6e5da10e-ae62-4bbc-9542-dc4497d76626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775898859-172.17.0.20-1595745845413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37418,DS-80ed4362-d581-4b1b-825d-19edbde5c830,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-169f4396-205b-41f6-8032-f1627c477cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-f33df83e-f285-4e0e-9995-faedcb95fd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-49f26db2-d9c5-46b1-aab5-d63d896ba4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-649ce5a2-9dbc-4b20-b32b-a9e0ef04cefb,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-9976e3ce-0f2e-4869-8c10-003351f79904,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-65a80c4f-313e-4e25-845a-c3f0db323701,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-597bf4df-44bf-495f-8bfc-3c1993e2db4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775898859-172.17.0.20-1595745845413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37418,DS-80ed4362-d581-4b1b-825d-19edbde5c830,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-169f4396-205b-41f6-8032-f1627c477cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-f33df83e-f285-4e0e-9995-faedcb95fd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-49f26db2-d9c5-46b1-aab5-d63d896ba4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-649ce5a2-9dbc-4b20-b32b-a9e0ef04cefb,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-9976e3ce-0f2e-4869-8c10-003351f79904,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-65a80c4f-313e-4e25-845a-c3f0db323701,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-597bf4df-44bf-495f-8bfc-3c1993e2db4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355904258-172.17.0.20-1595746052884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39389,DS-28c369a2-0d58-4c0d-9325-f1170b397b82,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-aae10688-8b83-42cd-800f-f5aab75cbc21,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-d52ff6c7-2c3d-45d7-87ed-0fb1e995cea0,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-9c3765c2-8428-4d1d-b384-2ef3438cebbd,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-b470affa-19e9-429b-abfe-afa8ee00c01b,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-b156699d-91d6-4afb-98a8-917b73134024,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-41aa1912-fe00-4ea0-86e4-376f20baf206,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-60ac7f42-2282-486a-b080-00c13db8fa30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355904258-172.17.0.20-1595746052884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39389,DS-28c369a2-0d58-4c0d-9325-f1170b397b82,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-aae10688-8b83-42cd-800f-f5aab75cbc21,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-d52ff6c7-2c3d-45d7-87ed-0fb1e995cea0,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-9c3765c2-8428-4d1d-b384-2ef3438cebbd,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-b470affa-19e9-429b-abfe-afa8ee00c01b,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-b156699d-91d6-4afb-98a8-917b73134024,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-41aa1912-fe00-4ea0-86e4-376f20baf206,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-60ac7f42-2282-486a-b080-00c13db8fa30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856658436-172.17.0.20-1595746695841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38582,DS-5984173a-33e8-4367-adb9-ca35a19ee45a,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-b3353715-8d83-4e3c-897d-e6794e4fd115,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-5391ee33-d7ad-4723-8f26-f34cf90dc67f,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-3c36b5de-ec59-432e-807b-723dedde9366,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-7a5028e0-3e23-4c1a-9b25-8b533eb6fcf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-e51f6081-8b22-4fe3-bfef-eedf01819f81,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-12e5c8df-7b29-4470-9fea-78e4d20bb3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-c9cc065f-b4cb-4ee5-8240-618ce95c823e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856658436-172.17.0.20-1595746695841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38582,DS-5984173a-33e8-4367-adb9-ca35a19ee45a,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-b3353715-8d83-4e3c-897d-e6794e4fd115,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-5391ee33-d7ad-4723-8f26-f34cf90dc67f,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-3c36b5de-ec59-432e-807b-723dedde9366,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-7a5028e0-3e23-4c1a-9b25-8b533eb6fcf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-e51f6081-8b22-4fe3-bfef-eedf01819f81,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-12e5c8df-7b29-4470-9fea-78e4d20bb3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-c9cc065f-b4cb-4ee5-8240-618ce95c823e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606524332-172.17.0.20-1595746737178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34297,DS-0c6bb2ad-90d8-44a9-ba1c-9b1a60a31377,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-15b70d41-0c94-4728-9c27-c24b3e4cd794,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-16791da7-e9dc-4edd-8fc7-e064cc1894cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-26016ec2-bd51-418f-967e-7e6c2a3337ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-5c58b9b8-ef7b-4e11-a269-736814cf2846,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-05b02f9c-37ce-4447-963e-8c91c2896b44,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-d77c6111-cee4-444a-97d0-33b4076332ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-22af6b49-c865-4d71-b871-124c4bd0e9c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606524332-172.17.0.20-1595746737178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34297,DS-0c6bb2ad-90d8-44a9-ba1c-9b1a60a31377,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-15b70d41-0c94-4728-9c27-c24b3e4cd794,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-16791da7-e9dc-4edd-8fc7-e064cc1894cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-26016ec2-bd51-418f-967e-7e6c2a3337ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-5c58b9b8-ef7b-4e11-a269-736814cf2846,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-05b02f9c-37ce-4447-963e-8c91c2896b44,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-d77c6111-cee4-444a-97d0-33b4076332ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-22af6b49-c865-4d71-b871-124c4bd0e9c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1893407207-172.17.0.20-1595746758023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35412,DS-e43f9ab1-c5da-4f57-a5be-99b15db9df7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-15574f62-db55-4831-b733-4820c2a2621d,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-fb16182b-cb6f-4f93-a04c-8fabe51abbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-7b0e8d5c-29e6-4b35-96e1-71aae5c4621e,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-e2843f37-52d3-471c-9365-89475bad582e,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-d70b6f55-d643-4a15-b826-6e0a54494d59,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-dd7a7484-0eb2-4c53-8e3b-4e9907c1b283,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-920b404c-40bf-4cc3-88d0-da88f6642889,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1893407207-172.17.0.20-1595746758023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35412,DS-e43f9ab1-c5da-4f57-a5be-99b15db9df7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-15574f62-db55-4831-b733-4820c2a2621d,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-fb16182b-cb6f-4f93-a04c-8fabe51abbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-7b0e8d5c-29e6-4b35-96e1-71aae5c4621e,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-e2843f37-52d3-471c-9365-89475bad582e,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-d70b6f55-d643-4a15-b826-6e0a54494d59,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-dd7a7484-0eb2-4c53-8e3b-4e9907c1b283,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-920b404c-40bf-4cc3-88d0-da88f6642889,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-812806960-172.17.0.20-1595746841747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34278,DS-6c605a3e-b923-48f9-85b6-e19e35c71bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-8d78061f-342a-42c5-94cc-798419d935ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-26e3d32a-8c23-440f-b628-0057166cf544,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-4fbdf589-2d5a-4633-bdf2-ee6ea9cd2cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-bef49e19-8e19-4c73-ba26-85484aec43d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-50410a39-79ca-4547-9628-11d991a96573,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-64269ae1-c007-4abd-93c8-8e9340f1c4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-8abbb60c-6329-4cd6-8fcc-847bf7edaa47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-812806960-172.17.0.20-1595746841747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34278,DS-6c605a3e-b923-48f9-85b6-e19e35c71bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-8d78061f-342a-42c5-94cc-798419d935ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-26e3d32a-8c23-440f-b628-0057166cf544,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-4fbdf589-2d5a-4633-bdf2-ee6ea9cd2cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-bef49e19-8e19-4c73-ba26-85484aec43d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-50410a39-79ca-4547-9628-11d991a96573,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-64269ae1-c007-4abd-93c8-8e9340f1c4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-8abbb60c-6329-4cd6-8fcc-847bf7edaa47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-364063159-172.17.0.20-1595747011048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32999,DS-3d07f591-c840-46d1-ab5c-e293baf66f59,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-bbeecd5e-744c-4dfb-a47c-f3859a4dd760,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-e512fcb4-bf07-4e98-8ffc-95eeb5adb492,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-8ebf69d4-b282-41b2-9f8e-cf3643c5cddd,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-0af48f27-ff09-49f6-b6f2-e65695b17b98,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-14b6d950-c9ab-4a39-854c-415da6f3fd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-cbf31d48-fd23-47b0-ad5c-9e2feefdc637,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-cc0be64e-27b4-405b-b96c-738c2e9efead,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-364063159-172.17.0.20-1595747011048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32999,DS-3d07f591-c840-46d1-ab5c-e293baf66f59,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-bbeecd5e-744c-4dfb-a47c-f3859a4dd760,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-e512fcb4-bf07-4e98-8ffc-95eeb5adb492,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-8ebf69d4-b282-41b2-9f8e-cf3643c5cddd,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-0af48f27-ff09-49f6-b6f2-e65695b17b98,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-14b6d950-c9ab-4a39-854c-415da6f3fd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-cbf31d48-fd23-47b0-ad5c-9e2feefdc637,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-cc0be64e-27b4-405b-b96c-738c2e9efead,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 4321
