reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1256616495-172.17.0.13-1595662614301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38402,DS-6e495276-8163-44f1-9d94-3345ee9634ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-38f0a51b-9c5d-4ddf-8da1-f8d77ccb0392,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-d0a4c3cc-421b-49cf-8305-bf7a3c0ab287,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-81ac088f-2eae-471d-abdb-564a32e8207d,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-2f0d671d-c6a3-4767-b248-5fed6e5f766a,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-6497e80f-a673-4830-9b61-ac5599ff525c,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-ee4d17cc-9e97-4c08-88b3-f0c17cba2b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-622a9ee5-0794-4dea-b530-c883595d76b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1256616495-172.17.0.13-1595662614301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38402,DS-6e495276-8163-44f1-9d94-3345ee9634ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-38f0a51b-9c5d-4ddf-8da1-f8d77ccb0392,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-d0a4c3cc-421b-49cf-8305-bf7a3c0ab287,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-81ac088f-2eae-471d-abdb-564a32e8207d,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-2f0d671d-c6a3-4767-b248-5fed6e5f766a,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-6497e80f-a673-4830-9b61-ac5599ff525c,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-ee4d17cc-9e97-4c08-88b3-f0c17cba2b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-622a9ee5-0794-4dea-b530-c883595d76b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-461330692-172.17.0.13-1595662969783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44060,DS-9c534cfe-a8b7-46c6-9a02-b7cf7bdc7c97,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-7620e50e-bd4b-4977-b227-ecb0146ccaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-73d9ab63-a3bd-4656-b997-e396f8746626,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-54b4eef0-466c-44e0-b944-3ea10009ba87,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-ff67d7e3-8020-4279-92a1-8dedc6f60595,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-3db1a4ff-87cb-4320-87d3-85787d1eabe4,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-a64c3efa-3b02-4b44-8da0-c893e6fb0c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-9eaf78bf-3dd1-4cc7-8ede-2846a762a2f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-461330692-172.17.0.13-1595662969783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44060,DS-9c534cfe-a8b7-46c6-9a02-b7cf7bdc7c97,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-7620e50e-bd4b-4977-b227-ecb0146ccaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-73d9ab63-a3bd-4656-b997-e396f8746626,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-54b4eef0-466c-44e0-b944-3ea10009ba87,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-ff67d7e3-8020-4279-92a1-8dedc6f60595,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-3db1a4ff-87cb-4320-87d3-85787d1eabe4,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-a64c3efa-3b02-4b44-8da0-c893e6fb0c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-9eaf78bf-3dd1-4cc7-8ede-2846a762a2f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1611393305-172.17.0.13-1595663247699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41839,DS-84aa5114-e955-4b81-afd7-5b7d9b4c5b77,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-7c01d122-4593-40c1-bb40-850faa3ba19d,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-6f939d37-abfb-464b-88ca-6ce310b09b98,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-1cd198e3-2174-4f56-a8c6-2f777ffefbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-7f6a6bc4-77ae-4151-a047-91d2b55a9317,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-767ec553-9f81-4453-9a05-60dd87f199bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-06247687-0571-4f1c-9b50-0fecffb8704f,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-a59c05c3-a4a2-48d3-9dc0-7987fcf54f1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1611393305-172.17.0.13-1595663247699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41839,DS-84aa5114-e955-4b81-afd7-5b7d9b4c5b77,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-7c01d122-4593-40c1-bb40-850faa3ba19d,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-6f939d37-abfb-464b-88ca-6ce310b09b98,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-1cd198e3-2174-4f56-a8c6-2f777ffefbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-7f6a6bc4-77ae-4151-a047-91d2b55a9317,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-767ec553-9f81-4453-9a05-60dd87f199bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-06247687-0571-4f1c-9b50-0fecffb8704f,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-a59c05c3-a4a2-48d3-9dc0-7987fcf54f1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1940316773-172.17.0.13-1595663469084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36863,DS-6300f855-25ad-4ecb-afd4-d211248e1e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-ac1f11d0-233a-4a35-85c0-22f9e8523d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-3e7777cb-3808-4307-b0bb-0d95d5a4c3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-eb80e896-1904-4f54-9182-8122102d3fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-f6e08346-1a3d-4475-b68d-61a79e6b40bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-a6146b31-121f-4466-b5a9-f8678812a553,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-c1c79e6c-4f31-4370-a5a2-848cbdab5294,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-a0bf0505-97e0-4e88-a1cf-01ea144569e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1940316773-172.17.0.13-1595663469084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36863,DS-6300f855-25ad-4ecb-afd4-d211248e1e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-ac1f11d0-233a-4a35-85c0-22f9e8523d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-3e7777cb-3808-4307-b0bb-0d95d5a4c3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-eb80e896-1904-4f54-9182-8122102d3fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-f6e08346-1a3d-4475-b68d-61a79e6b40bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-a6146b31-121f-4466-b5a9-f8678812a553,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-c1c79e6c-4f31-4370-a5a2-848cbdab5294,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-a0bf0505-97e0-4e88-a1cf-01ea144569e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429458777-172.17.0.13-1595664016010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46189,DS-16257dfd-420a-4ebb-83f0-f2bae2eb836a,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-e61edee4-2655-481d-a2c4-aa58d5f2ff1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-7f1322bb-4d6f-461f-8040-896c66835bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-1a4ef697-2557-4dd1-81a7-daa897b363f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-909f7206-d3e6-4a6c-b74d-46429d4267d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-895c6552-91d7-4feb-b0f0-a0d3707314ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-ddce1d75-3604-4bf4-bff4-c3a9672e122f,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-94f884f8-8f9d-4f8c-99ef-74bc0cd42ef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429458777-172.17.0.13-1595664016010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46189,DS-16257dfd-420a-4ebb-83f0-f2bae2eb836a,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-e61edee4-2655-481d-a2c4-aa58d5f2ff1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-7f1322bb-4d6f-461f-8040-896c66835bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-1a4ef697-2557-4dd1-81a7-daa897b363f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-909f7206-d3e6-4a6c-b74d-46429d4267d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-895c6552-91d7-4feb-b0f0-a0d3707314ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-ddce1d75-3604-4bf4-bff4-c3a9672e122f,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-94f884f8-8f9d-4f8c-99ef-74bc0cd42ef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1760430152-172.17.0.13-1595665335478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43118,DS-253c4d39-55df-4ca7-9516-616a1a800d76,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-7a30576c-c534-42f1-bfcc-4e431ae2747c,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-d80445ad-a5c2-4a1f-af7d-0ff0f520384e,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-2cf41dfb-520c-479f-8e2a-551fa94982c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-8d26af98-8eba-4f65-9105-1ccb3ff0cd34,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-28f0eb4c-62a1-44b9-b881-0c3a0c9e0279,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-44d663f5-32bf-4bdf-84b2-5efaa5033217,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-56d7af67-c12c-46ba-9624-5de07a420c42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1760430152-172.17.0.13-1595665335478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43118,DS-253c4d39-55df-4ca7-9516-616a1a800d76,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-7a30576c-c534-42f1-bfcc-4e431ae2747c,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-d80445ad-a5c2-4a1f-af7d-0ff0f520384e,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-2cf41dfb-520c-479f-8e2a-551fa94982c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-8d26af98-8eba-4f65-9105-1ccb3ff0cd34,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-28f0eb4c-62a1-44b9-b881-0c3a0c9e0279,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-44d663f5-32bf-4bdf-84b2-5efaa5033217,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-56d7af67-c12c-46ba-9624-5de07a420c42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1378226386-172.17.0.13-1595666298008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42454,DS-079fbf28-2cf1-4101-a636-05a31de34d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-09514a7c-01fa-4880-8566-eea5c0c9e9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-7e5d7636-534a-42a9-b9d1-9e898babe7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-73fd23cd-7c19-4b9e-b2c7-c9818d48f46d,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-e54240c8-93af-4ec7-a4d2-4994ce3686da,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-178db6f5-64f5-4f0d-9fa1-d6e173c1f95f,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-f5c957c9-bd23-40d0-b109-555587579f58,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-a5fa7052-068e-4617-b364-9e2908f433fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1378226386-172.17.0.13-1595666298008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42454,DS-079fbf28-2cf1-4101-a636-05a31de34d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-09514a7c-01fa-4880-8566-eea5c0c9e9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-7e5d7636-534a-42a9-b9d1-9e898babe7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-73fd23cd-7c19-4b9e-b2c7-c9818d48f46d,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-e54240c8-93af-4ec7-a4d2-4994ce3686da,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-178db6f5-64f5-4f0d-9fa1-d6e173c1f95f,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-f5c957c9-bd23-40d0-b109-555587579f58,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-a5fa7052-068e-4617-b364-9e2908f433fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-650686401-172.17.0.13-1595666426411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36461,DS-a59f16b6-d078-4d11-8bc0-df138a476eab,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-828c89fd-46de-47c1-8761-c7d5dff97422,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-b21dfd1b-89f5-41e1-b8f1-3dcdb92b385a,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-27646992-d16e-4023-8232-10f4ee39dcce,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-881ef794-a4bd-4dd4-af9c-9064ed81c5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-5ab8c7d6-40ac-4e73-b118-ad6811df174f,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-861c1215-6ea5-4a41-9a80-776099bd7709,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-64503ac7-8315-42ea-ba9f-afe92fa3783d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-650686401-172.17.0.13-1595666426411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36461,DS-a59f16b6-d078-4d11-8bc0-df138a476eab,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-828c89fd-46de-47c1-8761-c7d5dff97422,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-b21dfd1b-89f5-41e1-b8f1-3dcdb92b385a,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-27646992-d16e-4023-8232-10f4ee39dcce,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-881ef794-a4bd-4dd4-af9c-9064ed81c5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-5ab8c7d6-40ac-4e73-b118-ad6811df174f,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-861c1215-6ea5-4a41-9a80-776099bd7709,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-64503ac7-8315-42ea-ba9f-afe92fa3783d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163212250-172.17.0.13-1595666476635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45540,DS-e3049e59-784a-4014-b760-98a228898205,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-c797bdf1-9755-4684-98c6-301b618e5414,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-f4d3f47a-de30-44a5-94e4-47a34244050e,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-1b6b5691-126a-4350-85c5-2929dc551acf,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-4bf5d73b-6302-40b7-b522-9b62e04dd5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-e575806a-d574-4046-a966-1f468a01a7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-3b762c10-fdf6-48cb-a83b-cade9cf282a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-3c4aa474-e5a9-45ba-93fb-6b46ff0cd2c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163212250-172.17.0.13-1595666476635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45540,DS-e3049e59-784a-4014-b760-98a228898205,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-c797bdf1-9755-4684-98c6-301b618e5414,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-f4d3f47a-de30-44a5-94e4-47a34244050e,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-1b6b5691-126a-4350-85c5-2929dc551acf,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-4bf5d73b-6302-40b7-b522-9b62e04dd5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-e575806a-d574-4046-a966-1f468a01a7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-3b762c10-fdf6-48cb-a83b-cade9cf282a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-3c4aa474-e5a9-45ba-93fb-6b46ff0cd2c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542657341-172.17.0.13-1595666791991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37459,DS-8c8319ff-f883-44d1-87a3-e69a80d5fe58,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-2dba3eeb-3e28-4b37-a19d-eaa6895788bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-6415ac81-acc4-4302-8d36-ae344bad0ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-6f9b583b-1685-4489-8f12-cbc83bb078fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-01283f36-50e8-4dfa-9620-c3f02e646a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-88c18364-ed84-4c75-8cf5-432f4534e01c,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-46c9be36-43ce-48ee-afd1-d5488dc3c8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-7057bc1c-9397-43e1-8faa-b5043ba4f417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542657341-172.17.0.13-1595666791991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37459,DS-8c8319ff-f883-44d1-87a3-e69a80d5fe58,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-2dba3eeb-3e28-4b37-a19d-eaa6895788bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-6415ac81-acc4-4302-8d36-ae344bad0ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-6f9b583b-1685-4489-8f12-cbc83bb078fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-01283f36-50e8-4dfa-9620-c3f02e646a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-88c18364-ed84-4c75-8cf5-432f4534e01c,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-46c9be36-43ce-48ee-afd1-d5488dc3c8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-7057bc1c-9397-43e1-8faa-b5043ba4f417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-208331511-172.17.0.13-1595666989633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44145,DS-c382ed84-fdfa-41a0-b2a0-9fab11d6219c,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-639cd148-42a3-4069-9e07-4793c9381be0,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-39aa9c73-e851-4910-952b-a09672452ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-ca953568-9d84-4336-bb51-695d4cab8a26,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-93741d2a-2676-4033-a5df-6b8f5239e002,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-57c1f101-32df-4f66-8a49-aa4efbc8ba31,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-ec8a4f52-0c3b-4e7a-8d6c-9370d839e83a,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-c822e631-abb4-4d30-9acf-9b5fef9118e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-208331511-172.17.0.13-1595666989633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44145,DS-c382ed84-fdfa-41a0-b2a0-9fab11d6219c,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-639cd148-42a3-4069-9e07-4793c9381be0,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-39aa9c73-e851-4910-952b-a09672452ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-ca953568-9d84-4336-bb51-695d4cab8a26,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-93741d2a-2676-4033-a5df-6b8f5239e002,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-57c1f101-32df-4f66-8a49-aa4efbc8ba31,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-ec8a4f52-0c3b-4e7a-8d6c-9370d839e83a,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-c822e631-abb4-4d30-9acf-9b5fef9118e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80635674-172.17.0.13-1595667347272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34678,DS-13f5dfbc-79bc-4b73-a422-6fc557a36fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-4ed04c87-19c5-4484-9c0b-693d68117e65,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-eb641db1-7292-4362-b131-fa4c5e046aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-57fac642-781e-490a-88fc-51e9f5d93783,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-13a7e818-1217-427c-ba24-341c33b61e05,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-9e9fa13e-43f6-4a88-9403-cd5ee217e0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-7ca70321-db66-4dd9-a97c-ef336251f052,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-bb7e8db2-5c48-47ac-adb5-586d1b9a65f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80635674-172.17.0.13-1595667347272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34678,DS-13f5dfbc-79bc-4b73-a422-6fc557a36fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-4ed04c87-19c5-4484-9c0b-693d68117e65,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-eb641db1-7292-4362-b131-fa4c5e046aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-57fac642-781e-490a-88fc-51e9f5d93783,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-13a7e818-1217-427c-ba24-341c33b61e05,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-9e9fa13e-43f6-4a88-9403-cd5ee217e0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-7ca70321-db66-4dd9-a97c-ef336251f052,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-bb7e8db2-5c48-47ac-adb5-586d1b9a65f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-906130372-172.17.0.13-1595667851999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34066,DS-09e7f716-431e-487b-822d-37983f0b708c,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-efcb6148-d75f-4e5c-a672-72179f91be6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-2939f1a3-c1fc-4347-9bc8-d5be25807077,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-cf3dc08a-2778-4c48-a13d-c0f3e95ca46f,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-66c12567-14a1-4fc9-b8af-77f028a39150,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-9d2b6739-1b00-47a0-b9cb-1b8ff8747993,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-d36b6492-1000-47f8-a0d4-24c9ef16dbed,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-200129c8-c4bd-4fe6-b4d2-07be14db376a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-906130372-172.17.0.13-1595667851999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34066,DS-09e7f716-431e-487b-822d-37983f0b708c,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-efcb6148-d75f-4e5c-a672-72179f91be6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-2939f1a3-c1fc-4347-9bc8-d5be25807077,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-cf3dc08a-2778-4c48-a13d-c0f3e95ca46f,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-66c12567-14a1-4fc9-b8af-77f028a39150,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-9d2b6739-1b00-47a0-b9cb-1b8ff8747993,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-d36b6492-1000-47f8-a0d4-24c9ef16dbed,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-200129c8-c4bd-4fe6-b4d2-07be14db376a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1618738771-172.17.0.13-1595667897695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42389,DS-1f4e1377-efb7-444a-a9eb-d1478f0a89c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-6865fb7a-d43c-4b05-ae5d-7362bf32038d,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-cac8f7f3-8782-4d1b-a432-96697aed6cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-726b428f-4df5-478c-b096-a498957fa504,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-7f238f17-e444-4c0f-a624-d9d42579b387,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-884d46d1-f37a-44e2-b09d-f91adf8c253a,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-623e7325-8cf5-48f1-8316-489da5e9e432,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-afcb2a25-3e7f-4c9e-b8ec-1efd04d3c59f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1618738771-172.17.0.13-1595667897695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42389,DS-1f4e1377-efb7-444a-a9eb-d1478f0a89c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-6865fb7a-d43c-4b05-ae5d-7362bf32038d,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-cac8f7f3-8782-4d1b-a432-96697aed6cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-726b428f-4df5-478c-b096-a498957fa504,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-7f238f17-e444-4c0f-a624-d9d42579b387,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-884d46d1-f37a-44e2-b09d-f91adf8c253a,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-623e7325-8cf5-48f1-8316-489da5e9e432,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-afcb2a25-3e7f-4c9e-b8ec-1efd04d3c59f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-918336325-172.17.0.13-1595668459390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40960,DS-02c8279c-8089-4263-973e-2486e439aa95,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-c0f48201-9c9c-493e-963e-35559ca9107a,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-228ea1d6-53e5-4bb3-8558-aef96ec6d1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-b6bb7cf7-aa2f-45e5-a094-53ea9ce625a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-49541a93-3ab0-48c1-96ee-67c854c07287,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-16f400f0-08bd-457e-b839-3d205a981d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-1e083e6b-a95f-4813-9732-ac59fa4e15f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-38b66a1d-df36-40bf-a79d-c30d55064c3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-918336325-172.17.0.13-1595668459390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40960,DS-02c8279c-8089-4263-973e-2486e439aa95,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-c0f48201-9c9c-493e-963e-35559ca9107a,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-228ea1d6-53e5-4bb3-8558-aef96ec6d1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-b6bb7cf7-aa2f-45e5-a094-53ea9ce625a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-49541a93-3ab0-48c1-96ee-67c854c07287,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-16f400f0-08bd-457e-b839-3d205a981d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-1e083e6b-a95f-4813-9732-ac59fa4e15f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-38b66a1d-df36-40bf-a79d-c30d55064c3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-303376641-172.17.0.13-1595668508260:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36668,DS-68e2704a-9858-420d-a43d-d34f432efad8,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-a18fbf2e-2f17-4a81-ba7b-9cf9dc448614,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-d7d6efb1-cd28-4dbd-b002-ec394699cdec,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-02c86486-3fa1-499f-8169-4371a90834dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-04c7fd6b-550b-4f5e-b8f4-576ea7c5633e,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-b4442f99-f038-4992-a5ff-659627159805,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-5120273b-3586-4b47-bee3-d240e7c2da5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-aeb01e9f-dc30-4122-8b04-a0b0597c167d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-303376641-172.17.0.13-1595668508260:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36668,DS-68e2704a-9858-420d-a43d-d34f432efad8,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-a18fbf2e-2f17-4a81-ba7b-9cf9dc448614,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-d7d6efb1-cd28-4dbd-b002-ec394699cdec,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-02c86486-3fa1-499f-8169-4371a90834dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-04c7fd6b-550b-4f5e-b8f4-576ea7c5633e,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-b4442f99-f038-4992-a5ff-659627159805,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-5120273b-3586-4b47-bee3-d240e7c2da5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-aeb01e9f-dc30-4122-8b04-a0b0597c167d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-955892472-172.17.0.13-1595668604153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37842,DS-569a9ee4-5f3e-47f1-a5f2-58ac39cbc06a,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-9ef7217d-05ff-4734-9832-7ce7bf9ab471,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-544f9e0d-f1e4-456b-af77-20084d978959,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-55d58d3f-fdb8-4d35-9b63-0b0f12b4d849,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-c83dea6c-ee50-4285-9228-9221a6d58792,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-275daf2d-d04b-43a0-89a5-74def68e8611,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-29e2b762-e5e3-457a-bc7c-c602a8cce56f,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-78d31c9d-d647-4539-a34a-615cc7d43ff2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-955892472-172.17.0.13-1595668604153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37842,DS-569a9ee4-5f3e-47f1-a5f2-58ac39cbc06a,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-9ef7217d-05ff-4734-9832-7ce7bf9ab471,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-544f9e0d-f1e4-456b-af77-20084d978959,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-55d58d3f-fdb8-4d35-9b63-0b0f12b4d849,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-c83dea6c-ee50-4285-9228-9221a6d58792,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-275daf2d-d04b-43a0-89a5-74def68e8611,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-29e2b762-e5e3-457a-bc7c-c602a8cce56f,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-78d31c9d-d647-4539-a34a-615cc7d43ff2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1427838294-172.17.0.13-1595668759324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39659,DS-501525c4-c996-42a1-a30c-4a8c2ac87161,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-acf2e7c3-4cb4-4f41-b7b2-b76574f5798d,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-df5e539a-8ccd-4b76-b546-0da03d23b708,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-35fcd547-7d8a-4428-9099-140aa82b3d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-bd5b82d6-28bf-4c44-bc7b-fd280e8bca03,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-56d2101e-2243-4a1a-ba27-73893ccffc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-e88ca297-a0d2-4ead-9f17-67f3af686f72,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-6deab913-5325-4b49-abac-05661f9af2a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1427838294-172.17.0.13-1595668759324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39659,DS-501525c4-c996-42a1-a30c-4a8c2ac87161,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-acf2e7c3-4cb4-4f41-b7b2-b76574f5798d,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-df5e539a-8ccd-4b76-b546-0da03d23b708,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-35fcd547-7d8a-4428-9099-140aa82b3d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-bd5b82d6-28bf-4c44-bc7b-fd280e8bca03,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-56d2101e-2243-4a1a-ba27-73893ccffc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-e88ca297-a0d2-4ead-9f17-67f3af686f72,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-6deab913-5325-4b49-abac-05661f9af2a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6871
