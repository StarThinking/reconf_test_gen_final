reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-388358224-172.17.0.12-1595693043474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43052,DS-926d0382-7fde-4128-98eb-4fbc2ec9cb51,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-9ff88778-df58-4303-bb0f-c16f9172b02f,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-0ce0a68d-dd31-4de7-8bd8-ad9525e9b0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-006a8b33-49fa-4e3e-b64d-8eb622666bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-27526289-645a-4eea-837c-01bee3603956,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-1e1638e5-99a2-4d23-8ad7-ce87c6bbd6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-6b826804-f9c4-42ae-af5f-b748ee17cf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-69fd872e-b6d7-4c27-98e0-508410e01d45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-388358224-172.17.0.12-1595693043474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43052,DS-926d0382-7fde-4128-98eb-4fbc2ec9cb51,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-9ff88778-df58-4303-bb0f-c16f9172b02f,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-0ce0a68d-dd31-4de7-8bd8-ad9525e9b0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-006a8b33-49fa-4e3e-b64d-8eb622666bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-27526289-645a-4eea-837c-01bee3603956,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-1e1638e5-99a2-4d23-8ad7-ce87c6bbd6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-6b826804-f9c4-42ae-af5f-b748ee17cf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-69fd872e-b6d7-4c27-98e0-508410e01d45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900725754-172.17.0.12-1595693157051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43425,DS-6c2ff07b-1cce-4ab8-a6aa-8628c0121d73,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-2f7cee9c-cca6-485b-a177-e5da1ad24de3,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-5385b04e-bfb2-4315-b04a-ce81962db7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-ebd3c784-9d2d-483e-8bb4-f0109955c5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-88eea7b3-56b8-46e0-b2a5-2bf74a7de154,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-67f91d7a-e385-410a-b363-5928b54d7ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-3231e420-0052-40c4-9181-1f93cb283596,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-cb0fd060-a51c-48f3-a936-6853cde1e4c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900725754-172.17.0.12-1595693157051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43425,DS-6c2ff07b-1cce-4ab8-a6aa-8628c0121d73,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-2f7cee9c-cca6-485b-a177-e5da1ad24de3,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-5385b04e-bfb2-4315-b04a-ce81962db7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-ebd3c784-9d2d-483e-8bb4-f0109955c5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-88eea7b3-56b8-46e0-b2a5-2bf74a7de154,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-67f91d7a-e385-410a-b363-5928b54d7ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-3231e420-0052-40c4-9181-1f93cb283596,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-cb0fd060-a51c-48f3-a936-6853cde1e4c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614979133-172.17.0.12-1595693198528:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34485,DS-1a591da1-885e-4892-b607-2bc061bb071f,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-c99db6cf-330a-4164-946e-cf762ca047e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-e1e57706-cd45-45b9-a1cd-6b33b545b8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-d7e8f0b2-b10b-4172-a710-4a5cb2888091,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-90ec6639-dbc2-4f63-aef5-a49ad15c3017,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-299c53bd-e7ca-4a1b-9921-c04d3b1170c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-46942a69-29cd-49d9-af85-9f1ba6a018be,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-9e9eec31-a9d2-480f-be3e-b62426cdbcfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614979133-172.17.0.12-1595693198528:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34485,DS-1a591da1-885e-4892-b607-2bc061bb071f,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-c99db6cf-330a-4164-946e-cf762ca047e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-e1e57706-cd45-45b9-a1cd-6b33b545b8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-d7e8f0b2-b10b-4172-a710-4a5cb2888091,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-90ec6639-dbc2-4f63-aef5-a49ad15c3017,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-299c53bd-e7ca-4a1b-9921-c04d3b1170c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-46942a69-29cd-49d9-af85-9f1ba6a018be,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-9e9eec31-a9d2-480f-be3e-b62426cdbcfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904851242-172.17.0.12-1595693308531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35647,DS-7721496b-14d5-4c9c-a0a5-2abad66cb4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-305e5390-9e68-45a3-b489-86bb03a8ccd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-b710e309-3136-40ef-a313-2fc3ef9f4b53,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-7ff2c522-051b-4d27-b36d-44bd005ad0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-f81d2be1-5c90-42e2-b6c7-bfb0018a75b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-d1976b8b-9769-4a3a-b247-fcd8eb594b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-cbae6db6-d98c-4b0e-8a31-b31377fcbec8,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-b8582e89-8795-40c4-be01-72596d1eef5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904851242-172.17.0.12-1595693308531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35647,DS-7721496b-14d5-4c9c-a0a5-2abad66cb4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-305e5390-9e68-45a3-b489-86bb03a8ccd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-b710e309-3136-40ef-a313-2fc3ef9f4b53,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-7ff2c522-051b-4d27-b36d-44bd005ad0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-f81d2be1-5c90-42e2-b6c7-bfb0018a75b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-d1976b8b-9769-4a3a-b247-fcd8eb594b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-cbae6db6-d98c-4b0e-8a31-b31377fcbec8,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-b8582e89-8795-40c4-be01-72596d1eef5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1922859850-172.17.0.12-1595693417589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36230,DS-626c2ae7-5bc6-4b2d-ab1a-5b0e4c50970b,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-8b822d9a-5a94-4993-abe0-a0b768963e40,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-28944e63-b924-4940-91e0-6579454afab4,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-f251141c-bdd1-4604-8632-11ee3855aee5,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-d3f1e0d7-59bc-4b62-b2ae-8a60f59d6590,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-098d1f10-b16d-41fd-84a8-df0efc270169,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-f6efa8dd-b4a9-48cf-ad13-fb8ea0d0b924,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-01fbf2f8-7beb-4c31-8e31-7014188e4718,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1922859850-172.17.0.12-1595693417589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36230,DS-626c2ae7-5bc6-4b2d-ab1a-5b0e4c50970b,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-8b822d9a-5a94-4993-abe0-a0b768963e40,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-28944e63-b924-4940-91e0-6579454afab4,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-f251141c-bdd1-4604-8632-11ee3855aee5,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-d3f1e0d7-59bc-4b62-b2ae-8a60f59d6590,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-098d1f10-b16d-41fd-84a8-df0efc270169,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-f6efa8dd-b4a9-48cf-ad13-fb8ea0d0b924,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-01fbf2f8-7beb-4c31-8e31-7014188e4718,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-179299617-172.17.0.12-1595693634122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39619,DS-ccf29065-266b-4716-95e2-4b068450c9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-f9aee68c-55ed-4394-839b-f7b23ceeda85,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-8afdc4f9-7616-448a-85b6-f5292dcfede4,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-f8594801-d3c1-4439-993c-d0970c16005d,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-0f5cb3b1-2e6f-4009-9d3d-282634742980,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-09898c5a-f17f-4c43-b4e7-b0dcd6f5e82c,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-23d9b6ee-8b5b-4924-8dd3-00d950c39ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-aeda26d6-bd2c-4fe7-b93a-c11a263890f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-179299617-172.17.0.12-1595693634122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39619,DS-ccf29065-266b-4716-95e2-4b068450c9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-f9aee68c-55ed-4394-839b-f7b23ceeda85,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-8afdc4f9-7616-448a-85b6-f5292dcfede4,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-f8594801-d3c1-4439-993c-d0970c16005d,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-0f5cb3b1-2e6f-4009-9d3d-282634742980,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-09898c5a-f17f-4c43-b4e7-b0dcd6f5e82c,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-23d9b6ee-8b5b-4924-8dd3-00d950c39ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-aeda26d6-bd2c-4fe7-b93a-c11a263890f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1628636061-172.17.0.12-1595693770223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44292,DS-d0fbe51f-74e4-49d5-938f-089aebf8d38f,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-06c06e39-a850-47f0-abe3-8788c2cf1c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-221dc435-6a56-4e9f-8b02-81220d214eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-1d7af057-921d-4dec-9083-1fd87bb2c8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-4083c744-1a3b-4303-aaa1-a060bf55e4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-c0705d02-eb22-44e0-b6c3-d7c5f528728d,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-587e0dfe-5102-459b-87e5-263c141e25bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-40f5e2f2-91c2-4aaa-b8d8-6966b010aefa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1628636061-172.17.0.12-1595693770223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44292,DS-d0fbe51f-74e4-49d5-938f-089aebf8d38f,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-06c06e39-a850-47f0-abe3-8788c2cf1c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-221dc435-6a56-4e9f-8b02-81220d214eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-1d7af057-921d-4dec-9083-1fd87bb2c8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-4083c744-1a3b-4303-aaa1-a060bf55e4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-c0705d02-eb22-44e0-b6c3-d7c5f528728d,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-587e0dfe-5102-459b-87e5-263c141e25bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-40f5e2f2-91c2-4aaa-b8d8-6966b010aefa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-227432115-172.17.0.12-1595693847026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33932,DS-0cc4be2b-986f-47cc-9f7c-e937a42baedb,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-0ee0e466-d592-48e3-971c-761ccfd459af,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-9d138e31-c610-4b38-88ca-19f5f4ec3179,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-a3906bd0-4f00-41e8-9e41-4aa17e4480f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-d35c9939-8ce3-4f75-a4d2-6e800b8d8213,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-6c11a485-0c0a-477e-b066-bd55513556bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-438ce400-debb-46cf-b515-13042190f46e,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-d22aee66-b06f-4362-b4b5-c734de508e9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-227432115-172.17.0.12-1595693847026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33932,DS-0cc4be2b-986f-47cc-9f7c-e937a42baedb,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-0ee0e466-d592-48e3-971c-761ccfd459af,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-9d138e31-c610-4b38-88ca-19f5f4ec3179,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-a3906bd0-4f00-41e8-9e41-4aa17e4480f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-d35c9939-8ce3-4f75-a4d2-6e800b8d8213,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-6c11a485-0c0a-477e-b066-bd55513556bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-438ce400-debb-46cf-b515-13042190f46e,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-d22aee66-b06f-4362-b4b5-c734de508e9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630553715-172.17.0.12-1595693960276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46570,DS-026fb679-bf59-4630-ac18-1db9d2a244a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-89a5a6f7-236f-41fa-89ba-5f45ba69b07e,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-3f674cfc-7537-498c-a76d-7975ea0a1cba,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-44f1e98b-b9f4-43f9-9241-650dd4d5d14f,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-e9c1f470-62fc-4592-b86f-b11868b76b97,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-e62333d0-19be-4b89-beb5-50c8626aa2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-e14ea2f5-ac10-4c6a-bd3a-097c7198f9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-f5fb7b45-c509-4d1b-93b7-4cc2188d45a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630553715-172.17.0.12-1595693960276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46570,DS-026fb679-bf59-4630-ac18-1db9d2a244a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-89a5a6f7-236f-41fa-89ba-5f45ba69b07e,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-3f674cfc-7537-498c-a76d-7975ea0a1cba,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-44f1e98b-b9f4-43f9-9241-650dd4d5d14f,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-e9c1f470-62fc-4592-b86f-b11868b76b97,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-e62333d0-19be-4b89-beb5-50c8626aa2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-e14ea2f5-ac10-4c6a-bd3a-097c7198f9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-f5fb7b45-c509-4d1b-93b7-4cc2188d45a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-963751618-172.17.0.12-1595694311301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37273,DS-126b2a28-d0d3-4182-b905-a9231f4f3c83,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-530c5333-5f34-44be-873f-8eb545baf03e,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-a088da71-6d54-4d6c-8885-74cbd05bcd06,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-cfa6b36a-11e5-4b5e-b82c-747f235bca77,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-448d266b-6a3c-4e02-8405-7794e6d7acd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-3c46ea5d-29f3-48b9-9909-740a98ae1405,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-94f35a64-6cc1-447b-a3c9-78986be987b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-369a8bbd-dffa-4838-858d-7cb281a9c1d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-963751618-172.17.0.12-1595694311301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37273,DS-126b2a28-d0d3-4182-b905-a9231f4f3c83,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-530c5333-5f34-44be-873f-8eb545baf03e,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-a088da71-6d54-4d6c-8885-74cbd05bcd06,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-cfa6b36a-11e5-4b5e-b82c-747f235bca77,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-448d266b-6a3c-4e02-8405-7794e6d7acd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-3c46ea5d-29f3-48b9-9909-740a98ae1405,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-94f35a64-6cc1-447b-a3c9-78986be987b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-369a8bbd-dffa-4838-858d-7cb281a9c1d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1842173463-172.17.0.12-1595694458190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43973,DS-1cb7ce49-6c6d-4a78-8302-54677d268106,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-76feb04c-169c-4963-ba62-b5f92171e19f,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-933fc582-ae68-4eae-ac1f-8c079c70a933,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-7ecd5a5c-886d-42d2-9eca-d5d1075d7b21,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-8a42de54-02c1-4eac-b528-e26432961a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-15d82b1f-74e6-4560-8f4a-253be89763f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-939f737c-853f-4810-9c04-dedf3d37ef41,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-89060e45-a560-40cf-861a-e2774d05f885,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1842173463-172.17.0.12-1595694458190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43973,DS-1cb7ce49-6c6d-4a78-8302-54677d268106,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-76feb04c-169c-4963-ba62-b5f92171e19f,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-933fc582-ae68-4eae-ac1f-8c079c70a933,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-7ecd5a5c-886d-42d2-9eca-d5d1075d7b21,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-8a42de54-02c1-4eac-b528-e26432961a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-15d82b1f-74e6-4560-8f4a-253be89763f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-939f737c-853f-4810-9c04-dedf3d37ef41,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-89060e45-a560-40cf-861a-e2774d05f885,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1328067459-172.17.0.12-1595694564431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38208,DS-d28ee3a0-4796-4a18-9178-ea01faacab30,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-ffb9c088-0b61-473c-9427-f1b034061643,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-fcde1937-b571-40f7-907f-1801c749034b,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-d5a3f0da-d66b-4dc1-9150-2250755d4e48,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-0899ae7a-25d9-4aa0-9fc3-27edc327983c,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-a2cd97ee-b00c-4bc4-80cc-c989bfc54e13,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-dea8bc83-a95e-488b-a4ad-0ac113cfa6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-eb01c2f5-03fe-4515-8073-04dca3983c25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1328067459-172.17.0.12-1595694564431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38208,DS-d28ee3a0-4796-4a18-9178-ea01faacab30,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-ffb9c088-0b61-473c-9427-f1b034061643,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-fcde1937-b571-40f7-907f-1801c749034b,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-d5a3f0da-d66b-4dc1-9150-2250755d4e48,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-0899ae7a-25d9-4aa0-9fc3-27edc327983c,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-a2cd97ee-b00c-4bc4-80cc-c989bfc54e13,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-dea8bc83-a95e-488b-a4ad-0ac113cfa6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-eb01c2f5-03fe-4515-8073-04dca3983c25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-851197888-172.17.0.12-1595694881643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38684,DS-8ed1a473-70d4-43fb-b26b-64cec270beb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-e8221370-f35a-46be-bfb1-e28ccb98718a,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-f8d0fd90-bd72-4136-afe3-8d36723d7ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-3c3a976d-1a09-4a5f-a63a-ff2309e1ef8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-9e53d638-c99c-4508-8c7c-389fd4f99f61,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-c62a7a1a-2be1-4c7d-b647-b92e0eed21ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-54fbc7ef-a30e-4652-b6e4-c5258daed366,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-04a6ee7a-5342-41e3-8811-bf040d99b45a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-851197888-172.17.0.12-1595694881643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38684,DS-8ed1a473-70d4-43fb-b26b-64cec270beb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-e8221370-f35a-46be-bfb1-e28ccb98718a,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-f8d0fd90-bd72-4136-afe3-8d36723d7ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-3c3a976d-1a09-4a5f-a63a-ff2309e1ef8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-9e53d638-c99c-4508-8c7c-389fd4f99f61,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-c62a7a1a-2be1-4c7d-b647-b92e0eed21ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-54fbc7ef-a30e-4652-b6e4-c5258daed366,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-04a6ee7a-5342-41e3-8811-bf040d99b45a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1955207634-172.17.0.12-1595695104916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41558,DS-3c792224-5f83-4827-b5a0-cc6b062ea81f,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-886fc021-48c2-4973-83ca-2674e4f61098,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-0d4d7d76-9612-4c5a-956f-e28f25412f27,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-3038f410-e661-43ba-8b89-3e8a663996dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-d9c41c63-7733-4f38-82d8-9c636733bdef,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-dae790ac-3e4b-4550-a30c-dd7e01c49d85,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-b9e4ff7c-e77f-4d27-8a73-66238128d519,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-5dda68af-02e9-42ff-9123-edcf590ab654,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1955207634-172.17.0.12-1595695104916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41558,DS-3c792224-5f83-4827-b5a0-cc6b062ea81f,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-886fc021-48c2-4973-83ca-2674e4f61098,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-0d4d7d76-9612-4c5a-956f-e28f25412f27,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-3038f410-e661-43ba-8b89-3e8a663996dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-d9c41c63-7733-4f38-82d8-9c636733bdef,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-dae790ac-3e4b-4550-a30c-dd7e01c49d85,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-b9e4ff7c-e77f-4d27-8a73-66238128d519,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-5dda68af-02e9-42ff-9123-edcf590ab654,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2089128489-172.17.0.12-1595695414394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46340,DS-f0e46ced-1cfe-47f2-98bb-e1589e39e260,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-e554d686-5ce1-431a-a01b-c0ff11b80b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-45045985-4bec-442c-ac07-07582b6598a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-d8abd874-c02e-433a-b338-9ddeb0bffb52,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-65b72512-afe6-43f8-85e5-8c1c2db8e988,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-d5aff7b0-a523-427e-8f2f-31f70c46b35f,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-06a0d4b0-81c0-4802-a7cf-00aefaca7443,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-8c2bc539-8506-45f2-b462-fd0bcff0566c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2089128489-172.17.0.12-1595695414394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46340,DS-f0e46ced-1cfe-47f2-98bb-e1589e39e260,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-e554d686-5ce1-431a-a01b-c0ff11b80b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-45045985-4bec-442c-ac07-07582b6598a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-d8abd874-c02e-433a-b338-9ddeb0bffb52,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-65b72512-afe6-43f8-85e5-8c1c2db8e988,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-d5aff7b0-a523-427e-8f2f-31f70c46b35f,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-06a0d4b0-81c0-4802-a7cf-00aefaca7443,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-8c2bc539-8506-45f2-b462-fd0bcff0566c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-316858040-172.17.0.12-1595695453657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45393,DS-74e4be1d-751a-4848-8360-7113bac518a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-e55b4e19-80b5-4424-a4b3-674aa57f6b45,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-26dc1665-2173-4ab9-adb2-bb716e6e35fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-5de2ebb1-a037-4542-a2db-f693bcccf910,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-9d0c616c-3ffd-42e9-a985-64a088a92d72,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-b1b63e6b-5470-4986-bcde-452ea00523a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-67ccf83b-b92f-49e7-a7dc-508ce72353b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-48e0bd70-8f90-4477-99f7-a42f618f7977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-316858040-172.17.0.12-1595695453657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45393,DS-74e4be1d-751a-4848-8360-7113bac518a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-e55b4e19-80b5-4424-a4b3-674aa57f6b45,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-26dc1665-2173-4ab9-adb2-bb716e6e35fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-5de2ebb1-a037-4542-a2db-f693bcccf910,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-9d0c616c-3ffd-42e9-a985-64a088a92d72,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-b1b63e6b-5470-4986-bcde-452ea00523a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-67ccf83b-b92f-49e7-a7dc-508ce72353b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-48e0bd70-8f90-4477-99f7-a42f618f7977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123276394-172.17.0.12-1595695718247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38769,DS-52e5baa8-5c07-435b-b8a9-aad9cbee16a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-bab3291d-f0e3-4d69-a6d3-e7413466af1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-61ac8d56-4b1a-4976-8d7d-eb729e9b42e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-95e0296e-be0a-44c9-bcd2-b98a599901fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-cf373ab0-4209-443f-a1ff-17138970df70,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-9d67fae1-a40d-47be-8328-033832557c90,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-54c59ae2-1697-49c8-bcbc-693fd156e1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-64e00fa4-58ed-4864-913f-6a93b1f9052b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123276394-172.17.0.12-1595695718247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38769,DS-52e5baa8-5c07-435b-b8a9-aad9cbee16a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-bab3291d-f0e3-4d69-a6d3-e7413466af1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-61ac8d56-4b1a-4976-8d7d-eb729e9b42e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-95e0296e-be0a-44c9-bcd2-b98a599901fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-cf373ab0-4209-443f-a1ff-17138970df70,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-9d67fae1-a40d-47be-8328-033832557c90,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-54c59ae2-1697-49c8-bcbc-693fd156e1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-64e00fa4-58ed-4864-913f-6a93b1f9052b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1694677124-172.17.0.12-1595695827324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36327,DS-64bbaf0b-588f-4b75-ac90-a6dc195571d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-aefd56ec-a495-4561-8344-a0092b60a0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34030,DS-7708fb95-80e9-40c4-a493-82f6704e6c73,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-ee29d409-2cfc-4aa1-9438-96bca36f6093,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-a3d7f9e3-cd20-490d-a0e2-29ef37511167,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-42eb1e39-a350-4610-8f84-6401cac3645d,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-9b57aee0-f486-4f99-a34e-30f32ec6210b,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-4bb27692-e345-4fe3-a43f-acd2d8e44ecb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1694677124-172.17.0.12-1595695827324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36327,DS-64bbaf0b-588f-4b75-ac90-a6dc195571d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-aefd56ec-a495-4561-8344-a0092b60a0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34030,DS-7708fb95-80e9-40c4-a493-82f6704e6c73,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-ee29d409-2cfc-4aa1-9438-96bca36f6093,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-a3d7f9e3-cd20-490d-a0e2-29ef37511167,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-42eb1e39-a350-4610-8f84-6401cac3645d,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-9b57aee0-f486-4f99-a34e-30f32ec6210b,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-4bb27692-e345-4fe3-a43f-acd2d8e44ecb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1854228178-172.17.0.12-1595696121354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45557,DS-cc08ca4d-99d4-4a0f-a63a-2cfb2ef2b282,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-2da59ebb-093a-4aef-bdc0-319892f3800f,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-c5ec580d-8c58-4a90-8682-302219afd1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-3384ac54-3427-4fe4-b18a-2389afc54a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-0ec1460e-5956-41dd-9e5a-ac74aea7d4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-1a538786-73bb-4c41-b8bc-2db047c6169d,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-525a8ce3-4bee-4cc4-af5b-5363cde4b91f,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-801fc5e0-7ed3-40e3-b6bb-28f72b0912ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1854228178-172.17.0.12-1595696121354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45557,DS-cc08ca4d-99d4-4a0f-a63a-2cfb2ef2b282,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-2da59ebb-093a-4aef-bdc0-319892f3800f,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-c5ec580d-8c58-4a90-8682-302219afd1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-3384ac54-3427-4fe4-b18a-2389afc54a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-0ec1460e-5956-41dd-9e5a-ac74aea7d4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-1a538786-73bb-4c41-b8bc-2db047c6169d,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-525a8ce3-4bee-4cc4-af5b-5363cde4b91f,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-801fc5e0-7ed3-40e3-b6bb-28f72b0912ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-326883193-172.17.0.12-1595696235022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41364,DS-7cc1c4fb-f38e-4d54-9b02-900c31973e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-7fc9f5b6-9eac-49bf-9196-bae76ea6a856,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-c938a50d-bc71-4ea4-a295-5a81bdf1666c,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-94d1ea41-2f97-44a7-a78e-bc42ee1884b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-adcb698f-0d3e-4a62-9d9b-58cbfd84c475,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-8a9c82c2-b1f9-49dd-b4f8-0fe4c8a0417d,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-8da5e015-4cf6-4002-98e3-d7df7503452b,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-c109e046-3cd2-4eaa-946c-e8758c6cf3e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-326883193-172.17.0.12-1595696235022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41364,DS-7cc1c4fb-f38e-4d54-9b02-900c31973e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-7fc9f5b6-9eac-49bf-9196-bae76ea6a856,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-c938a50d-bc71-4ea4-a295-5a81bdf1666c,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-94d1ea41-2f97-44a7-a78e-bc42ee1884b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-adcb698f-0d3e-4a62-9d9b-58cbfd84c475,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-8a9c82c2-b1f9-49dd-b4f8-0fe4c8a0417d,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-8da5e015-4cf6-4002-98e3-d7df7503452b,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-c109e046-3cd2-4eaa-946c-e8758c6cf3e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-605992252-172.17.0.12-1595697122880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42441,DS-b835f735-f7f8-4994-a3c3-b5c68a2b9e76,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-bb2e6649-ca4c-496b-b49f-414bda851597,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-e126ec66-790e-45e6-9a08-7a4688bf106b,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-5c637de9-401a-4cc3-bb6c-836fb3e53c09,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-cd9d66a4-9618-47e9-964a-99532171ab01,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-906be1eb-a3e9-4e96-9381-d55a7aa9e7de,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-bd9cf747-95d1-4c64-ad6c-1304a416af38,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-abdebd97-cf77-4f2a-ae3b-f8c598682e74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-605992252-172.17.0.12-1595697122880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42441,DS-b835f735-f7f8-4994-a3c3-b5c68a2b9e76,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-bb2e6649-ca4c-496b-b49f-414bda851597,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-e126ec66-790e-45e6-9a08-7a4688bf106b,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-5c637de9-401a-4cc3-bb6c-836fb3e53c09,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-cd9d66a4-9618-47e9-964a-99532171ab01,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-906be1eb-a3e9-4e96-9381-d55a7aa9e7de,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-bd9cf747-95d1-4c64-ad6c-1304a416af38,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-abdebd97-cf77-4f2a-ae3b-f8c598682e74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-322804493-172.17.0.12-1595697357982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42800,DS-bedd1950-6d4e-4849-b230-65f087f3e8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-cd07f71b-b138-443c-b647-e8e020235643,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-d50bff31-2af4-414e-82b2-9624f52ee4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-b62ee7a1-0f10-47d7-bccc-0974a0b8b784,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-153dfd05-b30a-48e2-8429-cc18adeb0c69,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-92917201-02ab-42a6-a0c9-a3dcfd73c5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40927,DS-7482203e-ddbe-401a-becc-90c3a07e3261,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-30f9facf-867f-47fc-a2f5-7635c4740dab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-322804493-172.17.0.12-1595697357982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42800,DS-bedd1950-6d4e-4849-b230-65f087f3e8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-cd07f71b-b138-443c-b647-e8e020235643,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-d50bff31-2af4-414e-82b2-9624f52ee4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-b62ee7a1-0f10-47d7-bccc-0974a0b8b784,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-153dfd05-b30a-48e2-8429-cc18adeb0c69,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-92917201-02ab-42a6-a0c9-a3dcfd73c5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40927,DS-7482203e-ddbe-401a-becc-90c3a07e3261,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-30f9facf-867f-47fc-a2f5-7635c4740dab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1112601931-172.17.0.12-1595697873557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38181,DS-59f12722-ce4e-4647-aa96-07ff69851fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-542a8f1e-fc34-472f-91dd-f0546c668189,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-2a725d1d-f63e-4aef-82e9-9f62531f2a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-6fa88c2d-8b75-43b6-b700-8ec1c57c413c,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-93a245cd-bcc2-44bc-acc2-47ad52390a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-e523233a-f838-4ffb-8f5f-b0e102186cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-d6a4a710-c7f4-4214-8016-302490fd1e88,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-9ee9c380-8924-4d55-b8c0-fbc0b69d9213,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1112601931-172.17.0.12-1595697873557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38181,DS-59f12722-ce4e-4647-aa96-07ff69851fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-542a8f1e-fc34-472f-91dd-f0546c668189,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-2a725d1d-f63e-4aef-82e9-9f62531f2a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-6fa88c2d-8b75-43b6-b700-8ec1c57c413c,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-93a245cd-bcc2-44bc-acc2-47ad52390a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-e523233a-f838-4ffb-8f5f-b0e102186cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-d6a4a710-c7f4-4214-8016-302490fd1e88,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-9ee9c380-8924-4d55-b8c0-fbc0b69d9213,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1421978624-172.17.0.12-1595698161787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39905,DS-0231ffcf-d0d0-4501-ad7f-6eaa7bb8c961,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-c952bef3-3a7e-4239-8d16-9053013df601,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-5e439136-131f-42f6-85ed-c7bfbda57c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-b484e899-17fb-4aa5-84af-a3c5e7fd7ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-9e84e09e-90e6-4938-b155-ab2564b94623,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-f0d43805-3ad8-405b-87e4-98c975bce318,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-a8004f55-6a2c-4e74-ab27-63de477d9344,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-bd4433c1-af5b-4ae5-b90a-2387ad4271c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1421978624-172.17.0.12-1595698161787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39905,DS-0231ffcf-d0d0-4501-ad7f-6eaa7bb8c961,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-c952bef3-3a7e-4239-8d16-9053013df601,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-5e439136-131f-42f6-85ed-c7bfbda57c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-b484e899-17fb-4aa5-84af-a3c5e7fd7ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-9e84e09e-90e6-4938-b155-ab2564b94623,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-f0d43805-3ad8-405b-87e4-98c975bce318,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-a8004f55-6a2c-4e74-ab27-63de477d9344,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-bd4433c1-af5b-4ae5-b90a-2387ad4271c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5560
