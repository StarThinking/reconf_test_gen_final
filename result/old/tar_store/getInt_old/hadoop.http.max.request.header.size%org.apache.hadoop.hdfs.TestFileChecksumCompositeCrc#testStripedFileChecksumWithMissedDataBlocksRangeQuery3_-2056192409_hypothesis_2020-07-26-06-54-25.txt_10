reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926453736-172.17.0.19-1595746772084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33085,DS-381ff1b1-47aa-49f4-80cb-6ad6a05ea38f,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-a9ea26ed-4de1-4227-a6c0-a7993a883919,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-66306aa3-ba5f-43e0-a8b0-57aae78d7ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-997dff11-24ea-41de-af1c-e57cc181f53b,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-b0932e09-c443-48ed-947d-3080444c753e,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-223c27df-6828-4cdb-82fb-04240e8ed847,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-587bed65-8c7f-47c2-b200-08f3f04f5323,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-a7c7bed6-b489-4302-902d-fa3b93440711,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926453736-172.17.0.19-1595746772084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33085,DS-381ff1b1-47aa-49f4-80cb-6ad6a05ea38f,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-a9ea26ed-4de1-4227-a6c0-a7993a883919,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-66306aa3-ba5f-43e0-a8b0-57aae78d7ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-997dff11-24ea-41de-af1c-e57cc181f53b,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-b0932e09-c443-48ed-947d-3080444c753e,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-223c27df-6828-4cdb-82fb-04240e8ed847,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-587bed65-8c7f-47c2-b200-08f3f04f5323,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-a7c7bed6-b489-4302-902d-fa3b93440711,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1880070187-172.17.0.19-1595746803674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46039,DS-cdd9d437-f00b-492a-8651-89c4648fca4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-1680eb9d-6ae0-496a-97fb-3c77a7a975e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-c3b0d343-33d8-4056-920c-f8d95f26cc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-6eec9eaf-a51d-403f-b5a7-f944d5457566,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-b8092faf-1d4b-417a-aa61-e6b7e9084b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-408e3d98-d312-497a-895f-8658be65ed2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-4ad1feaa-6cb9-4ec1-874d-5523a79718d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-b4800646-8a12-40e0-bf72-83ea324e4b2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1880070187-172.17.0.19-1595746803674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46039,DS-cdd9d437-f00b-492a-8651-89c4648fca4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-1680eb9d-6ae0-496a-97fb-3c77a7a975e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-c3b0d343-33d8-4056-920c-f8d95f26cc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-6eec9eaf-a51d-403f-b5a7-f944d5457566,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-b8092faf-1d4b-417a-aa61-e6b7e9084b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-408e3d98-d312-497a-895f-8658be65ed2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-4ad1feaa-6cb9-4ec1-874d-5523a79718d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-b4800646-8a12-40e0-bf72-83ea324e4b2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2022847779-172.17.0.19-1595746841097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33360,DS-b12da649-c614-4aa2-a950-a423b1b1d2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-3fe51f72-b435-475d-9f3a-bcd4ef3848b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-ed08858b-808e-4126-8b6a-17102d64545e,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-ca303fd9-c0bc-49c5-95c1-74a74675a714,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-07c1ad4c-7f91-4067-b8e1-c740143f252f,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-6c76ca6e-563e-4de5-b91c-b87b46e3ab12,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-6c448e56-0b62-4c41-a348-a4ca7174479a,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-e5f598f3-ede3-4779-813a-805ed1cbb316,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2022847779-172.17.0.19-1595746841097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33360,DS-b12da649-c614-4aa2-a950-a423b1b1d2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-3fe51f72-b435-475d-9f3a-bcd4ef3848b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-ed08858b-808e-4126-8b6a-17102d64545e,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-ca303fd9-c0bc-49c5-95c1-74a74675a714,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-07c1ad4c-7f91-4067-b8e1-c740143f252f,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-6c76ca6e-563e-4de5-b91c-b87b46e3ab12,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-6c448e56-0b62-4c41-a348-a4ca7174479a,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-e5f598f3-ede3-4779-813a-805ed1cbb316,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106684661-172.17.0.19-1595746992631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46815,DS-795613c6-5c7b-4827-9363-94c1863de2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-855b8216-8a53-4f8f-9fa1-3f773a313d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-29f7d998-cacd-4fdc-acf4-93b9767e8d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-a9dd3593-fba1-4e9d-969d-30e83bb1d7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-c64102a0-bd5e-49cb-8d04-18bbf530772a,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-37ee0b55-1152-4bee-847c-6277c824629d,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-38d87830-fc4a-4dea-8cda-58892cc58db8,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-689a57bb-c084-42c0-91f6-2d6b1a4baa25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106684661-172.17.0.19-1595746992631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46815,DS-795613c6-5c7b-4827-9363-94c1863de2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-855b8216-8a53-4f8f-9fa1-3f773a313d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-29f7d998-cacd-4fdc-acf4-93b9767e8d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-a9dd3593-fba1-4e9d-969d-30e83bb1d7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-c64102a0-bd5e-49cb-8d04-18bbf530772a,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-37ee0b55-1152-4bee-847c-6277c824629d,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-38d87830-fc4a-4dea-8cda-58892cc58db8,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-689a57bb-c084-42c0-91f6-2d6b1a4baa25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700605200-172.17.0.19-1595748388925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32806,DS-0634af58-bf31-4c78-8767-7b95e4b045f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-3bc81a26-d3d9-49d2-a7de-2918f465b076,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-1d7e4ddd-f78c-45e8-bb7b-b73064d2563b,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-87465132-12db-48b3-b0aa-d1e01d125dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-1fdf62ac-7477-4fd2-a396-3d032d3dcf72,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-c81c9ff5-bb8c-4216-9514-62aab843336f,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-9a2d1346-defe-4da9-b0a5-d8ca574c50f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-109ebbff-c87e-4b04-ae2d-8cc106cf2c76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700605200-172.17.0.19-1595748388925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32806,DS-0634af58-bf31-4c78-8767-7b95e4b045f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-3bc81a26-d3d9-49d2-a7de-2918f465b076,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-1d7e4ddd-f78c-45e8-bb7b-b73064d2563b,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-87465132-12db-48b3-b0aa-d1e01d125dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-1fdf62ac-7477-4fd2-a396-3d032d3dcf72,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-c81c9ff5-bb8c-4216-9514-62aab843336f,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-9a2d1346-defe-4da9-b0a5-d8ca574c50f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-109ebbff-c87e-4b04-ae2d-8cc106cf2c76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691928766-172.17.0.19-1595748841413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40619,DS-b149b07a-a75d-4574-83bb-dac46386d82c,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-59e9cc1c-7e78-4562-95e4-f86aec31edfb,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-6d56681f-beee-455b-aa1f-04d528def4da,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-cbc071dc-9dd4-4b4f-a2a5-e004836e349f,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-7557011b-b2c6-4598-96ee-89f1a1ed44b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-c750b976-63cb-4de9-827b-1667d7525b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-81f0b594-3318-4791-8c65-0324ed7a2861,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-c5334f8c-a4ce-43d4-8213-9748a0f69342,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691928766-172.17.0.19-1595748841413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40619,DS-b149b07a-a75d-4574-83bb-dac46386d82c,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-59e9cc1c-7e78-4562-95e4-f86aec31edfb,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-6d56681f-beee-455b-aa1f-04d528def4da,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-cbc071dc-9dd4-4b4f-a2a5-e004836e349f,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-7557011b-b2c6-4598-96ee-89f1a1ed44b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-c750b976-63cb-4de9-827b-1667d7525b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-81f0b594-3318-4791-8c65-0324ed7a2861,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-c5334f8c-a4ce-43d4-8213-9748a0f69342,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-233461030-172.17.0.19-1595749125735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43670,DS-1412af7c-4d9d-4880-bda9-b009b7b88098,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-cf2c1e66-f8f4-4ebb-8b49-b414ce36af6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-82d28b50-26a5-4898-8078-5c53b68c9c52,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-e3b9c280-3059-4b19-81aa-9e46d62ae910,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-b828b1d3-7272-4eab-bc87-28911af25d96,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-e0d12ec4-ba6d-4bef-a191-e67311330a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-33595972-449b-4009-bf19-b4730ff30365,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-4a2dce10-173b-41d2-98ab-69c4d8611380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-233461030-172.17.0.19-1595749125735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43670,DS-1412af7c-4d9d-4880-bda9-b009b7b88098,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-cf2c1e66-f8f4-4ebb-8b49-b414ce36af6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-82d28b50-26a5-4898-8078-5c53b68c9c52,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-e3b9c280-3059-4b19-81aa-9e46d62ae910,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-b828b1d3-7272-4eab-bc87-28911af25d96,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-e0d12ec4-ba6d-4bef-a191-e67311330a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-33595972-449b-4009-bf19-b4730ff30365,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-4a2dce10-173b-41d2-98ab-69c4d8611380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209631787-172.17.0.19-1595749199383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39397,DS-8f0b6c1a-59ad-4661-973b-ab6d3a7a8bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-88477175-4996-41cf-a249-83e2ae2c2027,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-443562aa-ada8-4af3-b8dc-e107b2393886,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-8fc26a0e-5c3e-4647-be9b-333ce33748c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-9991ba48-bc2c-4162-95be-354c3bc7e81c,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-da08e629-927b-4e90-a76c-cc75a6e413a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-dd41b34d-8e06-46f9-85b0-1cb63a2e30a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-b8698a8b-4461-4419-8ee0-d642d30bbbdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209631787-172.17.0.19-1595749199383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39397,DS-8f0b6c1a-59ad-4661-973b-ab6d3a7a8bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-88477175-4996-41cf-a249-83e2ae2c2027,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-443562aa-ada8-4af3-b8dc-e107b2393886,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-8fc26a0e-5c3e-4647-be9b-333ce33748c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-9991ba48-bc2c-4162-95be-354c3bc7e81c,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-da08e629-927b-4e90-a76c-cc75a6e413a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-dd41b34d-8e06-46f9-85b0-1cb63a2e30a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-b8698a8b-4461-4419-8ee0-d642d30bbbdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274674496-172.17.0.19-1595750253215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33886,DS-7ce5dc3e-fdf5-45e6-9cd6-7cf9058da6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-de8163ec-1d8c-4384-81a8-108bd1d97140,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-5a71fb8a-2fde-4879-9b37-2fc7b7d7e59e,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-61ef1b5a-fd0d-4b23-9431-f9de21d35531,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-846566de-abb4-4d51-8944-e73e44f6e4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-a6729eb6-3e6e-4f86-94c0-131ac2bf37f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-82037656-42a0-4ba1-a506-6e6ef6250ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-29803a84-3906-4d8c-b8f7-e43a06b678cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274674496-172.17.0.19-1595750253215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33886,DS-7ce5dc3e-fdf5-45e6-9cd6-7cf9058da6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-de8163ec-1d8c-4384-81a8-108bd1d97140,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-5a71fb8a-2fde-4879-9b37-2fc7b7d7e59e,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-61ef1b5a-fd0d-4b23-9431-f9de21d35531,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-846566de-abb4-4d51-8944-e73e44f6e4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-a6729eb6-3e6e-4f86-94c0-131ac2bf37f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-82037656-42a0-4ba1-a506-6e6ef6250ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-29803a84-3906-4d8c-b8f7-e43a06b678cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369943366-172.17.0.19-1595750340670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46645,DS-1a0328f9-5144-4550-bab6-9f1e278d5a61,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-0a7fd426-ad15-4a47-891b-d5b9750d3ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-63252135-37db-4727-b3b9-4c8c71249905,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-c8133c75-3cf7-4760-90c6-2395ba033eae,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-bace295b-62c6-4799-922b-220ce867a8de,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-d5446b8b-f6ff-4d7e-bfd2-95f5d653d9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-84e634f1-ef57-4e7a-9475-8f12c1cd2d85,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-d64def28-e537-4099-a332-fe7d31c27d1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369943366-172.17.0.19-1595750340670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46645,DS-1a0328f9-5144-4550-bab6-9f1e278d5a61,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-0a7fd426-ad15-4a47-891b-d5b9750d3ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-63252135-37db-4727-b3b9-4c8c71249905,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-c8133c75-3cf7-4760-90c6-2395ba033eae,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-bace295b-62c6-4799-922b-220ce867a8de,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-d5446b8b-f6ff-4d7e-bfd2-95f5d653d9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-84e634f1-ef57-4e7a-9475-8f12c1cd2d85,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-d64def28-e537-4099-a332-fe7d31c27d1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397827588-172.17.0.19-1595750387390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39352,DS-ca05b82c-995a-401a-b0fd-98c20b6a06b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-aa7459c8-f49e-4f24-b7be-88fed6b9d3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-40d14cd4-0ac9-4cb9-9910-eeccffd3d6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-4a4ba522-99c3-437a-855f-09b3e00186f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-6dcb294b-f216-419f-8c87-d3a7a0253056,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-221a3dee-f8bb-4c24-b36f-ed18c578e26f,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-cbeaa8df-8e1c-49ad-89ea-935236e0a90c,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-8934bb71-ee84-4c84-a0bc-435f11e25d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397827588-172.17.0.19-1595750387390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39352,DS-ca05b82c-995a-401a-b0fd-98c20b6a06b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-aa7459c8-f49e-4f24-b7be-88fed6b9d3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-40d14cd4-0ac9-4cb9-9910-eeccffd3d6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-4a4ba522-99c3-437a-855f-09b3e00186f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-6dcb294b-f216-419f-8c87-d3a7a0253056,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-221a3dee-f8bb-4c24-b36f-ed18c578e26f,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-cbeaa8df-8e1c-49ad-89ea-935236e0a90c,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-8934bb71-ee84-4c84-a0bc-435f11e25d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1734651160-172.17.0.19-1595750780839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33733,DS-a2f8cb85-257d-483c-aab2-07a654c898d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-82c988ce-7b8b-45f2-acff-de1f63d03132,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-233c4abd-ab7b-4cdd-9b41-d2ac29adb594,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-5b2d84ed-b8b7-4d86-91b8-0c3e2fadfd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-9f17d849-6362-4bfd-be87-d409d8576b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-60159e4a-ce93-4f62-bf0b-8c8ca594608a,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-f388bff8-64d7-4714-9b27-85b86d4ef29d,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-77efa626-0a6c-4a9e-b709-7dc2c9372dbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1734651160-172.17.0.19-1595750780839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33733,DS-a2f8cb85-257d-483c-aab2-07a654c898d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-82c988ce-7b8b-45f2-acff-de1f63d03132,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-233c4abd-ab7b-4cdd-9b41-d2ac29adb594,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-5b2d84ed-b8b7-4d86-91b8-0c3e2fadfd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-9f17d849-6362-4bfd-be87-d409d8576b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-60159e4a-ce93-4f62-bf0b-8c8ca594608a,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-f388bff8-64d7-4714-9b27-85b86d4ef29d,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-77efa626-0a6c-4a9e-b709-7dc2c9372dbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787981039-172.17.0.19-1595751168013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33768,DS-4c810b8c-c30d-4aaf-aae2-4e6c72c58a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-a40366ea-1991-4ec3-9623-f7f60a810237,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-0b1ae9a3-ca1d-4002-9f93-cc22cdc7e81f,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-ea237f63-8482-4685-a897-09ec17f6aff9,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-346f8446-7393-4cb5-be1c-896189b515d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-0185bfa7-1633-4abe-b209-b1c8c12cdb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-07c1eac3-fa04-4307-888d-dba4de76b7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-66cfa455-82e6-4475-b39d-260d3dd19d2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787981039-172.17.0.19-1595751168013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33768,DS-4c810b8c-c30d-4aaf-aae2-4e6c72c58a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-a40366ea-1991-4ec3-9623-f7f60a810237,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-0b1ae9a3-ca1d-4002-9f93-cc22cdc7e81f,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-ea237f63-8482-4685-a897-09ec17f6aff9,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-346f8446-7393-4cb5-be1c-896189b515d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-0185bfa7-1633-4abe-b209-b1c8c12cdb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-07c1eac3-fa04-4307-888d-dba4de76b7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-66cfa455-82e6-4475-b39d-260d3dd19d2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-179099285-172.17.0.19-1595751200613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42081,DS-d25f0c30-d759-4e63-aeec-32ce7fc765d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-430c5597-10a6-42ea-a6ee-574b019bd744,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-156eeb81-1e09-474a-98e3-05299744fb53,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-2f9d3474-415a-48f1-b637-1f326ac206b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-3f2609c4-61fb-4159-91a8-837496da774e,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-7a95e2d8-05e8-4f01-b17b-9b96abe0b6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-9d18670a-844d-4120-a808-1b0ac80745f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-04c9f3f2-8225-487d-bde7-73f4d2f4303b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-179099285-172.17.0.19-1595751200613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42081,DS-d25f0c30-d759-4e63-aeec-32ce7fc765d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-430c5597-10a6-42ea-a6ee-574b019bd744,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-156eeb81-1e09-474a-98e3-05299744fb53,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-2f9d3474-415a-48f1-b637-1f326ac206b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-3f2609c4-61fb-4159-91a8-837496da774e,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-7a95e2d8-05e8-4f01-b17b-9b96abe0b6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-9d18670a-844d-4120-a808-1b0ac80745f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-04c9f3f2-8225-487d-bde7-73f4d2f4303b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712574693-172.17.0.19-1595751374751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43826,DS-6c94d7f8-d2e2-45fe-9bba-b5a1f299bfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-58844285-5f57-4285-adaf-ba664210e5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-f5e54186-3a85-416a-9fa3-5415e5fc87e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-b4e4251b-1add-4152-90e3-629542164cca,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-a38557d4-9f11-4c6c-beac-5c851f156137,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-678337db-e00c-4666-b759-d732fb67adf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-ee6c1c9c-e738-403b-a6a1-d2a80b8a7d20,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-22b76232-9675-466b-a3cc-286cb03d1d15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712574693-172.17.0.19-1595751374751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43826,DS-6c94d7f8-d2e2-45fe-9bba-b5a1f299bfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-58844285-5f57-4285-adaf-ba664210e5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-f5e54186-3a85-416a-9fa3-5415e5fc87e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-b4e4251b-1add-4152-90e3-629542164cca,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-a38557d4-9f11-4c6c-beac-5c851f156137,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-678337db-e00c-4666-b759-d732fb67adf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-ee6c1c9c-e738-403b-a6a1-d2a80b8a7d20,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-22b76232-9675-466b-a3cc-286cb03d1d15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6237
