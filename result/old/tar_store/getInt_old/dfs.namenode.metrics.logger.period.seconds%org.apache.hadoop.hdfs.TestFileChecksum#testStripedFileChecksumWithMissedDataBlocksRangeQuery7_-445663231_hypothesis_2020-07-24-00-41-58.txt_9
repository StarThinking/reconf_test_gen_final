reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-379911174-172.17.0.13-1595551371423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43263,DS-b2eccb4e-2fcc-4d2e-9ee0-b3c261aa1fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-47b2d6de-a9bd-420f-95ef-5f7b84ff8cac,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-8b9d5d3d-13d1-4823-b8a5-4ca2b8d00b92,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-3a4ccdfd-248c-4f40-9990-f425f8ee21f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-cec68ab6-5ebc-430c-afa9-892c08268761,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-bbe10022-b91f-4bd9-b639-10755e97679c,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-97120cfb-df38-476b-b7fc-d8bf9dd0cce2,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-74c269c1-3cf5-4d32-8cb9-96caf3013c59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-379911174-172.17.0.13-1595551371423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43263,DS-b2eccb4e-2fcc-4d2e-9ee0-b3c261aa1fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-47b2d6de-a9bd-420f-95ef-5f7b84ff8cac,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-8b9d5d3d-13d1-4823-b8a5-4ca2b8d00b92,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-3a4ccdfd-248c-4f40-9990-f425f8ee21f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-cec68ab6-5ebc-430c-afa9-892c08268761,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-bbe10022-b91f-4bd9-b639-10755e97679c,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-97120cfb-df38-476b-b7fc-d8bf9dd0cce2,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-74c269c1-3cf5-4d32-8cb9-96caf3013c59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1136294772-172.17.0.13-1595551445219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35156,DS-84ea8b25-d96b-4714-a2ec-c046e30d6e75,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-3b61aa43-1f4d-4c74-aaa3-b4384e26fa64,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-b9943d6b-7fd8-4371-bc88-f43cc0b2b689,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-88a08c45-6def-44fa-9f8f-4828322dcbed,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-9af90fe8-1c19-4692-8aaa-e8a3d5691fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-63121ce6-69c7-4257-bc5c-3263a7a4dc96,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-d9497852-8da8-4b43-9a17-8b718391e9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-ec4cbbe7-c8bc-4d6b-9c78-9b73c5bbba7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1136294772-172.17.0.13-1595551445219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35156,DS-84ea8b25-d96b-4714-a2ec-c046e30d6e75,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-3b61aa43-1f4d-4c74-aaa3-b4384e26fa64,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-b9943d6b-7fd8-4371-bc88-f43cc0b2b689,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-88a08c45-6def-44fa-9f8f-4828322dcbed,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-9af90fe8-1c19-4692-8aaa-e8a3d5691fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-63121ce6-69c7-4257-bc5c-3263a7a4dc96,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-d9497852-8da8-4b43-9a17-8b718391e9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-ec4cbbe7-c8bc-4d6b-9c78-9b73c5bbba7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166083388-172.17.0.13-1595551512761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41197,DS-5535dfa9-5087-4a67-8f91-f87b2e794113,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-3edafca8-7e73-4b51-8f55-9bf1f233e44a,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-6f865274-47f5-42e4-b683-434ad7240317,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-805b0df0-22a9-4790-a2fb-e182d2580a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-7fde9da3-2138-4b39-aa54-64dd15fd2e39,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-d142e0a6-b7a9-4f8b-8011-f4301d9ebf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-8bc054b9-cbbe-425e-a41e-373407f22c87,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-ac500627-0cfd-494e-a50b-bd61c876f0fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166083388-172.17.0.13-1595551512761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41197,DS-5535dfa9-5087-4a67-8f91-f87b2e794113,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-3edafca8-7e73-4b51-8f55-9bf1f233e44a,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-6f865274-47f5-42e4-b683-434ad7240317,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-805b0df0-22a9-4790-a2fb-e182d2580a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-7fde9da3-2138-4b39-aa54-64dd15fd2e39,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-d142e0a6-b7a9-4f8b-8011-f4301d9ebf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-8bc054b9-cbbe-425e-a41e-373407f22c87,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-ac500627-0cfd-494e-a50b-bd61c876f0fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-701585449-172.17.0.13-1595551551916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33037,DS-26dd8439-1df6-4b6f-91fe-e3422a364cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-c1effa0d-e1fa-4b51-8797-57ec486b38a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-1929addd-ac4a-42b2-9a63-da02454b4208,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-ddc2bf2d-83af-4d0e-a690-0cfe1a5d8270,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-083afe87-0d8e-47ad-885b-e2a448076729,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-6bfc13c3-c62a-4a20-9f51-b2a956b3b49e,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-daa660f7-9afa-4b79-a511-11f3cf2a4788,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-8e05a00e-a1ff-4be5-bed3-2901d0df37ed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-701585449-172.17.0.13-1595551551916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33037,DS-26dd8439-1df6-4b6f-91fe-e3422a364cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-c1effa0d-e1fa-4b51-8797-57ec486b38a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-1929addd-ac4a-42b2-9a63-da02454b4208,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-ddc2bf2d-83af-4d0e-a690-0cfe1a5d8270,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-083afe87-0d8e-47ad-885b-e2a448076729,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-6bfc13c3-c62a-4a20-9f51-b2a956b3b49e,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-daa660f7-9afa-4b79-a511-11f3cf2a4788,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-8e05a00e-a1ff-4be5-bed3-2901d0df37ed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1689012540-172.17.0.13-1595551689672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40386,DS-c3bc7a66-1396-4dc9-921a-05c2aa07a449,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-d8d4ec9a-df2d-443c-8c42-db0195b78ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-8539ccdc-1c47-4082-9cb5-29844ea2c020,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-e655ea0c-9960-44d5-aff1-ff3bdb760c30,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-00b0c1fb-020f-47d0-af15-b90898e05196,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-adadae39-2053-49d3-88ce-6770cf130985,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-1ce05333-edb2-4d75-bc43-a7e5cddafd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-94fb5dcc-1a81-4fe5-bdaf-7a37c7805300,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1689012540-172.17.0.13-1595551689672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40386,DS-c3bc7a66-1396-4dc9-921a-05c2aa07a449,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-d8d4ec9a-df2d-443c-8c42-db0195b78ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-8539ccdc-1c47-4082-9cb5-29844ea2c020,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-e655ea0c-9960-44d5-aff1-ff3bdb760c30,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-00b0c1fb-020f-47d0-af15-b90898e05196,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-adadae39-2053-49d3-88ce-6770cf130985,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-1ce05333-edb2-4d75-bc43-a7e5cddafd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-94fb5dcc-1a81-4fe5-bdaf-7a37c7805300,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758243331-172.17.0.13-1595551750599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34643,DS-7feabc4f-5171-441d-a70c-acda349b0929,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-a2549b27-4a29-4d80-877e-00c7035f22de,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-b91732a9-0d4c-4110-8d7a-57f0507286ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-67c0c225-0e71-4256-86c1-222d81a476a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-ac5b8fdd-c5b0-4f4a-8695-b089cacfd9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-139f0dfa-8a2a-4643-a6d2-01dacc47d2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-2e7e432e-404e-496e-b9d3-f2cf13bbe627,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-1091640d-be90-4ab1-86c7-12b856f0e091,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758243331-172.17.0.13-1595551750599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34643,DS-7feabc4f-5171-441d-a70c-acda349b0929,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-a2549b27-4a29-4d80-877e-00c7035f22de,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-b91732a9-0d4c-4110-8d7a-57f0507286ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-67c0c225-0e71-4256-86c1-222d81a476a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-ac5b8fdd-c5b0-4f4a-8695-b089cacfd9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-139f0dfa-8a2a-4643-a6d2-01dacc47d2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-2e7e432e-404e-496e-b9d3-f2cf13bbe627,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-1091640d-be90-4ab1-86c7-12b856f0e091,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823417759-172.17.0.13-1595551786973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45518,DS-707ffdfa-fe29-40cb-8d52-dc8b6c3e2d45,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-47ef391b-4420-4e45-a569-97fec398091f,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-9131fa1e-f1a6-43a6-8326-e18bf645e58c,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-4dca2da2-7366-4b7d-8567-b48d05a09256,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-cbc8eacc-6b81-42e6-b1b8-2e25cb29f862,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-3651655f-4b3c-47d6-8b49-1fabb626ee7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-3755d149-c98a-402d-8efb-2e5983039e21,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-6b2b9ce4-719f-4dd9-b3ac-b88af98625be,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823417759-172.17.0.13-1595551786973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45518,DS-707ffdfa-fe29-40cb-8d52-dc8b6c3e2d45,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-47ef391b-4420-4e45-a569-97fec398091f,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-9131fa1e-f1a6-43a6-8326-e18bf645e58c,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-4dca2da2-7366-4b7d-8567-b48d05a09256,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-cbc8eacc-6b81-42e6-b1b8-2e25cb29f862,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-3651655f-4b3c-47d6-8b49-1fabb626ee7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-3755d149-c98a-402d-8efb-2e5983039e21,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-6b2b9ce4-719f-4dd9-b3ac-b88af98625be,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258017117-172.17.0.13-1595552017644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35126,DS-47094575-8399-48c4-835e-417a7b8e246e,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-9980c3c9-7913-4e3a-a4a8-8f3a2ff32c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-c1f3f163-5973-41df-bebe-a3f6d35c7540,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-294a8ef7-a096-4b0e-9b53-d7236722b054,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-3eacc7ec-8033-4763-98e2-e288fed999b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-751daa9c-4c79-4481-b30e-fbaba216b4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-404cf6eb-b68e-4ead-b1b3-8c57a7ccd155,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-baa1a4fa-9192-4009-9450-3a1781cd7eac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258017117-172.17.0.13-1595552017644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35126,DS-47094575-8399-48c4-835e-417a7b8e246e,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-9980c3c9-7913-4e3a-a4a8-8f3a2ff32c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-c1f3f163-5973-41df-bebe-a3f6d35c7540,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-294a8ef7-a096-4b0e-9b53-d7236722b054,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-3eacc7ec-8033-4763-98e2-e288fed999b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-751daa9c-4c79-4481-b30e-fbaba216b4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-404cf6eb-b68e-4ead-b1b3-8c57a7ccd155,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-baa1a4fa-9192-4009-9450-3a1781cd7eac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996447163-172.17.0.13-1595552114599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42555,DS-f2389bb2-0f0b-4740-a5ae-da08ac50d0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-a6c8df0f-6e42-4a61-998d-88510eb9e3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-82ade4ec-acad-4275-b15a-0b50b13599e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-eaa2bf95-805c-4a88-82df-b4d5b4455700,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-15f1a732-8a29-47fe-82d9-bc71c06ea6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-6e6206be-e6a5-4e58-b91e-f98eeb189534,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-76b1a21a-f747-4347-a028-67d721e61805,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-5076fbb5-df8f-4206-b3c8-2095f0de5f58,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996447163-172.17.0.13-1595552114599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42555,DS-f2389bb2-0f0b-4740-a5ae-da08ac50d0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-a6c8df0f-6e42-4a61-998d-88510eb9e3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-82ade4ec-acad-4275-b15a-0b50b13599e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-eaa2bf95-805c-4a88-82df-b4d5b4455700,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-15f1a732-8a29-47fe-82d9-bc71c06ea6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-6e6206be-e6a5-4e58-b91e-f98eeb189534,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-76b1a21a-f747-4347-a028-67d721e61805,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-5076fbb5-df8f-4206-b3c8-2095f0de5f58,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772551331-172.17.0.13-1595552336356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34892,DS-89fc6999-1eee-49f8-b410-5d455733dd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-f2584dee-a50d-43a6-8fb3-e73bd334e706,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-3b91f7cb-eed5-4e2f-8565-0f0487906889,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-cd464405-64fe-4c69-82a4-d3161708bace,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-a9bfe263-d1c2-4844-b36f-148c6d57f4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-c9243e5f-7ad1-4da0-b838-8b430c24a913,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-ef5d42a2-0c7c-40e1-8d2a-c819b65e331e,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-6db28b33-c32f-4c34-9066-8d69665d853d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772551331-172.17.0.13-1595552336356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34892,DS-89fc6999-1eee-49f8-b410-5d455733dd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-f2584dee-a50d-43a6-8fb3-e73bd334e706,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-3b91f7cb-eed5-4e2f-8565-0f0487906889,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-cd464405-64fe-4c69-82a4-d3161708bace,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-a9bfe263-d1c2-4844-b36f-148c6d57f4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-c9243e5f-7ad1-4da0-b838-8b430c24a913,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-ef5d42a2-0c7c-40e1-8d2a-c819b65e331e,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-6db28b33-c32f-4c34-9066-8d69665d853d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084157529-172.17.0.13-1595552440218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43022,DS-f35abd75-1777-4fa5-9c9d-26654585eed8,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-8f1b2707-c798-4047-b259-339730e1eb67,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-133fa2bf-20a6-43f4-9027-1c9fa930e349,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-6a9df2d9-da08-45c8-81c4-44eefe326362,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-4bdebe69-a5f0-44e6-92f2-220912433371,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-807d3eea-ac54-4424-ac00-714c1a468378,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-83cc9be4-84d7-42b8-a662-46a4dc435407,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-a6acd1d1-e1df-4910-9550-3c50cb3d06ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084157529-172.17.0.13-1595552440218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43022,DS-f35abd75-1777-4fa5-9c9d-26654585eed8,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-8f1b2707-c798-4047-b259-339730e1eb67,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-133fa2bf-20a6-43f4-9027-1c9fa930e349,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-6a9df2d9-da08-45c8-81c4-44eefe326362,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-4bdebe69-a5f0-44e6-92f2-220912433371,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-807d3eea-ac54-4424-ac00-714c1a468378,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-83cc9be4-84d7-42b8-a662-46a4dc435407,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-a6acd1d1-e1df-4910-9550-3c50cb3d06ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-720536192-172.17.0.13-1595552558879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34013,DS-bf4d1c7a-7699-4906-8754-bfcfdc39f1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-d9077239-19e6-4744-a8b2-69dbe497f09e,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-12634014-4f61-4943-b16e-20bd74e8bc45,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-936d10e7-07a2-462c-b249-593e0635945a,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-b167cd60-ffb6-48f9-8206-9be4aa1afa72,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-c37f7391-9882-435f-a3f4-0122c84b5d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-716d81fc-e025-46d1-b485-e16d85983a32,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-50a078a5-837b-40c3-a1ee-a8af567d81af,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-720536192-172.17.0.13-1595552558879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34013,DS-bf4d1c7a-7699-4906-8754-bfcfdc39f1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-d9077239-19e6-4744-a8b2-69dbe497f09e,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-12634014-4f61-4943-b16e-20bd74e8bc45,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-936d10e7-07a2-462c-b249-593e0635945a,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-b167cd60-ffb6-48f9-8206-9be4aa1afa72,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-c37f7391-9882-435f-a3f4-0122c84b5d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-716d81fc-e025-46d1-b485-e16d85983a32,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-50a078a5-837b-40c3-a1ee-a8af567d81af,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825706656-172.17.0.13-1595552843038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43978,DS-168da082-06b7-4263-a09a-e0818d0acfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-ad9e910f-697a-4192-aa1d-45b1568efd95,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-9c18dcb8-b195-4c62-aad2-f204c0401b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-2c327681-a366-4285-b6e3-373bf87ea95b,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-f1416304-2cbb-4eae-b777-562bb041cb50,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-e4233b99-8c38-4a3d-a719-a84f3af58251,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-ddc623b1-e2e4-4df1-b69c-8defc9b1583d,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-65c41463-2029-4d34-ae3a-6ea615ad77ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825706656-172.17.0.13-1595552843038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43978,DS-168da082-06b7-4263-a09a-e0818d0acfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-ad9e910f-697a-4192-aa1d-45b1568efd95,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-9c18dcb8-b195-4c62-aad2-f204c0401b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-2c327681-a366-4285-b6e3-373bf87ea95b,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-f1416304-2cbb-4eae-b777-562bb041cb50,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-e4233b99-8c38-4a3d-a719-a84f3af58251,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-ddc623b1-e2e4-4df1-b69c-8defc9b1583d,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-65c41463-2029-4d34-ae3a-6ea615ad77ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341321541-172.17.0.13-1595553011648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38410,DS-d816de03-6802-48da-8469-bdc93359e971,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-e68783fc-44a2-475b-88ad-57399af5c54e,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-d00d4d5b-9662-4efe-94d2-c4d385b4f733,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-2eef09bc-2e4e-4a75-b8fc-e3f82cc2a0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-86abbce1-c0e0-4b4f-8ced-491863e85b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-d9c4e6b7-0d19-40ff-93ac-1803d17fb6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-641f7b74-2d0f-4654-beeb-70bec8eb0679,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-cf7de03f-737f-4041-b6c9-bb2f949dc9b2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341321541-172.17.0.13-1595553011648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38410,DS-d816de03-6802-48da-8469-bdc93359e971,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-e68783fc-44a2-475b-88ad-57399af5c54e,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-d00d4d5b-9662-4efe-94d2-c4d385b4f733,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-2eef09bc-2e4e-4a75-b8fc-e3f82cc2a0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-86abbce1-c0e0-4b4f-8ced-491863e85b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-d9c4e6b7-0d19-40ff-93ac-1803d17fb6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-641f7b74-2d0f-4654-beeb-70bec8eb0679,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-cf7de03f-737f-4041-b6c9-bb2f949dc9b2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-94933553-172.17.0.13-1595553045898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33736,DS-bb3a0f16-c815-434c-b3d5-10a6184ac772,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-cf97a4f2-c6bb-4606-929d-8118d9652f68,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-0570aeb1-e7f1-46b2-a650-02d22743c30f,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-c50e7c9b-0ee3-4839-8ed6-bf71215b53c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-9f08ee2d-c6ee-4b9b-b9c2-586c90b7e15d,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-04b552bf-4be2-428c-a60e-1b9df8ebd2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-3b256015-1b01-4de8-a7ed-200f062b8b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-e26602d7-69ac-4f60-9c37-61f244aef7eb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-94933553-172.17.0.13-1595553045898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33736,DS-bb3a0f16-c815-434c-b3d5-10a6184ac772,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-cf97a4f2-c6bb-4606-929d-8118d9652f68,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-0570aeb1-e7f1-46b2-a650-02d22743c30f,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-c50e7c9b-0ee3-4839-8ed6-bf71215b53c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-9f08ee2d-c6ee-4b9b-b9c2-586c90b7e15d,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-04b552bf-4be2-428c-a60e-1b9df8ebd2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-3b256015-1b01-4de8-a7ed-200f062b8b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-e26602d7-69ac-4f60-9c37-61f244aef7eb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1297806541-172.17.0.13-1595553079370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45536,DS-32cb5973-4164-4e0b-8998-db683ef3f96a,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-b5c05fc8-c808-4110-ab95-5a135bc333c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-e2e74b9b-bea5-4807-b5cb-ee67e8385b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-1aa7523e-d221-4691-8896-518352d0a19c,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-e6b97cdb-3099-4828-a183-849d724cf1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-245e264d-290a-45da-91bd-2ba31e282f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-3f0714d1-1c96-4be5-b707-dcba56fabcca,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-d381d519-e7a4-40cc-998c-124707dc6dcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1297806541-172.17.0.13-1595553079370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45536,DS-32cb5973-4164-4e0b-8998-db683ef3f96a,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-b5c05fc8-c808-4110-ab95-5a135bc333c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-e2e74b9b-bea5-4807-b5cb-ee67e8385b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-1aa7523e-d221-4691-8896-518352d0a19c,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-e6b97cdb-3099-4828-a183-849d724cf1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-245e264d-290a-45da-91bd-2ba31e282f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-3f0714d1-1c96-4be5-b707-dcba56fabcca,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-d381d519-e7a4-40cc-998c-124707dc6dcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643774991-172.17.0.13-1595553249080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34240,DS-a7f37098-ef63-4f0d-af2d-bdcb1db697b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-3ee0cdec-07d2-4328-8f9d-5c3715289364,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-308706b2-8674-497d-ac9f-dc9dadb54846,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-96c04ad9-97cd-411f-9ffd-bc66113dfc47,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-e06ca5d7-c23a-4ce0-87b9-36951f4bcf24,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-bf6ac768-271b-4051-b5b2-5d759e638648,DISK], DatanodeInfoWithStorage[127.0.0.1:45758,DS-7d32c77a-8af9-44d9-8153-dcb588bf758e,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-aa06685d-b0cd-40a5-be3f-3bee8b8fc4dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643774991-172.17.0.13-1595553249080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34240,DS-a7f37098-ef63-4f0d-af2d-bdcb1db697b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-3ee0cdec-07d2-4328-8f9d-5c3715289364,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-308706b2-8674-497d-ac9f-dc9dadb54846,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-96c04ad9-97cd-411f-9ffd-bc66113dfc47,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-e06ca5d7-c23a-4ce0-87b9-36951f4bcf24,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-bf6ac768-271b-4051-b5b2-5d759e638648,DISK], DatanodeInfoWithStorage[127.0.0.1:45758,DS-7d32c77a-8af9-44d9-8153-dcb588bf758e,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-aa06685d-b0cd-40a5-be3f-3bee8b8fc4dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612580124-172.17.0.13-1595553408111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39104,DS-d28a6a58-9de5-46d1-9d87-50ab7071278d,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-06f0385d-dbd0-4733-b15d-ba5ecab06eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-4b274041-93d3-48d7-b00d-71fd5fd6fc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-be4bca64-7cc9-440e-b2ba-7669992e5e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-c9dc7354-7528-4b04-934c-9677340b7c00,DISK], DatanodeInfoWithStorage[127.0.0.1:40389,DS-c1eced0f-280a-4114-9063-773122e62d31,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-a6a1350e-130d-4432-bbbb-1edcaba48490,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-1ba11a89-a4e9-48b1-8c46-b92f2dd226c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612580124-172.17.0.13-1595553408111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39104,DS-d28a6a58-9de5-46d1-9d87-50ab7071278d,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-06f0385d-dbd0-4733-b15d-ba5ecab06eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-4b274041-93d3-48d7-b00d-71fd5fd6fc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-be4bca64-7cc9-440e-b2ba-7669992e5e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-c9dc7354-7528-4b04-934c-9677340b7c00,DISK], DatanodeInfoWithStorage[127.0.0.1:40389,DS-c1eced0f-280a-4114-9063-773122e62d31,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-a6a1350e-130d-4432-bbbb-1edcaba48490,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-1ba11a89-a4e9-48b1-8c46-b92f2dd226c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-682525153-172.17.0.13-1595553517321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46008,DS-fde55d34-008b-40f1-9fc4-155b1c8924c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-64f4eb4a-4f14-4818-95ca-66a2230c840a,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-0afa9fc4-33a9-4162-a7f7-c00bbd3f0140,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-4edf78e8-b49c-4d01-ad70-87ff7ab016cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-09f476d5-a145-489f-8c1d-b01f3fe663c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-54fb8cc1-0dcc-449d-9b5e-2ded0cdd72bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-4620cb2a-ef67-48dd-bad7-42db2ecd204c,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-360457d0-52ec-4742-90d5-bee237b22cae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-682525153-172.17.0.13-1595553517321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46008,DS-fde55d34-008b-40f1-9fc4-155b1c8924c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-64f4eb4a-4f14-4818-95ca-66a2230c840a,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-0afa9fc4-33a9-4162-a7f7-c00bbd3f0140,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-4edf78e8-b49c-4d01-ad70-87ff7ab016cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-09f476d5-a145-489f-8c1d-b01f3fe663c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-54fb8cc1-0dcc-449d-9b5e-2ded0cdd72bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-4620cb2a-ef67-48dd-bad7-42db2ecd204c,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-360457d0-52ec-4742-90d5-bee237b22cae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914711290-172.17.0.13-1595553553032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38748,DS-f58c6e3a-ddb6-4fc2-9dd1-90032fd15c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-2c066caa-d499-4fbd-b20a-56fee765d416,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-eabea8c8-52ad-4724-a9d6-37380b0867f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-fa162393-8c30-46c5-9b29-c637ecd376ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-39d73419-915f-4bd9-beb4-b5d2d779b349,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-95c5be8d-7ddb-4298-b88a-df97e08d359f,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-e022ec0e-40ad-4413-86d5-6740e7f2a3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-db707cd1-4cd0-40d0-8b97-2c1001656434,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914711290-172.17.0.13-1595553553032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38748,DS-f58c6e3a-ddb6-4fc2-9dd1-90032fd15c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-2c066caa-d499-4fbd-b20a-56fee765d416,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-eabea8c8-52ad-4724-a9d6-37380b0867f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-fa162393-8c30-46c5-9b29-c637ecd376ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-39d73419-915f-4bd9-beb4-b5d2d779b349,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-95c5be8d-7ddb-4298-b88a-df97e08d359f,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-e022ec0e-40ad-4413-86d5-6740e7f2a3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-db707cd1-4cd0-40d0-8b97-2c1001656434,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616947145-172.17.0.13-1595553585132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33437,DS-70dc4736-fae5-48aa-b6ea-073653894eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-0f538b96-44be-4788-81ba-9b3a31639daa,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-08f84d07-a321-45e1-bdba-fa616b69f366,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-c24ef99f-df85-43c7-b5a1-8a752b53ee38,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-68a06d05-3e53-4a05-a180-f93e6abb966a,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-ec865431-063c-43b4-ab1e-e977896d0b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-240983ed-79b2-466c-92d2-ac5ea7d60b66,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-5dd23ad9-594a-4dbb-bde4-dc043feccc37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616947145-172.17.0.13-1595553585132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33437,DS-70dc4736-fae5-48aa-b6ea-073653894eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-0f538b96-44be-4788-81ba-9b3a31639daa,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-08f84d07-a321-45e1-bdba-fa616b69f366,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-c24ef99f-df85-43c7-b5a1-8a752b53ee38,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-68a06d05-3e53-4a05-a180-f93e6abb966a,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-ec865431-063c-43b4-ab1e-e977896d0b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-240983ed-79b2-466c-92d2-ac5ea7d60b66,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-5dd23ad9-594a-4dbb-bde4-dc043feccc37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001077706-172.17.0.13-1595553697228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41254,DS-b91e1f73-35e4-46b0-b25f-dfe32586a1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-88bb06dd-c99f-418d-aca1-9643110e31e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-1481a94b-89e8-45b9-97b5-77e8e98e350c,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-9e9f9a9e-e4f3-43fd-9c22-c065ccd20224,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-0da557e6-6168-4524-937b-88d051fa8823,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-d7da08c5-4923-4d8c-96b0-fe41b8158dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-4e6c8f40-74b2-495a-afd8-a5f913a45b01,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-88cc4b31-eca4-4d73-86b8-bd60713be100,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001077706-172.17.0.13-1595553697228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41254,DS-b91e1f73-35e4-46b0-b25f-dfe32586a1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-88bb06dd-c99f-418d-aca1-9643110e31e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-1481a94b-89e8-45b9-97b5-77e8e98e350c,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-9e9f9a9e-e4f3-43fd-9c22-c065ccd20224,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-0da557e6-6168-4524-937b-88d051fa8823,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-d7da08c5-4923-4d8c-96b0-fe41b8158dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-4e6c8f40-74b2-495a-afd8-a5f913a45b01,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-88cc4b31-eca4-4d73-86b8-bd60713be100,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488725817-172.17.0.13-1595553731243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34322,DS-b9227f7b-7776-4405-af8b-5c45aaa5cadf,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-9774f32c-0eed-40ff-a596-9c804a786588,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-24d78331-0510-439a-b6d0-8addf7afa158,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-3bd01169-8d0e-44e5-958e-c1111d0e58b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-07c45a6a-12c4-40f7-899f-de31fc166ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-ccb07be5-c138-43c2-a4cb-b08741793a20,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-b86b1706-b392-4eb2-bfcc-a68a8af54fec,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-30c775dd-95f2-42e1-a6df-b5df875bc1d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488725817-172.17.0.13-1595553731243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34322,DS-b9227f7b-7776-4405-af8b-5c45aaa5cadf,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-9774f32c-0eed-40ff-a596-9c804a786588,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-24d78331-0510-439a-b6d0-8addf7afa158,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-3bd01169-8d0e-44e5-958e-c1111d0e58b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-07c45a6a-12c4-40f7-899f-de31fc166ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-ccb07be5-c138-43c2-a4cb-b08741793a20,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-b86b1706-b392-4eb2-bfcc-a68a8af54fec,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-30c775dd-95f2-42e1-a6df-b5df875bc1d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-334276267-172.17.0.13-1595553971055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45614,DS-28b554aa-570a-48fb-96d8-f5a4c100ce71,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-7f0845c1-8e0f-4e5a-ac95-4a81afff4cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-63324217-16da-4ef5-a60a-cb6b5b98c11a,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-00a6a0b0-168c-486d-b6f6-80596b81950b,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-dd94cce6-9aa5-4394-a4df-d0ae7360eda5,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-cb529e73-fec3-4fdb-8415-019a29e0e6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-5a9b49d6-27a9-422f-8e4c-8c996af7c689,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-5a71a3b6-6cae-4ea6-95dc-6be7b896bfe4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-334276267-172.17.0.13-1595553971055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45614,DS-28b554aa-570a-48fb-96d8-f5a4c100ce71,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-7f0845c1-8e0f-4e5a-ac95-4a81afff4cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-63324217-16da-4ef5-a60a-cb6b5b98c11a,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-00a6a0b0-168c-486d-b6f6-80596b81950b,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-dd94cce6-9aa5-4394-a4df-d0ae7360eda5,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-cb529e73-fec3-4fdb-8415-019a29e0e6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-5a9b49d6-27a9-422f-8e4c-8c996af7c689,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-5a71a3b6-6cae-4ea6-95dc-6be7b896bfe4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-824774777-172.17.0.13-1595554002747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42089,DS-c32947d5-bd7c-410d-961a-a831def61ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-8a9753e6-73b2-4961-9a7f-6271159f8070,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-412e39bd-513f-4e7f-994a-4178cbb9278a,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-d956ce17-21e5-4143-afff-3ca4bfc17a38,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-c79c4e91-a17d-4d3d-a57c-c49f81c99dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-4dcc9330-60ab-4133-8835-8c4ac5e0e428,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-e5ce3faa-1a17-4363-8886-2af63bb29bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-7d47c477-0a7d-4b37-a7ff-df0da3dc9461,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-824774777-172.17.0.13-1595554002747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42089,DS-c32947d5-bd7c-410d-961a-a831def61ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-8a9753e6-73b2-4961-9a7f-6271159f8070,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-412e39bd-513f-4e7f-994a-4178cbb9278a,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-d956ce17-21e5-4143-afff-3ca4bfc17a38,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-c79c4e91-a17d-4d3d-a57c-c49f81c99dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-4dcc9330-60ab-4133-8835-8c4ac5e0e428,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-e5ce3faa-1a17-4363-8886-2af63bb29bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-7d47c477-0a7d-4b37-a7ff-df0da3dc9461,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-449340652-172.17.0.13-1595554033908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43616,DS-c8f4edca-4fcd-4464-8720-9f1b7393e8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-4d761153-aec3-4937-9b80-f49aeb5e3b64,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-796fa57c-8dee-4fdf-8aaa-c54d7b9d4f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-3b9f06d9-c6f4-40ef-91e8-b3185764292f,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-04040fba-f4c6-4fdf-9cad-0c37538c85b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-915e0dc6-76ce-4184-a54b-29db377adbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-dbe1b88b-ae12-4462-bfb1-e4df10affa09,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-3d766fff-df60-417e-8bfa-b2b5d160f067,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-449340652-172.17.0.13-1595554033908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43616,DS-c8f4edca-4fcd-4464-8720-9f1b7393e8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-4d761153-aec3-4937-9b80-f49aeb5e3b64,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-796fa57c-8dee-4fdf-8aaa-c54d7b9d4f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-3b9f06d9-c6f4-40ef-91e8-b3185764292f,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-04040fba-f4c6-4fdf-9cad-0c37538c85b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-915e0dc6-76ce-4184-a54b-29db377adbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-dbe1b88b-ae12-4462-bfb1-e4df10affa09,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-3d766fff-df60-417e-8bfa-b2b5d160f067,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1129470179-172.17.0.13-1595554109394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39356,DS-3e51c5ab-6212-4786-b069-6295a999f918,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-a916aba3-a055-441d-8ccd-5b76334f1d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-d914fc40-4b26-48ee-99ee-5c42b60778b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-8419f2ef-c1f2-460b-8925-45958e03e4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-1cd28712-7ed1-420b-b432-70f0ff09cd41,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-84cd2d8c-4a90-4e36-b9e4-0e69b91c96ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-2a9d326f-74c6-43d7-92d1-42a4fa260117,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-93fcb00b-5a39-40a9-a673-32877e48a481,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1129470179-172.17.0.13-1595554109394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39356,DS-3e51c5ab-6212-4786-b069-6295a999f918,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-a916aba3-a055-441d-8ccd-5b76334f1d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-d914fc40-4b26-48ee-99ee-5c42b60778b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-8419f2ef-c1f2-460b-8925-45958e03e4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-1cd28712-7ed1-420b-b432-70f0ff09cd41,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-84cd2d8c-4a90-4e36-b9e4-0e69b91c96ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-2a9d326f-74c6-43d7-92d1-42a4fa260117,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-93fcb00b-5a39-40a9-a673-32877e48a481,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885322806-172.17.0.13-1595554148666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34686,DS-0a628eb3-8e56-47f3-8267-f2d0f294689f,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-7df3619d-b9ab-43f2-85d2-b8c2142fff53,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-efeb8f0b-9c2f-44e7-828e-191b64be2c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-e74375e1-6e0c-4cd8-85ab-c091865b60b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-b8bee271-c39f-405d-9f3f-11aaead20414,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-dc7f8b79-ace1-42a7-8a35-9c3bfc4166d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-0802bfee-d425-4880-bfb4-eac5cad0a7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-83d2a1df-2dce-42ae-8f6c-29d3e56cfc76,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885322806-172.17.0.13-1595554148666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34686,DS-0a628eb3-8e56-47f3-8267-f2d0f294689f,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-7df3619d-b9ab-43f2-85d2-b8c2142fff53,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-efeb8f0b-9c2f-44e7-828e-191b64be2c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-e74375e1-6e0c-4cd8-85ab-c091865b60b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-b8bee271-c39f-405d-9f3f-11aaead20414,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-dc7f8b79-ace1-42a7-8a35-9c3bfc4166d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-0802bfee-d425-4880-bfb4-eac5cad0a7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-83d2a1df-2dce-42ae-8f6c-29d3e56cfc76,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764824265-172.17.0.13-1595554220085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33143,DS-8e9e8889-f8db-47f6-bd8d-77c39c01257e,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-8acf2976-91c4-47f0-9df8-b7e6b7aab93b,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-9af1a9d8-3bd0-4b31-8741-0770b0a3941d,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-3fa05750-e11c-49af-a30e-79a04b3c91ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-741c171e-6abc-44d4-93a2-873058b6e113,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-e8a8d998-d78e-46ac-8a79-436d39aee375,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-3974a42f-04c2-4898-8b96-3d2f7f51bb15,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-1db9cc9e-8a44-4627-ac9f-e5ad3d590c25,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764824265-172.17.0.13-1595554220085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33143,DS-8e9e8889-f8db-47f6-bd8d-77c39c01257e,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-8acf2976-91c4-47f0-9df8-b7e6b7aab93b,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-9af1a9d8-3bd0-4b31-8741-0770b0a3941d,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-3fa05750-e11c-49af-a30e-79a04b3c91ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-741c171e-6abc-44d4-93a2-873058b6e113,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-e8a8d998-d78e-46ac-8a79-436d39aee375,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-3974a42f-04c2-4898-8b96-3d2f7f51bb15,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-1db9cc9e-8a44-4627-ac9f-e5ad3d590c25,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778657766-172.17.0.13-1595554253189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35484,DS-77cf95b6-27b6-4e2e-9a19-ab95206ae1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-653cae9e-a329-4699-9e12-58472db99313,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-0d13d273-9917-49c9-9db4-3f6b5c82dce8,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-48c30bd1-8346-4f95-ab45-24f7072b6ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-5b37e359-2f8a-4c24-8426-9d0ea2151e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-786e479a-02dc-44b4-a969-62bbe419320c,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-0fa2ba6d-6733-474d-968f-9e4daeab6fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-1d8423cb-4614-4a2a-aae0-c990c5c12497,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778657766-172.17.0.13-1595554253189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35484,DS-77cf95b6-27b6-4e2e-9a19-ab95206ae1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-653cae9e-a329-4699-9e12-58472db99313,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-0d13d273-9917-49c9-9db4-3f6b5c82dce8,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-48c30bd1-8346-4f95-ab45-24f7072b6ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-5b37e359-2f8a-4c24-8426-9d0ea2151e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-786e479a-02dc-44b4-a969-62bbe419320c,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-0fa2ba6d-6733-474d-968f-9e4daeab6fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-1d8423cb-4614-4a2a-aae0-c990c5c12497,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2074811383-172.17.0.13-1595554285811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46489,DS-1350906d-78de-4ed6-9010-04e171026695,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-27110b6d-b860-4ba8-9033-c4baf8a3b8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-240a5342-a1f6-4a43-83a3-1c3a484edd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-0ac64186-c886-4a46-aa0a-052c4c6676b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-d588f822-b005-49c1-8570-ab0a0e05cd94,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-d55d9ac6-e1ea-4e87-b780-c58fb1b62d79,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-aac6be5c-1fdf-493c-b61a-3c1d0ad1d738,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-8a1fc99b-17d7-4841-a9fe-a1867fc6b0e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2074811383-172.17.0.13-1595554285811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46489,DS-1350906d-78de-4ed6-9010-04e171026695,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-27110b6d-b860-4ba8-9033-c4baf8a3b8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-240a5342-a1f6-4a43-83a3-1c3a484edd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-0ac64186-c886-4a46-aa0a-052c4c6676b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-d588f822-b005-49c1-8570-ab0a0e05cd94,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-d55d9ac6-e1ea-4e87-b780-c58fb1b62d79,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-aac6be5c-1fdf-493c-b61a-3c1d0ad1d738,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-8a1fc99b-17d7-4841-a9fe-a1867fc6b0e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931973333-172.17.0.13-1595554322494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35807,DS-f7827dc7-b6bd-4770-ab6d-6f0d019ff7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-8790b565-ec26-4282-95f1-b835e7719a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-1b143c7e-c768-4117-b935-2ebceb8cafa9,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-41b40290-f85e-464a-8734-b5b7b75ba6db,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-524a4ebb-4bea-4a0c-83bf-a47818e6d1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-e4b93545-582b-418f-809e-cba18fe08b17,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-426a5f60-6616-42b8-88ba-bef7136c802a,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-1ff6894f-daa4-4979-a29e-942545900e16,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931973333-172.17.0.13-1595554322494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35807,DS-f7827dc7-b6bd-4770-ab6d-6f0d019ff7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-8790b565-ec26-4282-95f1-b835e7719a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-1b143c7e-c768-4117-b935-2ebceb8cafa9,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-41b40290-f85e-464a-8734-b5b7b75ba6db,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-524a4ebb-4bea-4a0c-83bf-a47818e6d1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-e4b93545-582b-418f-809e-cba18fe08b17,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-426a5f60-6616-42b8-88ba-bef7136c802a,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-1ff6894f-daa4-4979-a29e-942545900e16,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5693710-172.17.0.13-1595554501797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37332,DS-5582b21d-a486-4efb-b010-ea5ccd3f60a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-a97e780b-6df3-4c2d-85b2-102edfb97bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-f7e8633b-6adb-4f47-96f9-db7f1dc8f901,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-e984b9aa-0a63-4efa-ab1d-274bf011e7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-2e202c83-ab97-45c7-b6b7-f4cc52aebc54,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-51b3b05e-9adf-43c2-b2b6-15f0bf2cf7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-8566668a-d5a4-4b1e-a13e-def3b2e464fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-0addab3e-bcbb-459b-9da6-fa6479d0a092,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5693710-172.17.0.13-1595554501797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37332,DS-5582b21d-a486-4efb-b010-ea5ccd3f60a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-a97e780b-6df3-4c2d-85b2-102edfb97bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-f7e8633b-6adb-4f47-96f9-db7f1dc8f901,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-e984b9aa-0a63-4efa-ab1d-274bf011e7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-2e202c83-ab97-45c7-b6b7-f4cc52aebc54,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-51b3b05e-9adf-43c2-b2b6-15f0bf2cf7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-8566668a-d5a4-4b1e-a13e-def3b2e464fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-0addab3e-bcbb-459b-9da6-fa6479d0a092,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454679428-172.17.0.13-1595554533624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42150,DS-0e0d5bb9-da7c-4e08-9a66-0d9817d52da3,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-7477ed82-fc82-46e0-bddb-d6ba7ec1f110,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-1e39deb4-88da-4744-a468-e67034a71864,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-5b3988fc-f506-4a81-9ed9-405c20215a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-1bfca8c3-fb50-47ff-ab8d-851104258270,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-2adccd06-9c5f-4e92-8f72-4db26b15cc46,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-5bd3c7a3-a6c5-4251-a338-bd4f18b0e182,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-eb4fc389-0732-49d0-8518-bc32f697f90e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454679428-172.17.0.13-1595554533624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42150,DS-0e0d5bb9-da7c-4e08-9a66-0d9817d52da3,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-7477ed82-fc82-46e0-bddb-d6ba7ec1f110,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-1e39deb4-88da-4744-a468-e67034a71864,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-5b3988fc-f506-4a81-9ed9-405c20215a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-1bfca8c3-fb50-47ff-ab8d-851104258270,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-2adccd06-9c5f-4e92-8f72-4db26b15cc46,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-5bd3c7a3-a6c5-4251-a338-bd4f18b0e182,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-eb4fc389-0732-49d0-8518-bc32f697f90e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1049765151-172.17.0.13-1595554567385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44097,DS-4d1fa357-2157-4027-8a21-d0bda9e017d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-8da4b62f-90df-413c-8fbb-a1d56a7f64ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-52c4c63b-19cc-48e6-a112-b67b5fb892a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-54bfce2e-723a-49b9-9e20-6a4da7870aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-8956cc00-4dfa-4ad5-ae14-c994d6d84bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-069651eb-24ce-448f-9dae-b68a0365f1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-edcb1433-aa41-429d-b3ef-6026b0aa9654,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-f22437eb-4339-4cea-878b-3a93654d83b8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1049765151-172.17.0.13-1595554567385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44097,DS-4d1fa357-2157-4027-8a21-d0bda9e017d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-8da4b62f-90df-413c-8fbb-a1d56a7f64ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-52c4c63b-19cc-48e6-a112-b67b5fb892a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-54bfce2e-723a-49b9-9e20-6a4da7870aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-8956cc00-4dfa-4ad5-ae14-c994d6d84bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-069651eb-24ce-448f-9dae-b68a0365f1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-edcb1433-aa41-429d-b3ef-6026b0aa9654,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-f22437eb-4339-4cea-878b-3a93654d83b8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1605581311-172.17.0.13-1595554663146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33418,DS-6f15fcb6-8fcd-45b6-b0b9-3333cb67f6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-0bc9d27c-a97e-453b-b10b-97e8582db77c,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-4077ea79-129e-4f69-b8a3-f689aa660216,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-e9d6b4e4-0d4d-4ccd-963b-4ca5872a8f68,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-51262d8d-00d4-453a-bff0-f62540670d81,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-f771d9d6-fcfc-49e7-b2b1-e01c3cfac32e,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-b78f19a1-90ee-4833-83f0-16023dc81ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-a01d44da-4359-44cd-b37f-4366aa67ab01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1605581311-172.17.0.13-1595554663146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33418,DS-6f15fcb6-8fcd-45b6-b0b9-3333cb67f6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-0bc9d27c-a97e-453b-b10b-97e8582db77c,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-4077ea79-129e-4f69-b8a3-f689aa660216,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-e9d6b4e4-0d4d-4ccd-963b-4ca5872a8f68,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-51262d8d-00d4-453a-bff0-f62540670d81,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-f771d9d6-fcfc-49e7-b2b1-e01c3cfac32e,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-b78f19a1-90ee-4833-83f0-16023dc81ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-a01d44da-4359-44cd-b37f-4366aa67ab01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1168557955-172.17.0.13-1595554929163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45352,DS-355e3759-3451-4e32-acae-3eb367a9093a,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-27a65bf2-056f-4b08-bd22-eb01965ba287,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-b2d706d3-e8f6-45e9-b276-b38acf5ce748,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-672dc8d1-b675-43f0-9dc6-955790575646,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-fcc9ef7e-1a07-4eb4-ad07-d1075013a9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-8acb636f-4e48-489c-b869-a44601cfb83a,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-38f91222-0529-42c0-b406-ca89c449f167,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-a372bd72-bd70-49ec-8da3-3913edde74af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1168557955-172.17.0.13-1595554929163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45352,DS-355e3759-3451-4e32-acae-3eb367a9093a,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-27a65bf2-056f-4b08-bd22-eb01965ba287,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-b2d706d3-e8f6-45e9-b276-b38acf5ce748,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-672dc8d1-b675-43f0-9dc6-955790575646,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-fcc9ef7e-1a07-4eb4-ad07-d1075013a9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-8acb636f-4e48-489c-b869-a44601cfb83a,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-38f91222-0529-42c0-b406-ca89c449f167,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-a372bd72-bd70-49ec-8da3-3913edde74af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-385350734-172.17.0.13-1595554959147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32997,DS-66ffcff0-e274-46d8-bd4d-1bb35e950d40,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-e040bc6f-e81e-4368-895c-9f1ad0cdb2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-c413210f-a099-4982-8df0-61120f1996fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-73109844-b853-4b54-ad2f-f05a909e61c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-795f9a9c-0ac7-4d2e-a344-568e1f46a6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-025bc837-530b-45ed-af72-def15af09465,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-81aad014-13e3-4d7f-9189-5d36cc5c7318,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-1835ce75-7a25-4094-af83-2a5137f71ca9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-385350734-172.17.0.13-1595554959147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32997,DS-66ffcff0-e274-46d8-bd4d-1bb35e950d40,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-e040bc6f-e81e-4368-895c-9f1ad0cdb2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-c413210f-a099-4982-8df0-61120f1996fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-73109844-b853-4b54-ad2f-f05a909e61c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-795f9a9c-0ac7-4d2e-a344-568e1f46a6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-025bc837-530b-45ed-af72-def15af09465,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-81aad014-13e3-4d7f-9189-5d36cc5c7318,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-1835ce75-7a25-4094-af83-2a5137f71ca9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113834114-172.17.0.13-1595555171287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43188,DS-4016156c-84f6-485c-9231-2702039ed9de,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-3548be57-e37e-4e42-8fa4-c03723a90ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-2d1bb043-fda8-49d6-ac4b-18aa69f8aaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-4d67057a-a9c7-4f85-8819-c0dd4aff60e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-c28faab5-b88c-4992-8f50-40151a52328e,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-cde62132-ef64-4732-b1fe-7a95860c78bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-f4051bc1-0ff4-41ba-b2a0-ef2d136bb66b,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-83c77257-ef56-4f3c-80c4-37f01644bf29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113834114-172.17.0.13-1595555171287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43188,DS-4016156c-84f6-485c-9231-2702039ed9de,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-3548be57-e37e-4e42-8fa4-c03723a90ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-2d1bb043-fda8-49d6-ac4b-18aa69f8aaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-4d67057a-a9c7-4f85-8819-c0dd4aff60e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-c28faab5-b88c-4992-8f50-40151a52328e,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-cde62132-ef64-4732-b1fe-7a95860c78bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-f4051bc1-0ff4-41ba-b2a0-ef2d136bb66b,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-83c77257-ef56-4f3c-80c4-37f01644bf29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1263793399-172.17.0.13-1595555211151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42080,DS-e3ad3797-ec62-4ab8-9c01-c2f3f6d04f95,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-c668aace-b88a-48f2-90be-44fc8522b6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-d5a71f17-e368-4c3d-a20e-8412e40bd67b,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-27dc33b1-fd1e-4cc6-ae06-103f9061a8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-5bf8409a-0381-41e7-9cb2-3631849eb056,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-fcc26b5f-0c73-418a-bfe1-4946769c93a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-b728aeb4-c3fe-4976-ade0-784b825123b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-20d19fae-8e3a-43c4-986c-45f0794794c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1263793399-172.17.0.13-1595555211151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42080,DS-e3ad3797-ec62-4ab8-9c01-c2f3f6d04f95,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-c668aace-b88a-48f2-90be-44fc8522b6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-d5a71f17-e368-4c3d-a20e-8412e40bd67b,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-27dc33b1-fd1e-4cc6-ae06-103f9061a8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-5bf8409a-0381-41e7-9cb2-3631849eb056,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-fcc26b5f-0c73-418a-bfe1-4946769c93a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-b728aeb4-c3fe-4976-ade0-784b825123b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-20d19fae-8e3a-43c4-986c-45f0794794c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1589544276-172.17.0.13-1595555248164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44477,DS-24f26216-26de-4c8a-b375-262184afc0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-e43bb59c-ec1e-4d9f-b28e-c3d2a729b266,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-bfa6f92b-4f4f-41f4-ad9a-4ed3994f388f,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-fbfe4a60-8d70-4abf-8d80-20f930e1bf27,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-fcd65935-11cd-4c00-85e6-a1e63b790e97,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-39fb5424-6057-48c0-96a0-ffcc76f867b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-9ad05322-c642-4d8a-8bf3-16886d244211,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-d3f80d55-0f6a-4db8-887f-45f51cfba872,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1589544276-172.17.0.13-1595555248164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44477,DS-24f26216-26de-4c8a-b375-262184afc0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-e43bb59c-ec1e-4d9f-b28e-c3d2a729b266,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-bfa6f92b-4f4f-41f4-ad9a-4ed3994f388f,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-fbfe4a60-8d70-4abf-8d80-20f930e1bf27,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-fcd65935-11cd-4c00-85e6-a1e63b790e97,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-39fb5424-6057-48c0-96a0-ffcc76f867b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-9ad05322-c642-4d8a-8bf3-16886d244211,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-d3f80d55-0f6a-4db8-887f-45f51cfba872,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1834137840-172.17.0.13-1595555468682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46741,DS-ce65abfa-ad09-4bab-86e2-78866d7c4bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-5b72d40f-356b-4b94-8cdd-22868cd88a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-a76871c1-dca9-4e75-90e0-81a566179e22,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-002ddc07-8854-48f7-94a2-c9e4745e2ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-c378b6f4-9946-489c-91cc-2c4d4f2c4550,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-004ef69f-f122-4b1f-b46c-64e634c9058f,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-3ed2c7bd-0896-4072-b513-b6f4eec31138,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-9a55daad-da2e-45ac-9715-851315a04494,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1834137840-172.17.0.13-1595555468682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46741,DS-ce65abfa-ad09-4bab-86e2-78866d7c4bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-5b72d40f-356b-4b94-8cdd-22868cd88a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-a76871c1-dca9-4e75-90e0-81a566179e22,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-002ddc07-8854-48f7-94a2-c9e4745e2ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-c378b6f4-9946-489c-91cc-2c4d4f2c4550,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-004ef69f-f122-4b1f-b46c-64e634c9058f,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-3ed2c7bd-0896-4072-b513-b6f4eec31138,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-9a55daad-da2e-45ac-9715-851315a04494,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225236116-172.17.0.13-1595555623773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41923,DS-87374687-407a-4d33-a05a-4ef99990e469,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-05068d4f-5ce9-44e2-bd22-64aef64ad6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-b4385524-07d5-4344-9a73-e0172da908f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-d0261823-b646-4695-b2e0-9f4a4cc735c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-23a0f514-f8d4-4ce2-900b-556ec2a0b9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-7ca8ea57-d06d-4c8f-9d63-54bc2a70e57b,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-c3917e67-a202-41a5-9d7b-06d13939572c,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-82f1afc0-a961-42fc-925a-934d3de2ef7a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225236116-172.17.0.13-1595555623773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41923,DS-87374687-407a-4d33-a05a-4ef99990e469,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-05068d4f-5ce9-44e2-bd22-64aef64ad6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-b4385524-07d5-4344-9a73-e0172da908f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-d0261823-b646-4695-b2e0-9f4a4cc735c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-23a0f514-f8d4-4ce2-900b-556ec2a0b9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-7ca8ea57-d06d-4c8f-9d63-54bc2a70e57b,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-c3917e67-a202-41a5-9d7b-06d13939572c,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-82f1afc0-a961-42fc-925a-934d3de2ef7a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1377493445-172.17.0.13-1595555892874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46050,DS-35781d3c-4f7f-41eb-8526-d2209b9649a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-8d0f8e4f-fb96-4dfa-bea8-e59498065cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-2c99a23c-21c8-4654-b183-66feec0faeac,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-a8a3dee7-45bf-4ca1-a472-c1f2f09c686a,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-a14dec43-d566-493e-8a5a-6f68793a9ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-7286ef51-a666-4b11-9894-7429e4abbeff,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-6ce8197c-c123-4b08-97d1-2190d15b5f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-e112485d-2522-457d-ba05-dd77ea7b2429,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1377493445-172.17.0.13-1595555892874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46050,DS-35781d3c-4f7f-41eb-8526-d2209b9649a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-8d0f8e4f-fb96-4dfa-bea8-e59498065cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-2c99a23c-21c8-4654-b183-66feec0faeac,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-a8a3dee7-45bf-4ca1-a472-c1f2f09c686a,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-a14dec43-d566-493e-8a5a-6f68793a9ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-7286ef51-a666-4b11-9894-7429e4abbeff,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-6ce8197c-c123-4b08-97d1-2190d15b5f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-e112485d-2522-457d-ba05-dd77ea7b2429,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-717927294-172.17.0.13-1595556325616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43108,DS-ec969202-9d9b-41ca-a0a4-58d99619001a,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-b4a2bca8-39bb-405c-9657-2013a5d2dfb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-d9baabd5-0244-4a34-9e0b-30a1994dc80d,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-8a79ab92-476b-4178-aad5-c4617ef1baa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-ca4333ab-1ab0-47d1-b3fa-d35289c231ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-13872426-293d-4ddf-a19a-48ca3a91dfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:46166,DS-2e32c3a3-39bc-4a5b-bdd3-53392fc0c520,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-e5f37d17-ed94-4365-9d87-d8a206ce0339,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-717927294-172.17.0.13-1595556325616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43108,DS-ec969202-9d9b-41ca-a0a4-58d99619001a,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-b4a2bca8-39bb-405c-9657-2013a5d2dfb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-d9baabd5-0244-4a34-9e0b-30a1994dc80d,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-8a79ab92-476b-4178-aad5-c4617ef1baa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-ca4333ab-1ab0-47d1-b3fa-d35289c231ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-13872426-293d-4ddf-a19a-48ca3a91dfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:46166,DS-2e32c3a3-39bc-4a5b-bdd3-53392fc0c520,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-e5f37d17-ed94-4365-9d87-d8a206ce0339,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 16 out of 50
v1v1v2v2 failed with probability 23 out of 50
result: false positive !!!
Total execution time in seconds : 5189
