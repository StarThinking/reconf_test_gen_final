reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113441366-172.17.0.21-1595563101559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39552,DS-7b45ae75-30ca-4c79-9502-b6d4af336725,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-41e38aca-fba3-445d-a25b-893a71ec0285,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-3f5f9cb7-dcf7-4821-b4e3-a74156b34615,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-b776d6ee-c13b-4fad-a766-0d8b5eda0b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-208a465f-dcce-4ecc-81c7-4fb83000c4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-adf6138f-aa4a-42ec-833f-972fdffe3fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-1c53e126-fd1f-46a5-bc9d-1ac99b34442e,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-fe6b563a-7969-43d8-bd58-47680cf7a1c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113441366-172.17.0.21-1595563101559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39552,DS-7b45ae75-30ca-4c79-9502-b6d4af336725,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-41e38aca-fba3-445d-a25b-893a71ec0285,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-3f5f9cb7-dcf7-4821-b4e3-a74156b34615,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-b776d6ee-c13b-4fad-a766-0d8b5eda0b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-208a465f-dcce-4ecc-81c7-4fb83000c4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-adf6138f-aa4a-42ec-833f-972fdffe3fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-1c53e126-fd1f-46a5-bc9d-1ac99b34442e,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-fe6b563a-7969-43d8-bd58-47680cf7a1c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094970992-172.17.0.21-1595563458826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37654,DS-ece06397-911e-41ac-85a9-6fc1f08bef41,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-a421ed56-9337-481c-990b-9a4b9b08e3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-c7373e27-69e6-4c83-9c71-d2944d4c65d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-295aa1ed-ef1f-4bb0-bcee-7688ab541ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-c8141a86-9d54-46fc-8e44-7c8c611e9023,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-8daa4023-8e64-49b5-bda9-fc2572f2fb88,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-e0621d98-beba-40c9-b1dc-a6dbd19dd87b,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-be69e04d-4b53-4c5f-988a-fffec8f78aa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094970992-172.17.0.21-1595563458826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37654,DS-ece06397-911e-41ac-85a9-6fc1f08bef41,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-a421ed56-9337-481c-990b-9a4b9b08e3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-c7373e27-69e6-4c83-9c71-d2944d4c65d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-295aa1ed-ef1f-4bb0-bcee-7688ab541ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-c8141a86-9d54-46fc-8e44-7c8c611e9023,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-8daa4023-8e64-49b5-bda9-fc2572f2fb88,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-e0621d98-beba-40c9-b1dc-a6dbd19dd87b,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-be69e04d-4b53-4c5f-988a-fffec8f78aa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-510286188-172.17.0.21-1595564824727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37790,DS-22df0533-a31a-4b7b-810d-7bd44dbea476,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-9257f787-5097-4d68-8171-62a7abced622,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-7cde5461-cfe3-41a6-ba49-d0ef3161f9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-838c53f0-ef2d-4608-af07-6617b6f142e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-a6bad7a6-32cb-417b-b302-544ed5d15caf,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-b88960c8-35a3-4097-b4aa-3348e8315b14,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-b0e39b87-8d3f-40e6-bbf2-f913a94be2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-f9884086-4c1c-4090-aa32-a59639b4e870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-510286188-172.17.0.21-1595564824727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37790,DS-22df0533-a31a-4b7b-810d-7bd44dbea476,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-9257f787-5097-4d68-8171-62a7abced622,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-7cde5461-cfe3-41a6-ba49-d0ef3161f9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-838c53f0-ef2d-4608-af07-6617b6f142e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-a6bad7a6-32cb-417b-b302-544ed5d15caf,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-b88960c8-35a3-4097-b4aa-3348e8315b14,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-b0e39b87-8d3f-40e6-bbf2-f913a94be2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-f9884086-4c1c-4090-aa32-a59639b4e870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21389948-172.17.0.21-1595565021658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38801,DS-efb0fe33-2873-4d92-b87a-6c7515eadf66,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-42f1d826-ad9f-41fd-9398-d2e89bd5bba3,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-b919b1ce-7b03-43d2-af5e-f4b1ab50ec4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-a6807753-3518-400b-82df-198a685325c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-6133cf61-21c6-4fbb-ad79-5f8a4f3b227e,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-826cc8a4-b7bd-4b43-b767-689a710672bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-869cf98e-72db-4f77-9e9b-03a7f9be22e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-7c2a5ca8-6e00-4d3b-ad0d-5ff97083ab9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21389948-172.17.0.21-1595565021658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38801,DS-efb0fe33-2873-4d92-b87a-6c7515eadf66,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-42f1d826-ad9f-41fd-9398-d2e89bd5bba3,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-b919b1ce-7b03-43d2-af5e-f4b1ab50ec4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-a6807753-3518-400b-82df-198a685325c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-6133cf61-21c6-4fbb-ad79-5f8a4f3b227e,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-826cc8a4-b7bd-4b43-b767-689a710672bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-869cf98e-72db-4f77-9e9b-03a7f9be22e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-7c2a5ca8-6e00-4d3b-ad0d-5ff97083ab9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66274030-172.17.0.21-1595565101929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41969,DS-102a4143-70f1-4124-8888-a8fc89fed15d,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-f3613855-9f8f-434c-a75a-7673d799d014,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-84b135c9-6181-4dfc-b27c-b2405dcbe2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-35c412da-250d-47cd-81b2-ed49ec1abb62,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-8f96b24f-84a6-4817-b8b0-3c3ff2fcab28,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-aed5af72-ef4d-498e-8e48-d81b715a38ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-0e19bac6-966b-487d-9d0f-dd12dd68b6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-eba71923-b10a-417b-afb2-4a73de13bfb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66274030-172.17.0.21-1595565101929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41969,DS-102a4143-70f1-4124-8888-a8fc89fed15d,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-f3613855-9f8f-434c-a75a-7673d799d014,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-84b135c9-6181-4dfc-b27c-b2405dcbe2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-35c412da-250d-47cd-81b2-ed49ec1abb62,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-8f96b24f-84a6-4817-b8b0-3c3ff2fcab28,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-aed5af72-ef4d-498e-8e48-d81b715a38ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-0e19bac6-966b-487d-9d0f-dd12dd68b6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-eba71923-b10a-417b-afb2-4a73de13bfb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2068972855-172.17.0.21-1595565457385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39990,DS-66df2b8a-3f03-4ec5-8cac-46a9d6004383,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-f1bf733d-6e37-4af6-b615-90bf289a1201,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-f07b2d5c-aa88-4857-ba89-2ef4b28f20a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-d3eadba5-6314-4e2e-a630-4e85fc55a28c,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-dabff046-8792-4655-bd9b-123d21ef4441,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-7bd0d6f4-77e5-48d4-81c3-100d519def81,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-1ee62716-77dc-4025-99c0-2c82ef738592,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-114f108a-31b6-49ff-92b4-7260c3c5b960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2068972855-172.17.0.21-1595565457385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39990,DS-66df2b8a-3f03-4ec5-8cac-46a9d6004383,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-f1bf733d-6e37-4af6-b615-90bf289a1201,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-f07b2d5c-aa88-4857-ba89-2ef4b28f20a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-d3eadba5-6314-4e2e-a630-4e85fc55a28c,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-dabff046-8792-4655-bd9b-123d21ef4441,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-7bd0d6f4-77e5-48d4-81c3-100d519def81,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-1ee62716-77dc-4025-99c0-2c82ef738592,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-114f108a-31b6-49ff-92b4-7260c3c5b960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516963368-172.17.0.21-1595565961594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45951,DS-106f852f-3027-457d-a9c0-251614df3744,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-09cba86d-e37c-4ed6-a2f8-3716bb6c1c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-91299224-becc-415c-9ce4-b4e64b10508a,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-53ed9c31-c682-42ea-84a8-2785cb5569a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-a4c3a5b2-79e0-4f11-ba3f-815395f9354d,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-7e3c14f6-6f24-4ac8-bd84-ee2014f2aa25,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-7033f4f2-ffa5-485a-bcf5-758528dd54fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-80f762f2-fd05-425e-b082-16fe5da59f97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516963368-172.17.0.21-1595565961594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45951,DS-106f852f-3027-457d-a9c0-251614df3744,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-09cba86d-e37c-4ed6-a2f8-3716bb6c1c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-91299224-becc-415c-9ce4-b4e64b10508a,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-53ed9c31-c682-42ea-84a8-2785cb5569a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-a4c3a5b2-79e0-4f11-ba3f-815395f9354d,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-7e3c14f6-6f24-4ac8-bd84-ee2014f2aa25,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-7033f4f2-ffa5-485a-bcf5-758528dd54fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-80f762f2-fd05-425e-b082-16fe5da59f97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246594216-172.17.0.21-1595566475194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38764,DS-a5cd1f1d-386e-406a-ada9-f3a7301f9d54,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-5f997a60-52ba-4458-98b8-8830cb648315,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-28421fe3-6218-4d6f-b13b-c4068e900cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-270882ec-ab5d-4fb6-a2be-b184d82bc771,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-7af078c9-9aba-4c93-a30a-0f3f47f044c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-1aaf66a9-d8ef-4cfa-870a-5f563702c85d,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-617331fb-6609-47e1-99b8-e8137602d13d,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-df0d48a9-0812-4ab2-8be7-bb08e7701d8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246594216-172.17.0.21-1595566475194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38764,DS-a5cd1f1d-386e-406a-ada9-f3a7301f9d54,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-5f997a60-52ba-4458-98b8-8830cb648315,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-28421fe3-6218-4d6f-b13b-c4068e900cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-270882ec-ab5d-4fb6-a2be-b184d82bc771,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-7af078c9-9aba-4c93-a30a-0f3f47f044c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-1aaf66a9-d8ef-4cfa-870a-5f563702c85d,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-617331fb-6609-47e1-99b8-e8137602d13d,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-df0d48a9-0812-4ab2-8be7-bb08e7701d8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2066092971-172.17.0.21-1595566619888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33228,DS-e8cc3dde-5cb8-461f-b5b6-eabc09eb3d75,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-77ffb409-3f78-4ab2-b9fb-c0634d42358d,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-d516cd92-feb6-488a-ad1e-dba6218edae6,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-eaa722b9-f104-4844-927d-1e682faa63ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-0febc2d2-280f-4291-be9f-750a8552788d,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-fe2ce5b6-8ca7-4c73-a05b-793d1bfffde9,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-d5a6ba55-a153-4dec-af07-e33077d32e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-d6dd731a-9480-49b2-a2da-1b3c4175486e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2066092971-172.17.0.21-1595566619888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33228,DS-e8cc3dde-5cb8-461f-b5b6-eabc09eb3d75,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-77ffb409-3f78-4ab2-b9fb-c0634d42358d,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-d516cd92-feb6-488a-ad1e-dba6218edae6,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-eaa722b9-f104-4844-927d-1e682faa63ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-0febc2d2-280f-4291-be9f-750a8552788d,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-fe2ce5b6-8ca7-4c73-a05b-793d1bfffde9,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-d5a6ba55-a153-4dec-af07-e33077d32e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-d6dd731a-9480-49b2-a2da-1b3c4175486e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672262796-172.17.0.21-1595567369480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40816,DS-9c652234-23d8-4950-98c7-4fb47115e077,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-6febd3d7-b641-4e51-8f78-7bba013e1abc,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-bafce550-2a2b-4f95-aab2-2412eb0003e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-fbe04cf5-f2c2-42b7-a205-c8d4f6f886c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-1fb79dad-a134-4626-80e1-7dea0244b2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-8a851d71-dd78-45b0-8281-609ee7f77ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-97305daf-7c80-4b82-9b75-e7ceb34a6c80,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-d4eeacbf-87cc-4546-849b-89e810cf4af2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672262796-172.17.0.21-1595567369480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40816,DS-9c652234-23d8-4950-98c7-4fb47115e077,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-6febd3d7-b641-4e51-8f78-7bba013e1abc,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-bafce550-2a2b-4f95-aab2-2412eb0003e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-fbe04cf5-f2c2-42b7-a205-c8d4f6f886c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-1fb79dad-a134-4626-80e1-7dea0244b2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-8a851d71-dd78-45b0-8281-609ee7f77ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-97305daf-7c80-4b82-9b75-e7ceb34a6c80,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-d4eeacbf-87cc-4546-849b-89e810cf4af2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-114101970-172.17.0.21-1595567671171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45826,DS-76093f4a-cadf-4da8-86cc-6b4a1fa0f29e,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-33b1d67b-5e6a-4791-8e5c-dad900109bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-b060ef97-9f0c-4c9f-8fe6-723bb24fc627,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-66b94289-b658-4cc1-b04e-a2d6221d5cab,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-2b945367-bc32-46cd-a6cc-d20ba6ecf0af,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-00183eb6-1637-4453-8998-236cca87e405,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-3d2befec-eced-4f46-8b49-f8dddc0776a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-2c130dbc-0f9f-48de-95de-e4a033bff762,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-114101970-172.17.0.21-1595567671171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45826,DS-76093f4a-cadf-4da8-86cc-6b4a1fa0f29e,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-33b1d67b-5e6a-4791-8e5c-dad900109bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-b060ef97-9f0c-4c9f-8fe6-723bb24fc627,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-66b94289-b658-4cc1-b04e-a2d6221d5cab,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-2b945367-bc32-46cd-a6cc-d20ba6ecf0af,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-00183eb6-1637-4453-8998-236cca87e405,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-3d2befec-eced-4f46-8b49-f8dddc0776a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-2c130dbc-0f9f-48de-95de-e4a033bff762,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5452
