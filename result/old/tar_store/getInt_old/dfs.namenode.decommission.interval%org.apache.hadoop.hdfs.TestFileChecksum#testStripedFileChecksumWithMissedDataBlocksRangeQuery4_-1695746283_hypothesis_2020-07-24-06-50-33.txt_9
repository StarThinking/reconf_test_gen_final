reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244516655-172.17.0.18-1595575172813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42617,DS-1b75c707-d453-4fbf-ae3d-25152953d1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-8fb41302-5950-4c68-b1fc-ad0d5977e757,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-59a8d97a-6fcf-46ad-879f-e1cd90face41,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-1c613a83-deae-4cdb-b921-1836984e227a,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-c35fa2f5-10cb-4125-95fb-574ff51a6450,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-f960b154-8a83-4e06-a4b7-7ab4be7a9f67,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-b908769d-dc46-435b-a485-840e96278404,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-79bd06cb-8687-495a-bde8-c1b649545786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244516655-172.17.0.18-1595575172813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42617,DS-1b75c707-d453-4fbf-ae3d-25152953d1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-8fb41302-5950-4c68-b1fc-ad0d5977e757,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-59a8d97a-6fcf-46ad-879f-e1cd90face41,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-1c613a83-deae-4cdb-b921-1836984e227a,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-c35fa2f5-10cb-4125-95fb-574ff51a6450,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-f960b154-8a83-4e06-a4b7-7ab4be7a9f67,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-b908769d-dc46-435b-a485-840e96278404,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-79bd06cb-8687-495a-bde8-c1b649545786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537158366-172.17.0.18-1595575379149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44867,DS-2fab43ff-1644-4702-b03f-684d4175332c,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-93aa9fcc-2764-4c35-95b4-ceffec4fd8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-d1c3b03e-6a13-435f-8f78-ea109d31559b,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-04aa6a6e-e3ee-4151-8b35-2a53763ca5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-6d0ee4a0-e8fe-49df-8eba-c5173d33cff3,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-18f70dc2-1dfe-42a2-bc33-12fbcaf67507,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-abf3305b-3022-4052-a150-2754ff9b128b,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-3565e9e6-a402-40b6-9fcc-b897d3d7c61c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537158366-172.17.0.18-1595575379149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44867,DS-2fab43ff-1644-4702-b03f-684d4175332c,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-93aa9fcc-2764-4c35-95b4-ceffec4fd8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-d1c3b03e-6a13-435f-8f78-ea109d31559b,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-04aa6a6e-e3ee-4151-8b35-2a53763ca5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-6d0ee4a0-e8fe-49df-8eba-c5173d33cff3,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-18f70dc2-1dfe-42a2-bc33-12fbcaf67507,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-abf3305b-3022-4052-a150-2754ff9b128b,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-3565e9e6-a402-40b6-9fcc-b897d3d7c61c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-813486076-172.17.0.18-1595575461847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41346,DS-ce3dae17-fd97-4763-b102-64327c26e80e,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-6af0f1c8-b55a-4927-b439-6dcaddfcd4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-c1b45fe0-8b8a-4505-ad9e-2038d94d9515,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-8fd14fba-9e9f-4b24-bf31-b5969383c2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-964ccb8b-0b11-47d0-891b-291788b578a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-34d081d1-be16-4b6a-8e6a-0fdb73d7557c,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-03e3fe3c-5454-44cd-b0b8-7097d6b98a26,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-1759b67a-d095-4b59-8c78-5ad4463db7a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-813486076-172.17.0.18-1595575461847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41346,DS-ce3dae17-fd97-4763-b102-64327c26e80e,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-6af0f1c8-b55a-4927-b439-6dcaddfcd4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-c1b45fe0-8b8a-4505-ad9e-2038d94d9515,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-8fd14fba-9e9f-4b24-bf31-b5969383c2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-964ccb8b-0b11-47d0-891b-291788b578a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-34d081d1-be16-4b6a-8e6a-0fdb73d7557c,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-03e3fe3c-5454-44cd-b0b8-7097d6b98a26,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-1759b67a-d095-4b59-8c78-5ad4463db7a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455897912-172.17.0.18-1595575813146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34789,DS-110a1c63-cdec-4f7f-81bf-22e43c033d50,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-b48b139a-0b20-476f-9633-665facff0d23,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-8fe0af25-a538-48f6-99d9-0a83cca20d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-622aee72-c707-4ec9-8392-1da6e5deec34,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-1fbb5b58-586b-45d0-83d7-9c55b9349a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-a30bc25e-df4c-4a58-9ac7-faff09961530,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-880b3343-9fff-4541-a7f0-bef770c5178f,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-cb6b2b7a-7573-4047-935a-dec3ea48d860,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455897912-172.17.0.18-1595575813146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34789,DS-110a1c63-cdec-4f7f-81bf-22e43c033d50,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-b48b139a-0b20-476f-9633-665facff0d23,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-8fe0af25-a538-48f6-99d9-0a83cca20d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-622aee72-c707-4ec9-8392-1da6e5deec34,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-1fbb5b58-586b-45d0-83d7-9c55b9349a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-a30bc25e-df4c-4a58-9ac7-faff09961530,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-880b3343-9fff-4541-a7f0-bef770c5178f,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-cb6b2b7a-7573-4047-935a-dec3ea48d860,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447777852-172.17.0.18-1595576110034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35560,DS-817b0d50-515c-4727-8f55-4207f7c4d58e,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-6935b803-cafc-4817-9d91-638fbe9a066f,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-5a15a5ab-cbf9-45b3-b15c-cc55e6cb6503,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-b5deae7b-b6af-40ad-9ab9-f189351c550f,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-afd8600e-4e7e-47b8-880a-88737f5f1e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-aa574593-709c-4cca-bce0-397346223a66,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-b88d985a-1184-4b0c-8cad-dac59a716660,DISK], DatanodeInfoWithStorage[127.0.0.1:33865,DS-b7ed24b3-7632-49dc-a4ef-01557534f043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447777852-172.17.0.18-1595576110034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35560,DS-817b0d50-515c-4727-8f55-4207f7c4d58e,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-6935b803-cafc-4817-9d91-638fbe9a066f,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-5a15a5ab-cbf9-45b3-b15c-cc55e6cb6503,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-b5deae7b-b6af-40ad-9ab9-f189351c550f,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-afd8600e-4e7e-47b8-880a-88737f5f1e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-aa574593-709c-4cca-bce0-397346223a66,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-b88d985a-1184-4b0c-8cad-dac59a716660,DISK], DatanodeInfoWithStorage[127.0.0.1:33865,DS-b7ed24b3-7632-49dc-a4ef-01557534f043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964837428-172.17.0.18-1595576270402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42314,DS-2ac09675-8277-4f76-a2d5-038983bf833d,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-dced54d4-357a-429c-bd69-8cdee92fe5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-6fd09192-1b6e-4442-a95e-4776456b475d,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-d129a1da-3ebd-40f0-a665-5be589556d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-24cf547e-5cbd-49bf-bb5e-37627cec4402,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-8bfa6988-9282-49a8-8b91-3317aaa5a347,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-b009e121-6f30-4a54-ba3b-5f8faa963464,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-dc8e156e-7f4c-409c-a617-255624ff5f1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964837428-172.17.0.18-1595576270402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42314,DS-2ac09675-8277-4f76-a2d5-038983bf833d,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-dced54d4-357a-429c-bd69-8cdee92fe5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-6fd09192-1b6e-4442-a95e-4776456b475d,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-d129a1da-3ebd-40f0-a665-5be589556d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-24cf547e-5cbd-49bf-bb5e-37627cec4402,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-8bfa6988-9282-49a8-8b91-3317aaa5a347,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-b009e121-6f30-4a54-ba3b-5f8faa963464,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-dc8e156e-7f4c-409c-a617-255624ff5f1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1217325058-172.17.0.18-1595577293683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33144,DS-809c7c76-0636-434d-b12e-f3fc4e02b2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-5b2b4468-9a5a-4f05-bf25-39982bc813f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-4411194e-6790-4912-8131-b2af1d3d7e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-b69b45d2-541d-4281-9ace-e098ed3d5376,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-4cd3c26b-57d3-4ea2-be65-63c131c32b37,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-6471387f-8962-450f-b564-bcc5ae0ad041,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-d4fd09ab-abed-43e0-86de-a8d128c6136f,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-fde55cd9-630a-447b-9c09-35a05770d7b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1217325058-172.17.0.18-1595577293683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33144,DS-809c7c76-0636-434d-b12e-f3fc4e02b2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-5b2b4468-9a5a-4f05-bf25-39982bc813f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-4411194e-6790-4912-8131-b2af1d3d7e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-b69b45d2-541d-4281-9ace-e098ed3d5376,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-4cd3c26b-57d3-4ea2-be65-63c131c32b37,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-6471387f-8962-450f-b564-bcc5ae0ad041,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-d4fd09ab-abed-43e0-86de-a8d128c6136f,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-fde55cd9-630a-447b-9c09-35a05770d7b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-91719417-172.17.0.18-1595577594935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36368,DS-9f6f8de8-6458-4e64-8880-4aec4f5ee1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-c9d365ac-1c46-45a7-a566-7782899f6f70,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-1873d642-689f-4f7e-a41d-90e8c89552de,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-9e5f1b77-2f42-4957-b4c4-f389b568e37d,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-bec113fe-1cf2-4057-9451-8cc17a1cf785,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-f53ddf30-9c4c-4629-85fe-1ceb5ff2b377,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-db98d53b-998d-4cdb-b75d-83be22f5b194,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-c784f3c4-4b7c-480d-b400-79fa7ca1dfce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-91719417-172.17.0.18-1595577594935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36368,DS-9f6f8de8-6458-4e64-8880-4aec4f5ee1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-c9d365ac-1c46-45a7-a566-7782899f6f70,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-1873d642-689f-4f7e-a41d-90e8c89552de,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-9e5f1b77-2f42-4957-b4c4-f389b568e37d,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-bec113fe-1cf2-4057-9451-8cc17a1cf785,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-f53ddf30-9c4c-4629-85fe-1ceb5ff2b377,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-db98d53b-998d-4cdb-b75d-83be22f5b194,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-c784f3c4-4b7c-480d-b400-79fa7ca1dfce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-260727835-172.17.0.18-1595577714449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41265,DS-1a17dc64-9ff9-4d2d-afa3-c4ef5a60aa59,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-53965fcf-74f2-4770-9190-0b522d87b0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-597e95be-5aa1-4b33-b2ba-edda9864cb69,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-bdf52030-1f45-4146-9e14-14cdf68e50a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-6a352b92-b04b-47db-a497-b22178e310c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-6d818523-bf66-4c96-92f3-951ad2136a43,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-0ff74401-d790-46cb-9973-d152f87c40f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-e7e76cb0-906f-43b4-a086-d152ec760c9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-260727835-172.17.0.18-1595577714449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41265,DS-1a17dc64-9ff9-4d2d-afa3-c4ef5a60aa59,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-53965fcf-74f2-4770-9190-0b522d87b0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-597e95be-5aa1-4b33-b2ba-edda9864cb69,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-bdf52030-1f45-4146-9e14-14cdf68e50a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-6a352b92-b04b-47db-a497-b22178e310c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-6d818523-bf66-4c96-92f3-951ad2136a43,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-0ff74401-d790-46cb-9973-d152f87c40f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-e7e76cb0-906f-43b4-a086-d152ec760c9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-118334052-172.17.0.18-1595578509522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38531,DS-c4706640-7b39-4dfa-8eee-bb43833a6fec,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-638ed1b7-6aca-4ef6-840a-1d7f13624c86,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-8d663cbd-9e6b-45e0-9f15-a3172f683a90,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-0c2981e7-124f-4910-bd96-06e83f840f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-4a1bd6f6-1936-43fb-b4cd-cb70e4942849,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-ae4a3ace-56dd-43eb-9c90-a146c1d147e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-1dcdf362-02ea-4c35-bda4-622b40e5533e,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-c5b5c573-1638-4b31-aa35-24ed8a976025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-118334052-172.17.0.18-1595578509522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38531,DS-c4706640-7b39-4dfa-8eee-bb43833a6fec,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-638ed1b7-6aca-4ef6-840a-1d7f13624c86,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-8d663cbd-9e6b-45e0-9f15-a3172f683a90,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-0c2981e7-124f-4910-bd96-06e83f840f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-4a1bd6f6-1936-43fb-b4cd-cb70e4942849,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-ae4a3ace-56dd-43eb-9c90-a146c1d147e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-1dcdf362-02ea-4c35-bda4-622b40e5533e,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-c5b5c573-1638-4b31-aa35-24ed8a976025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997186529-172.17.0.18-1595578547853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38861,DS-a16bd184-f515-40e4-9e9b-d85cdeae9a51,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-26ad6a97-692c-4461-8fd2-8accfca16998,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-07a7819b-3ecf-4654-b9d2-4f207fbdf392,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-2b0a0a12-fdb8-4c50-913e-47d0205730f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-b26c6974-b1f4-4f19-b5c1-6f61de005dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-75733f56-cc97-41c2-af93-36e38d876822,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-7edd9316-2e98-4e42-aa54-66b2889fb881,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-06ec4155-be31-47ff-b5b6-a9e46321b9db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997186529-172.17.0.18-1595578547853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38861,DS-a16bd184-f515-40e4-9e9b-d85cdeae9a51,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-26ad6a97-692c-4461-8fd2-8accfca16998,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-07a7819b-3ecf-4654-b9d2-4f207fbdf392,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-2b0a0a12-fdb8-4c50-913e-47d0205730f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-b26c6974-b1f4-4f19-b5c1-6f61de005dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-75733f56-cc97-41c2-af93-36e38d876822,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-7edd9316-2e98-4e42-aa54-66b2889fb881,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-06ec4155-be31-47ff-b5b6-a9e46321b9db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410399430-172.17.0.18-1595578586874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38479,DS-601eb9f6-92db-47d8-952e-65d29ccaf2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-717b29a0-ba6a-4469-87ce-a7f4a4a94095,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-2bf4fae3-6d4d-49cc-b050-3824f2c39fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-e534d678-bcba-4bb8-9766-88079b778487,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-3933f4bc-f34a-4901-9256-0045e63e625c,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-795d43b3-3fbc-4270-9da8-3ad87482132a,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-aa3d9019-da8b-49b7-b768-71e2a3547b20,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-892824f6-f2bd-4955-a4a5-0c7b8eee6e5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410399430-172.17.0.18-1595578586874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38479,DS-601eb9f6-92db-47d8-952e-65d29ccaf2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-717b29a0-ba6a-4469-87ce-a7f4a4a94095,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-2bf4fae3-6d4d-49cc-b050-3824f2c39fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-e534d678-bcba-4bb8-9766-88079b778487,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-3933f4bc-f34a-4901-9256-0045e63e625c,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-795d43b3-3fbc-4270-9da8-3ad87482132a,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-aa3d9019-da8b-49b7-b768-71e2a3547b20,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-892824f6-f2bd-4955-a4a5-0c7b8eee6e5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274141765-172.17.0.18-1595578825737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37633,DS-1839f9cd-92e3-476b-9deb-d0948f05702f,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-e3d1cc57-1dd2-4bf0-9be7-597f36486465,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-5b2ed150-bcc0-4290-acca-f140a7dcb093,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-b2fec0d6-9e04-4524-bab6-37d4927be7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-a36f91f9-9f96-47bb-b979-503849f76a15,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-f6fab306-f59c-4128-aca8-07903f980199,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-7150b88b-ea89-426e-a0d7-79697b032063,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-3a8a1ab3-5319-4761-a6a0-0cccd4bfa249,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274141765-172.17.0.18-1595578825737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37633,DS-1839f9cd-92e3-476b-9deb-d0948f05702f,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-e3d1cc57-1dd2-4bf0-9be7-597f36486465,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-5b2ed150-bcc0-4290-acca-f140a7dcb093,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-b2fec0d6-9e04-4524-bab6-37d4927be7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-a36f91f9-9f96-47bb-b979-503849f76a15,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-f6fab306-f59c-4128-aca8-07903f980199,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-7150b88b-ea89-426e-a0d7-79697b032063,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-3a8a1ab3-5319-4761-a6a0-0cccd4bfa249,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-654284856-172.17.0.18-1595578865841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41713,DS-a4ef79bc-b072-4885-8f19-2a6b263ae5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-f3a1e7ca-9665-4866-8f4f-4dd03a5c73ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-ec253bbf-d61d-47d5-bdf6-1614ff2b6e91,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-592502b1-6f94-4533-90c5-54bb49b32c97,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-cc587adb-e837-4e9c-984d-81926f835331,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-94b57c2c-2735-4679-8fa4-59fe6ca6881c,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-ba1ea637-e44b-4183-8777-9782cb1fadfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-2784c8b1-bc4c-4e3d-8373-f62fb570af46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-654284856-172.17.0.18-1595578865841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41713,DS-a4ef79bc-b072-4885-8f19-2a6b263ae5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-f3a1e7ca-9665-4866-8f4f-4dd03a5c73ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-ec253bbf-d61d-47d5-bdf6-1614ff2b6e91,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-592502b1-6f94-4533-90c5-54bb49b32c97,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-cc587adb-e837-4e9c-984d-81926f835331,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-94b57c2c-2735-4679-8fa4-59fe6ca6881c,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-ba1ea637-e44b-4183-8777-9782cb1fadfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-2784c8b1-bc4c-4e3d-8373-f62fb570af46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5565
