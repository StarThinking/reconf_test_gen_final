reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876592043-172.17.0.14-1595524124646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42548,DS-c95dea52-1fa8-4b3a-87df-e7a0cf268c63,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-8e3f3fa0-7f4b-4803-b922-3c7b5de66963,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-073905b1-10af-4657-aae2-e2e86d52cd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-176c7ce1-2313-4a50-bcb8-50cb4b9beb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-57426d6d-c79b-429d-a476-b2ad13d231ae,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-8033d847-8e8b-4816-a692-cad3e13f44a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-39388f90-0f2b-4219-90f9-2da7b6e951d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-49f88c1b-f0f8-479f-80c4-e00fb4d7d995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876592043-172.17.0.14-1595524124646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42548,DS-c95dea52-1fa8-4b3a-87df-e7a0cf268c63,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-8e3f3fa0-7f4b-4803-b922-3c7b5de66963,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-073905b1-10af-4657-aae2-e2e86d52cd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-176c7ce1-2313-4a50-bcb8-50cb4b9beb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-57426d6d-c79b-429d-a476-b2ad13d231ae,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-8033d847-8e8b-4816-a692-cad3e13f44a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-39388f90-0f2b-4219-90f9-2da7b6e951d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-49f88c1b-f0f8-479f-80c4-e00fb4d7d995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1852690860-172.17.0.14-1595524158562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35321,DS-cf45acd2-0aa4-490f-bb46-b72994df3f23,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-83feb75d-c46a-4a00-9560-c2f80e32807b,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-78446da5-f01c-4a0a-b8a9-168e1df6a832,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-2722af14-bc76-48b2-a53c-74f269e9c305,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-85b7a735-3605-475f-982b-2f4b5c0e8ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-ede26c4b-a316-45e8-ac0b-fdcbd7d9a80a,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-a1a13ca3-738d-40c9-8626-6309204fa70d,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-db367256-fb7a-47e8-8cee-9485e13672db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1852690860-172.17.0.14-1595524158562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35321,DS-cf45acd2-0aa4-490f-bb46-b72994df3f23,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-83feb75d-c46a-4a00-9560-c2f80e32807b,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-78446da5-f01c-4a0a-b8a9-168e1df6a832,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-2722af14-bc76-48b2-a53c-74f269e9c305,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-85b7a735-3605-475f-982b-2f4b5c0e8ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-ede26c4b-a316-45e8-ac0b-fdcbd7d9a80a,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-a1a13ca3-738d-40c9-8626-6309204fa70d,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-db367256-fb7a-47e8-8cee-9485e13672db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113031634-172.17.0.14-1595524688553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43078,DS-658f9108-a4d5-4822-850c-93886f015d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-e4b1dd39-fe5d-4c90-b1a9-fb01e7acca9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-ac360806-4179-44e8-a20a-5eefb2548f67,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-8cf4edb7-b384-4e98-8af6-f246dde0402c,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-2aead25d-7681-4799-9963-94fe5653cdad,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-4ce33e99-f1a2-49a9-8c98-bb28c6d3a194,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-f2f12458-1a70-4bc1-ae45-99df0ef3b28a,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-5bc4a418-13f8-4394-a293-33166961f187,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113031634-172.17.0.14-1595524688553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43078,DS-658f9108-a4d5-4822-850c-93886f015d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-e4b1dd39-fe5d-4c90-b1a9-fb01e7acca9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-ac360806-4179-44e8-a20a-5eefb2548f67,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-8cf4edb7-b384-4e98-8af6-f246dde0402c,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-2aead25d-7681-4799-9963-94fe5653cdad,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-4ce33e99-f1a2-49a9-8c98-bb28c6d3a194,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-f2f12458-1a70-4bc1-ae45-99df0ef3b28a,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-5bc4a418-13f8-4394-a293-33166961f187,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010887628-172.17.0.14-1595524770833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46202,DS-b9ac14ea-8c2f-4f97-945d-1e7c26bf68b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-545245b3-6d57-456e-b63a-590035035b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-1a1b1f86-a4de-4438-af27-0d4882db3ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-e55ac6ce-24b8-4133-97cb-e4134866949f,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-034bad31-152f-4870-9451-d94681367e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-12587bc1-1342-446d-8eca-7291a0fab8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-0a98515a-c534-47fb-ade8-6019ad2c3ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-9ec81b05-e8ab-43ba-b000-6bf0925e5cd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010887628-172.17.0.14-1595524770833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46202,DS-b9ac14ea-8c2f-4f97-945d-1e7c26bf68b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-545245b3-6d57-456e-b63a-590035035b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-1a1b1f86-a4de-4438-af27-0d4882db3ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-e55ac6ce-24b8-4133-97cb-e4134866949f,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-034bad31-152f-4870-9451-d94681367e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-12587bc1-1342-446d-8eca-7291a0fab8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-0a98515a-c534-47fb-ade8-6019ad2c3ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-9ec81b05-e8ab-43ba-b000-6bf0925e5cd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956256343-172.17.0.14-1595524858769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32893,DS-1d7d0e1f-28f2-499d-9a50-0196b38811b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-278be1f9-96a3-422c-a7d7-80646f8dc99f,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-ad5a04e5-55c8-4084-af7a-b14881596d26,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-024b1887-b6fd-4331-9ee4-611cbf280f15,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-7caec349-319b-4422-bc5d-69fea0a0182a,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-974e8146-bfe3-4e91-bd78-431233426ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-3606adfc-5ff7-4018-ad4b-ae18e244ed37,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-49a5cd22-40cd-426f-85e2-0e9e7689544e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956256343-172.17.0.14-1595524858769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32893,DS-1d7d0e1f-28f2-499d-9a50-0196b38811b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-278be1f9-96a3-422c-a7d7-80646f8dc99f,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-ad5a04e5-55c8-4084-af7a-b14881596d26,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-024b1887-b6fd-4331-9ee4-611cbf280f15,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-7caec349-319b-4422-bc5d-69fea0a0182a,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-974e8146-bfe3-4e91-bd78-431233426ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-3606adfc-5ff7-4018-ad4b-ae18e244ed37,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-49a5cd22-40cd-426f-85e2-0e9e7689544e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-118443133-172.17.0.14-1595525219766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38293,DS-fd3126ba-2cff-4f0c-8725-a4317fa21978,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-2549f191-7959-4616-a0e0-beec5b340633,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-1792467b-2dd7-46c0-8b3d-d2875af3ca6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-eb1eda96-da5d-41bf-b06c-d2414c7e0214,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-10b97e02-f1df-4e03-8615-24e0e12e904f,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-73e1938c-a255-4da9-a68c-6db406302a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-09ba8254-b192-4157-b93a-fe8a1198e7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-32bbd0c5-7547-45f8-b0da-a9d4dedbe566,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-118443133-172.17.0.14-1595525219766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38293,DS-fd3126ba-2cff-4f0c-8725-a4317fa21978,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-2549f191-7959-4616-a0e0-beec5b340633,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-1792467b-2dd7-46c0-8b3d-d2875af3ca6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-eb1eda96-da5d-41bf-b06c-d2414c7e0214,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-10b97e02-f1df-4e03-8615-24e0e12e904f,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-73e1938c-a255-4da9-a68c-6db406302a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-09ba8254-b192-4157-b93a-fe8a1198e7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-32bbd0c5-7547-45f8-b0da-a9d4dedbe566,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505289699-172.17.0.14-1595525600083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41841,DS-7e519fd0-6426-497a-b7b4-b85565e43fab,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-74a40162-162a-4550-b729-66883ffdc842,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-6b4d9425-7d18-463a-bdf9-1e52989e47d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-799e4bfb-ee0a-4145-a9ad-17344f41a781,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-80396dbd-0cad-4f0b-8848-6fa10ae713c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-c7ea9b6c-1aae-4a3d-9e62-9f1d09f76396,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-50e974d4-d4a8-4460-891e-7a25b77c3de3,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-a68c0143-f713-4b33-87ed-e866320e7858,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505289699-172.17.0.14-1595525600083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41841,DS-7e519fd0-6426-497a-b7b4-b85565e43fab,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-74a40162-162a-4550-b729-66883ffdc842,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-6b4d9425-7d18-463a-bdf9-1e52989e47d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-799e4bfb-ee0a-4145-a9ad-17344f41a781,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-80396dbd-0cad-4f0b-8848-6fa10ae713c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-c7ea9b6c-1aae-4a3d-9e62-9f1d09f76396,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-50e974d4-d4a8-4460-891e-7a25b77c3de3,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-a68c0143-f713-4b33-87ed-e866320e7858,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1112903342-172.17.0.14-1595526166283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46522,DS-618e56c0-0ff6-4c62-89f5-0475749c0650,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-e434f954-8ee9-4d4a-9944-f492e336247d,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-c7905c53-76f6-4bef-b8b8-0aa788dc88f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-a64a38a7-f62e-49cb-a5e2-0669dbd81405,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-ee7fde5c-626f-4ea7-8dc8-e79ced12aff6,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-a7f5f7a2-a3ec-4d72-b2dd-9e3b69ef1579,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-8d3e2d23-ffcb-4473-a1d6-ea6fbbb69bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-d92461b3-056e-4b9e-947e-5d13ae3c4188,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1112903342-172.17.0.14-1595526166283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46522,DS-618e56c0-0ff6-4c62-89f5-0475749c0650,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-e434f954-8ee9-4d4a-9944-f492e336247d,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-c7905c53-76f6-4bef-b8b8-0aa788dc88f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-a64a38a7-f62e-49cb-a5e2-0669dbd81405,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-ee7fde5c-626f-4ea7-8dc8-e79ced12aff6,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-a7f5f7a2-a3ec-4d72-b2dd-9e3b69ef1579,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-8d3e2d23-ffcb-4473-a1d6-ea6fbbb69bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-d92461b3-056e-4b9e-947e-5d13ae3c4188,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257222691-172.17.0.14-1595526206881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33052,DS-d65248e6-f67b-4cc9-a853-8e18bfd49b57,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-d9eefa77-f725-44aa-8da3-61950700ef4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-a8e46e18-89e7-482d-822b-94e0c8f26c47,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-1e82bbf9-2dbe-45e3-bba2-d215a644deb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-0e5d9e0f-f9d8-41a9-b829-5a3e3d60343e,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-a89b8c00-bfad-44c1-af35-101a04a70cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-6f4d9371-5741-429f-98fd-a2a3e5055957,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-ab221d99-a038-4ab4-8588-e62b5ba1892a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257222691-172.17.0.14-1595526206881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33052,DS-d65248e6-f67b-4cc9-a853-8e18bfd49b57,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-d9eefa77-f725-44aa-8da3-61950700ef4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-a8e46e18-89e7-482d-822b-94e0c8f26c47,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-1e82bbf9-2dbe-45e3-bba2-d215a644deb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-0e5d9e0f-f9d8-41a9-b829-5a3e3d60343e,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-a89b8c00-bfad-44c1-af35-101a04a70cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-6f4d9371-5741-429f-98fd-a2a3e5055957,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-ab221d99-a038-4ab4-8588-e62b5ba1892a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749604460-172.17.0.14-1595526305909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36187,DS-df7b2289-33eb-4ecf-9fab-d417b8cf7fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-a432f675-61ae-4568-9d0a-3ab222621c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-2b864960-bd10-4b0e-92ad-059ca00a12c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-dd099395-f0cb-4c24-a740-61d5d9a18619,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-8af2834e-9f6f-4afe-9ae9-feadd3a12018,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-8d5664fe-3fe8-468a-8baf-93e631a85464,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-84ccd61a-8ae9-489c-86ba-84d874ff1843,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-c3f1d1bc-384f-4049-8fc5-4047f40bb534,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749604460-172.17.0.14-1595526305909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36187,DS-df7b2289-33eb-4ecf-9fab-d417b8cf7fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-a432f675-61ae-4568-9d0a-3ab222621c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-2b864960-bd10-4b0e-92ad-059ca00a12c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-dd099395-f0cb-4c24-a740-61d5d9a18619,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-8af2834e-9f6f-4afe-9ae9-feadd3a12018,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-8d5664fe-3fe8-468a-8baf-93e631a85464,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-84ccd61a-8ae9-489c-86ba-84d874ff1843,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-c3f1d1bc-384f-4049-8fc5-4047f40bb534,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122134656-172.17.0.14-1595526430306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42852,DS-ee033e6b-187c-4835-8f76-b67595267a67,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-489206f5-6acf-4651-8826-f7491ba0ccf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-7b5c13f3-63f1-4cb6-9ed6-64de38b7434a,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-1d56ff59-67b9-41da-b703-bb8e1aecebd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-df2594da-f834-474b-8b24-6e05c9af7f80,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-08863acc-e85b-4ddf-a6d8-0a0c5c376309,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-e37e37f4-0af8-4a8f-918f-a74e2f6b37d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-130084ba-3321-4f6d-b606-046325ed9215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122134656-172.17.0.14-1595526430306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42852,DS-ee033e6b-187c-4835-8f76-b67595267a67,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-489206f5-6acf-4651-8826-f7491ba0ccf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-7b5c13f3-63f1-4cb6-9ed6-64de38b7434a,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-1d56ff59-67b9-41da-b703-bb8e1aecebd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-df2594da-f834-474b-8b24-6e05c9af7f80,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-08863acc-e85b-4ddf-a6d8-0a0c5c376309,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-e37e37f4-0af8-4a8f-918f-a74e2f6b37d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-130084ba-3321-4f6d-b606-046325ed9215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-625352570-172.17.0.14-1595526652481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36976,DS-c301e820-368f-403d-94a0-e7fc0d684f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-31de5849-00e4-4dda-9876-574585021956,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-039ec329-1cc8-41e1-9278-f3271fcbf88d,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-673b948b-162c-410e-b069-adff653dac69,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-fc0adc45-e591-4900-b4bc-27074a1f9bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-99dfb0bb-954d-43b0-91c7-6a97d05082e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-b40bb02d-4169-4b0c-956f-6cccc53b9c93,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-e4a0c3c4-4b28-4ff5-93d1-5a3f57da08b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-625352570-172.17.0.14-1595526652481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36976,DS-c301e820-368f-403d-94a0-e7fc0d684f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-31de5849-00e4-4dda-9876-574585021956,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-039ec329-1cc8-41e1-9278-f3271fcbf88d,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-673b948b-162c-410e-b069-adff653dac69,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-fc0adc45-e591-4900-b4bc-27074a1f9bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-99dfb0bb-954d-43b0-91c7-6a97d05082e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-b40bb02d-4169-4b0c-956f-6cccc53b9c93,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-e4a0c3c4-4b28-4ff5-93d1-5a3f57da08b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027416604-172.17.0.14-1595527006512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42745,DS-41035e44-268a-42d0-9d5d-a5742352053f,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-295290cb-035e-40e9-9a49-ecd87dfe4f09,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-41c5c5a3-173b-434b-8efe-8cd8b1e343dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-e2f991ca-101f-4508-b12c-2ec41ae0a73a,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-c884b14a-29f7-4672-be1b-fa3b7d1a6a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-e2358f4a-40fe-4f4c-9191-68b220598889,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-9b4dbda0-65f9-4f6c-b550-f5cae1d89e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-790e377a-28ff-4e70-a385-d4b21da1b440,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027416604-172.17.0.14-1595527006512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42745,DS-41035e44-268a-42d0-9d5d-a5742352053f,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-295290cb-035e-40e9-9a49-ecd87dfe4f09,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-41c5c5a3-173b-434b-8efe-8cd8b1e343dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-e2f991ca-101f-4508-b12c-2ec41ae0a73a,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-c884b14a-29f7-4672-be1b-fa3b7d1a6a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-e2358f4a-40fe-4f4c-9191-68b220598889,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-9b4dbda0-65f9-4f6c-b550-f5cae1d89e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-790e377a-28ff-4e70-a385-d4b21da1b440,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1925958958-172.17.0.14-1595527400025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36411,DS-ec09dc78-a0e4-425b-b72d-4d2e80df8549,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-70606b7d-4aa0-470d-853d-f8f06fbe9769,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-ccf3e999-cff0-48d0-ae8e-cb0ff68cdfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-8c92ffc7-3a01-4466-9fce-7706035d400b,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-bb45f431-2b68-4974-a937-1c2738d50691,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-0270d0a7-6a74-4bd5-b5be-2743610da1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-ee5eaef3-7e75-48c6-aed9-3134b0644f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-47d54d5c-81b1-42e7-941e-2e8ecc259d3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1925958958-172.17.0.14-1595527400025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36411,DS-ec09dc78-a0e4-425b-b72d-4d2e80df8549,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-70606b7d-4aa0-470d-853d-f8f06fbe9769,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-ccf3e999-cff0-48d0-ae8e-cb0ff68cdfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-8c92ffc7-3a01-4466-9fce-7706035d400b,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-bb45f431-2b68-4974-a937-1c2738d50691,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-0270d0a7-6a74-4bd5-b5be-2743610da1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-ee5eaef3-7e75-48c6-aed9-3134b0644f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-47d54d5c-81b1-42e7-941e-2e8ecc259d3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292646529-172.17.0.14-1595528242686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40691,DS-4d08fae5-2590-4d4a-bdba-ff442e6fd22c,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-14b63982-fc62-4735-b357-5ac4564e9615,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-765f75d1-dfad-488d-9c9a-e7f84e14d263,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-55d3d3d1-5724-430c-8e17-2624ad975534,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-5e8c5c59-a262-4e8f-adbc-9a1af873af49,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-0285007d-bed0-495b-97e9-97035389f559,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-b31a968d-5c46-4cd6-b5ee-53a665f5a64b,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-5a420299-77f2-407c-b1e0-a7fa0c82f405,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292646529-172.17.0.14-1595528242686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40691,DS-4d08fae5-2590-4d4a-bdba-ff442e6fd22c,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-14b63982-fc62-4735-b357-5ac4564e9615,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-765f75d1-dfad-488d-9c9a-e7f84e14d263,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-55d3d3d1-5724-430c-8e17-2624ad975534,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-5e8c5c59-a262-4e8f-adbc-9a1af873af49,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-0285007d-bed0-495b-97e9-97035389f559,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-b31a968d-5c46-4cd6-b5ee-53a665f5a64b,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-5a420299-77f2-407c-b1e0-a7fa0c82f405,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1790995372-172.17.0.14-1595528468804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46721,DS-e806e52b-3c31-4a44-8d5a-52f2bc0a9262,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-da4eb7a6-7f4d-48c3-a7a7-7595a03db0af,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-7d1ce126-50ab-4ba7-b7d4-734d50873499,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-957b6fa4-8320-4c82-95a3-8cd9741a19fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-425de169-d8e0-4c96-9390-cab154e97617,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-cb1de2d9-0909-4e0b-829d-55ce2d0749ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-cfe89722-9217-491e-9ea8-934449c03e33,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-fdd43808-dead-45a2-8070-663b076e0eb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1790995372-172.17.0.14-1595528468804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46721,DS-e806e52b-3c31-4a44-8d5a-52f2bc0a9262,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-da4eb7a6-7f4d-48c3-a7a7-7595a03db0af,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-7d1ce126-50ab-4ba7-b7d4-734d50873499,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-957b6fa4-8320-4c82-95a3-8cd9741a19fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-425de169-d8e0-4c96-9390-cab154e97617,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-cb1de2d9-0909-4e0b-829d-55ce2d0749ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-cfe89722-9217-491e-9ea8-934449c03e33,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-fdd43808-dead-45a2-8070-663b076e0eb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2110005138-172.17.0.14-1595528550326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45278,DS-c9c2b8dc-a366-46bd-839f-745c288188af,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-09d3cbf3-9de9-45e8-8f32-c65a0a27e8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-639a651a-abfb-4aef-b8b9-1d489e4fe934,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-1c12ed07-1cb1-489a-9f26-8fb8b9ce8e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-75a24648-68f2-4ebd-a36c-4ee4ee0c7b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-d2d3e635-fa63-4465-bc07-b356c05b30f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-089155a1-014a-434b-908c-6c86cdb03d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-63318480-517a-4c49-8077-c75ff02ded54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2110005138-172.17.0.14-1595528550326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45278,DS-c9c2b8dc-a366-46bd-839f-745c288188af,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-09d3cbf3-9de9-45e8-8f32-c65a0a27e8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-639a651a-abfb-4aef-b8b9-1d489e4fe934,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-1c12ed07-1cb1-489a-9f26-8fb8b9ce8e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-75a24648-68f2-4ebd-a36c-4ee4ee0c7b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-d2d3e635-fa63-4465-bc07-b356c05b30f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-089155a1-014a-434b-908c-6c86cdb03d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-63318480-517a-4c49-8077-c75ff02ded54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784482815-172.17.0.14-1595528598598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41534,DS-29faa323-365b-44ec-9d24-13063a1fb870,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-c3a0ea32-8522-4c1b-8de9-faa2f48b1e54,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-f54584f1-87e0-43eb-b89d-511662cdb876,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-951ef61f-43d2-45f8-936d-16f9f66257f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-875d7d16-5178-4d43-8572-6038c6d9758d,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-9e184455-6ea4-416f-b5cd-a14059d171b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-a0d87adc-95d2-4e83-8a8b-1ccd3d86e5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-61a84870-5479-4982-8f47-1eb91200c018,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784482815-172.17.0.14-1595528598598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41534,DS-29faa323-365b-44ec-9d24-13063a1fb870,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-c3a0ea32-8522-4c1b-8de9-faa2f48b1e54,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-f54584f1-87e0-43eb-b89d-511662cdb876,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-951ef61f-43d2-45f8-936d-16f9f66257f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-875d7d16-5178-4d43-8572-6038c6d9758d,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-9e184455-6ea4-416f-b5cd-a14059d171b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-a0d87adc-95d2-4e83-8a8b-1ccd3d86e5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-61a84870-5479-4982-8f47-1eb91200c018,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-55398071-172.17.0.14-1595529020003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43394,DS-db7201e1-f8cd-4fed-97ee-6607ef30754b,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-213e949e-9717-4e30-811a-7ea90000872a,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-c6131191-3e0c-4f31-8892-19f1021af333,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-95cf4b28-2fc4-4cef-8bb6-9d77b8947fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-31e20c50-6fb8-4367-85bc-819eef89f2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-a0e4b4ec-8f43-4e54-b388-959f717f0b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-d33fba06-2205-44f5-b7fd-39ff31f269f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-2c4b6750-a2ca-48d3-923f-4e5f4ec2cdfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-55398071-172.17.0.14-1595529020003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43394,DS-db7201e1-f8cd-4fed-97ee-6607ef30754b,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-213e949e-9717-4e30-811a-7ea90000872a,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-c6131191-3e0c-4f31-8892-19f1021af333,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-95cf4b28-2fc4-4cef-8bb6-9d77b8947fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-31e20c50-6fb8-4367-85bc-819eef89f2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-a0e4b4ec-8f43-4e54-b388-959f717f0b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-d33fba06-2205-44f5-b7fd-39ff31f269f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-2c4b6750-a2ca-48d3-923f-4e5f4ec2cdfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2070171147-172.17.0.14-1595529275218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35718,DS-ab87ae42-403c-449a-8bce-2fce817e2a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-266bc1df-84d3-45cc-a084-78d5b8679dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-b17ad9df-adc0-4244-86f7-634648fbebbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-8ed46564-46ca-4366-989e-6cfa18822eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-a8590f6c-1661-428e-bf75-b0f946009613,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-7f3f213d-11c6-4f51-a617-5c014006db2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-ff283887-9c79-49b2-a26e-2424b5334a46,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-23e8a288-376c-47f6-ade3-839430b481f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2070171147-172.17.0.14-1595529275218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35718,DS-ab87ae42-403c-449a-8bce-2fce817e2a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-266bc1df-84d3-45cc-a084-78d5b8679dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-b17ad9df-adc0-4244-86f7-634648fbebbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-8ed46564-46ca-4366-989e-6cfa18822eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-a8590f6c-1661-428e-bf75-b0f946009613,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-7f3f213d-11c6-4f51-a617-5c014006db2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-ff283887-9c79-49b2-a26e-2424b5334a46,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-23e8a288-376c-47f6-ade3-839430b481f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1895428764-172.17.0.14-1595529711210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42594,DS-5dd498a5-932b-49dc-beea-5e9597ee3958,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-9f6ba514-a1d6-4554-b332-ba413bb24f57,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-af5bd585-c6a4-4665-bceb-9cc52be01ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-7d6c50c1-4791-4a65-95b0-cca3b54df65a,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-3771d51c-0de7-495b-8c08-14940ebc0bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-8105ff23-6c53-4548-a340-a5e843e76748,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-815730da-f0e4-49ac-8f1f-c13654b3526f,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-0d6eb3bb-0c7a-4f7a-b1a6-79d3f9244685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1895428764-172.17.0.14-1595529711210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42594,DS-5dd498a5-932b-49dc-beea-5e9597ee3958,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-9f6ba514-a1d6-4554-b332-ba413bb24f57,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-af5bd585-c6a4-4665-bceb-9cc52be01ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-7d6c50c1-4791-4a65-95b0-cca3b54df65a,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-3771d51c-0de7-495b-8c08-14940ebc0bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-8105ff23-6c53-4548-a340-a5e843e76748,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-815730da-f0e4-49ac-8f1f-c13654b3526f,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-0d6eb3bb-0c7a-4f7a-b1a6-79d3f9244685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6619
