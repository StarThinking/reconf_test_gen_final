reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2136103777-172.17.0.4-1595492951669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36339,DS-c07605a5-b06f-4070-89c4-3b1ba4204a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-562f19c9-0015-485e-bbcc-d3ec37398e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-39e3da94-4c97-4388-811f-923cac1e3b34,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-a98e1030-ab7b-4bf2-8488-18d9213d8e39,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-bd27f82e-3dad-4783-9357-2ac345f1ab06,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-ccc2c6a1-1d8e-46ca-b31e-8057155cc3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-100362bd-d674-4c36-ab13-4ae8425ebac0,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-a4ef898d-40b6-44d8-a5d3-eb05b6e73953,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2136103777-172.17.0.4-1595492951669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36339,DS-c07605a5-b06f-4070-89c4-3b1ba4204a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-562f19c9-0015-485e-bbcc-d3ec37398e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-39e3da94-4c97-4388-811f-923cac1e3b34,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-a98e1030-ab7b-4bf2-8488-18d9213d8e39,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-bd27f82e-3dad-4783-9357-2ac345f1ab06,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-ccc2c6a1-1d8e-46ca-b31e-8057155cc3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-100362bd-d674-4c36-ab13-4ae8425ebac0,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-a4ef898d-40b6-44d8-a5d3-eb05b6e73953,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1456937460-172.17.0.4-1595493565383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45733,DS-9182c5e0-2547-461d-ba95-e9b9daa4a70e,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-13d2f81a-0e0b-414a-81e4-bc853aae0ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-c197a61c-f469-482f-a849-b11a61641e41,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-00ebde06-5787-4b91-96da-f102875136ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45758,DS-2e151bab-c833-4c13-9797-1b9f4fbb78d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-139c54d6-ab25-4bb2-89b6-10dde4c06512,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-83ad733e-3adc-4ee8-8de6-28dabe95afed,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-7a19c6a5-20f2-4572-844c-a709ab57d5ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1456937460-172.17.0.4-1595493565383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45733,DS-9182c5e0-2547-461d-ba95-e9b9daa4a70e,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-13d2f81a-0e0b-414a-81e4-bc853aae0ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-c197a61c-f469-482f-a849-b11a61641e41,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-00ebde06-5787-4b91-96da-f102875136ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45758,DS-2e151bab-c833-4c13-9797-1b9f4fbb78d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-139c54d6-ab25-4bb2-89b6-10dde4c06512,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-83ad733e-3adc-4ee8-8de6-28dabe95afed,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-7a19c6a5-20f2-4572-844c-a709ab57d5ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1943690707-172.17.0.4-1595494184749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38385,DS-7ad16e2c-5187-4e6d-991f-b845a9e4155f,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-b6c4a91e-fd4b-46fc-9366-8df545a14dce,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-5477bbe2-1ebc-4507-a411-0cd856c9b42c,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-f78ecbcc-1e0f-49ef-812f-fafc36b5e8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-ccfe29bc-4cff-4c7b-956e-86358bcbe151,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-eccb3ef6-ccbc-4242-809f-842fb3809e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-187d4e18-250e-4a00-b61c-8e28b25b2878,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-42913f71-167b-4604-ac05-46ec9613725f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1943690707-172.17.0.4-1595494184749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38385,DS-7ad16e2c-5187-4e6d-991f-b845a9e4155f,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-b6c4a91e-fd4b-46fc-9366-8df545a14dce,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-5477bbe2-1ebc-4507-a411-0cd856c9b42c,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-f78ecbcc-1e0f-49ef-812f-fafc36b5e8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-ccfe29bc-4cff-4c7b-956e-86358bcbe151,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-eccb3ef6-ccbc-4242-809f-842fb3809e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-187d4e18-250e-4a00-b61c-8e28b25b2878,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-42913f71-167b-4604-ac05-46ec9613725f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1269958447-172.17.0.4-1595494229240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38783,DS-88a2dab5-c6d2-49c5-84bf-b33be6675cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-d315c392-8845-48c6-9fea-1aac0e4db4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-b9eab645-a749-4bec-98d5-75f391943165,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-3cb8234e-9c92-4a14-a563-40ab55c60cad,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-83082e08-720d-49fb-aaca-9d536507db07,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-314a3ffc-e996-4be6-ae88-1a441fa4f4de,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-9df099be-4411-46be-a7e3-d3262cbee17a,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-cae2c291-2500-4f24-8f68-caa7807d086b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1269958447-172.17.0.4-1595494229240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38783,DS-88a2dab5-c6d2-49c5-84bf-b33be6675cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-d315c392-8845-48c6-9fea-1aac0e4db4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-b9eab645-a749-4bec-98d5-75f391943165,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-3cb8234e-9c92-4a14-a563-40ab55c60cad,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-83082e08-720d-49fb-aaca-9d536507db07,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-314a3ffc-e996-4be6-ae88-1a441fa4f4de,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-9df099be-4411-46be-a7e3-d3262cbee17a,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-cae2c291-2500-4f24-8f68-caa7807d086b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1409214848-172.17.0.4-1595494283954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45727,DS-628d9f77-b6e9-44d3-ab24-593531d42167,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-6de71c10-d68a-4777-8d0a-880cd04392ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-8c253f62-db1a-4655-b488-091ef5214f41,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-1377229e-72ea-4b92-ae7b-3ac49c0f5677,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-86313f5f-6eaf-4c5d-b8a3-44161436ccb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-b5d0463c-581c-4f77-8727-56dc51e9474d,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-8fb2fff5-bd98-4c68-bea3-3515c7ba7e57,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-df944c5a-8148-490b-913e-3b75ef24c6df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1409214848-172.17.0.4-1595494283954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45727,DS-628d9f77-b6e9-44d3-ab24-593531d42167,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-6de71c10-d68a-4777-8d0a-880cd04392ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-8c253f62-db1a-4655-b488-091ef5214f41,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-1377229e-72ea-4b92-ae7b-3ac49c0f5677,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-86313f5f-6eaf-4c5d-b8a3-44161436ccb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-b5d0463c-581c-4f77-8727-56dc51e9474d,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-8fb2fff5-bd98-4c68-bea3-3515c7ba7e57,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-df944c5a-8148-490b-913e-3b75ef24c6df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-287796845-172.17.0.4-1595494458787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39279,DS-8eab843c-d141-4dd7-9701-5ca4d1c39dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-dc6764f3-b8d4-4362-829f-e912a8d5e447,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-c7fbaac5-aae6-4e77-8a1f-bb6a36461027,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-21577da6-e3a9-4e1a-a864-98fc2c0e6d96,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-9fd5b7f5-472e-4089-b177-40ba129bfee8,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-8963b608-4bc3-4cf2-a1f6-42d1eb761dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-ef54ad0c-e3c3-41d3-9ebe-67e1f02d51d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-459cf47d-26c4-4b4d-b0e9-2356534804d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-287796845-172.17.0.4-1595494458787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39279,DS-8eab843c-d141-4dd7-9701-5ca4d1c39dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-dc6764f3-b8d4-4362-829f-e912a8d5e447,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-c7fbaac5-aae6-4e77-8a1f-bb6a36461027,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-21577da6-e3a9-4e1a-a864-98fc2c0e6d96,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-9fd5b7f5-472e-4089-b177-40ba129bfee8,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-8963b608-4bc3-4cf2-a1f6-42d1eb761dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-ef54ad0c-e3c3-41d3-9ebe-67e1f02d51d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-459cf47d-26c4-4b4d-b0e9-2356534804d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-353425174-172.17.0.4-1595494545319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33584,DS-b9a13afa-2a5e-4ffd-aaa6-68fe3040f63b,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-10471d77-9d1f-48da-8601-c87dc2a723f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-d87fae01-301d-4e2a-8e3b-5808045523eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-731b564d-c69a-48c0-b7a0-370a99b74b20,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-7b238c76-247b-4728-bb45-b94f1b6d0df9,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-efe6f170-af7f-411c-a5a2-165c3e631471,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-41128d51-6d75-4a2b-8634-6124892597f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-b8da482e-431d-4619-bf62-13ada9824efc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-353425174-172.17.0.4-1595494545319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33584,DS-b9a13afa-2a5e-4ffd-aaa6-68fe3040f63b,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-10471d77-9d1f-48da-8601-c87dc2a723f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-d87fae01-301d-4e2a-8e3b-5808045523eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-731b564d-c69a-48c0-b7a0-370a99b74b20,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-7b238c76-247b-4728-bb45-b94f1b6d0df9,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-efe6f170-af7f-411c-a5a2-165c3e631471,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-41128d51-6d75-4a2b-8634-6124892597f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-b8da482e-431d-4619-bf62-13ada9824efc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31558587-172.17.0.4-1595494884392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40457,DS-18289c66-41b2-4fd8-ac24-ce63e53aabf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-b791dd8c-ba2d-4c2a-8f03-5eccb8be42c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-59c7231c-dae3-4a96-981b-65d600d829b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-31f20138-ef67-4985-9512-be6dd4c3d88e,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-fc2d2eb5-1d21-4160-849c-da21d14ecbee,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-bc5103e8-9d70-4646-a7b4-db5d781fb842,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-57b7274f-cc8f-44e2-861c-3523437e1eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-4b989d22-c213-40e6-b859-2d624777cd5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31558587-172.17.0.4-1595494884392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40457,DS-18289c66-41b2-4fd8-ac24-ce63e53aabf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-b791dd8c-ba2d-4c2a-8f03-5eccb8be42c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-59c7231c-dae3-4a96-981b-65d600d829b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-31f20138-ef67-4985-9512-be6dd4c3d88e,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-fc2d2eb5-1d21-4160-849c-da21d14ecbee,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-bc5103e8-9d70-4646-a7b4-db5d781fb842,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-57b7274f-cc8f-44e2-861c-3523437e1eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-4b989d22-c213-40e6-b859-2d624777cd5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597964662-172.17.0.4-1595495895310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35668,DS-90b269e6-652f-4f32-9c0f-c9c89289d7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-45b897f9-e334-42b5-95ff-96b9fede7fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-375b7bb4-0907-4dd2-9365-f5d27fce8787,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-e1b5ea50-d9cf-4e43-bb0a-6d8186b88f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-f182ec8e-d06a-4e7a-9f5a-fda20cf07195,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-8802740c-8bf6-49d2-bb28-67a19e9b6824,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-44ebd07c-fa12-4e05-a0ea-c2b5ca9eb6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-8693c930-be67-4a60-9845-4f3c00f092e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597964662-172.17.0.4-1595495895310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35668,DS-90b269e6-652f-4f32-9c0f-c9c89289d7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-45b897f9-e334-42b5-95ff-96b9fede7fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-375b7bb4-0907-4dd2-9365-f5d27fce8787,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-e1b5ea50-d9cf-4e43-bb0a-6d8186b88f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-f182ec8e-d06a-4e7a-9f5a-fda20cf07195,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-8802740c-8bf6-49d2-bb28-67a19e9b6824,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-44ebd07c-fa12-4e05-a0ea-c2b5ca9eb6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-8693c930-be67-4a60-9845-4f3c00f092e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2018563681-172.17.0.4-1595496031607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39676,DS-acb16f75-b3dd-4c43-887d-073dd0ae4bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-1ca26632-8939-46e6-a717-22e50e7b928d,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-96d4f067-744c-4b16-bd52-6136aac3f6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-36951fe3-41d0-4734-8e43-c1fbba0ae1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-850be256-1382-428f-950a-0e70ac81582f,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-243f22ff-7f9a-4f88-b004-4c5da9ced92e,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-d255ce23-90f6-4fe6-97e9-f007e88d5393,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-2748afd7-265a-483a-a8fd-1f9bd36b5f92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2018563681-172.17.0.4-1595496031607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39676,DS-acb16f75-b3dd-4c43-887d-073dd0ae4bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-1ca26632-8939-46e6-a717-22e50e7b928d,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-96d4f067-744c-4b16-bd52-6136aac3f6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-36951fe3-41d0-4734-8e43-c1fbba0ae1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-850be256-1382-428f-950a-0e70ac81582f,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-243f22ff-7f9a-4f88-b004-4c5da9ced92e,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-d255ce23-90f6-4fe6-97e9-f007e88d5393,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-2748afd7-265a-483a-a8fd-1f9bd36b5f92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1251543518-172.17.0.4-1595496617742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46591,DS-f9f9efc7-633a-4a15-9aad-ad6b827f23b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-958d19db-52b0-4913-b0c3-717fe88fa7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-2009148b-6967-4ba9-8ad0-5342d0d6b643,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-85bdae68-d455-4c1e-a2ab-71a24d61a21b,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-b4e3c7bb-6a5d-45fb-be0b-c2e0b9f3a04a,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-0195f7fb-d0dd-4b34-84ac-e23efabd31ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-5f34462e-8e38-4574-8efe-5a95cd89a1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-8c1b882f-66cb-4e38-aaf0-fd837868f27a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1251543518-172.17.0.4-1595496617742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46591,DS-f9f9efc7-633a-4a15-9aad-ad6b827f23b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-958d19db-52b0-4913-b0c3-717fe88fa7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-2009148b-6967-4ba9-8ad0-5342d0d6b643,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-85bdae68-d455-4c1e-a2ab-71a24d61a21b,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-b4e3c7bb-6a5d-45fb-be0b-c2e0b9f3a04a,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-0195f7fb-d0dd-4b34-84ac-e23efabd31ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-5f34462e-8e38-4574-8efe-5a95cd89a1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-8c1b882f-66cb-4e38-aaf0-fd837868f27a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-899057087-172.17.0.4-1595496893820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41878,DS-8357768a-6a76-43ee-9a6d-29b890cfe0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-1bc76f8c-6409-4f40-9b69-3db5f72b930a,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-500776ee-1b49-4908-9df8-9599696e4d59,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-3efb340b-8a49-4e71-ba40-7603a6b3fe36,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-4c3b89e4-89df-4287-85d7-febf3be2ce17,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-ed1ce209-9996-4b4d-817c-3582596eca8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-a9867bf1-22b1-42ff-919e-f8cfca03395f,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-21c9fea5-cc6c-4880-8e5d-8af722e115d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-899057087-172.17.0.4-1595496893820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41878,DS-8357768a-6a76-43ee-9a6d-29b890cfe0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-1bc76f8c-6409-4f40-9b69-3db5f72b930a,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-500776ee-1b49-4908-9df8-9599696e4d59,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-3efb340b-8a49-4e71-ba40-7603a6b3fe36,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-4c3b89e4-89df-4287-85d7-febf3be2ce17,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-ed1ce209-9996-4b4d-817c-3582596eca8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-a9867bf1-22b1-42ff-919e-f8cfca03395f,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-21c9fea5-cc6c-4880-8e5d-8af722e115d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1538791172-172.17.0.4-1595497022876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45049,DS-c8a27f5f-9c62-420d-bdfa-3858b119d035,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-ef05ffc7-7569-4281-8775-596b484f5e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-985e2210-7e57-4dd2-b070-1e3e2549426c,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-e5f87813-f524-4025-b04d-c09ad1d5cb79,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-17c97608-8348-4558-8d7e-26038b4a0213,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-f32e85ec-70fb-4607-8dd0-bfb99f9e1ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-423f6143-685a-4385-b38a-b73c97d1e5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-9b5cbc8c-c150-4086-8550-0f7b57903c27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1538791172-172.17.0.4-1595497022876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45049,DS-c8a27f5f-9c62-420d-bdfa-3858b119d035,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-ef05ffc7-7569-4281-8775-596b484f5e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-985e2210-7e57-4dd2-b070-1e3e2549426c,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-e5f87813-f524-4025-b04d-c09ad1d5cb79,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-17c97608-8348-4558-8d7e-26038b4a0213,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-f32e85ec-70fb-4607-8dd0-bfb99f9e1ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-423f6143-685a-4385-b38a-b73c97d1e5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-9b5cbc8c-c150-4086-8550-0f7b57903c27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-424932288-172.17.0.4-1595497223973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40219,DS-8d8f0c40-7ce1-4566-b390-0fca428090fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-3cb256bf-ffac-4168-a854-1dd72f279b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-0b8fe8fe-ac1f-4b46-a09d-0b1d4ad27127,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-f4b9bf6c-7930-4daa-9aa1-2d6f45d731fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-8d246ab0-cd59-4187-a295-b7c450fa3016,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-5a73363b-9f5f-4e7c-82d5-295b5f3f40f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-299fc94a-f244-4357-a7aa-66f6b1f18d49,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-a11d6ca2-372a-4a22-9d1b-e1cf2b763fa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-424932288-172.17.0.4-1595497223973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40219,DS-8d8f0c40-7ce1-4566-b390-0fca428090fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-3cb256bf-ffac-4168-a854-1dd72f279b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-0b8fe8fe-ac1f-4b46-a09d-0b1d4ad27127,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-f4b9bf6c-7930-4daa-9aa1-2d6f45d731fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-8d246ab0-cd59-4187-a295-b7c450fa3016,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-5a73363b-9f5f-4e7c-82d5-295b5f3f40f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-299fc94a-f244-4357-a7aa-66f6b1f18d49,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-a11d6ca2-372a-4a22-9d1b-e1cf2b763fa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 6940
