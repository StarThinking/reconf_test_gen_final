reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-115598648-172.17.0.8-1595733835991:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38046,DS-f25ccb2c-0531-4d9f-88c1-a4119b76ee01,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-c913ade0-1945-436c-98a6-9696f787d403,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-161d450b-7c42-4d58-9f73-da3ae95b1f09,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-b4d3b336-ab7e-4016-b518-24f657b8378f,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-ac20e445-4634-4ab1-9f32-09a8673887cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-06274e94-7f3f-4469-a16e-2bc4c8651154,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-f9e8ad44-6c9e-428f-8165-b68836120589,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-f7ed80bb-51f4-447a-b79b-2fd394473065,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-115598648-172.17.0.8-1595733835991:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38046,DS-f25ccb2c-0531-4d9f-88c1-a4119b76ee01,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-c913ade0-1945-436c-98a6-9696f787d403,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-161d450b-7c42-4d58-9f73-da3ae95b1f09,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-b4d3b336-ab7e-4016-b518-24f657b8378f,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-ac20e445-4634-4ab1-9f32-09a8673887cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-06274e94-7f3f-4469-a16e-2bc4c8651154,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-f9e8ad44-6c9e-428f-8165-b68836120589,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-f7ed80bb-51f4-447a-b79b-2fd394473065,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547535747-172.17.0.8-1595734470713:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46252,DS-0b85f62a-c96b-4387-a6ef-e0a0e8e3c798,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-891ccf40-27bc-41a1-a62e-7ae1149ffd66,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-b593d6aa-de17-43c2-85ac-6615a294fb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-0db7aa78-397c-42f3-a2eb-48d92a09ebd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-568240bc-0cd7-473b-973d-e295b9966ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-ec0a9425-bfbe-4314-97d0-3e119085b6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-3d493226-9486-4825-8d6d-e2439b12c5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-d422b999-157b-4e56-86b5-3af559205897,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547535747-172.17.0.8-1595734470713:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46252,DS-0b85f62a-c96b-4387-a6ef-e0a0e8e3c798,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-891ccf40-27bc-41a1-a62e-7ae1149ffd66,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-b593d6aa-de17-43c2-85ac-6615a294fb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-0db7aa78-397c-42f3-a2eb-48d92a09ebd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-568240bc-0cd7-473b-973d-e295b9966ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-ec0a9425-bfbe-4314-97d0-3e119085b6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-3d493226-9486-4825-8d6d-e2439b12c5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-d422b999-157b-4e56-86b5-3af559205897,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-324527750-172.17.0.8-1595734567585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39381,DS-4214231c-30c8-489d-b2f4-ce43c444d562,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-da6da726-383c-4801-ad20-58036943e439,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-47f8c411-ea7b-42fc-8867-5bb6be537aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-0d9e894c-956e-4757-99ff-80be7d203514,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-7cb81b57-8b3c-41ca-a1cc-881111388380,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-1b9531ec-2cfc-4cea-b8cc-a6495e12a98f,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-9dfe1ce8-6c2c-4582-b749-95e9a1c7389c,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-5bde1923-b92a-4f61-8874-69e3457ac87f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-324527750-172.17.0.8-1595734567585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39381,DS-4214231c-30c8-489d-b2f4-ce43c444d562,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-da6da726-383c-4801-ad20-58036943e439,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-47f8c411-ea7b-42fc-8867-5bb6be537aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-0d9e894c-956e-4757-99ff-80be7d203514,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-7cb81b57-8b3c-41ca-a1cc-881111388380,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-1b9531ec-2cfc-4cea-b8cc-a6495e12a98f,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-9dfe1ce8-6c2c-4582-b749-95e9a1c7389c,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-5bde1923-b92a-4f61-8874-69e3457ac87f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1143952284-172.17.0.8-1595734888242:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46337,DS-5df2ab86-4f93-4792-9384-8b2645e62048,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-0ff67b06-6b2c-49cf-9131-0b4e35c74491,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-49fe5cff-43a8-427e-86c2-92f1c825ac2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-00fc613a-77d5-4258-a36c-0ef6f9f529d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-06340d86-1791-4a6e-bc1e-009d87081c75,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-3f747d70-22a2-471a-866c-a3c7e29b2632,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-27e82ef4-3a6b-498a-a888-6d9545c7f673,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-c3fdc938-67b4-4893-afbe-625f3f19f7c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1143952284-172.17.0.8-1595734888242:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46337,DS-5df2ab86-4f93-4792-9384-8b2645e62048,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-0ff67b06-6b2c-49cf-9131-0b4e35c74491,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-49fe5cff-43a8-427e-86c2-92f1c825ac2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-00fc613a-77d5-4258-a36c-0ef6f9f529d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-06340d86-1791-4a6e-bc1e-009d87081c75,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-3f747d70-22a2-471a-866c-a3c7e29b2632,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-27e82ef4-3a6b-498a-a888-6d9545c7f673,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-c3fdc938-67b4-4893-afbe-625f3f19f7c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-867087141-172.17.0.8-1595735490533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33714,DS-03b5679e-3027-48f5-b191-a0698183ba4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-b3e4fc36-4e01-422a-88d0-6f907fbfc906,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-7b7be515-68ba-4974-84ab-509f69149afe,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-c45467ab-fb4d-4579-957f-f928298fe130,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-5b49aa8a-16a9-4fbe-9a06-f0536a0c4f64,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-67b12d74-3f1a-4f89-b20f-702a88df96f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-19e0af61-5451-4370-9d31-5ba40f95e398,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-5ee01a25-5baf-490f-829b-13155cae9650,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-867087141-172.17.0.8-1595735490533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33714,DS-03b5679e-3027-48f5-b191-a0698183ba4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-b3e4fc36-4e01-422a-88d0-6f907fbfc906,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-7b7be515-68ba-4974-84ab-509f69149afe,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-c45467ab-fb4d-4579-957f-f928298fe130,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-5b49aa8a-16a9-4fbe-9a06-f0536a0c4f64,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-67b12d74-3f1a-4f89-b20f-702a88df96f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-19e0af61-5451-4370-9d31-5ba40f95e398,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-5ee01a25-5baf-490f-829b-13155cae9650,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1504398433-172.17.0.8-1595735578936:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37617,DS-0891bd05-929d-49f2-a54b-a3ffe4acae00,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-ad47db7f-72c1-4806-a310-2395bab9efa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-be741756-c5fd-4dbf-b7a4-e612eb15c073,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-4ea908d6-41de-4a5a-aca9-e392a1a61783,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-59b12647-f609-4336-98f4-759cbfb609b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-ca97cfda-b8b4-48a4-9956-c85eebafafb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-b482dc23-1fd2-46ab-8555-201ecf97e78a,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-fc1e7c99-97dc-4fec-a4e2-6bc47ece1797,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1504398433-172.17.0.8-1595735578936:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37617,DS-0891bd05-929d-49f2-a54b-a3ffe4acae00,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-ad47db7f-72c1-4806-a310-2395bab9efa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-be741756-c5fd-4dbf-b7a4-e612eb15c073,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-4ea908d6-41de-4a5a-aca9-e392a1a61783,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-59b12647-f609-4336-98f4-759cbfb609b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-ca97cfda-b8b4-48a4-9956-c85eebafafb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-b482dc23-1fd2-46ab-8555-201ecf97e78a,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-fc1e7c99-97dc-4fec-a4e2-6bc47ece1797,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014868068-172.17.0.8-1595736966233:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45067,DS-4d375f71-7af9-44dc-b84b-6d3f90aca4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-5cbeeaff-8911-4e3b-9e60-3d84716ee8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-a0cd1dcd-6049-4e73-a98b-fc13015aba11,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-a7e8a269-ce44-475e-bed4-973a023ccb93,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-15213520-2f2e-43b8-9982-437f8bfa5659,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-2ccc02da-1116-4ccd-99ce-49903f183a08,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-e6840c03-4bcf-4fa1-86aa-4f2a047d5a70,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-d748da17-92a4-4f66-9213-a2a0f45b5fdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014868068-172.17.0.8-1595736966233:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45067,DS-4d375f71-7af9-44dc-b84b-6d3f90aca4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-5cbeeaff-8911-4e3b-9e60-3d84716ee8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-a0cd1dcd-6049-4e73-a98b-fc13015aba11,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-a7e8a269-ce44-475e-bed4-973a023ccb93,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-15213520-2f2e-43b8-9982-437f8bfa5659,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-2ccc02da-1116-4ccd-99ce-49903f183a08,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-e6840c03-4bcf-4fa1-86aa-4f2a047d5a70,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-d748da17-92a4-4f66-9213-a2a0f45b5fdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846211803-172.17.0.8-1595737134283:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44213,DS-dbb16b73-8820-4fd4-9735-9c5d79141dae,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-c86d726e-eb75-408f-bd19-9540d1cc1971,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-9031753f-d78f-4af8-bd44-938872139b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-b6639de2-4e8d-4611-b7ec-285f7c1a41c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-bac430a6-997c-44ca-a081-9efe845795c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-89eed553-de64-4380-9317-138c42da4c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-34a6da74-f4c7-43db-8396-041e4cd1f67a,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-70856240-2c28-4720-b124-5feb254f501d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846211803-172.17.0.8-1595737134283:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44213,DS-dbb16b73-8820-4fd4-9735-9c5d79141dae,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-c86d726e-eb75-408f-bd19-9540d1cc1971,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-9031753f-d78f-4af8-bd44-938872139b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-b6639de2-4e8d-4611-b7ec-285f7c1a41c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-bac430a6-997c-44ca-a081-9efe845795c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-89eed553-de64-4380-9317-138c42da4c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-34a6da74-f4c7-43db-8396-041e4cd1f67a,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-70856240-2c28-4720-b124-5feb254f501d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-377123445-172.17.0.8-1595737250183:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38358,DS-269f1db6-fedd-4da8-a5c6-bb0ae216cb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-4913c541-0e82-4922-b109-469041e2afa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-97a6b0d1-6d60-42ca-827a-fbb52c1eb6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-a5046d76-2519-4463-81d6-85a0f2c67297,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-34cc1619-8db3-41dc-a7f7-945c1abb5c79,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-8d24c5e0-a913-4ac9-9718-ee539864c73e,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-2c48f6b5-5c82-489b-aabd-56624eea83f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-d3b8234b-9e12-4b32-86e1-05564e59d36d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-377123445-172.17.0.8-1595737250183:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38358,DS-269f1db6-fedd-4da8-a5c6-bb0ae216cb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-4913c541-0e82-4922-b109-469041e2afa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-97a6b0d1-6d60-42ca-827a-fbb52c1eb6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-a5046d76-2519-4463-81d6-85a0f2c67297,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-34cc1619-8db3-41dc-a7f7-945c1abb5c79,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-8d24c5e0-a913-4ac9-9718-ee539864c73e,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-2c48f6b5-5c82-489b-aabd-56624eea83f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-d3b8234b-9e12-4b32-86e1-05564e59d36d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-169408815-172.17.0.8-1595737382392:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35935,DS-d763f708-de0b-4e86-bd72-831b697f7fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-e7074ea2-35b4-4905-be50-a7718c8d565e,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-897c39e0-c4d3-4cf6-b0fe-b74d34f3f2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-0c53c000-0acb-4759-9abc-686c46bcb588,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-2f014ca6-eb4d-46df-8ba7-8a6fd964ae4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-48f79dac-784f-4b80-9ca7-e37d5e1c9575,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-68a5a857-f9bf-4b5a-b1ff-d53f58c1a877,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-8b1f42ab-4766-4275-b378-620ece82cd15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-169408815-172.17.0.8-1595737382392:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35935,DS-d763f708-de0b-4e86-bd72-831b697f7fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-e7074ea2-35b4-4905-be50-a7718c8d565e,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-897c39e0-c4d3-4cf6-b0fe-b74d34f3f2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-0c53c000-0acb-4759-9abc-686c46bcb588,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-2f014ca6-eb4d-46df-8ba7-8a6fd964ae4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-48f79dac-784f-4b80-9ca7-e37d5e1c9575,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-68a5a857-f9bf-4b5a-b1ff-d53f58c1a877,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-8b1f42ab-4766-4275-b378-620ece82cd15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-107173307-172.17.0.8-1595737795253:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39474,DS-55bf542e-e17e-470e-8d20-4a27fe66252f,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-1e5de581-08eb-4a7a-9a38-4c209c81048a,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-91383569-4e4f-430b-825f-a52734d013de,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-c8864dda-aa45-4f47-b6ed-767baf90bd79,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-2552ae99-41e5-4a89-a6a4-8f8e5cf2927c,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-b18c81a1-98a8-423d-83cb-c91f1890f51e,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-bd81d0ed-5555-4799-ad85-e81cc76987f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-29eb42b2-3fbe-4ce7-8b79-e5c5683a52aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-107173307-172.17.0.8-1595737795253:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39474,DS-55bf542e-e17e-470e-8d20-4a27fe66252f,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-1e5de581-08eb-4a7a-9a38-4c209c81048a,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-91383569-4e4f-430b-825f-a52734d013de,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-c8864dda-aa45-4f47-b6ed-767baf90bd79,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-2552ae99-41e5-4a89-a6a4-8f8e5cf2927c,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-b18c81a1-98a8-423d-83cb-c91f1890f51e,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-bd81d0ed-5555-4799-ad85-e81cc76987f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-29eb42b2-3fbe-4ce7-8b79-e5c5683a52aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1594682705-172.17.0.8-1595738136525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44866,DS-d6aa3be1-c7ef-4425-9ff1-911d3160bdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-50fe5719-73bc-48f5-a0dc-efb2f33c979d,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-b44d55cc-f575-4249-92fb-8641c23af89d,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-050f861c-282d-4fd3-91d3-062d83ce416a,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-f5187fd9-fd91-432f-be33-8c27bb317647,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-7f1ec727-e4dd-4dc7-be5a-e23112faa0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-12e568ed-91bf-473a-86d0-32ac138d2fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-6017f5fe-108e-4545-a8b5-dffb3c101844,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1594682705-172.17.0.8-1595738136525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44866,DS-d6aa3be1-c7ef-4425-9ff1-911d3160bdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-50fe5719-73bc-48f5-a0dc-efb2f33c979d,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-b44d55cc-f575-4249-92fb-8641c23af89d,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-050f861c-282d-4fd3-91d3-062d83ce416a,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-f5187fd9-fd91-432f-be33-8c27bb317647,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-7f1ec727-e4dd-4dc7-be5a-e23112faa0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-12e568ed-91bf-473a-86d0-32ac138d2fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-6017f5fe-108e-4545-a8b5-dffb3c101844,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-154361741-172.17.0.8-1595738187644:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33451,DS-d9cbed15-86e2-49c2-b72d-37743a7fef8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-cb06930c-a94c-4b23-9ec2-3419bae8ab02,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-49a12a50-0e3b-4af1-b42c-f4cd53b30d12,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-2d86855e-2f37-4b3e-9716-3e50a900dfcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-6f885385-be1d-4b7a-b79c-5c1ced47d02b,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-b4add98e-f06f-49a6-977a-f0dee5b50202,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-1c3713e1-1f59-4318-a8f8-ad70f4ea4b78,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-8dc44fd3-2852-45c5-a3d8-2af6b6a87115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-154361741-172.17.0.8-1595738187644:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33451,DS-d9cbed15-86e2-49c2-b72d-37743a7fef8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-cb06930c-a94c-4b23-9ec2-3419bae8ab02,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-49a12a50-0e3b-4af1-b42c-f4cd53b30d12,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-2d86855e-2f37-4b3e-9716-3e50a900dfcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-6f885385-be1d-4b7a-b79c-5c1ced47d02b,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-b4add98e-f06f-49a6-977a-f0dee5b50202,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-1c3713e1-1f59-4318-a8f8-ad70f4ea4b78,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-8dc44fd3-2852-45c5-a3d8-2af6b6a87115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-318601555-172.17.0.8-1595738324977:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35706,DS-d0456d8b-55c4-42e5-8500-384e60c0aad1,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-97c93858-4d17-46de-aa69-3898e6f43504,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-f0c88c88-db33-48aa-a949-917252acfe07,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-f137a3e5-4306-4c33-bccc-002df22a9263,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-94152e10-25fa-40b2-bb33-24b65879d296,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-65ca229b-04c1-4531-8b45-b8a6e315b348,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-f815e911-1ab7-451a-847e-27b661b7c236,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-adda7432-eae9-48a4-8e05-316480650e0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-318601555-172.17.0.8-1595738324977:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35706,DS-d0456d8b-55c4-42e5-8500-384e60c0aad1,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-97c93858-4d17-46de-aa69-3898e6f43504,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-f0c88c88-db33-48aa-a949-917252acfe07,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-f137a3e5-4306-4c33-bccc-002df22a9263,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-94152e10-25fa-40b2-bb33-24b65879d296,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-65ca229b-04c1-4531-8b45-b8a6e315b348,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-f815e911-1ab7-451a-847e-27b661b7c236,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-adda7432-eae9-48a4-8e05-316480650e0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1387979393-172.17.0.8-1595738370519:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44313,DS-a4aeb6d3-0353-499f-a254-a37849c7ee00,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-f3a70a95-11c6-4d68-aaa9-12061e86a9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-e40c5ed9-9882-4d0c-a4af-a32df88d8320,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-fd994e73-4607-495e-820b-06565a5ecb09,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-a498a284-8110-43a0-ae13-d09e2bc9bd43,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-bc9a71eb-b233-4f57-b154-3244a342c0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-1cbfb81c-acea-4b13-8678-40608d5bfc14,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-476b335d-6da6-4ced-a0ce-3021f13f3573,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1387979393-172.17.0.8-1595738370519:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44313,DS-a4aeb6d3-0353-499f-a254-a37849c7ee00,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-f3a70a95-11c6-4d68-aaa9-12061e86a9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-e40c5ed9-9882-4d0c-a4af-a32df88d8320,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-fd994e73-4607-495e-820b-06565a5ecb09,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-a498a284-8110-43a0-ae13-d09e2bc9bd43,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-bc9a71eb-b233-4f57-b154-3244a342c0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-1cbfb81c-acea-4b13-8678-40608d5bfc14,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-476b335d-6da6-4ced-a0ce-3021f13f3573,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-613453529-172.17.0.8-1595739027376:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37657,DS-8a153c1e-43ef-441e-833c-708ae961681f,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-4fbbddd8-9ec4-4971-9129-0aea9f79760e,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-ba3dff43-69f2-4dc8-add3-6ccb21945534,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-79960b2c-6819-4308-9e31-fb65e70fe994,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-9fc3c978-323c-42d4-93ca-173c1f8ce129,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-9aa42f91-34fb-4198-995d-ac5ee8434be6,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-e573e76c-94ac-409d-98ea-0d4be0a98bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-b891550a-dad5-476e-b1e7-00baf2bed419,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-613453529-172.17.0.8-1595739027376:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37657,DS-8a153c1e-43ef-441e-833c-708ae961681f,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-4fbbddd8-9ec4-4971-9129-0aea9f79760e,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-ba3dff43-69f2-4dc8-add3-6ccb21945534,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-79960b2c-6819-4308-9e31-fb65e70fe994,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-9fc3c978-323c-42d4-93ca-173c1f8ce129,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-9aa42f91-34fb-4198-995d-ac5ee8434be6,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-e573e76c-94ac-409d-98ea-0d4be0a98bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-b891550a-dad5-476e-b1e7-00baf2bed419,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-48296459-172.17.0.8-1595739482436:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46034,DS-60764495-d06e-460a-9dcf-e97224c9a2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-55444cb3-ecde-497e-a52a-34f05fa42cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-2ece8449-01cf-41e6-9645-f81e808fc4da,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-887353a1-0c5f-4aed-9e40-f4682c7d7764,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-35d96c30-46ff-4213-964b-997fb1959ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-3284bb4c-5561-4db0-a364-cb72d007b0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-57330ef4-2174-446a-a8a4-abc0be624757,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-ad0995fd-3d1d-4e08-ae93-e2731f4b540a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-48296459-172.17.0.8-1595739482436:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46034,DS-60764495-d06e-460a-9dcf-e97224c9a2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-55444cb3-ecde-497e-a52a-34f05fa42cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-2ece8449-01cf-41e6-9645-f81e808fc4da,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-887353a1-0c5f-4aed-9e40-f4682c7d7764,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-35d96c30-46ff-4213-964b-997fb1959ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-3284bb4c-5561-4db0-a364-cb72d007b0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-57330ef4-2174-446a-a8a4-abc0be624757,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-ad0995fd-3d1d-4e08-ae93-e2731f4b540a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1497288637-172.17.0.8-1595739628542:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40413,DS-f2351183-b677-407d-8cc5-c0e19bd6105d,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-8135964b-7b73-4084-893b-0d6eca7676b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-3d312904-2c9b-4fd1-81bd-f8068e6f261d,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-637a2207-8da2-43e6-ac81-2558a1824843,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-09861a5c-a66f-49e2-85ba-4d637ccae064,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-cb6a57dc-7117-41ee-a5fe-7bcbae09026f,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-2bb95e1b-4a65-4bef-b425-a301c18705f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-928654c9-19da-4e14-8be5-d29f81014d8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1497288637-172.17.0.8-1595739628542:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40413,DS-f2351183-b677-407d-8cc5-c0e19bd6105d,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-8135964b-7b73-4084-893b-0d6eca7676b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-3d312904-2c9b-4fd1-81bd-f8068e6f261d,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-637a2207-8da2-43e6-ac81-2558a1824843,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-09861a5c-a66f-49e2-85ba-4d637ccae064,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-cb6a57dc-7117-41ee-a5fe-7bcbae09026f,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-2bb95e1b-4a65-4bef-b425-a301c18705f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-928654c9-19da-4e14-8be5-d29f81014d8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1297707710-172.17.0.8-1595739949411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37800,DS-4e244972-b09e-4ea4-b270-84eea7a2cf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-adbffbcd-0a95-4f23-891b-ea603d1603cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-8d6e9d43-3536-4336-8342-b7c7ff758c83,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-fdd69ca6-9be1-410a-9803-3d3e61bebe61,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-ede2259e-f3a9-4096-912d-5a74cb1001b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-15f7e4b8-e2a8-4118-8a65-9aa247453a24,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-9d450d33-dd4f-4c99-9844-eda52b7ed2af,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-b6a53b02-6a2e-4d7c-a55e-7523bfb6cd9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1297707710-172.17.0.8-1595739949411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37800,DS-4e244972-b09e-4ea4-b270-84eea7a2cf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-adbffbcd-0a95-4f23-891b-ea603d1603cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-8d6e9d43-3536-4336-8342-b7c7ff758c83,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-fdd69ca6-9be1-410a-9803-3d3e61bebe61,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-ede2259e-f3a9-4096-912d-5a74cb1001b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-15f7e4b8-e2a8-4118-8a65-9aa247453a24,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-9d450d33-dd4f-4c99-9844-eda52b7ed2af,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-b6a53b02-6a2e-4d7c-a55e-7523bfb6cd9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-144334538-172.17.0.8-1595740494855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33873,DS-a8f96eed-3e10-44b1-8d0f-c1942eb9a12f,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-947557e2-34ff-41b4-93ef-f4a4da757a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-72ab98f1-fddd-4e3f-9606-ad4d255d005e,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-b438d107-6b03-4483-8404-be23aab19aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-f2d2eff9-927a-461c-9af4-c0bce651999f,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-b40d2448-caad-4a1e-b990-868bdf9c41c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-12ba6ff4-c3d5-48bf-acac-173be7ad6b04,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-6e2a9cf5-a8db-44de-9b39-e8d0522b8c9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-144334538-172.17.0.8-1595740494855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33873,DS-a8f96eed-3e10-44b1-8d0f-c1942eb9a12f,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-947557e2-34ff-41b4-93ef-f4a4da757a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-72ab98f1-fddd-4e3f-9606-ad4d255d005e,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-b438d107-6b03-4483-8404-be23aab19aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-f2d2eff9-927a-461c-9af4-c0bce651999f,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-b40d2448-caad-4a1e-b990-868bdf9c41c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-12ba6ff4-c3d5-48bf-acac-173be7ad6b04,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-6e2a9cf5-a8db-44de-9b39-e8d0522b8c9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6887
