reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962982755-172.17.0.10-1595577178097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41274,DS-a32aa3c4-4c1b-4be2-883e-467c3a2e1089,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-8ce758ec-7957-4462-9187-2fa467386089,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-c9ef96e6-7e19-461e-a788-a3ed0616bad7,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-8c6991e3-9759-4a3b-a5f3-1826611dca86,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-a8f629af-1f32-466b-8d0c-5f66ef25b1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-79bd6f58-6cb3-4455-a487-8fc64b7f12dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-eeb1bd2a-531f-4c89-9772-528466378192,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-08d4c201-315b-4ddc-af49-5d6a6d441bae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962982755-172.17.0.10-1595577178097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41274,DS-a32aa3c4-4c1b-4be2-883e-467c3a2e1089,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-8ce758ec-7957-4462-9187-2fa467386089,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-c9ef96e6-7e19-461e-a788-a3ed0616bad7,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-8c6991e3-9759-4a3b-a5f3-1826611dca86,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-a8f629af-1f32-466b-8d0c-5f66ef25b1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-79bd6f58-6cb3-4455-a487-8fc64b7f12dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-eeb1bd2a-531f-4c89-9772-528466378192,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-08d4c201-315b-4ddc-af49-5d6a6d441bae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1779505827-172.17.0.10-1595577770379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34057,DS-15b776d2-062a-44d5-8e95-ba53518b4ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-750679e6-4c90-4946-939e-b0b7bcd30b99,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-7fda8264-b286-43a0-ac74-8b9fdd6d89f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-abc3904d-6456-49c6-ba97-1fa52d1d18a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-17c7fc2b-74a6-4447-8a8e-904225fca686,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-a47d618f-dae1-4d33-962d-f15891628751,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-071ac448-65e6-447a-abdf-012eaa31d52c,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-a37d1a00-6f14-4844-a882-138c8acb907a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1779505827-172.17.0.10-1595577770379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34057,DS-15b776d2-062a-44d5-8e95-ba53518b4ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-750679e6-4c90-4946-939e-b0b7bcd30b99,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-7fda8264-b286-43a0-ac74-8b9fdd6d89f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-abc3904d-6456-49c6-ba97-1fa52d1d18a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-17c7fc2b-74a6-4447-8a8e-904225fca686,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-a47d618f-dae1-4d33-962d-f15891628751,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-071ac448-65e6-447a-abdf-012eaa31d52c,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-a37d1a00-6f14-4844-a882-138c8acb907a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292548972-172.17.0.10-1595577889342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43524,DS-45cb3c5c-58dd-403e-a802-0c2a19c5bbde,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-cffbc61d-a553-40c5-929d-61868101acdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-ef729519-35fb-4993-99e8-d23ac45963cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-5420eed0-aae5-4776-8a78-17a1c3a38819,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-4cf07f76-237c-4494-b6ad-370f30453992,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-6f7b0d17-c637-40e9-918c-35de0a9d2cba,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-b8f97edf-ca4d-4862-91ee-7e71376e69e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-f1a39dd5-525b-416e-a5a8-cd31c83be4b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292548972-172.17.0.10-1595577889342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43524,DS-45cb3c5c-58dd-403e-a802-0c2a19c5bbde,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-cffbc61d-a553-40c5-929d-61868101acdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-ef729519-35fb-4993-99e8-d23ac45963cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-5420eed0-aae5-4776-8a78-17a1c3a38819,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-4cf07f76-237c-4494-b6ad-370f30453992,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-6f7b0d17-c637-40e9-918c-35de0a9d2cba,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-b8f97edf-ca4d-4862-91ee-7e71376e69e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-f1a39dd5-525b-416e-a5a8-cd31c83be4b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695716667-172.17.0.10-1595578106348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37876,DS-319edc43-d4b6-47ac-9f00-48f7a9f75704,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-601f246b-3e1a-4adc-b067-f0dd7ed85bca,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-d8c81e62-47f8-4f3e-a8a6-f46d87232821,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-bbee0a52-a53f-470d-a04c-840409d69080,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-be5c39b4-2778-439f-bf75-45e3b9dda180,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-e2dda031-fa32-4a9f-9097-6ee2bd8f9336,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-29d1e8ac-2005-4d00-bc35-0b3512a7cf53,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-7a20faf1-7da8-480c-b0f4-f1ae302d812a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695716667-172.17.0.10-1595578106348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37876,DS-319edc43-d4b6-47ac-9f00-48f7a9f75704,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-601f246b-3e1a-4adc-b067-f0dd7ed85bca,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-d8c81e62-47f8-4f3e-a8a6-f46d87232821,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-bbee0a52-a53f-470d-a04c-840409d69080,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-be5c39b4-2778-439f-bf75-45e3b9dda180,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-e2dda031-fa32-4a9f-9097-6ee2bd8f9336,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-29d1e8ac-2005-4d00-bc35-0b3512a7cf53,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-7a20faf1-7da8-480c-b0f4-f1ae302d812a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2072783492-172.17.0.10-1595578671316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45348,DS-017d84a1-2651-4ff2-b392-84159b8f4415,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-0379904e-250f-4b2b-bcb6-94d34c540f94,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-a8f6c8c3-3a7a-448e-8478-3b5774cc90a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-e4158105-4f33-44b4-97f2-cf9f4b8851ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-0ac446e2-f292-466e-8b95-dbeafc068b82,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-25d0cf95-9af6-4aa6-abb2-442e74836ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-66e2c8d3-883a-441c-8dfc-10fb20b78f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-1ad82430-9432-4752-9798-15f13e0cc695,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2072783492-172.17.0.10-1595578671316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45348,DS-017d84a1-2651-4ff2-b392-84159b8f4415,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-0379904e-250f-4b2b-bcb6-94d34c540f94,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-a8f6c8c3-3a7a-448e-8478-3b5774cc90a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-e4158105-4f33-44b4-97f2-cf9f4b8851ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-0ac446e2-f292-466e-8b95-dbeafc068b82,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-25d0cf95-9af6-4aa6-abb2-442e74836ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-66e2c8d3-883a-441c-8dfc-10fb20b78f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-1ad82430-9432-4752-9798-15f13e0cc695,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166835741-172.17.0.10-1595578839457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34045,DS-e2364e0f-edd1-4bc6-8c14-04de8391e9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-c003b4a0-c343-4cd2-8c12-a9a67d740222,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-b7d49f1e-825b-49df-bd38-84aa87dc2651,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-96836cb3-5527-450a-9c5d-9d2bd2baddd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-37cc3c2b-5f13-42a1-bed3-01a7eaa27d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-4e0f3790-b3f1-4a7c-96d4-ab9ef7d1a758,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-e28e33ac-8ebb-41e0-b634-5fd1f5ae255d,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-64090ecb-3893-4ee0-a8d5-f12809a7b61a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166835741-172.17.0.10-1595578839457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34045,DS-e2364e0f-edd1-4bc6-8c14-04de8391e9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-c003b4a0-c343-4cd2-8c12-a9a67d740222,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-b7d49f1e-825b-49df-bd38-84aa87dc2651,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-96836cb3-5527-450a-9c5d-9d2bd2baddd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-37cc3c2b-5f13-42a1-bed3-01a7eaa27d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-4e0f3790-b3f1-4a7c-96d4-ab9ef7d1a758,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-e28e33ac-8ebb-41e0-b634-5fd1f5ae255d,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-64090ecb-3893-4ee0-a8d5-f12809a7b61a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-582164296-172.17.0.10-1595578883769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35378,DS-1c6bcd0d-90d7-4cd5-a92b-3e33c3c02ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-1e682b04-03ac-46d3-af6d-de66701e1838,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-0850d32e-1248-44c6-bb79-700a243e9b91,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-ce7deac3-afbb-44a9-a8fd-47ccb6a86b16,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-471de1d4-aa72-4fa3-b2cb-3fbd7915abac,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-0dd35d56-9551-4487-86da-670d3312f266,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-cd4076f9-5061-414f-82c4-eceb045c0777,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-c86f152b-2fe2-4c5e-a050-4e69ac439571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-582164296-172.17.0.10-1595578883769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35378,DS-1c6bcd0d-90d7-4cd5-a92b-3e33c3c02ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-1e682b04-03ac-46d3-af6d-de66701e1838,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-0850d32e-1248-44c6-bb79-700a243e9b91,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-ce7deac3-afbb-44a9-a8fd-47ccb6a86b16,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-471de1d4-aa72-4fa3-b2cb-3fbd7915abac,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-0dd35d56-9551-4487-86da-670d3312f266,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-cd4076f9-5061-414f-82c4-eceb045c0777,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-c86f152b-2fe2-4c5e-a050-4e69ac439571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-504964250-172.17.0.10-1595579069605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39330,DS-4cc15a15-c4a8-4407-a745-35f2251e97cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-a08a69d6-cc5f-4788-830d-ab58c2887920,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-56856b7f-236f-4286-9c1f-5a20a2208465,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-6aa490ff-1738-411e-8ea8-ed70514b2ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-bf4201b3-cffb-410a-b5ce-17df60812624,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-17fba2a2-c0ac-49c9-b3b0-7d55e5dac2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-59072ace-91cc-473c-bb5b-e4c0f5c1f262,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-e8d99738-06db-4934-a393-4ca9e1a09d27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-504964250-172.17.0.10-1595579069605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39330,DS-4cc15a15-c4a8-4407-a745-35f2251e97cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-a08a69d6-cc5f-4788-830d-ab58c2887920,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-56856b7f-236f-4286-9c1f-5a20a2208465,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-6aa490ff-1738-411e-8ea8-ed70514b2ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-bf4201b3-cffb-410a-b5ce-17df60812624,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-17fba2a2-c0ac-49c9-b3b0-7d55e5dac2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-59072ace-91cc-473c-bb5b-e4c0f5c1f262,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-e8d99738-06db-4934-a393-4ca9e1a09d27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-423690368-172.17.0.10-1595579105353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45332,DS-d5c3bc96-210d-454c-80a4-e7ac0f3807c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-691c8bc6-78ac-41e6-93bc-1bf9ebe0f025,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-804b5776-e425-4133-9789-bd3917710e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-ec05fa28-1b5a-4a24-bb07-d03ea1c6f838,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-b86339eb-af15-45fb-9156-123eb948ddf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-52167d57-4cec-40ac-88fe-0101021f8cae,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-941eb69c-826a-45dd-b0d3-f91dfc06d896,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-e2d1bcc4-5c1e-4467-b17c-42b169590bda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-423690368-172.17.0.10-1595579105353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45332,DS-d5c3bc96-210d-454c-80a4-e7ac0f3807c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-691c8bc6-78ac-41e6-93bc-1bf9ebe0f025,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-804b5776-e425-4133-9789-bd3917710e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-ec05fa28-1b5a-4a24-bb07-d03ea1c6f838,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-b86339eb-af15-45fb-9156-123eb948ddf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-52167d57-4cec-40ac-88fe-0101021f8cae,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-941eb69c-826a-45dd-b0d3-f91dfc06d896,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-e2d1bcc4-5c1e-4467-b17c-42b169590bda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800430589-172.17.0.10-1595579309760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39959,DS-83b25615-a8d4-4751-9a03-e0dc536c4de8,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-ebbbea01-9cab-4b1b-8db8-bd358d8f114d,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-62e0db08-d349-42d0-bc7f-407319a50220,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-77d36473-d697-49c4-a017-605da19dec2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-674f155d-070b-4080-844e-55deecb0f218,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-77a376a5-e570-4c71-a06e-327ee1d4cc04,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-c92f98d1-5688-4d5c-9d96-d99244c7981d,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-ce203ac1-21d8-4679-b73d-f03a71640b4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800430589-172.17.0.10-1595579309760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39959,DS-83b25615-a8d4-4751-9a03-e0dc536c4de8,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-ebbbea01-9cab-4b1b-8db8-bd358d8f114d,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-62e0db08-d349-42d0-bc7f-407319a50220,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-77d36473-d697-49c4-a017-605da19dec2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-674f155d-070b-4080-844e-55deecb0f218,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-77a376a5-e570-4c71-a06e-327ee1d4cc04,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-c92f98d1-5688-4d5c-9d96-d99244c7981d,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-ce203ac1-21d8-4679-b73d-f03a71640b4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477940198-172.17.0.10-1595580273601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43379,DS-c9570087-645b-44a2-a1eb-d439bd0eaf96,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-50c69a9e-30f2-429c-85db-588c301b907a,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-14924f4c-eec9-4b16-88fc-766fea06d94c,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-2a467817-e27f-4fa0-885d-ffee9df388aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-6a2b1715-2aa1-48ef-8bf9-19cf4b33e6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-212c7be3-d508-4e96-ae42-ad2cc8208fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-ffa8359e-3d64-437f-9c2a-0945acb3e42f,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-e737096d-0cc3-4c4c-903d-1dc803082dda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477940198-172.17.0.10-1595580273601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43379,DS-c9570087-645b-44a2-a1eb-d439bd0eaf96,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-50c69a9e-30f2-429c-85db-588c301b907a,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-14924f4c-eec9-4b16-88fc-766fea06d94c,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-2a467817-e27f-4fa0-885d-ffee9df388aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-6a2b1715-2aa1-48ef-8bf9-19cf4b33e6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-212c7be3-d508-4e96-ae42-ad2cc8208fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-ffa8359e-3d64-437f-9c2a-0945acb3e42f,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-e737096d-0cc3-4c4c-903d-1dc803082dda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299363586-172.17.0.10-1595580352663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45227,DS-2998747b-a3bb-4116-b394-843449b9e74e,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-b8291b1c-9e01-4e03-b490-078ba293f035,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-bbf73753-d4cf-4c76-82d8-00f66bad1211,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-495d1e93-7eab-4792-9d66-0b72dce3af3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-854dd23b-a985-4da2-aa76-9121b97f9b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-c6400407-0656-48a8-a8ee-f97c1660831f,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-443fa81c-d681-49f5-8476-1110488ae6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-7c90585b-99ef-466f-a3db-43f84aff2d25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299363586-172.17.0.10-1595580352663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45227,DS-2998747b-a3bb-4116-b394-843449b9e74e,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-b8291b1c-9e01-4e03-b490-078ba293f035,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-bbf73753-d4cf-4c76-82d8-00f66bad1211,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-495d1e93-7eab-4792-9d66-0b72dce3af3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-854dd23b-a985-4da2-aa76-9121b97f9b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-c6400407-0656-48a8-a8ee-f97c1660831f,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-443fa81c-d681-49f5-8476-1110488ae6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-7c90585b-99ef-466f-a3db-43f84aff2d25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894381739-172.17.0.10-1595581136409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35064,DS-8cbe1e6a-b1fc-4520-b014-00e4c965955a,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-bd14e4e6-3098-40a7-9577-2563d3067549,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-c4a44d01-6523-44b9-97cf-2f7acda4bb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-9d111f74-595b-44d1-ab4e-bee7e9e16dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-79523cdd-d2df-45ff-9803-688ab9168fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-b044c2f1-0373-4e41-978d-748d91438784,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-f6a90b24-14fa-44a3-80d8-9b14a0155357,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-d140f423-0cf8-48c3-9be3-20744d3e1239,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894381739-172.17.0.10-1595581136409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35064,DS-8cbe1e6a-b1fc-4520-b014-00e4c965955a,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-bd14e4e6-3098-40a7-9577-2563d3067549,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-c4a44d01-6523-44b9-97cf-2f7acda4bb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-9d111f74-595b-44d1-ab4e-bee7e9e16dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-79523cdd-d2df-45ff-9803-688ab9168fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-b044c2f1-0373-4e41-978d-748d91438784,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-f6a90b24-14fa-44a3-80d8-9b14a0155357,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-d140f423-0cf8-48c3-9be3-20744d3e1239,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-384546339-172.17.0.10-1595581620814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39398,DS-070e2854-00d5-4dda-8ea8-1e5a7e597146,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-d921547a-ebfd-4d03-9f15-1f0ab1908ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:39072,DS-a05a9b1b-6481-45cf-910b-47464aa8e006,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-389c894c-6c92-4776-9296-94a7860e6380,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-25f4474c-3966-4059-af01-43b8a7fb116e,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-4892df76-179a-42a1-ba20-1b987d0792a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-644a3968-fa11-47d5-8d7f-c48b68c0a450,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-b9ac1ff8-b009-4b55-aed9-be76a4120d65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-384546339-172.17.0.10-1595581620814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39398,DS-070e2854-00d5-4dda-8ea8-1e5a7e597146,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-d921547a-ebfd-4d03-9f15-1f0ab1908ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:39072,DS-a05a9b1b-6481-45cf-910b-47464aa8e006,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-389c894c-6c92-4776-9296-94a7860e6380,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-25f4474c-3966-4059-af01-43b8a7fb116e,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-4892df76-179a-42a1-ba20-1b987d0792a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-644a3968-fa11-47d5-8d7f-c48b68c0a450,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-b9ac1ff8-b009-4b55-aed9-be76a4120d65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1750617523-172.17.0.10-1595581979172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33184,DS-8c54dc9f-ef20-4312-b757-3f111f89dd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-471d9302-3926-41d0-b706-1015aa043915,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-761713ac-a2a2-4e35-bc94-06d9000329c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-9dd1d6d7-a6fa-4941-853f-70a81079fd54,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-88c2c4b7-49e5-46d9-ab1e-e52a7a4319d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-476f8377-33c3-42e3-bc5f-9104b74b8dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-027f3b97-dbe4-4b83-9d44-4c3f96d533f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-2bd339b6-8481-482e-ac3f-695f0b3b8306,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1750617523-172.17.0.10-1595581979172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33184,DS-8c54dc9f-ef20-4312-b757-3f111f89dd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-471d9302-3926-41d0-b706-1015aa043915,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-761713ac-a2a2-4e35-bc94-06d9000329c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-9dd1d6d7-a6fa-4941-853f-70a81079fd54,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-88c2c4b7-49e5-46d9-ab1e-e52a7a4319d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-476f8377-33c3-42e3-bc5f-9104b74b8dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-027f3b97-dbe4-4b83-9d44-4c3f96d533f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-2bd339b6-8481-482e-ac3f-695f0b3b8306,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976677429-172.17.0.10-1595582479667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42147,DS-86b84d9e-9763-4f13-a3ca-55fbec97c297,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-bca6a1ef-69be-4f58-8210-717ee7e86239,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-fd2723fe-80d9-436d-815d-d2ea8f3d2ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-e78b9808-7c26-48d2-b5a7-a734fdef0416,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-4e66f757-bea2-4ea5-9aa6-fd4f96d2c1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-af9844a1-793b-446a-970e-3c19e3cc423c,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-b101e152-1011-4f46-956d-45f883f2f9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-1883e465-8808-4e68-929f-b8decda7cef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976677429-172.17.0.10-1595582479667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42147,DS-86b84d9e-9763-4f13-a3ca-55fbec97c297,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-bca6a1ef-69be-4f58-8210-717ee7e86239,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-fd2723fe-80d9-436d-815d-d2ea8f3d2ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-e78b9808-7c26-48d2-b5a7-a734fdef0416,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-4e66f757-bea2-4ea5-9aa6-fd4f96d2c1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-af9844a1-793b-446a-970e-3c19e3cc423c,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-b101e152-1011-4f46-956d-45f883f2f9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-1883e465-8808-4e68-929f-b8decda7cef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6441
