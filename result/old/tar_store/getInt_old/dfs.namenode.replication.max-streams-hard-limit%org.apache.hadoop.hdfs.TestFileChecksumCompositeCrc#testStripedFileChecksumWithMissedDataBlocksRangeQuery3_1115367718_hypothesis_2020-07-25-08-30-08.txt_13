reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141976984-172.17.0.9-1595665963549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42300,DS-c4a79891-ee5f-4d48-ac0a-ed239976f3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-4becc176-1d23-43e7-a858-3cf2e8045d10,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-b3464932-9007-4a48-8227-c252c38e5ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-2a0e6610-b124-4ce4-ab0b-2495b20ef572,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-f35d6d34-59a5-4647-9de1-6d0ac95aa106,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-f356da46-9079-41c9-a306-05a8e3c523da,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-a506158f-6370-4f1b-af54-d9518847fb53,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-da4be0bc-666a-463f-b3f1-0f393d0d1218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141976984-172.17.0.9-1595665963549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42300,DS-c4a79891-ee5f-4d48-ac0a-ed239976f3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-4becc176-1d23-43e7-a858-3cf2e8045d10,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-b3464932-9007-4a48-8227-c252c38e5ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-2a0e6610-b124-4ce4-ab0b-2495b20ef572,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-f35d6d34-59a5-4647-9de1-6d0ac95aa106,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-f356da46-9079-41c9-a306-05a8e3c523da,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-a506158f-6370-4f1b-af54-d9518847fb53,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-da4be0bc-666a-463f-b3f1-0f393d0d1218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-379967687-172.17.0.9-1595665998276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36197,DS-58437985-94f2-482c-a0ac-96211d1a6774,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-a4b02fa7-bd7c-44ad-b943-8fc8bc9ddf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-934f3787-9b27-41fc-8a5f-6ea7c3be0200,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-8a0c8830-8e6a-4aae-b617-3acaaf75012b,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-4c0088f0-ec88-4c65-8e9c-acb8510626f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-fd228238-7f1c-4bd3-994b-da5505267204,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-14aafa5c-95bc-4096-892d-ad540380193a,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-4a8ccd88-791c-4a3d-bac5-3613d8f6f7a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-379967687-172.17.0.9-1595665998276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36197,DS-58437985-94f2-482c-a0ac-96211d1a6774,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-a4b02fa7-bd7c-44ad-b943-8fc8bc9ddf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-934f3787-9b27-41fc-8a5f-6ea7c3be0200,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-8a0c8830-8e6a-4aae-b617-3acaaf75012b,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-4c0088f0-ec88-4c65-8e9c-acb8510626f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-fd228238-7f1c-4bd3-994b-da5505267204,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-14aafa5c-95bc-4096-892d-ad540380193a,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-4a8ccd88-791c-4a3d-bac5-3613d8f6f7a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188498985-172.17.0.9-1595666037331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36359,DS-3b8f9fa3-b0bc-480a-8cf3-91da857a2a50,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-0413935c-9d9c-463c-8a8e-ecea6592a594,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-5ee0d22c-aaf2-4b84-9c28-221dbee977ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-f54c1f74-f057-4535-997f-d86b6e68c6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-5ee64520-d28b-4d8b-a60a-89af9613d39e,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-168944e2-7686-4971-be16-aa460e4f6966,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-5f9924e0-bb11-4620-a7a7-9d6b5caa1f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-c380a4b1-32ab-40a5-b018-0e7f2e9e7b0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188498985-172.17.0.9-1595666037331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36359,DS-3b8f9fa3-b0bc-480a-8cf3-91da857a2a50,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-0413935c-9d9c-463c-8a8e-ecea6592a594,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-5ee0d22c-aaf2-4b84-9c28-221dbee977ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-f54c1f74-f057-4535-997f-d86b6e68c6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-5ee64520-d28b-4d8b-a60a-89af9613d39e,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-168944e2-7686-4971-be16-aa460e4f6966,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-5f9924e0-bb11-4620-a7a7-9d6b5caa1f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-c380a4b1-32ab-40a5-b018-0e7f2e9e7b0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137104610-172.17.0.9-1595666164028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37027,DS-f1c86a6b-93b9-4af5-be57-53f70d7eff15,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-3f295b54-b4b0-41ea-b074-c703a21c4d95,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-dcfac719-fb9d-4b3c-962d-7a39cf739719,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-d005e044-482b-46ab-bf97-b02389a0784c,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-4bb7dd59-12d1-45cc-a9ef-d33a280f2370,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-22f924ee-cd5d-4ed8-9b75-db040974d814,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-fd3cc06f-2d3a-4e91-835f-55e5e8d231a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-117e5ce8-b3bf-4b97-b3a3-787a69248a53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137104610-172.17.0.9-1595666164028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37027,DS-f1c86a6b-93b9-4af5-be57-53f70d7eff15,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-3f295b54-b4b0-41ea-b074-c703a21c4d95,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-dcfac719-fb9d-4b3c-962d-7a39cf739719,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-d005e044-482b-46ab-bf97-b02389a0784c,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-4bb7dd59-12d1-45cc-a9ef-d33a280f2370,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-22f924ee-cd5d-4ed8-9b75-db040974d814,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-fd3cc06f-2d3a-4e91-835f-55e5e8d231a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-117e5ce8-b3bf-4b97-b3a3-787a69248a53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130449767-172.17.0.9-1595666197871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39866,DS-f6082725-c4d5-41c6-9852-f1614deca016,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-be1f0006-4089-4b1a-86ec-43cba3dc9a77,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-0b781fa9-4bf7-4aff-8d70-5c582bd4b131,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-af4b0bff-d446-42ff-b870-39a20e038a52,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-ec99e02d-4a43-45c8-bc74-ab85f7d66d99,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-29bfa490-5f0d-4abd-a0b8-606b9b1b1b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-f9d50d0d-6118-4e22-9052-0847380e37fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-5992bf00-0f43-436a-bcbf-2aef79019f52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130449767-172.17.0.9-1595666197871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39866,DS-f6082725-c4d5-41c6-9852-f1614deca016,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-be1f0006-4089-4b1a-86ec-43cba3dc9a77,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-0b781fa9-4bf7-4aff-8d70-5c582bd4b131,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-af4b0bff-d446-42ff-b870-39a20e038a52,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-ec99e02d-4a43-45c8-bc74-ab85f7d66d99,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-29bfa490-5f0d-4abd-a0b8-606b9b1b1b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-f9d50d0d-6118-4e22-9052-0847380e37fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-5992bf00-0f43-436a-bcbf-2aef79019f52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811590362-172.17.0.9-1595666234242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39033,DS-bc453df8-71bc-4243-ac3b-42ea78ce08f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-60ee796f-d374-4565-a34c-886fb2b762e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-af816e9e-9de1-47c5-958c-c904dcb97946,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-e304b895-c69d-4df8-9837-7f852aca69bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-5fb0a4a4-c78f-44e7-8660-8f58301eae8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-14b48169-020b-4537-9a64-5134c48b012b,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-a664aee7-2d4a-4f1c-b1da-f7b0d2af6e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-75139f31-ed6e-4718-9924-88d2623f1850,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811590362-172.17.0.9-1595666234242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39033,DS-bc453df8-71bc-4243-ac3b-42ea78ce08f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-60ee796f-d374-4565-a34c-886fb2b762e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-af816e9e-9de1-47c5-958c-c904dcb97946,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-e304b895-c69d-4df8-9837-7f852aca69bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-5fb0a4a4-c78f-44e7-8660-8f58301eae8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-14b48169-020b-4537-9a64-5134c48b012b,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-a664aee7-2d4a-4f1c-b1da-f7b0d2af6e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-75139f31-ed6e-4718-9924-88d2623f1850,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1648376837-172.17.0.9-1595666387985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38977,DS-b7c53b16-2bad-45f0-8808-e1f551f4ca65,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-962147dd-ccce-45a7-a2e0-5f40cee376eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-ae560197-3d36-4a7d-aecb-742b16d18ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-e06fbd42-9b83-4a64-ad7a-0ea9fc902778,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-10dce8ff-5522-4b1d-b6be-bd5d73c1a498,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-321d307e-5fb3-422e-b35f-e3e3984e21fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-ac7936a9-ae96-4f5e-9b4c-119b45271377,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-7a502a21-786b-4b62-992a-fadc4549135d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1648376837-172.17.0.9-1595666387985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38977,DS-b7c53b16-2bad-45f0-8808-e1f551f4ca65,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-962147dd-ccce-45a7-a2e0-5f40cee376eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-ae560197-3d36-4a7d-aecb-742b16d18ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-e06fbd42-9b83-4a64-ad7a-0ea9fc902778,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-10dce8ff-5522-4b1d-b6be-bd5d73c1a498,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-321d307e-5fb3-422e-b35f-e3e3984e21fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-ac7936a9-ae96-4f5e-9b4c-119b45271377,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-7a502a21-786b-4b62-992a-fadc4549135d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961949386-172.17.0.9-1595666541796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42182,DS-725392e2-5991-412f-b653-74e0403ad58c,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-3b732bbe-f511-4451-a9f4-def358129c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-5c9f426a-703a-42be-b0cb-c195a62de4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-063faa84-4d6d-4585-9511-4711c6b303df,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-1b9c8383-613d-404b-97a7-30e7fae43db3,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-edd9146c-d4c6-40be-b0e3-554701569d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-8d54fe1f-3c71-4647-b2b0-00939da43a28,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-4cf34177-1b20-460d-af9c-0aaec8f44cdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961949386-172.17.0.9-1595666541796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42182,DS-725392e2-5991-412f-b653-74e0403ad58c,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-3b732bbe-f511-4451-a9f4-def358129c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-5c9f426a-703a-42be-b0cb-c195a62de4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-063faa84-4d6d-4585-9511-4711c6b303df,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-1b9c8383-613d-404b-97a7-30e7fae43db3,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-edd9146c-d4c6-40be-b0e3-554701569d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-8d54fe1f-3c71-4647-b2b0-00939da43a28,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-4cf34177-1b20-460d-af9c-0aaec8f44cdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-966275991-172.17.0.9-1595666583699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37156,DS-de83f8f8-2eef-412c-bbf1-3f20ec671864,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-77f4c5f7-ba0c-4cfd-bd9a-bbf795c24d02,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-5f3bf858-d74d-48e1-aac4-f5e79a0da8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-fca7e81a-0aa8-47c6-a33d-b74d60c47015,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-64130c3f-a503-4797-9999-ed6f45ae49b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-1a23e19f-09c3-48ae-b91e-0996e963d593,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-34a8e0b7-97fe-4270-8a47-518dbe4ec3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-2309ba30-4b6d-4f32-832a-f5d8d0b4a1f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-966275991-172.17.0.9-1595666583699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37156,DS-de83f8f8-2eef-412c-bbf1-3f20ec671864,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-77f4c5f7-ba0c-4cfd-bd9a-bbf795c24d02,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-5f3bf858-d74d-48e1-aac4-f5e79a0da8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-fca7e81a-0aa8-47c6-a33d-b74d60c47015,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-64130c3f-a503-4797-9999-ed6f45ae49b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-1a23e19f-09c3-48ae-b91e-0996e963d593,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-34a8e0b7-97fe-4270-8a47-518dbe4ec3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-2309ba30-4b6d-4f32-832a-f5d8d0b4a1f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040690530-172.17.0.9-1595666925139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34776,DS-212dd22e-351c-40ca-9cda-a6307da22326,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-824f9ca2-d18d-4401-8c0d-4d25fb1e2bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-886afcdf-1a2a-4677-b017-f5c6842c6642,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-617a05a3-ce61-4e50-aecc-dd5134f43951,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-890591af-b428-47ab-8981-a0ba0f957e25,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-b116bea6-451e-4cb6-8655-ec93d9783613,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-601158cf-000a-4cbb-991e-ab1598f9acdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-3490d5bb-cd17-4ec5-84ef-29e8f1903ab9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040690530-172.17.0.9-1595666925139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34776,DS-212dd22e-351c-40ca-9cda-a6307da22326,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-824f9ca2-d18d-4401-8c0d-4d25fb1e2bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-886afcdf-1a2a-4677-b017-f5c6842c6642,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-617a05a3-ce61-4e50-aecc-dd5134f43951,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-890591af-b428-47ab-8981-a0ba0f957e25,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-b116bea6-451e-4cb6-8655-ec93d9783613,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-601158cf-000a-4cbb-991e-ab1598f9acdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-3490d5bb-cd17-4ec5-84ef-29e8f1903ab9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1787561055-172.17.0.9-1595667065634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42284,DS-2d89a918-e32c-45b5-89fc-551105ae9589,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-ef328242-e52b-4ffb-babb-bd29da07dccd,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-9938c234-4641-45f0-b696-2d3ad8e863ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-19da777a-f143-4378-a866-fac4a9389e35,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-5b3e3b79-9b18-4fa9-b338-22bf00d48ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-66dbbc13-29c5-45aa-a120-fe96cd125123,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-92552ccb-3264-4792-852b-6e631683cf96,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-e1e29e79-4ffa-4a5e-a4d5-293625181d62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1787561055-172.17.0.9-1595667065634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42284,DS-2d89a918-e32c-45b5-89fc-551105ae9589,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-ef328242-e52b-4ffb-babb-bd29da07dccd,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-9938c234-4641-45f0-b696-2d3ad8e863ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-19da777a-f143-4378-a866-fac4a9389e35,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-5b3e3b79-9b18-4fa9-b338-22bf00d48ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-66dbbc13-29c5-45aa-a120-fe96cd125123,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-92552ccb-3264-4792-852b-6e631683cf96,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-e1e29e79-4ffa-4a5e-a4d5-293625181d62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268138730-172.17.0.9-1595667220915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41794,DS-e80d0458-6c17-430a-85c4-3e7cfbc18bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-072bc4ef-c473-4445-a3c0-6ee5748a6a72,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-714c722f-1217-4387-8f8e-3f055f6e20bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-7efba5a5-5077-4314-a21d-1b3cd18d97b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-49227f38-8f39-4edd-883a-f61320fdcfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-14700a25-5e04-46c1-b006-203c4eaee2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-52bb243e-2c00-44f3-88c3-a5ed17776c20,DISK], DatanodeInfoWithStorage[127.0.0.1:34182,DS-4071a42d-dcb1-4c30-8b5a-ecba07ea7ceb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268138730-172.17.0.9-1595667220915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41794,DS-e80d0458-6c17-430a-85c4-3e7cfbc18bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-072bc4ef-c473-4445-a3c0-6ee5748a6a72,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-714c722f-1217-4387-8f8e-3f055f6e20bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-7efba5a5-5077-4314-a21d-1b3cd18d97b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-49227f38-8f39-4edd-883a-f61320fdcfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-14700a25-5e04-46c1-b006-203c4eaee2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-52bb243e-2c00-44f3-88c3-a5ed17776c20,DISK], DatanodeInfoWithStorage[127.0.0.1:34182,DS-4071a42d-dcb1-4c30-8b5a-ecba07ea7ceb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489408800-172.17.0.9-1595667637368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34893,DS-a6e15784-08b9-43a6-83c7-f2eaae15e325,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-b7653b87-21a1-471e-adb5-5cf6a4da40c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-7364d697-c16a-484e-b750-6e56a23d5845,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-42ae50c5-070d-48a6-93e5-19e47ee2a104,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-f07a2a2e-cc66-4e00-9483-85da419ce28c,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-2e225d29-76a3-4751-be5b-4c2486396cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-eb569551-185e-454c-a9a8-65da7476853e,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-7b0bf061-16ea-41d3-9d98-462db92fb302,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489408800-172.17.0.9-1595667637368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34893,DS-a6e15784-08b9-43a6-83c7-f2eaae15e325,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-b7653b87-21a1-471e-adb5-5cf6a4da40c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-7364d697-c16a-484e-b750-6e56a23d5845,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-42ae50c5-070d-48a6-93e5-19e47ee2a104,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-f07a2a2e-cc66-4e00-9483-85da419ce28c,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-2e225d29-76a3-4751-be5b-4c2486396cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-eb569551-185e-454c-a9a8-65da7476853e,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-7b0bf061-16ea-41d3-9d98-462db92fb302,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1778427507-172.17.0.9-1595669060545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35457,DS-29833acb-8512-428b-b66d-48c734c5ed08,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-ba788fdd-8c34-47d5-8a55-02a0718fab38,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-61284c24-5688-40c6-b162-81619d216a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-48518dc2-caae-4037-9fa8-75055c00e362,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-0fc1a6be-3b3c-4826-a8f2-6b5d1755d904,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-352a3eea-41da-4819-90b1-df7de871aa2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-64419854-47f0-4f6b-a7d4-bce9c903d2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-6610ef1c-13fb-4152-85a1-038ee1e671e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1778427507-172.17.0.9-1595669060545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35457,DS-29833acb-8512-428b-b66d-48c734c5ed08,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-ba788fdd-8c34-47d5-8a55-02a0718fab38,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-61284c24-5688-40c6-b162-81619d216a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-48518dc2-caae-4037-9fa8-75055c00e362,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-0fc1a6be-3b3c-4826-a8f2-6b5d1755d904,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-352a3eea-41da-4819-90b1-df7de871aa2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-64419854-47f0-4f6b-a7d4-bce9c903d2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-6610ef1c-13fb-4152-85a1-038ee1e671e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606852876-172.17.0.9-1595669128690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33246,DS-1716a61d-fc1d-4717-b0e9-0474555971f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-e91c9ef9-1bfa-4c89-b57e-e728428cd27d,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-0889a477-c066-44db-9d95-a3594e0f9dee,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-7772d00b-0b2b-4fcd-bb40-0830214b72b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-ea1aca30-cf1f-4044-939c-f505d6f700c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-65e06361-fc68-4e59-99b0-dfdd81714d98,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-177e11af-ffbf-42ff-9248-aec288a95cad,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-0c49bc8a-1abd-4fc0-ac89-ecb54bfacd06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606852876-172.17.0.9-1595669128690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33246,DS-1716a61d-fc1d-4717-b0e9-0474555971f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-e91c9ef9-1bfa-4c89-b57e-e728428cd27d,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-0889a477-c066-44db-9d95-a3594e0f9dee,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-7772d00b-0b2b-4fcd-bb40-0830214b72b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-ea1aca30-cf1f-4044-939c-f505d6f700c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-65e06361-fc68-4e59-99b0-dfdd81714d98,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-177e11af-ffbf-42ff-9248-aec288a95cad,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-0c49bc8a-1abd-4fc0-ac89-ecb54bfacd06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1910970863-172.17.0.9-1595669348486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41879,DS-31b2f921-4571-4995-8658-cb88ca7b91b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-34a56a9d-e952-4f65-b4a6-e376f1e5926c,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-17e5a835-d499-48df-adf6-7ed66b64b792,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-20c1ba1b-992c-483f-8eeb-c51a90f97a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-008e1732-ffd5-4399-9cb5-c10e9a58dab0,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-14f17df2-ea32-47c9-b72b-3760e4448cef,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-bd803737-d919-461f-9ec9-364f18c93dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-0b578cd8-c197-412a-8165-8695d127c05d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1910970863-172.17.0.9-1595669348486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41879,DS-31b2f921-4571-4995-8658-cb88ca7b91b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-34a56a9d-e952-4f65-b4a6-e376f1e5926c,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-17e5a835-d499-48df-adf6-7ed66b64b792,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-20c1ba1b-992c-483f-8eeb-c51a90f97a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-008e1732-ffd5-4399-9cb5-c10e9a58dab0,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-14f17df2-ea32-47c9-b72b-3760e4448cef,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-bd803737-d919-461f-9ec9-364f18c93dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-0b578cd8-c197-412a-8165-8695d127c05d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903660378-172.17.0.9-1595669661579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43452,DS-5d270d17-2611-4a5e-8bbd-3ff8f9cdb3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-ce449d8f-83c7-4de0-ae26-7f776e159e20,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-e202bc57-d459-4ee7-a53e-6e16c3d4d038,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-7fbd5e45-9208-4080-b3fc-1e96144be0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-daa2e832-0a29-46d6-8540-52d6e44e492a,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-020f7be6-4769-4ea5-af4a-f9d1ae376214,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-c2ebe98b-3e58-4742-8377-236f669b7a89,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-31000f90-f8ec-4bfa-bb75-e399e60d7ea9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903660378-172.17.0.9-1595669661579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43452,DS-5d270d17-2611-4a5e-8bbd-3ff8f9cdb3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-ce449d8f-83c7-4de0-ae26-7f776e159e20,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-e202bc57-d459-4ee7-a53e-6e16c3d4d038,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-7fbd5e45-9208-4080-b3fc-1e96144be0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-daa2e832-0a29-46d6-8540-52d6e44e492a,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-020f7be6-4769-4ea5-af4a-f9d1ae376214,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-c2ebe98b-3e58-4742-8377-236f669b7a89,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-31000f90-f8ec-4bfa-bb75-e399e60d7ea9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749738914-172.17.0.9-1595670319471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44273,DS-7e2878fb-e2d9-40e2-af01-cae6556f44f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-db4e396c-3092-468f-820b-88b2fc679b21,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-95d64cdd-06dd-4585-9151-81dce0afb627,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-b5ff8cef-7c64-40c9-842d-61c51f59bd93,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-361582f6-fd9c-4a46-8ad7-e98441636e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-ee01d6ae-7da1-4940-a523-9f65705cb100,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-f145288a-e64a-4aa2-8b27-bf2863b572e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-042bf994-f2e3-41d9-9dd5-a76c6ea391d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749738914-172.17.0.9-1595670319471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44273,DS-7e2878fb-e2d9-40e2-af01-cae6556f44f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-db4e396c-3092-468f-820b-88b2fc679b21,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-95d64cdd-06dd-4585-9151-81dce0afb627,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-b5ff8cef-7c64-40c9-842d-61c51f59bd93,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-361582f6-fd9c-4a46-8ad7-e98441636e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-ee01d6ae-7da1-4940-a523-9f65705cb100,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-f145288a-e64a-4aa2-8b27-bf2863b572e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-042bf994-f2e3-41d9-9dd5-a76c6ea391d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933964147-172.17.0.9-1595670562111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39308,DS-e2a311ab-3e83-441f-915e-44ad29842a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-cf06b077-a5f7-4bc7-917f-1b667be32814,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-ee8bcb61-adeb-42f5-8ce1-d3fcbf506112,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-bc55db87-f871-47bf-95e2-901deae5add4,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-0d21df2b-ee41-4a89-aafd-0b5fa082d887,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-13b83dc1-9b76-4dc3-acc8-c0e25bceb138,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-b0debad0-f80e-49cf-862e-590fca61c013,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-0b3184de-ca55-4f1d-a21e-df1c274034af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933964147-172.17.0.9-1595670562111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39308,DS-e2a311ab-3e83-441f-915e-44ad29842a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-cf06b077-a5f7-4bc7-917f-1b667be32814,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-ee8bcb61-adeb-42f5-8ce1-d3fcbf506112,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-bc55db87-f871-47bf-95e2-901deae5add4,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-0d21df2b-ee41-4a89-aafd-0b5fa082d887,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-13b83dc1-9b76-4dc3-acc8-c0e25bceb138,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-b0debad0-f80e-49cf-862e-590fca61c013,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-0b3184de-ca55-4f1d-a21e-df1c274034af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5401
