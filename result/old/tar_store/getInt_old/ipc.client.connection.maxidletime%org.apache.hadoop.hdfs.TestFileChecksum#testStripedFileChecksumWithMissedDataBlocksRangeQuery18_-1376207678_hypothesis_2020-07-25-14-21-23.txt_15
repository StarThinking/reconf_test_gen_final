reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-977077828-172.17.0.18-1595687159605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33111,DS-bc64ed57-633b-48d7-9c0f-51e7db3aaa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-935df068-c83c-4c35-acd9-98156d0ab6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-37540cbc-6334-4da1-b31d-22efee93daeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-9d1e3c6b-0e5e-47f6-8946-74575cd93522,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-1fc39d55-11d6-41c7-bb14-b64cf09e2ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-6604eb4e-27ba-4c46-b2fc-10a6edaee9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-0acdd55f-371b-4dd6-86d2-d2f7af7917b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-80d599a7-c464-48d7-a252-3925f5fb95c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-977077828-172.17.0.18-1595687159605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33111,DS-bc64ed57-633b-48d7-9c0f-51e7db3aaa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-935df068-c83c-4c35-acd9-98156d0ab6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-37540cbc-6334-4da1-b31d-22efee93daeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-9d1e3c6b-0e5e-47f6-8946-74575cd93522,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-1fc39d55-11d6-41c7-bb14-b64cf09e2ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-6604eb4e-27ba-4c46-b2fc-10a6edaee9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-0acdd55f-371b-4dd6-86d2-d2f7af7917b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-80d599a7-c464-48d7-a252-3925f5fb95c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1783730813-172.17.0.18-1595687451558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45722,DS-160eb612-2efd-41a1-ad02-2ccffc6b2ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-3b8789ca-cc17-4e11-8cc1-5d18f469f08e,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-aa756007-f6e0-4c91-9c78-f5637c42b9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-1368dbfb-7fef-4a10-b40e-c9937432caea,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-76196dae-22d8-4f44-b696-a177180f9055,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-8619209c-8c98-4c86-92f0-a02850c5d9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-a66eaa1d-db7e-4910-a398-eaae5922b707,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-a3432d38-5019-45a4-8621-eae6208647b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1783730813-172.17.0.18-1595687451558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45722,DS-160eb612-2efd-41a1-ad02-2ccffc6b2ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-3b8789ca-cc17-4e11-8cc1-5d18f469f08e,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-aa756007-f6e0-4c91-9c78-f5637c42b9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-1368dbfb-7fef-4a10-b40e-c9937432caea,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-76196dae-22d8-4f44-b696-a177180f9055,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-8619209c-8c98-4c86-92f0-a02850c5d9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-a66eaa1d-db7e-4910-a398-eaae5922b707,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-a3432d38-5019-45a4-8621-eae6208647b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1990895306-172.17.0.18-1595687948985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44320,DS-b18486e2-b047-4d1b-a692-9759e7c66f76,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-8edb5151-54db-4aa1-96b1-6c20c88cd69e,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-81e1efad-ff93-47a3-82f1-fa61329189d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-ba67e0de-42c5-476d-8037-d435309eb6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-6a251957-a45d-4b90-94ea-0844dd59b3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-456cf966-c6a0-401f-abf7-932cc190c689,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-74824fcb-5ef9-4b8f-b5a5-7a1a709c1dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-e7207fe1-6002-4fa6-9b2a-bdb9fc045e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1990895306-172.17.0.18-1595687948985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44320,DS-b18486e2-b047-4d1b-a692-9759e7c66f76,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-8edb5151-54db-4aa1-96b1-6c20c88cd69e,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-81e1efad-ff93-47a3-82f1-fa61329189d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-ba67e0de-42c5-476d-8037-d435309eb6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-6a251957-a45d-4b90-94ea-0844dd59b3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-456cf966-c6a0-401f-abf7-932cc190c689,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-74824fcb-5ef9-4b8f-b5a5-7a1a709c1dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-e7207fe1-6002-4fa6-9b2a-bdb9fc045e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-921418532-172.17.0.18-1595688349942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33082,DS-2d5d2d92-6caf-40b3-a7ea-7b6715d7fd85,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-a96a642b-ca4f-4c21-bda2-14ea83b40fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-f3df9bf9-c62c-47f9-8a01-5345b2d1e446,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-f194ff96-81ec-4e07-bdcd-56bbb3eb7fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-b8b96f1c-5006-4f74-b4e8-72a4733790e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-dd90358a-bfa8-4067-bd8e-0c604af5f319,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-551904ea-3e24-4469-9ba1-76e28a6c8310,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-75a8c91b-a4a3-4a9d-a682-988915bb1355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-921418532-172.17.0.18-1595688349942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33082,DS-2d5d2d92-6caf-40b3-a7ea-7b6715d7fd85,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-a96a642b-ca4f-4c21-bda2-14ea83b40fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-f3df9bf9-c62c-47f9-8a01-5345b2d1e446,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-f194ff96-81ec-4e07-bdcd-56bbb3eb7fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-b8b96f1c-5006-4f74-b4e8-72a4733790e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-dd90358a-bfa8-4067-bd8e-0c604af5f319,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-551904ea-3e24-4469-9ba1-76e28a6c8310,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-75a8c91b-a4a3-4a9d-a682-988915bb1355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-964918934-172.17.0.18-1595690015380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46813,DS-fa4e7f46-3bcc-4dd0-9599-351fc7411313,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-9dafc85c-f7e7-4b2a-bfaa-37ffc1e67c24,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-610ccb51-0b50-4515-a14a-8490ca34baf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36476,DS-bf9475af-ca00-4741-a73c-6dc447d6b548,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-241d8bf2-5d42-470f-8e80-fe378aae41e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-86107acf-7ef5-4934-8127-1bbc6168bac2,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-4282c2ed-7b6b-4664-87e5-fd11cb35ea90,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-4f75a9d1-18b9-40c4-9142-24df67d5c4c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-964918934-172.17.0.18-1595690015380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46813,DS-fa4e7f46-3bcc-4dd0-9599-351fc7411313,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-9dafc85c-f7e7-4b2a-bfaa-37ffc1e67c24,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-610ccb51-0b50-4515-a14a-8490ca34baf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36476,DS-bf9475af-ca00-4741-a73c-6dc447d6b548,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-241d8bf2-5d42-470f-8e80-fe378aae41e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-86107acf-7ef5-4934-8127-1bbc6168bac2,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-4282c2ed-7b6b-4664-87e5-fd11cb35ea90,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-4f75a9d1-18b9-40c4-9142-24df67d5c4c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-525806530-172.17.0.18-1595690210125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33011,DS-bfd62303-8e28-4529-af4c-2185040be7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-1c1dd423-8ebc-4891-bc5b-e9f3c8c2c03a,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-224c65a1-4811-4bc9-9053-0b639c14106f,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-e9fe4ea9-1f52-4621-bcaf-701a26d966cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-af352d01-fda5-40b4-8e41-8e36f3c87c16,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-5c7195dd-862b-4ce8-9af7-47a692fbb86d,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-f9d512d8-9d11-4a0e-b3a6-85fc2e4894c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-4db3bc6a-5d87-4ca9-8c03-4c13c1bb3357,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-525806530-172.17.0.18-1595690210125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33011,DS-bfd62303-8e28-4529-af4c-2185040be7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-1c1dd423-8ebc-4891-bc5b-e9f3c8c2c03a,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-224c65a1-4811-4bc9-9053-0b639c14106f,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-e9fe4ea9-1f52-4621-bcaf-701a26d966cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-af352d01-fda5-40b4-8e41-8e36f3c87c16,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-5c7195dd-862b-4ce8-9af7-47a692fbb86d,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-f9d512d8-9d11-4a0e-b3a6-85fc2e4894c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-4db3bc6a-5d87-4ca9-8c03-4c13c1bb3357,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458230427-172.17.0.18-1595690529909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44248,DS-ee3e3435-3550-42b8-84c2-6c7f933f2a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-33a7527f-d189-4df5-bf9d-af0924102490,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-19485d9c-37a7-4647-be86-9cb8898d69a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-c27a80f9-0651-4373-8aeb-4a6515a46704,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-6f0d083f-d5be-4550-bb6c-51fa13513caf,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-f5089883-341e-4ec7-87f8-ba59779f6ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-db24720a-7c6c-43b4-ac7b-c8b97bb72f86,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-cab8e2a5-848e-4036-ab74-8dfe11eea196,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458230427-172.17.0.18-1595690529909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44248,DS-ee3e3435-3550-42b8-84c2-6c7f933f2a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-33a7527f-d189-4df5-bf9d-af0924102490,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-19485d9c-37a7-4647-be86-9cb8898d69a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-c27a80f9-0651-4373-8aeb-4a6515a46704,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-6f0d083f-d5be-4550-bb6c-51fa13513caf,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-f5089883-341e-4ec7-87f8-ba59779f6ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-db24720a-7c6c-43b4-ac7b-c8b97bb72f86,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-cab8e2a5-848e-4036-ab74-8dfe11eea196,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1386834777-172.17.0.18-1595690664569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34014,DS-522a6164-6f24-4224-a47a-3fec4b6a1e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-78466247-f036-4e3f-bdd0-df3f11e0a543,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-861385c5-7ee5-4398-91a7-0d24ce1723d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-3c47e660-719d-45c7-8568-01714d870749,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-5e24415d-b3f8-4903-b201-3694a7526930,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-f552d04a-0030-43e7-bfc2-6f16ffbb1225,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-fd072f2a-d61a-43c4-b75d-c7f575fdc572,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-1c8cf0c0-af5f-4526-b5be-14d7409ced22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1386834777-172.17.0.18-1595690664569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34014,DS-522a6164-6f24-4224-a47a-3fec4b6a1e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-78466247-f036-4e3f-bdd0-df3f11e0a543,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-861385c5-7ee5-4398-91a7-0d24ce1723d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-3c47e660-719d-45c7-8568-01714d870749,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-5e24415d-b3f8-4903-b201-3694a7526930,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-f552d04a-0030-43e7-bfc2-6f16ffbb1225,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-fd072f2a-d61a-43c4-b75d-c7f575fdc572,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-1c8cf0c0-af5f-4526-b5be-14d7409ced22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-357779144-172.17.0.18-1595690724635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35202,DS-eac5024d-df19-4afd-af92-7f983b3f71fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-934a2bb6-1342-4f88-94e4-b19583a1aa00,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-83b0c972-15a4-4d24-9d04-4c93a608969d,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-55ff0ee0-7a25-481b-aa24-d94b6e759088,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-9b4ede13-ac40-4ba0-adfa-b68e17a5ad78,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-3ec5688a-a105-43ec-8439-908e3892b64a,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-cd0dd6d2-f79a-4c58-85d9-8518d61ea48c,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-a53b4a28-320f-4bda-a184-0d1b2faaf6c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-357779144-172.17.0.18-1595690724635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35202,DS-eac5024d-df19-4afd-af92-7f983b3f71fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-934a2bb6-1342-4f88-94e4-b19583a1aa00,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-83b0c972-15a4-4d24-9d04-4c93a608969d,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-55ff0ee0-7a25-481b-aa24-d94b6e759088,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-9b4ede13-ac40-4ba0-adfa-b68e17a5ad78,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-3ec5688a-a105-43ec-8439-908e3892b64a,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-cd0dd6d2-f79a-4c58-85d9-8518d61ea48c,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-a53b4a28-320f-4bda-a184-0d1b2faaf6c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-834260812-172.17.0.18-1595691034584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33871,DS-9ce33e31-9d2f-4a17-bb92-928b15564b31,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-92e8ba40-9b6b-4523-a2ab-dcfc42289ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-0d46df5e-4fc5-4c29-89b7-102cafff6e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-bd096c37-659c-461e-9288-284318508e21,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-e30f4c17-6899-4649-a8c5-e0734e410736,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-45784d39-8e03-4a4e-b126-6f9e827c73e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-b6a3580e-f9dd-45c0-a0d0-bc4b1ade61b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-f5f8f80d-8e02-4ed5-a270-c20d1651aefd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-834260812-172.17.0.18-1595691034584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33871,DS-9ce33e31-9d2f-4a17-bb92-928b15564b31,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-92e8ba40-9b6b-4523-a2ab-dcfc42289ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-0d46df5e-4fc5-4c29-89b7-102cafff6e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-bd096c37-659c-461e-9288-284318508e21,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-e30f4c17-6899-4649-a8c5-e0734e410736,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-45784d39-8e03-4a4e-b126-6f9e827c73e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-b6a3580e-f9dd-45c0-a0d0-bc4b1ade61b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-f5f8f80d-8e02-4ed5-a270-c20d1651aefd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1684275028-172.17.0.18-1595691274656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37701,DS-c4045c2a-f788-4495-ba64-79b243e3baad,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-e291d3b7-b6a9-40f6-b4ed-48052e4a6cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-1512d0fe-2eef-4c42-a7ae-68c198b05e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-7f52e1b4-5470-48e6-a572-8c9ba5a8529e,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-57435a3e-517b-4b26-bc82-c8b8245e16c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-a266c692-a8b1-4b88-a354-362e33764a00,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-9d8723f2-891d-4d86-96ac-1e60159aded2,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-f96b94a9-3fe7-44f5-b0ce-fc9b0d42f98c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1684275028-172.17.0.18-1595691274656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37701,DS-c4045c2a-f788-4495-ba64-79b243e3baad,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-e291d3b7-b6a9-40f6-b4ed-48052e4a6cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-1512d0fe-2eef-4c42-a7ae-68c198b05e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-7f52e1b4-5470-48e6-a572-8c9ba5a8529e,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-57435a3e-517b-4b26-bc82-c8b8245e16c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-a266c692-a8b1-4b88-a354-362e33764a00,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-9d8723f2-891d-4d86-96ac-1e60159aded2,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-f96b94a9-3fe7-44f5-b0ce-fc9b0d42f98c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-396558977-172.17.0.18-1595691569376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35027,DS-0d34edd3-8324-4466-8236-f89fe2191205,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-00c0b8b1-d6c7-4aad-81d2-e790dfcb9f32,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-1e2b7704-0ce9-4e57-9068-1b119effbf81,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-5dd2b27c-e1dd-43dd-a4d8-2bd81358caf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-4d2364aa-cd36-4d5d-9788-dbae3373fccb,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-698361fd-3d19-42e7-86f9-01c86c1a9886,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-4e39329a-c5b5-4658-a234-0b5b05d358ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-20a24c6f-04ec-4c41-ae44-0ad56b2e49b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-396558977-172.17.0.18-1595691569376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35027,DS-0d34edd3-8324-4466-8236-f89fe2191205,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-00c0b8b1-d6c7-4aad-81d2-e790dfcb9f32,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-1e2b7704-0ce9-4e57-9068-1b119effbf81,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-5dd2b27c-e1dd-43dd-a4d8-2bd81358caf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-4d2364aa-cd36-4d5d-9788-dbae3373fccb,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-698361fd-3d19-42e7-86f9-01c86c1a9886,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-4e39329a-c5b5-4658-a234-0b5b05d358ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-20a24c6f-04ec-4c41-ae44-0ad56b2e49b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1780848911-172.17.0.18-1595691635835:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33583,DS-f6352713-de84-41f0-92aa-e0b3c2ef8330,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-65168529-8fc9-4151-957e-03c765b18adb,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-6a760552-0b1e-47d9-81df-0615ea13b70d,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-c6fbc9e7-dd0c-4f1f-b58d-f981ee5396f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-103cd5b5-4e2b-41cd-a012-8e1e0bfe9c08,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-10eff70f-0c18-45b2-a554-2eab413c2cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-09a40f3b-94fb-49fd-8a1b-2305a4f03ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-8f2764f5-d87a-4737-965e-b6cd3a2ba397,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1780848911-172.17.0.18-1595691635835:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33583,DS-f6352713-de84-41f0-92aa-e0b3c2ef8330,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-65168529-8fc9-4151-957e-03c765b18adb,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-6a760552-0b1e-47d9-81df-0615ea13b70d,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-c6fbc9e7-dd0c-4f1f-b58d-f981ee5396f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-103cd5b5-4e2b-41cd-a012-8e1e0bfe9c08,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-10eff70f-0c18-45b2-a554-2eab413c2cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-09a40f3b-94fb-49fd-8a1b-2305a4f03ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-8f2764f5-d87a-4737-965e-b6cd3a2ba397,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-580730830-172.17.0.18-1595691949899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38372,DS-ae7c9ca7-f551-4522-9e24-6723e7265d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-cab5af3c-a105-483a-be6c-8fb036cd297d,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-7d219321-f6f1-4e20-a90e-bf8e2daacf44,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-cfb70607-5974-44a4-b0e7-5d5738db293e,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-cd045556-5a06-4597-9d7a-21c320da2f12,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-10d66178-8403-4400-8182-8117257823cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-d985170e-018c-4826-a713-0c32aafa04e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-3ee718e5-a1d4-4f72-81af-acc7b0f3894b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-580730830-172.17.0.18-1595691949899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38372,DS-ae7c9ca7-f551-4522-9e24-6723e7265d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-cab5af3c-a105-483a-be6c-8fb036cd297d,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-7d219321-f6f1-4e20-a90e-bf8e2daacf44,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-cfb70607-5974-44a4-b0e7-5d5738db293e,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-cd045556-5a06-4597-9d7a-21c320da2f12,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-10d66178-8403-4400-8182-8117257823cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-d985170e-018c-4826-a713-0c32aafa04e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-3ee718e5-a1d4-4f72-81af-acc7b0f3894b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2078268422-172.17.0.18-1595692014512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33128,DS-b7bf2e4c-7a73-4b26-8b27-96dd73dfcd72,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-3754c62c-e871-4499-9d4b-0799ad734327,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-f952eb9f-6354-42a0-8114-125937069802,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-f1b3132c-c83c-4ad7-9a1d-cc11b11ef195,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-d890328b-551b-4437-a23f-1ea7155a2dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-895bd295-005b-426d-9414-e8e4c6190aba,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-fad05ec6-1123-4f23-8528-1516565d2d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-a05f91e8-7d1b-4ffa-8df0-ae6ccec6e32b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2078268422-172.17.0.18-1595692014512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33128,DS-b7bf2e4c-7a73-4b26-8b27-96dd73dfcd72,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-3754c62c-e871-4499-9d4b-0799ad734327,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-f952eb9f-6354-42a0-8114-125937069802,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-f1b3132c-c83c-4ad7-9a1d-cc11b11ef195,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-d890328b-551b-4437-a23f-1ea7155a2dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-895bd295-005b-426d-9414-e8e4c6190aba,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-fad05ec6-1123-4f23-8528-1516565d2d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-a05f91e8-7d1b-4ffa-8df0-ae6ccec6e32b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5188
