reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-55365613-172.17.0.12-1595669540023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33350,DS-eb4a0137-0920-4873-9ac3-c759ceec9700,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-fd1d2a7f-a9b1-402c-a0ec-7a8d53c858d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-6844a60e-4609-46f7-9512-a94dadfaa416,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-c3d4c47a-051e-4609-b1ba-6ef372e7f4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-9c5446d7-9f63-4feb-8ede-d3a42ebe6974,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-e6b9d392-3f50-4145-92c6-a03ddad8b9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-fda55117-dc63-4ed6-bdc2-838ba073b4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-0c39ea76-d514-4f1e-8571-155e27f5e49b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-55365613-172.17.0.12-1595669540023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33350,DS-eb4a0137-0920-4873-9ac3-c759ceec9700,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-fd1d2a7f-a9b1-402c-a0ec-7a8d53c858d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-6844a60e-4609-46f7-9512-a94dadfaa416,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-c3d4c47a-051e-4609-b1ba-6ef372e7f4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-9c5446d7-9f63-4feb-8ede-d3a42ebe6974,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-e6b9d392-3f50-4145-92c6-a03ddad8b9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-fda55117-dc63-4ed6-bdc2-838ba073b4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-0c39ea76-d514-4f1e-8571-155e27f5e49b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1397700823-172.17.0.12-1595670370946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37186,DS-760f0477-60eb-4069-a8fb-84af3e10d1be,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-272b6bcd-c860-4f31-95f1-9327efd17c38,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-b9ec7264-066e-4ba7-9d65-8dad51563bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-9f6bf54b-cd46-4232-9c91-cc7cd85ae38a,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-05d731d5-42a8-4230-9695-b4d53acf36dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-94c6f516-263d-4028-81bd-0aaf3a358229,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-aa4efb28-b7ae-41f3-aa29-4bf5023a4fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-d6bad844-9f38-4d2c-be61-4f8b8a9b7447,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1397700823-172.17.0.12-1595670370946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37186,DS-760f0477-60eb-4069-a8fb-84af3e10d1be,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-272b6bcd-c860-4f31-95f1-9327efd17c38,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-b9ec7264-066e-4ba7-9d65-8dad51563bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-9f6bf54b-cd46-4232-9c91-cc7cd85ae38a,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-05d731d5-42a8-4230-9695-b4d53acf36dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-94c6f516-263d-4028-81bd-0aaf3a358229,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-aa4efb28-b7ae-41f3-aa29-4bf5023a4fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-d6bad844-9f38-4d2c-be61-4f8b8a9b7447,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1960684547-172.17.0.12-1595670804376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45733,DS-733507fb-a1c3-4514-8705-7e397f6ef6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-c70c34c2-f05a-45be-958d-e60ef7f403cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-9ee0398a-dfc4-41db-b5c5-6928f877a240,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-aaefdc62-2c03-4996-a11f-b0c3720260fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-f3165de0-ecb1-4b2a-b1e7-5ecc826dac70,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-c255d10d-d49e-4401-8893-9ea57bf50012,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-bbe64dd0-2c83-4483-96d6-26f55d8ca139,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-ff9ce26b-f68f-4969-9397-55db3eff3fc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1960684547-172.17.0.12-1595670804376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45733,DS-733507fb-a1c3-4514-8705-7e397f6ef6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-c70c34c2-f05a-45be-958d-e60ef7f403cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-9ee0398a-dfc4-41db-b5c5-6928f877a240,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-aaefdc62-2c03-4996-a11f-b0c3720260fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-f3165de0-ecb1-4b2a-b1e7-5ecc826dac70,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-c255d10d-d49e-4401-8893-9ea57bf50012,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-bbe64dd0-2c83-4483-96d6-26f55d8ca139,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-ff9ce26b-f68f-4969-9397-55db3eff3fc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-522243447-172.17.0.12-1595670945398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43590,DS-ca53549e-9d66-4d90-bd46-e520aa2c9298,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-2b3af4ce-450c-4429-b5e1-a05ff9e5c6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-718555ad-c99a-4ab3-a825-57a7996156a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-141dd70b-9b8a-46a5-a703-ff405fbbb7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-47b4039c-13f1-4d58-b372-ac4f8362eeb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-eaace86d-aecd-4843-9644-3da627ee1d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-1118ae47-2189-478f-acdf-0085b10e4859,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-d0e42376-6220-4e6b-a954-9f70b0650b5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-522243447-172.17.0.12-1595670945398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43590,DS-ca53549e-9d66-4d90-bd46-e520aa2c9298,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-2b3af4ce-450c-4429-b5e1-a05ff9e5c6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-718555ad-c99a-4ab3-a825-57a7996156a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-141dd70b-9b8a-46a5-a703-ff405fbbb7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-47b4039c-13f1-4d58-b372-ac4f8362eeb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-eaace86d-aecd-4843-9644-3da627ee1d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-1118ae47-2189-478f-acdf-0085b10e4859,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-d0e42376-6220-4e6b-a954-9f70b0650b5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756822014-172.17.0.12-1595671112729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46064,DS-f4278580-7bae-43ea-b70e-0bc28b530cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-42b9f8e7-65bc-4144-864d-3222fc204cec,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-c2cca4b0-29c6-42ed-90e7-dfcfbf4aa8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-c7966bc5-74a5-4284-9776-f48a05324c02,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-f17475eb-fcee-480e-873a-7636ca950be4,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-64ffcaa4-897f-4b24-a092-6a713a42c1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-03f40d1b-be8f-4ccd-bee1-e7fd58436cde,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-72e88c92-c18c-4cf9-8286-4f2ff8503c8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756822014-172.17.0.12-1595671112729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46064,DS-f4278580-7bae-43ea-b70e-0bc28b530cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-42b9f8e7-65bc-4144-864d-3222fc204cec,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-c2cca4b0-29c6-42ed-90e7-dfcfbf4aa8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-c7966bc5-74a5-4284-9776-f48a05324c02,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-f17475eb-fcee-480e-873a-7636ca950be4,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-64ffcaa4-897f-4b24-a092-6a713a42c1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-03f40d1b-be8f-4ccd-bee1-e7fd58436cde,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-72e88c92-c18c-4cf9-8286-4f2ff8503c8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306965187-172.17.0.12-1595671855789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35846,DS-a8ef18dc-6f6e-4aaa-91fd-dab565895076,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-27555456-148b-4336-9aa4-163911b5cbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-36bbda69-c9f6-481e-9c16-99f62d1dfe67,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-43dc45f0-286b-47c7-9cc4-9d4f8c9997f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-0928414e-3050-407d-ad1e-5d2b8bac15bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-68171de4-c05d-4faf-8c99-68c4e5aec7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-0401078b-e49d-4fcc-a0bf-878cd9a6133a,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-79e96fdc-3024-4eb4-9570-fe89acaff61c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306965187-172.17.0.12-1595671855789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35846,DS-a8ef18dc-6f6e-4aaa-91fd-dab565895076,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-27555456-148b-4336-9aa4-163911b5cbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-36bbda69-c9f6-481e-9c16-99f62d1dfe67,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-43dc45f0-286b-47c7-9cc4-9d4f8c9997f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-0928414e-3050-407d-ad1e-5d2b8bac15bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-68171de4-c05d-4faf-8c99-68c4e5aec7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-0401078b-e49d-4fcc-a0bf-878cd9a6133a,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-79e96fdc-3024-4eb4-9570-fe89acaff61c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1781645800-172.17.0.12-1595672029602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40022,DS-2721c422-f12d-4522-9cae-921f8fd798c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-fa38162f-aa99-42ca-b472-1e49fedb5b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-bd7b8f33-7bdd-4e43-981e-3ee151abd1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-12ac1c17-312e-45b9-9049-d261e9a60379,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-482c42bf-2982-48dc-8795-9b36e00cafb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-52b44c51-aad2-46c4-8a54-609095ae10c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-26c4ddb0-4bc4-455b-b0bb-0fdce39ee3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-19a15669-3a59-42cc-922b-5cafa560e7c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1781645800-172.17.0.12-1595672029602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40022,DS-2721c422-f12d-4522-9cae-921f8fd798c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-fa38162f-aa99-42ca-b472-1e49fedb5b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-bd7b8f33-7bdd-4e43-981e-3ee151abd1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-12ac1c17-312e-45b9-9049-d261e9a60379,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-482c42bf-2982-48dc-8795-9b36e00cafb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-52b44c51-aad2-46c4-8a54-609095ae10c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-26c4ddb0-4bc4-455b-b0bb-0fdce39ee3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-19a15669-3a59-42cc-922b-5cafa560e7c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-492299804-172.17.0.12-1595672498399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43905,DS-bd6b94b3-1e8c-495a-bb22-718bfb5fb0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-3fae8e55-8935-4acf-a46d-6f9bbc63c22e,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-76138703-e0fb-4b55-86ee-9f954363f087,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-fa828721-e7ad-4935-b0e0-fa7954195242,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-9d665a51-fa2c-4227-83d7-bd6ed9de4814,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-7e277a79-7e96-49e4-8483-90999ae4e1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-7f88c679-a651-41de-ae6f-b5e8266371f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-1daaf458-4068-4e31-b7fd-a78f08b8987d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-492299804-172.17.0.12-1595672498399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43905,DS-bd6b94b3-1e8c-495a-bb22-718bfb5fb0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-3fae8e55-8935-4acf-a46d-6f9bbc63c22e,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-76138703-e0fb-4b55-86ee-9f954363f087,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-fa828721-e7ad-4935-b0e0-fa7954195242,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-9d665a51-fa2c-4227-83d7-bd6ed9de4814,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-7e277a79-7e96-49e4-8483-90999ae4e1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-7f88c679-a651-41de-ae6f-b5e8266371f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-1daaf458-4068-4e31-b7fd-a78f08b8987d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1961025152-172.17.0.12-1595672579423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33664,DS-d22f5251-f050-45fb-95ed-6a0914a452b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-8647e7c5-33c5-4404-95e6-02422d64b4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-ba47c97c-d1e5-466b-8229-bca5865d49f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-1a16c4c1-3ef1-4d42-8e7b-761d7580a6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-de0eae84-9e80-43ba-842d-cc696ad91267,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-c02564f2-bd97-40dc-bd88-5082064999af,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-750c6b9d-b759-45b0-a40a-f03099f80662,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-76d6f50a-d102-4e34-b906-2c6436094843,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1961025152-172.17.0.12-1595672579423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33664,DS-d22f5251-f050-45fb-95ed-6a0914a452b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-8647e7c5-33c5-4404-95e6-02422d64b4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-ba47c97c-d1e5-466b-8229-bca5865d49f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-1a16c4c1-3ef1-4d42-8e7b-761d7580a6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-de0eae84-9e80-43ba-842d-cc696ad91267,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-c02564f2-bd97-40dc-bd88-5082064999af,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-750c6b9d-b759-45b0-a40a-f03099f80662,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-76d6f50a-d102-4e34-b906-2c6436094843,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2000418830-172.17.0.12-1595672833561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40116,DS-423ce1c4-e85c-42cb-b8ce-8023342d5ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-025fb2b5-e2f5-4388-81c1-a1b41b1d0ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-4ca19f93-10fb-44e1-b9a4-761f91718df2,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-03bbe20f-94e7-4b1c-bd0b-82e71a22305a,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-8366c3fd-02f3-46a1-8a9b-0b194a0366dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-629900ea-79c4-48a4-8d98-e3b79f669c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-fdb92a44-b86a-40eb-9f22-ba19f7cae7af,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-5a877a74-0b00-4b03-b920-b4821bd1e76f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2000418830-172.17.0.12-1595672833561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40116,DS-423ce1c4-e85c-42cb-b8ce-8023342d5ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-025fb2b5-e2f5-4388-81c1-a1b41b1d0ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-4ca19f93-10fb-44e1-b9a4-761f91718df2,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-03bbe20f-94e7-4b1c-bd0b-82e71a22305a,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-8366c3fd-02f3-46a1-8a9b-0b194a0366dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-629900ea-79c4-48a4-8d98-e3b79f669c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-fdb92a44-b86a-40eb-9f22-ba19f7cae7af,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-5a877a74-0b00-4b03-b920-b4821bd1e76f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1252979162-172.17.0.12-1595673180675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40168,DS-123d777d-c2b0-4e10-912a-801be0d7596e,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-8d6d1fe9-2f58-4f8e-94a7-b481fce7bbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-65da62f7-4528-447f-bd82-2b2a38a37d70,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-9f14e1cb-e80a-45d4-8caa-aa62e0f29fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-e717d458-c7d6-40a4-8182-7b1b7353112a,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-71554f50-a21b-43da-b596-7927d7b92099,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-917f3b9b-6598-4cec-ae54-36afe4ebe204,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-71473bc2-3382-48d7-b9ba-9c77627e3619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1252979162-172.17.0.12-1595673180675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40168,DS-123d777d-c2b0-4e10-912a-801be0d7596e,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-8d6d1fe9-2f58-4f8e-94a7-b481fce7bbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-65da62f7-4528-447f-bd82-2b2a38a37d70,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-9f14e1cb-e80a-45d4-8caa-aa62e0f29fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-e717d458-c7d6-40a4-8182-7b1b7353112a,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-71554f50-a21b-43da-b596-7927d7b92099,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-917f3b9b-6598-4cec-ae54-36afe4ebe204,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-71473bc2-3382-48d7-b9ba-9c77627e3619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2022907093-172.17.0.12-1595673343301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40279,DS-b984b99d-cb39-4257-a92d-60c22673c190,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-0e4a495d-ce41-420a-a740-2255ca7065fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-908d874a-5065-4b1d-b84b-9490b1fd2116,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-d4127db2-52d0-421c-aed4-a261e04ff467,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-d442392d-8c77-4da3-9fb9-48bf10b33dde,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-f09f3680-999b-4331-902a-e48c2e193bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-183e1d92-6288-4413-b0b5-05cb0b5f13bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-d10fb64d-ec34-44d9-93a5-daff6ed7bf75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2022907093-172.17.0.12-1595673343301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40279,DS-b984b99d-cb39-4257-a92d-60c22673c190,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-0e4a495d-ce41-420a-a740-2255ca7065fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-908d874a-5065-4b1d-b84b-9490b1fd2116,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-d4127db2-52d0-421c-aed4-a261e04ff467,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-d442392d-8c77-4da3-9fb9-48bf10b33dde,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-f09f3680-999b-4331-902a-e48c2e193bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-183e1d92-6288-4413-b0b5-05cb0b5f13bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-d10fb64d-ec34-44d9-93a5-daff6ed7bf75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-167753117-172.17.0.12-1595673412803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40597,DS-33af413c-6e14-4926-8e0c-f375b3ffa4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-4b71a238-0621-4c0c-8e8f-e3abd3dc0d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-2a57a8c7-6142-4b4e-b78c-641616dc34db,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-6d60e42b-44c0-4b3f-a7d4-2b558090308c,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-51b6f349-e354-4488-ac3c-7acd5ad14a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-519da88a-8618-4682-add3-99f6080a3b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-b73d630c-a481-4098-8509-bbcb75d80311,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-d420a6a2-5814-4415-aa1f-0311d634b517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-167753117-172.17.0.12-1595673412803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40597,DS-33af413c-6e14-4926-8e0c-f375b3ffa4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-4b71a238-0621-4c0c-8e8f-e3abd3dc0d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-2a57a8c7-6142-4b4e-b78c-641616dc34db,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-6d60e42b-44c0-4b3f-a7d4-2b558090308c,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-51b6f349-e354-4488-ac3c-7acd5ad14a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-519da88a-8618-4682-add3-99f6080a3b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-b73d630c-a481-4098-8509-bbcb75d80311,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-d420a6a2-5814-4415-aa1f-0311d634b517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-615323519-172.17.0.12-1595673443946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43813,DS-0eb84dd2-f97f-432a-b501-ffb0cc94d555,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-9e1da3bc-ec17-450c-8c87-8965c2e6291f,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-149aef8d-9611-40a2-85a3-c5d236a465f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-668980c7-70af-47c5-ab61-86fcc5285522,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-3a291f66-7c7b-4faf-ac07-13122f7e36fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-781a2934-1357-4de8-b1db-06b3726579b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-55bbeaaf-1871-4e92-865d-63c2f5f6bd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-ee820246-e07a-4eb9-9c0a-e163f2b3621d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-615323519-172.17.0.12-1595673443946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43813,DS-0eb84dd2-f97f-432a-b501-ffb0cc94d555,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-9e1da3bc-ec17-450c-8c87-8965c2e6291f,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-149aef8d-9611-40a2-85a3-c5d236a465f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-668980c7-70af-47c5-ab61-86fcc5285522,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-3a291f66-7c7b-4faf-ac07-13122f7e36fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-781a2934-1357-4de8-b1db-06b3726579b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-55bbeaaf-1871-4e92-865d-63c2f5f6bd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-ee820246-e07a-4eb9-9c0a-e163f2b3621d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-554536835-172.17.0.12-1595673888097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34764,DS-28b1b538-c151-4bb1-8e6b-ccd77a4790e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-3a26e56f-5b84-4f5d-bb69-7e48db87b1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-783fe215-e17d-4eea-9f1c-55084a726d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-db450101-0a48-42de-9377-8a472965d947,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-309db561-de44-429d-9491-8ac6cfc57e63,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-b68c97b6-13bc-4c77-b02f-2a8bbe2eeefb,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-8ff098d0-60d3-4de8-919f-36095dc26cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-33ec3f72-51fd-4911-9487-15caef403655,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-554536835-172.17.0.12-1595673888097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34764,DS-28b1b538-c151-4bb1-8e6b-ccd77a4790e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-3a26e56f-5b84-4f5d-bb69-7e48db87b1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-783fe215-e17d-4eea-9f1c-55084a726d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-db450101-0a48-42de-9377-8a472965d947,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-309db561-de44-429d-9491-8ac6cfc57e63,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-b68c97b6-13bc-4c77-b02f-2a8bbe2eeefb,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-8ff098d0-60d3-4de8-919f-36095dc26cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-33ec3f72-51fd-4911-9487-15caef403655,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1725801214-172.17.0.12-1595673927121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37791,DS-da779f50-9232-4de4-88bf-c5c0a62cc73d,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-dbc004e3-2e6f-46f9-8430-3dab46c359e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-0c519d5f-d707-4353-ba95-112e31900645,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-008e01a0-1895-4290-9e49-98d4f0437543,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-5de54eb5-25b3-4950-91eb-d0195dd69967,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-3d92fd1f-c2c0-4d11-918e-0eac9986040e,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-264e42d4-622d-4415-96b3-a992582f2920,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-2c74d1f9-74bc-41e4-88c9-9d0bb0a26d78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1725801214-172.17.0.12-1595673927121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37791,DS-da779f50-9232-4de4-88bf-c5c0a62cc73d,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-dbc004e3-2e6f-46f9-8430-3dab46c359e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-0c519d5f-d707-4353-ba95-112e31900645,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-008e01a0-1895-4290-9e49-98d4f0437543,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-5de54eb5-25b3-4950-91eb-d0195dd69967,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-3d92fd1f-c2c0-4d11-918e-0eac9986040e,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-264e42d4-622d-4415-96b3-a992582f2920,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-2c74d1f9-74bc-41e4-88c9-9d0bb0a26d78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-806503418-172.17.0.12-1595674064556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43845,DS-9bd05c3b-4fbb-4685-8266-867ea8e41d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-0ca0a04a-ea32-4fe7-b66f-66c1b396a491,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-e191ffdf-0692-4166-8536-7e5f4b426f74,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-9abba122-d441-4a93-9184-f2f944b033a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-a6e1d484-c0be-4838-9492-d95e81d8fb99,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-b1af26be-3ea1-4e98-8fcd-1b2e671f1b46,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-4b0267e6-5bbd-456e-8632-1ba115f955aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-8efbc087-1885-4fb2-a78a-1a38ebd23cb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-806503418-172.17.0.12-1595674064556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43845,DS-9bd05c3b-4fbb-4685-8266-867ea8e41d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-0ca0a04a-ea32-4fe7-b66f-66c1b396a491,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-e191ffdf-0692-4166-8536-7e5f4b426f74,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-9abba122-d441-4a93-9184-f2f944b033a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-a6e1d484-c0be-4838-9492-d95e81d8fb99,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-b1af26be-3ea1-4e98-8fcd-1b2e671f1b46,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-4b0267e6-5bbd-456e-8632-1ba115f955aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-8efbc087-1885-4fb2-a78a-1a38ebd23cb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163846040-172.17.0.12-1595674525160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36376,DS-d8afe39e-9ccc-47cc-974b-f1ba7324b9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-7353e779-4c41-4751-983e-ecba3cbc0276,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-eb12fc70-2f6d-46a1-b131-22e37bcad9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-ec34da16-21f5-4d9a-af7d-9cd69b0f3305,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-8226f882-64ef-4d91-a357-ba6f9328ede2,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-a584c1a4-297c-40ef-828c-10c30b41ffa4,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-15a26a90-7624-438a-953e-4938fc4d55ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-a7ce0456-7309-405e-9d5e-8e9795562c41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163846040-172.17.0.12-1595674525160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36376,DS-d8afe39e-9ccc-47cc-974b-f1ba7324b9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-7353e779-4c41-4751-983e-ecba3cbc0276,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-eb12fc70-2f6d-46a1-b131-22e37bcad9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-ec34da16-21f5-4d9a-af7d-9cd69b0f3305,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-8226f882-64ef-4d91-a357-ba6f9328ede2,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-a584c1a4-297c-40ef-828c-10c30b41ffa4,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-15a26a90-7624-438a-953e-4938fc4d55ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-a7ce0456-7309-405e-9d5e-8e9795562c41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5288
