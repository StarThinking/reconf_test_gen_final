reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311069041-172.17.0.8-1595700043017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38805,DS-8dc931fd-ebcd-4309-a47f-a739bfa62877,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-836b2c05-8271-49ba-aa77-5e40203913d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-193941f3-2398-4bca-964d-34e13574c2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-022e8fe3-0010-460b-a386-a379144e197b,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-61ac36ee-c811-44f7-8ac3-7a41c2f53bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-aa8029ff-665c-47b8-9b45-bb04a0fe7b89,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-0d45dbf7-01d2-4ea4-80ce-8d78c9197305,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-b069cd1a-208a-4f9f-a7e7-d7a63e540285,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311069041-172.17.0.8-1595700043017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38805,DS-8dc931fd-ebcd-4309-a47f-a739bfa62877,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-836b2c05-8271-49ba-aa77-5e40203913d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-193941f3-2398-4bca-964d-34e13574c2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-022e8fe3-0010-460b-a386-a379144e197b,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-61ac36ee-c811-44f7-8ac3-7a41c2f53bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-aa8029ff-665c-47b8-9b45-bb04a0fe7b89,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-0d45dbf7-01d2-4ea4-80ce-8d78c9197305,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-b069cd1a-208a-4f9f-a7e7-d7a63e540285,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406181873-172.17.0.8-1595700539870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39644,DS-e756bb04-40c6-4090-a318-51dee20fefe2,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-7799de99-8d38-4354-bbea-cebd083f5224,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-f61d75d3-ba49-4a5f-8984-2ba06e07e59a,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-d00a5c19-c181-42b7-bcf0-986de19d54ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-a3110b18-0273-4ac1-bf13-13037964b9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-0ec4097b-c143-47e0-bfae-b45fc4e3db7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-f9b09009-fc09-42f2-8587-d250c2327213,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-4a862d98-21f4-4885-9875-66c8fa8ea1a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406181873-172.17.0.8-1595700539870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39644,DS-e756bb04-40c6-4090-a318-51dee20fefe2,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-7799de99-8d38-4354-bbea-cebd083f5224,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-f61d75d3-ba49-4a5f-8984-2ba06e07e59a,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-d00a5c19-c181-42b7-bcf0-986de19d54ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-a3110b18-0273-4ac1-bf13-13037964b9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-0ec4097b-c143-47e0-bfae-b45fc4e3db7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-f9b09009-fc09-42f2-8587-d250c2327213,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-4a862d98-21f4-4885-9875-66c8fa8ea1a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305395330-172.17.0.8-1595700720461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46297,DS-5968ff6b-00c6-40b5-93b7-abf9874d5118,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-e19be371-8ab7-49ef-8f70-8e9978dd3552,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-c1a865d1-cd78-4b76-81c9-6edc5d432903,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-9e10f76e-86a7-4b82-8a61-f85709708c20,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-8cc240da-0bb7-47dc-9149-17e6fe8b04ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-068f8975-0503-41b4-8ffb-74ddc9c41962,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-ce5d47ae-fb5a-4eef-889a-00a091bfefef,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-41e32c79-5c19-4ede-9ce8-05686fdd28f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305395330-172.17.0.8-1595700720461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46297,DS-5968ff6b-00c6-40b5-93b7-abf9874d5118,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-e19be371-8ab7-49ef-8f70-8e9978dd3552,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-c1a865d1-cd78-4b76-81c9-6edc5d432903,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-9e10f76e-86a7-4b82-8a61-f85709708c20,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-8cc240da-0bb7-47dc-9149-17e6fe8b04ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-068f8975-0503-41b4-8ffb-74ddc9c41962,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-ce5d47ae-fb5a-4eef-889a-00a091bfefef,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-41e32c79-5c19-4ede-9ce8-05686fdd28f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-805870518-172.17.0.8-1595700909407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43942,DS-6e941e7f-493a-4608-b9bb-0c829fa8b1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-655713cb-c08f-4c6e-9489-1aabab210c55,DISK], DatanodeInfoWithStorage[127.0.0.1:46100,DS-62c32e67-0d8e-48fc-9ab1-389eed0d7879,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-fb742b0b-9934-4e09-92c3-b77dc93894e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-b96a5444-3f5b-45c1-a8d4-0ec8e17f6847,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-74388766-a50b-4688-a146-b9b39b3de83a,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-e4d9ff5e-dbf6-4b05-9e56-5db740782be2,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-75edeb31-3f5d-483e-b88b-81c73ce99116,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-805870518-172.17.0.8-1595700909407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43942,DS-6e941e7f-493a-4608-b9bb-0c829fa8b1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-655713cb-c08f-4c6e-9489-1aabab210c55,DISK], DatanodeInfoWithStorage[127.0.0.1:46100,DS-62c32e67-0d8e-48fc-9ab1-389eed0d7879,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-fb742b0b-9934-4e09-92c3-b77dc93894e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-b96a5444-3f5b-45c1-a8d4-0ec8e17f6847,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-74388766-a50b-4688-a146-b9b39b3de83a,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-e4d9ff5e-dbf6-4b05-9e56-5db740782be2,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-75edeb31-3f5d-483e-b88b-81c73ce99116,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835184346-172.17.0.8-1595701056382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46393,DS-8b4e125b-36d8-4d5f-b648-3aaf5a196666,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-42e85df1-0421-4ff1-a172-6e6e9c6d0cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-0802d58d-ed20-44ee-8706-0a24ec7a42fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-3ed5ad7f-f7f0-46e8-8e4d-b2ffa21033c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-4f58cd97-7d29-43db-8c20-a9c376b1075e,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-e16ede0e-6d67-4f3f-a7e9-a82ae0c4050c,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-daad966f-c89e-432b-9f56-2cccc7cb3ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-e53cfcca-449b-4d5c-bb40-623d8c8bed4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835184346-172.17.0.8-1595701056382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46393,DS-8b4e125b-36d8-4d5f-b648-3aaf5a196666,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-42e85df1-0421-4ff1-a172-6e6e9c6d0cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-0802d58d-ed20-44ee-8706-0a24ec7a42fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-3ed5ad7f-f7f0-46e8-8e4d-b2ffa21033c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-4f58cd97-7d29-43db-8c20-a9c376b1075e,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-e16ede0e-6d67-4f3f-a7e9-a82ae0c4050c,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-daad966f-c89e-432b-9f56-2cccc7cb3ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-e53cfcca-449b-4d5c-bb40-623d8c8bed4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656558346-172.17.0.8-1595701162097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34845,DS-0ed349f3-3aa5-442b-a24e-a52074e8ddbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-3f877438-4fbb-4ca3-b488-8512975690b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-50d8202f-172b-47c8-a307-28a7df913efe,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-2a764e4f-435a-40fd-818a-e809e80440ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-d00a7fd7-a353-4dc2-b71e-7c8311c29749,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-83096535-94d2-4725-bd21-99e641c0106b,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-0ae28e42-f42e-4505-b66f-8f932a4ffdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-ad4773af-7862-4903-b5e5-aa64989c5820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656558346-172.17.0.8-1595701162097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34845,DS-0ed349f3-3aa5-442b-a24e-a52074e8ddbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-3f877438-4fbb-4ca3-b488-8512975690b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-50d8202f-172b-47c8-a307-28a7df913efe,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-2a764e4f-435a-40fd-818a-e809e80440ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-d00a7fd7-a353-4dc2-b71e-7c8311c29749,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-83096535-94d2-4725-bd21-99e641c0106b,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-0ae28e42-f42e-4505-b66f-8f932a4ffdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-ad4773af-7862-4903-b5e5-aa64989c5820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1048653879-172.17.0.8-1595701232013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46598,DS-6d8850bc-2295-44c9-8cb0-5d1af6c894ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-c071eb0e-9a66-4f12-b774-c9f06a0c01e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-f23d8862-55a0-4e97-b73e-35ea6f13c667,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-afde8fd1-2e61-4bd1-a2a5-6deba106f1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-169708a8-e732-4357-9ea8-9cf857a4a3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-0302bcc3-d7f0-4cdd-8c2c-26759379d352,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-57a26295-c24e-4c62-90d8-9ddefef50667,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-d883319e-50a6-4e5b-9fbd-1dbe3e3fdb95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1048653879-172.17.0.8-1595701232013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46598,DS-6d8850bc-2295-44c9-8cb0-5d1af6c894ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-c071eb0e-9a66-4f12-b774-c9f06a0c01e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-f23d8862-55a0-4e97-b73e-35ea6f13c667,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-afde8fd1-2e61-4bd1-a2a5-6deba106f1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-169708a8-e732-4357-9ea8-9cf857a4a3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-0302bcc3-d7f0-4cdd-8c2c-26759379d352,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-57a26295-c24e-4c62-90d8-9ddefef50667,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-d883319e-50a6-4e5b-9fbd-1dbe3e3fdb95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369614091-172.17.0.8-1595701801904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42385,DS-b3868788-d792-4ab0-afa3-3c94197af3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-54cd572f-ea8b-468d-8a94-8f4ac5c485a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-ad7a00e2-32cf-4674-a9f7-a426d04e3ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-22ca9041-9ee8-443b-8194-c881f8d2f10b,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-0f6cbe2d-5c46-41ca-82d6-7664f7362d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-9dd09ca4-55b2-4802-9480-d1bf253dd9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-e6fd80b5-e068-4d20-a694-e74ccca7cea2,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-c1dfd833-236a-4ca1-bda6-e53b3f2fb69f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369614091-172.17.0.8-1595701801904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42385,DS-b3868788-d792-4ab0-afa3-3c94197af3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-54cd572f-ea8b-468d-8a94-8f4ac5c485a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-ad7a00e2-32cf-4674-a9f7-a426d04e3ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-22ca9041-9ee8-443b-8194-c881f8d2f10b,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-0f6cbe2d-5c46-41ca-82d6-7664f7362d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-9dd09ca4-55b2-4802-9480-d1bf253dd9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-e6fd80b5-e068-4d20-a694-e74ccca7cea2,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-c1dfd833-236a-4ca1-bda6-e53b3f2fb69f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526112141-172.17.0.8-1595701832150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42184,DS-933b6089-814e-475a-b679-f54a9c1f5054,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-2f9d875d-6497-405e-91d4-65c2906d34f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-12b4f28b-4a5d-4751-a83a-8bf26dbf93da,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-54239d6b-9716-4f5d-85d3-b0bff8335f80,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-33829a57-15c2-4945-871f-40dded0e39d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-06766d43-11b9-4b48-b3bf-921582965e63,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-cb4a9e0b-bdbb-4770-a807-c705444d7bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-42c535a9-44f6-4eab-8fd2-bd55454f1fa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526112141-172.17.0.8-1595701832150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42184,DS-933b6089-814e-475a-b679-f54a9c1f5054,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-2f9d875d-6497-405e-91d4-65c2906d34f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-12b4f28b-4a5d-4751-a83a-8bf26dbf93da,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-54239d6b-9716-4f5d-85d3-b0bff8335f80,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-33829a57-15c2-4945-871f-40dded0e39d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-06766d43-11b9-4b48-b3bf-921582965e63,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-cb4a9e0b-bdbb-4770-a807-c705444d7bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-42c535a9-44f6-4eab-8fd2-bd55454f1fa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021782873-172.17.0.8-1595702291174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37003,DS-4d883187-b66e-468a-9a00-281e768e85d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-10192078-9a0a-4e41-97d1-f2d825d49548,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-cd031650-be71-429a-9c32-1aed1fb0a38d,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-5e31502e-aad0-41d8-b124-c2b575ea111e,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-11c7f484-e4c2-4683-a6cd-08be23c6660f,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-4fa547a6-837a-4f0a-88a0-101481c614dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-8deff172-6f71-4212-8876-ed95ca1adf85,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-ec5ea9f2-16e5-468a-821d-5b9420ed758a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021782873-172.17.0.8-1595702291174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37003,DS-4d883187-b66e-468a-9a00-281e768e85d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-10192078-9a0a-4e41-97d1-f2d825d49548,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-cd031650-be71-429a-9c32-1aed1fb0a38d,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-5e31502e-aad0-41d8-b124-c2b575ea111e,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-11c7f484-e4c2-4683-a6cd-08be23c6660f,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-4fa547a6-837a-4f0a-88a0-101481c614dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-8deff172-6f71-4212-8876-ed95ca1adf85,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-ec5ea9f2-16e5-468a-821d-5b9420ed758a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1242657924-172.17.0.8-1595702637839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38212,DS-e6630513-6635-4c0a-97ac-4edb3a5a7d29,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-40bcf8aa-4cbe-481e-bc2a-e988cdf4653d,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-275d94e3-0234-4968-9825-1fed6d5971b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-ce734c0c-a85f-4ac8-92c5-569d4941b6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-ed444360-1163-49a7-9ade-6769bc3163d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-9435425e-5dd5-4cd0-ab31-2224055176f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-4c461c83-81e9-4faa-8b77-eaa1c1b35689,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-5ce01421-820a-4beb-84b0-ee78ff17f578,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1242657924-172.17.0.8-1595702637839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38212,DS-e6630513-6635-4c0a-97ac-4edb3a5a7d29,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-40bcf8aa-4cbe-481e-bc2a-e988cdf4653d,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-275d94e3-0234-4968-9825-1fed6d5971b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-ce734c0c-a85f-4ac8-92c5-569d4941b6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-ed444360-1163-49a7-9ade-6769bc3163d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-9435425e-5dd5-4cd0-ab31-2224055176f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-4c461c83-81e9-4faa-8b77-eaa1c1b35689,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-5ce01421-820a-4beb-84b0-ee78ff17f578,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456780047-172.17.0.8-1595703016295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37381,DS-37b96abb-d7ee-4950-bbc9-eff05bb7ab59,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-187e0053-05d2-4702-816e-034ba9cfb23b,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-c1b9e282-f253-4f70-a6b8-f74aaa7e82c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-47712fe9-f28d-4e51-8d10-280c2adb7950,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-ec02dfde-48f6-4058-8214-4d85d1d91dac,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-613adb2b-0f1c-499a-822b-0a6e521ce87a,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-54ed5b4c-a1fa-4991-8136-aba56509af2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-79a57871-fb7d-407a-81cd-d5d0294dfbf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456780047-172.17.0.8-1595703016295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37381,DS-37b96abb-d7ee-4950-bbc9-eff05bb7ab59,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-187e0053-05d2-4702-816e-034ba9cfb23b,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-c1b9e282-f253-4f70-a6b8-f74aaa7e82c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-47712fe9-f28d-4e51-8d10-280c2adb7950,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-ec02dfde-48f6-4058-8214-4d85d1d91dac,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-613adb2b-0f1c-499a-822b-0a6e521ce87a,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-54ed5b4c-a1fa-4991-8136-aba56509af2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-79a57871-fb7d-407a-81cd-d5d0294dfbf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439524800-172.17.0.8-1595703143023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39019,DS-37e8be5c-81d8-4059-b00b-a3e6aeecdb30,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-eb44a846-b6b0-4f8c-aafc-0d828058843f,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-587d097d-7980-48ad-b218-101b2756ae8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-b07f27a7-be8f-4094-a70e-51253c094923,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-29639cc6-f5ec-4195-b280-f8d12788c04e,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-88196ec2-f881-477f-8386-bc3855ac8110,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-f00223e8-c849-409a-9b84-e01e3048a40c,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-05fab843-ab1f-43ad-9f64-4f93c88316a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439524800-172.17.0.8-1595703143023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39019,DS-37e8be5c-81d8-4059-b00b-a3e6aeecdb30,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-eb44a846-b6b0-4f8c-aafc-0d828058843f,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-587d097d-7980-48ad-b218-101b2756ae8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-b07f27a7-be8f-4094-a70e-51253c094923,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-29639cc6-f5ec-4195-b280-f8d12788c04e,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-88196ec2-f881-477f-8386-bc3855ac8110,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-f00223e8-c849-409a-9b84-e01e3048a40c,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-05fab843-ab1f-43ad-9f64-4f93c88316a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-879214210-172.17.0.8-1595703287118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40170,DS-1d5a62c5-afc3-4a50-a900-f4cbc845a556,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-61d08f2c-c428-40cb-b290-2903f23ec67a,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-f6cafc72-c540-48ae-a47e-ecce55574494,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-e931f49b-7d94-4a25-8b68-d6668fc9eb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-ba1184ae-e605-4f4b-85d9-a85811407602,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-8b820b0d-4dce-4e85-8d9c-59748d2a2709,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-df709138-0645-4457-874b-bc6fafbb19cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-ebe63a06-5fa2-4153-ad15-12478ab6a414,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-879214210-172.17.0.8-1595703287118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40170,DS-1d5a62c5-afc3-4a50-a900-f4cbc845a556,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-61d08f2c-c428-40cb-b290-2903f23ec67a,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-f6cafc72-c540-48ae-a47e-ecce55574494,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-e931f49b-7d94-4a25-8b68-d6668fc9eb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-ba1184ae-e605-4f4b-85d9-a85811407602,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-8b820b0d-4dce-4e85-8d9c-59748d2a2709,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-df709138-0645-4457-874b-bc6fafbb19cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-ebe63a06-5fa2-4153-ad15-12478ab6a414,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062854441-172.17.0.8-1595703695289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46132,DS-53fcaca0-b43f-40a8-b25c-0b3b10378510,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-491035d7-e4f5-4cd1-9ddc-317d67c03beb,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-ff2ea7f7-c38a-453f-be66-031d3a627301,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-f7823b49-29ee-49f7-8c7b-1f16e32cf044,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-ead1bb5d-40c2-4f1a-b30c-543386adc92f,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-2d901a0c-e088-4900-b023-29f1e56be23d,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-c2354eb3-b958-40f0-ae28-f176ee600322,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-a2140aca-490a-4006-a233-e895fd4d7fff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062854441-172.17.0.8-1595703695289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46132,DS-53fcaca0-b43f-40a8-b25c-0b3b10378510,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-491035d7-e4f5-4cd1-9ddc-317d67c03beb,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-ff2ea7f7-c38a-453f-be66-031d3a627301,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-f7823b49-29ee-49f7-8c7b-1f16e32cf044,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-ead1bb5d-40c2-4f1a-b30c-543386adc92f,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-2d901a0c-e088-4900-b023-29f1e56be23d,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-c2354eb3-b958-40f0-ae28-f176ee600322,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-a2140aca-490a-4006-a233-e895fd4d7fff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204892515-172.17.0.8-1595703728828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36476,DS-407c5c1e-b200-47a5-ae0b-8154d2350103,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-1d5de34c-1497-482d-870d-ebe8578578df,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-3d5bd839-fc55-4a2f-b7f0-31cb68ef222f,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-19660913-602a-4e15-8264-ccdd679e543b,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-5f54bd75-b8fa-41f6-9222-f08f5d6035f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-0c11e58c-3438-4b81-8f77-15a04c46adea,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-6af12c92-34fa-4f5a-bae3-227c18abc5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-b36fa161-e033-483e-abdb-91e4f7358ca5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204892515-172.17.0.8-1595703728828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36476,DS-407c5c1e-b200-47a5-ae0b-8154d2350103,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-1d5de34c-1497-482d-870d-ebe8578578df,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-3d5bd839-fc55-4a2f-b7f0-31cb68ef222f,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-19660913-602a-4e15-8264-ccdd679e543b,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-5f54bd75-b8fa-41f6-9222-f08f5d6035f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-0c11e58c-3438-4b81-8f77-15a04c46adea,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-6af12c92-34fa-4f5a-bae3-227c18abc5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-b36fa161-e033-483e-abdb-91e4f7358ca5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1408463709-172.17.0.8-1595703997263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39517,DS-9b4c9c08-e104-4246-acf7-f5fdfa06f1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-9c88784e-f93b-45e7-8766-f3c9c094a11b,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-d7f1c968-36ea-4a98-8e58-68d356526a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-00d35852-c495-4aed-a1ea-30a498177814,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-b10eeea1-bdb3-458f-938c-f4ae8addf39b,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-2e299a9c-98c3-4c95-934d-1f5f063a6e20,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-0b3866f2-7827-4d88-a2ed-e872cb8e54f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-b48380e0-5e95-49d4-b924-41f8124b4806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1408463709-172.17.0.8-1595703997263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39517,DS-9b4c9c08-e104-4246-acf7-f5fdfa06f1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-9c88784e-f93b-45e7-8766-f3c9c094a11b,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-d7f1c968-36ea-4a98-8e58-68d356526a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-00d35852-c495-4aed-a1ea-30a498177814,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-b10eeea1-bdb3-458f-938c-f4ae8addf39b,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-2e299a9c-98c3-4c95-934d-1f5f063a6e20,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-0b3866f2-7827-4d88-a2ed-e872cb8e54f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-b48380e0-5e95-49d4-b924-41f8124b4806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-719025831-172.17.0.8-1595704201230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40789,DS-4e1ef506-62ca-4086-a049-e4fb13085bda,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-4d3a163b-3599-4d30-8b80-9c9058f5ce06,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-c0e59091-1744-4279-b13b-acaa10514ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-1b4ada9d-ddcd-4f51-9e71-5dc8d3d3bb74,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-2cb98800-f6f0-4ddf-a836-11fc5e41d72d,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-fea0ed51-05ee-4a16-a05a-2438744cfc87,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-e20c9cc7-2613-456f-8c42-1c9eaff67b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-255c1e21-d118-4ddb-90cf-cafeb4f7b16f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-719025831-172.17.0.8-1595704201230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40789,DS-4e1ef506-62ca-4086-a049-e4fb13085bda,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-4d3a163b-3599-4d30-8b80-9c9058f5ce06,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-c0e59091-1744-4279-b13b-acaa10514ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-1b4ada9d-ddcd-4f51-9e71-5dc8d3d3bb74,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-2cb98800-f6f0-4ddf-a836-11fc5e41d72d,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-fea0ed51-05ee-4a16-a05a-2438744cfc87,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-e20c9cc7-2613-456f-8c42-1c9eaff67b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-255c1e21-d118-4ddb-90cf-cafeb4f7b16f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458767160-172.17.0.8-1595704346971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46556,DS-a24a8229-2123-4516-93d8-668282ff108b,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-670a9d10-c445-479d-aade-dabf916c5b71,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-c2bb12fb-349f-40fe-bcc8-75dbd02a969e,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-1c736490-a3c3-4462-a64e-0830f4f6a417,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-8fac2aaf-2839-481d-a8c9-3a7057c942d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-c2925285-dcd8-405a-9881-2142767ec7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-b83d0cd9-b1da-41e5-b6f0-40899d94775d,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-4fbc6e05-b74b-4070-9c83-dd624f4bd840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458767160-172.17.0.8-1595704346971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46556,DS-a24a8229-2123-4516-93d8-668282ff108b,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-670a9d10-c445-479d-aade-dabf916c5b71,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-c2bb12fb-349f-40fe-bcc8-75dbd02a969e,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-1c736490-a3c3-4462-a64e-0830f4f6a417,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-8fac2aaf-2839-481d-a8c9-3a7057c942d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-c2925285-dcd8-405a-9881-2142767ec7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-b83d0cd9-b1da-41e5-b6f0-40899d94775d,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-4fbc6e05-b74b-4070-9c83-dd624f4bd840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754023705-172.17.0.8-1595704384377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42965,DS-6faf7fbe-b4c7-4563-a474-cc11128a0de2,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-44c2826e-dd8b-4a32-8e4d-fe7373cc5ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-c02b1e07-fc76-4e01-b1fd-570e4db1c41f,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-0025e784-34a1-43c2-8aca-b2268aba03d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-5de0dd8d-7926-4b75-90fc-082b723eedfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-f17c2cf6-540d-417e-940d-88153b6e1cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-6c0a7336-2e23-425b-ad30-0a963df5f944,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-81f35500-557e-4ce9-89e1-11cfd493fa90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754023705-172.17.0.8-1595704384377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42965,DS-6faf7fbe-b4c7-4563-a474-cc11128a0de2,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-44c2826e-dd8b-4a32-8e4d-fe7373cc5ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-c02b1e07-fc76-4e01-b1fd-570e4db1c41f,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-0025e784-34a1-43c2-8aca-b2268aba03d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-5de0dd8d-7926-4b75-90fc-082b723eedfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-f17c2cf6-540d-417e-940d-88153b6e1cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-6c0a7336-2e23-425b-ad30-0a963df5f944,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-81f35500-557e-4ce9-89e1-11cfd493fa90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-625131638-172.17.0.8-1595704461780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34952,DS-c123fbfb-ac8e-401b-b950-dbe19155c607,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-f856d255-39cf-4d51-8d52-b32411bd7513,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-3a85d62f-1e56-4eaa-9d97-0cfbcd243daa,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-379dd3bf-a72f-4c52-9583-e13a28a9884f,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-b2ca85b8-30f3-42f1-a8b3-abb633f871af,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-c0f91c54-5ba7-4888-bd85-edcdf2a8cbec,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-f78d755f-d4b0-4bfb-9f67-5343731894e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-367165db-d5c9-48d3-9013-0a7c711792a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-625131638-172.17.0.8-1595704461780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34952,DS-c123fbfb-ac8e-401b-b950-dbe19155c607,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-f856d255-39cf-4d51-8d52-b32411bd7513,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-3a85d62f-1e56-4eaa-9d97-0cfbcd243daa,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-379dd3bf-a72f-4c52-9583-e13a28a9884f,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-b2ca85b8-30f3-42f1-a8b3-abb633f871af,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-c0f91c54-5ba7-4888-bd85-edcdf2a8cbec,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-f78d755f-d4b0-4bfb-9f67-5343731894e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-367165db-d5c9-48d3-9013-0a7c711792a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130807416-172.17.0.8-1595704532018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33957,DS-c08bd0e4-6ffa-42d1-9c15-dfe96253e9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-e164eddd-6acb-4107-8be0-19a287cb6e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-b9be61da-47e7-4cdd-aae5-81c432be08d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-b6fae20c-ced5-4a0d-92ca-f7e2ebca39dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-2ec0c59e-60d4-4249-baa1-34322b841134,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-bc8477bc-0b4e-419b-8a09-ddf399550998,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-b5c15bdb-e3de-45cc-9818-53db59032985,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-c164a9a4-ff09-40d9-a808-d0d3ec58edd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130807416-172.17.0.8-1595704532018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33957,DS-c08bd0e4-6ffa-42d1-9c15-dfe96253e9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-e164eddd-6acb-4107-8be0-19a287cb6e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-b9be61da-47e7-4cdd-aae5-81c432be08d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-b6fae20c-ced5-4a0d-92ca-f7e2ebca39dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-2ec0c59e-60d4-4249-baa1-34322b841134,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-bc8477bc-0b4e-419b-8a09-ddf399550998,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-b5c15bdb-e3de-45cc-9818-53db59032985,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-c164a9a4-ff09-40d9-a808-d0d3ec58edd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345953605-172.17.0.8-1595704804750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34123,DS-b69eaa8a-6454-4996-a24a-f3e4f767e2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-ed3a5577-6a83-4ebe-af39-b22af1295883,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-0617d5a2-8bb3-47de-9c9b-25b8a1e579b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-e43a80d7-0e13-4576-9db2-c2ece63ee74a,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-47f8d30a-44a1-4348-9ae5-ae19c1f0e838,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-3b210a13-fd0e-458a-bcbe-9b7c6df7313a,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-699b1e9f-81be-4ae9-aaff-01e77e3c7ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-821965f0-e241-4c66-8dde-11d61f7f757a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345953605-172.17.0.8-1595704804750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34123,DS-b69eaa8a-6454-4996-a24a-f3e4f767e2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-ed3a5577-6a83-4ebe-af39-b22af1295883,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-0617d5a2-8bb3-47de-9c9b-25b8a1e579b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-e43a80d7-0e13-4576-9db2-c2ece63ee74a,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-47f8d30a-44a1-4348-9ae5-ae19c1f0e838,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-3b210a13-fd0e-458a-bcbe-9b7c6df7313a,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-699b1e9f-81be-4ae9-aaff-01e77e3c7ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-821965f0-e241-4c66-8dde-11d61f7f757a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5378
