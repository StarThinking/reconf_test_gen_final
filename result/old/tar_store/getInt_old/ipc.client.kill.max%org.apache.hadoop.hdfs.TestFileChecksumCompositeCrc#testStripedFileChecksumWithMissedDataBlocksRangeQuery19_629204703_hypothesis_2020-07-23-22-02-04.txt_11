reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-317857167-172.17.0.8-1595541811031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45054,DS-7aadc8c2-03d1-4840-b628-0985d22cc1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-f1ad6ed4-b013-4e21-8aff-f4bbb62bf4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-cc1069f2-853d-4a67-a340-2396b199dd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-102f5822-18c1-4fbb-8f53-f4cd3303c9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-e1939351-c509-43ff-a48c-9600957bbb73,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-ec12f666-11f9-480f-aeef-6fb2de071af0,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-482efdb8-fbb1-4d49-a714-abea4762d1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-2b867ef0-f400-481f-91e9-90692a2a791b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-317857167-172.17.0.8-1595541811031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45054,DS-7aadc8c2-03d1-4840-b628-0985d22cc1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-f1ad6ed4-b013-4e21-8aff-f4bbb62bf4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-cc1069f2-853d-4a67-a340-2396b199dd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-102f5822-18c1-4fbb-8f53-f4cd3303c9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-e1939351-c509-43ff-a48c-9600957bbb73,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-ec12f666-11f9-480f-aeef-6fb2de071af0,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-482efdb8-fbb1-4d49-a714-abea4762d1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-2b867ef0-f400-481f-91e9-90692a2a791b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-631482548-172.17.0.8-1595542181876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46675,DS-6110dc1e-7984-414e-9b18-6e4c0a597f89,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-fd1fa60c-68e6-4bf3-b66c-984fa31370be,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-86b416a7-2bff-4c03-b6a0-1c32c6c35285,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-227bf9d1-a50d-46a9-95ea-0667004c21dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-02fffd8a-01b8-429c-8293-75c7de4782a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-d3e60121-01f5-48b6-84b0-0b844b5261ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-47f99ba8-d9a1-4ebe-8ca3-9dfc380cd679,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-cdd7ba28-6db7-44c7-8a0d-8ccce662ae24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-631482548-172.17.0.8-1595542181876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46675,DS-6110dc1e-7984-414e-9b18-6e4c0a597f89,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-fd1fa60c-68e6-4bf3-b66c-984fa31370be,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-86b416a7-2bff-4c03-b6a0-1c32c6c35285,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-227bf9d1-a50d-46a9-95ea-0667004c21dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-02fffd8a-01b8-429c-8293-75c7de4782a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-d3e60121-01f5-48b6-84b0-0b844b5261ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-47f99ba8-d9a1-4ebe-8ca3-9dfc380cd679,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-cdd7ba28-6db7-44c7-8a0d-8ccce662ae24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1967471961-172.17.0.8-1595543071561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45931,DS-2558b476-fce8-4615-9fea-a426fd81df89,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-1bfd3bc2-5c03-4d53-9bdd-d7ca6d9caccf,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-cfe360c9-d696-4fdd-80f1-6cf6ebdbdc79,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-f1b692a4-0fb7-403d-b9b2-e5cc51cd7689,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-d778db5d-3a25-413f-8c3b-960a6cb099e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-029f1e88-4c91-41ed-ac14-6dc9c8d56035,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-7e269ea0-b1e1-47e8-9206-bd65d3d2352c,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-301a5da6-3883-4b9a-8e82-e7d5710c7d86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1967471961-172.17.0.8-1595543071561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45931,DS-2558b476-fce8-4615-9fea-a426fd81df89,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-1bfd3bc2-5c03-4d53-9bdd-d7ca6d9caccf,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-cfe360c9-d696-4fdd-80f1-6cf6ebdbdc79,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-f1b692a4-0fb7-403d-b9b2-e5cc51cd7689,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-d778db5d-3a25-413f-8c3b-960a6cb099e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-029f1e88-4c91-41ed-ac14-6dc9c8d56035,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-7e269ea0-b1e1-47e8-9206-bd65d3d2352c,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-301a5da6-3883-4b9a-8e82-e7d5710c7d86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1404723764-172.17.0.8-1595543172568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34860,DS-d11d134a-5c10-4a3f-84a3-fd3fed97c30d,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-e859a755-49a7-43a5-8404-87f39ef54585,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-d2a0e5c7-599b-46af-91d7-892b732cfdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-f211a15c-dcb3-4f75-bda1-4e0eb954728f,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-27daf143-70fd-4bdf-b2f0-0e6d82de2925,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-e6ada13b-36fb-47ac-aa45-53a5ea3dba8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-1dcef938-7a4d-456c-9e0a-7200a947ade3,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-0aef9d6d-d421-443a-baf9-e99f85c60725,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1404723764-172.17.0.8-1595543172568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34860,DS-d11d134a-5c10-4a3f-84a3-fd3fed97c30d,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-e859a755-49a7-43a5-8404-87f39ef54585,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-d2a0e5c7-599b-46af-91d7-892b732cfdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-f211a15c-dcb3-4f75-bda1-4e0eb954728f,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-27daf143-70fd-4bdf-b2f0-0e6d82de2925,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-e6ada13b-36fb-47ac-aa45-53a5ea3dba8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-1dcef938-7a4d-456c-9e0a-7200a947ade3,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-0aef9d6d-d421-443a-baf9-e99f85c60725,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717951903-172.17.0.8-1595543233900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34208,DS-0d2f9223-9d8a-4eab-b0d5-c71158d96225,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-2077264e-7563-4b90-a312-9b2d91b080e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-4d1a65c4-d311-47cd-bd63-2ff5d960f6db,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-83e9099a-9482-4361-8fe0-422b06458ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-2ad1af26-be83-49a0-acd6-25710d298fee,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-29a2fca5-417e-40c3-a7f7-b74f2f6f7b40,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-f3cc90a3-7f05-44f7-9da9-768fda9914ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-d5ce0ad3-24e5-44b9-a2b5-cfccad552474,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717951903-172.17.0.8-1595543233900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34208,DS-0d2f9223-9d8a-4eab-b0d5-c71158d96225,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-2077264e-7563-4b90-a312-9b2d91b080e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-4d1a65c4-d311-47cd-bd63-2ff5d960f6db,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-83e9099a-9482-4361-8fe0-422b06458ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-2ad1af26-be83-49a0-acd6-25710d298fee,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-29a2fca5-417e-40c3-a7f7-b74f2f6f7b40,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-f3cc90a3-7f05-44f7-9da9-768fda9914ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-d5ce0ad3-24e5-44b9-a2b5-cfccad552474,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1760644700-172.17.0.8-1595543327920:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42409,DS-9f48103b-e722-4eef-b638-6c8173bc1d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-5d991fba-95f4-4f20-8994-71ae94649810,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-f91a3f20-9a59-4005-bace-7680b6bb8097,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-fd4e25af-fa6b-4124-bb15-d0ec18ef0d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-b5f18f0c-54c7-4ddd-98cf-61a9a82aa4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-ac3e2b73-0e16-4eba-a695-c83a4e230c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-7c2391e3-0417-4461-90f5-5f67c184a05e,DISK], DatanodeInfoWithStorage[127.0.0.1:37774,DS-b08ab0ab-a42c-4074-a376-138bc9a255b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1760644700-172.17.0.8-1595543327920:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42409,DS-9f48103b-e722-4eef-b638-6c8173bc1d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-5d991fba-95f4-4f20-8994-71ae94649810,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-f91a3f20-9a59-4005-bace-7680b6bb8097,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-fd4e25af-fa6b-4124-bb15-d0ec18ef0d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-b5f18f0c-54c7-4ddd-98cf-61a9a82aa4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-ac3e2b73-0e16-4eba-a695-c83a4e230c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-7c2391e3-0417-4461-90f5-5f67c184a05e,DISK], DatanodeInfoWithStorage[127.0.0.1:37774,DS-b08ab0ab-a42c-4074-a376-138bc9a255b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1863708898-172.17.0.8-1595544025724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39980,DS-27012860-c569-4661-8a6a-ecd0df176346,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-68810914-f6bc-4319-8c5b-c14e0b35ef3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-4625ff17-d299-4b90-884a-bda151c4f2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-8666055a-3893-45ca-8003-3ab49b4a045c,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-c4ddeaca-1319-43dc-b1b3-6eb9b8894bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-2f527d8a-6ca6-470a-a555-a71dfb940353,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-352789a7-01a1-4570-93bb-6fe81b8dee9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-e160e1d0-bdb9-441e-b782-17dc0bee33ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1863708898-172.17.0.8-1595544025724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39980,DS-27012860-c569-4661-8a6a-ecd0df176346,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-68810914-f6bc-4319-8c5b-c14e0b35ef3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-4625ff17-d299-4b90-884a-bda151c4f2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-8666055a-3893-45ca-8003-3ab49b4a045c,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-c4ddeaca-1319-43dc-b1b3-6eb9b8894bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-2f527d8a-6ca6-470a-a555-a71dfb940353,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-352789a7-01a1-4570-93bb-6fe81b8dee9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-e160e1d0-bdb9-441e-b782-17dc0bee33ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1337698255-172.17.0.8-1595544123525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45265,DS-fa088dd0-a658-4884-bbe1-84e8d4370a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-5c2ab039-a6cf-457d-8a16-f9a816ca0b43,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-55a56edc-60a4-4fd9-8594-94307ff42619,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-c0105464-1e0a-46b1-8f2e-ec27afafcf34,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-5c47a47d-631a-4b90-86b8-39dd68e6539c,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-12bc5ac7-73e7-437d-b6c8-62134ac9347b,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-078e3318-8549-40ae-a971-c9ccb75b3498,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-63789b12-e033-47f9-bcca-7e121b1a4e0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1337698255-172.17.0.8-1595544123525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45265,DS-fa088dd0-a658-4884-bbe1-84e8d4370a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-5c2ab039-a6cf-457d-8a16-f9a816ca0b43,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-55a56edc-60a4-4fd9-8594-94307ff42619,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-c0105464-1e0a-46b1-8f2e-ec27afafcf34,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-5c47a47d-631a-4b90-86b8-39dd68e6539c,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-12bc5ac7-73e7-437d-b6c8-62134ac9347b,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-078e3318-8549-40ae-a971-c9ccb75b3498,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-63789b12-e033-47f9-bcca-7e121b1a4e0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133554324-172.17.0.8-1595544683559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42769,DS-a0a6e26d-98cf-49c7-90b0-2c58bf4e69fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-e7de56e2-f57b-4855-a486-785e99cceebe,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-07cdbec1-a792-4523-9ddb-063485a64d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-031d4802-966d-454d-bf03-17f148ebe819,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-259f3aa7-ee04-45c0-b999-b72428122225,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-d33c27ab-8bdb-4255-b04a-0027f06cd10f,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-f144eed3-f096-4cc5-a98f-79216b9abc56,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-0bbf21a8-e51f-4bc2-8170-3d8d5452a8c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133554324-172.17.0.8-1595544683559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42769,DS-a0a6e26d-98cf-49c7-90b0-2c58bf4e69fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-e7de56e2-f57b-4855-a486-785e99cceebe,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-07cdbec1-a792-4523-9ddb-063485a64d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-031d4802-966d-454d-bf03-17f148ebe819,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-259f3aa7-ee04-45c0-b999-b72428122225,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-d33c27ab-8bdb-4255-b04a-0027f06cd10f,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-f144eed3-f096-4cc5-a98f-79216b9abc56,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-0bbf21a8-e51f-4bc2-8170-3d8d5452a8c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683122817-172.17.0.8-1595544878844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41507,DS-50d25148-b141-4592-bde8-0da66db4ae2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-2d7311b8-3300-4a08-88b7-99dd29a97d11,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-e0b979e5-d7fd-46d3-ae68-18fe43d3e427,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-e2d1a10c-19fa-4318-abfd-2385c3791eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-7794b484-8060-419f-b1ed-ec49d466a8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-e9f290d7-b126-43c1-85ce-b44fc1cf8b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-4480c991-0c67-4f99-9133-e99cf5d2804a,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-b52b2c64-c0f3-4987-9e49-f83c1577d600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683122817-172.17.0.8-1595544878844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41507,DS-50d25148-b141-4592-bde8-0da66db4ae2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-2d7311b8-3300-4a08-88b7-99dd29a97d11,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-e0b979e5-d7fd-46d3-ae68-18fe43d3e427,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-e2d1a10c-19fa-4318-abfd-2385c3791eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-7794b484-8060-419f-b1ed-ec49d466a8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-e9f290d7-b126-43c1-85ce-b44fc1cf8b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-4480c991-0c67-4f99-9133-e99cf5d2804a,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-b52b2c64-c0f3-4987-9e49-f83c1577d600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-189632814-172.17.0.8-1595545055805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40805,DS-5b804011-1959-4b09-a0b3-a6c099276f32,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-708a3a03-983f-42aa-a792-8aa49acc82d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-b1cdabb8-a0a0-4db1-bb58-da29f8bf2a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-c9186185-a3a1-438b-80e6-e82eff14e4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-58f9e46a-d78c-434d-920a-383e459b3569,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-4cf705f6-46b9-441d-9986-63582f8bc178,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-f8ba5197-8e7b-4a8c-9182-bf5370afb2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-a8e1f5ff-5697-49c7-bb98-1fd6f535f24e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-189632814-172.17.0.8-1595545055805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40805,DS-5b804011-1959-4b09-a0b3-a6c099276f32,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-708a3a03-983f-42aa-a792-8aa49acc82d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-b1cdabb8-a0a0-4db1-bb58-da29f8bf2a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-c9186185-a3a1-438b-80e6-e82eff14e4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-58f9e46a-d78c-434d-920a-383e459b3569,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-4cf705f6-46b9-441d-9986-63582f8bc178,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-f8ba5197-8e7b-4a8c-9182-bf5370afb2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-a8e1f5ff-5697-49c7-bb98-1fd6f535f24e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717673468-172.17.0.8-1595545158569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41203,DS-cd0e450a-4b17-45be-bd16-1714110f0cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-58742ec2-2cfc-414e-bba2-ade22dd1107f,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-f3bab51b-70d8-49dd-a88d-53fe821d694d,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-649cd85c-e3ff-49f8-92aa-c962676f6c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-540c48e0-3556-4cf2-b187-dc7d155689a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-9024786e-572e-41b1-9c5e-40fe213ba25b,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-4af4125f-113c-42e6-a81b-3fc3352842dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-06f0f826-948c-45c6-8281-b4c63de32cba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717673468-172.17.0.8-1595545158569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41203,DS-cd0e450a-4b17-45be-bd16-1714110f0cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-58742ec2-2cfc-414e-bba2-ade22dd1107f,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-f3bab51b-70d8-49dd-a88d-53fe821d694d,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-649cd85c-e3ff-49f8-92aa-c962676f6c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-540c48e0-3556-4cf2-b187-dc7d155689a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-9024786e-572e-41b1-9c5e-40fe213ba25b,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-4af4125f-113c-42e6-a81b-3fc3352842dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-06f0f826-948c-45c6-8281-b4c63de32cba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-792928512-172.17.0.8-1595545269725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37737,DS-cad732e8-e4a8-4977-8ba2-ea3c5ecbb394,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-2a0637ef-14d9-4313-a02f-34e09e97f67d,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-eb5ee674-7a59-4623-8822-28db5ae5c6db,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-161b30dc-014b-486c-aeec-84ab6a577d81,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-5e9ec93f-6540-4cd0-b3cc-a716e4491758,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-df1eb430-bbdc-4b3e-9e00-5e222826b6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-7846e448-68bb-4705-9749-d5189feb7df2,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-1ea8ee47-b2eb-4885-9745-aeade9ecdfb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-792928512-172.17.0.8-1595545269725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37737,DS-cad732e8-e4a8-4977-8ba2-ea3c5ecbb394,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-2a0637ef-14d9-4313-a02f-34e09e97f67d,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-eb5ee674-7a59-4623-8822-28db5ae5c6db,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-161b30dc-014b-486c-aeec-84ab6a577d81,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-5e9ec93f-6540-4cd0-b3cc-a716e4491758,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-df1eb430-bbdc-4b3e-9e00-5e222826b6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-7846e448-68bb-4705-9749-d5189feb7df2,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-1ea8ee47-b2eb-4885-9745-aeade9ecdfb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-910442356-172.17.0.8-1595545461364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36671,DS-01018f4b-4b09-452b-a95b-0b815522c291,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-0ad490be-2ee8-41db-b351-fc3a10558b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-19042ba2-af31-454d-a564-639a62ed5f39,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-03c1b84c-8417-48e8-a890-318eb45101ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-75004c14-8cb8-4395-bcb0-baa93fda72e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-9278d409-bd75-4e6b-baad-4f45557998c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-d5087b5b-8b62-47da-8194-9bb1c8c11d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-071c9c92-65fe-4a21-a2ca-22f00b378df6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-910442356-172.17.0.8-1595545461364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36671,DS-01018f4b-4b09-452b-a95b-0b815522c291,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-0ad490be-2ee8-41db-b351-fc3a10558b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-19042ba2-af31-454d-a564-639a62ed5f39,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-03c1b84c-8417-48e8-a890-318eb45101ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-75004c14-8cb8-4395-bcb0-baa93fda72e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-9278d409-bd75-4e6b-baad-4f45557998c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-d5087b5b-8b62-47da-8194-9bb1c8c11d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-071c9c92-65fe-4a21-a2ca-22f00b378df6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-690596645-172.17.0.8-1595545522561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44459,DS-851dc037-c452-4484-a69a-aab2d6337305,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-ead3031f-e3f6-46e8-896d-022a957d1e57,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-48c62d10-42f9-40c7-9e2d-62f6f15ff4de,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-c1b9934e-d91f-4771-9b09-e5a19a4be28c,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-defcf957-1ed9-4af1-8e0f-1cb8bf37ac94,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-19629715-abb9-49b7-ab2e-f8f887548ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-e2f868c3-8949-408f-bdd1-6a58eeb8f473,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-684b994b-ba88-41c5-8f15-3dd6ad8eee8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-690596645-172.17.0.8-1595545522561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44459,DS-851dc037-c452-4484-a69a-aab2d6337305,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-ead3031f-e3f6-46e8-896d-022a957d1e57,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-48c62d10-42f9-40c7-9e2d-62f6f15ff4de,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-c1b9934e-d91f-4771-9b09-e5a19a4be28c,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-defcf957-1ed9-4af1-8e0f-1cb8bf37ac94,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-19629715-abb9-49b7-ab2e-f8f887548ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-e2f868c3-8949-408f-bdd1-6a58eeb8f473,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-684b994b-ba88-41c5-8f15-3dd6ad8eee8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752446511-172.17.0.8-1595545625319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39604,DS-12c45cb0-8751-4877-87e7-08a8627fe778,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-1ccbbaf8-57d4-48ab-8cc7-fa013b4a22ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-1d51eeff-5b1a-4036-897a-d203a6f03f22,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-70f41775-0389-48eb-a13b-a4b906f07377,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-94f47b44-e863-432f-8d97-c847f54942fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-dbd868d1-3d8a-4813-8e72-895af33052a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-db76dbae-ba98-4a21-a95f-6ac6f81acd85,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-5ce1ec6b-cceb-41bb-b4c9-aeef339cb871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752446511-172.17.0.8-1595545625319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39604,DS-12c45cb0-8751-4877-87e7-08a8627fe778,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-1ccbbaf8-57d4-48ab-8cc7-fa013b4a22ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-1d51eeff-5b1a-4036-897a-d203a6f03f22,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-70f41775-0389-48eb-a13b-a4b906f07377,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-94f47b44-e863-432f-8d97-c847f54942fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-dbd868d1-3d8a-4813-8e72-895af33052a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-db76dbae-ba98-4a21-a95f-6ac6f81acd85,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-5ce1ec6b-cceb-41bb-b4c9-aeef339cb871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-814360046-172.17.0.8-1595545911183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44544,DS-6b8539b4-bbaf-44e5-b85d-dfa44f254b28,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-42ea62da-0e24-466f-a8c5-8e1af66ff79d,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-34733e13-89e1-4937-949c-9330a9e8ffbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-8a18931e-7e48-4187-9fc9-fab91a570e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-a556696d-32c7-4bc2-aa42-30e262111843,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-e6cbc1ee-bd7e-4bec-8ad9-00aafff074a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-99e3a7de-5a66-4a22-af72-9b5151504ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-6d4be663-2757-4c08-be86-ba9de8d1a2cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-814360046-172.17.0.8-1595545911183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44544,DS-6b8539b4-bbaf-44e5-b85d-dfa44f254b28,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-42ea62da-0e24-466f-a8c5-8e1af66ff79d,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-34733e13-89e1-4937-949c-9330a9e8ffbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-8a18931e-7e48-4187-9fc9-fab91a570e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-a556696d-32c7-4bc2-aa42-30e262111843,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-e6cbc1ee-bd7e-4bec-8ad9-00aafff074a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-99e3a7de-5a66-4a22-af72-9b5151504ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-6d4be663-2757-4c08-be86-ba9de8d1a2cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1417671897-172.17.0.8-1595546040280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40540,DS-3026e0fa-c19e-49ad-8bc0-dace8d313faf,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-21f3a688-5215-4c40-b4e9-9ce78f2740dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-e186b6ab-9cfd-475c-8795-a93718ab339e,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-ee1255cf-fb6a-4013-b52d-e43e3bca6544,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-a5b071b9-571b-42a9-813b-724058247de8,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-a3a8a2a6-368c-48ec-b27b-ca5ef1e5ea1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-d3dd47cc-a119-4836-8e4e-dcce2bf44112,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-0771c86e-4905-4f1d-bb18-a94855d8dbb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1417671897-172.17.0.8-1595546040280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40540,DS-3026e0fa-c19e-49ad-8bc0-dace8d313faf,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-21f3a688-5215-4c40-b4e9-9ce78f2740dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-e186b6ab-9cfd-475c-8795-a93718ab339e,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-ee1255cf-fb6a-4013-b52d-e43e3bca6544,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-a5b071b9-571b-42a9-813b-724058247de8,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-a3a8a2a6-368c-48ec-b27b-ca5ef1e5ea1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-d3dd47cc-a119-4836-8e4e-dcce2bf44112,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-0771c86e-4905-4f1d-bb18-a94855d8dbb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2030978786-172.17.0.8-1595546243770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37669,DS-8d54d0ec-53f0-4b6e-bb66-67a6658ce157,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-195b8e83-711e-481e-aab6-c5ad526b9678,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-4c0da8a6-2d6d-4a0e-aaa0-6520a970f029,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-dab1b276-ce53-4a0e-89c9-b7d70f1dbbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-97197734-10ed-44de-9b36-91f237117665,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-9c04fdc5-8992-438c-a054-aec02a3a682e,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-0fa7e384-865d-44ce-8bf9-d821e50d6a27,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-8fd5720d-2bfb-4c58-950c-11f44f719124,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2030978786-172.17.0.8-1595546243770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37669,DS-8d54d0ec-53f0-4b6e-bb66-67a6658ce157,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-195b8e83-711e-481e-aab6-c5ad526b9678,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-4c0da8a6-2d6d-4a0e-aaa0-6520a970f029,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-dab1b276-ce53-4a0e-89c9-b7d70f1dbbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-97197734-10ed-44de-9b36-91f237117665,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-9c04fdc5-8992-438c-a054-aec02a3a682e,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-0fa7e384-865d-44ce-8bf9-d821e50d6a27,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-8fd5720d-2bfb-4c58-950c-11f44f719124,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-334084077-172.17.0.8-1595546303918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34270,DS-bcc32652-128e-4dbb-a4ee-758c2278c4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-c81e2abe-5a7a-4e66-9064-b70c1f202c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-5692662b-ba64-42ea-b066-7570bc3f9a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-34cbe9e4-98c3-4b63-9695-371329e53f87,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-3ae4f76a-27e1-4477-99f0-10282171b8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-3a345bfb-b5c4-4ed4-8874-1c666a13fe7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-1587a168-0887-49c3-b7bd-95c313fc3b22,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-33d8c562-6a69-4454-81d9-a1119b031c26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-334084077-172.17.0.8-1595546303918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34270,DS-bcc32652-128e-4dbb-a4ee-758c2278c4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-c81e2abe-5a7a-4e66-9064-b70c1f202c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-5692662b-ba64-42ea-b066-7570bc3f9a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-34cbe9e4-98c3-4b63-9695-371329e53f87,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-3ae4f76a-27e1-4477-99f0-10282171b8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-3a345bfb-b5c4-4ed4-8874-1c666a13fe7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-1587a168-0887-49c3-b7bd-95c313fc3b22,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-33d8c562-6a69-4454-81d9-a1119b031c26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1383004885-172.17.0.8-1595546725278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45064,DS-7b852d97-ed09-4dc6-b296-f12b01dcc56f,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-b0f17dee-823e-45b9-8916-2f4275019958,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-89f959d3-b092-4ba4-b414-905b28687955,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-b9199240-ee27-478f-b1f0-adf165a7a97b,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-1e193e6d-c248-452b-bf86-453c78043cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-98f8d678-adfe-47cb-8714-013c0b353bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-99f45e2b-4fc6-4799-905c-b5a3aaf75ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-c283a50a-7dfc-43ec-94a1-885be5fe6b80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1383004885-172.17.0.8-1595546725278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45064,DS-7b852d97-ed09-4dc6-b296-f12b01dcc56f,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-b0f17dee-823e-45b9-8916-2f4275019958,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-89f959d3-b092-4ba4-b414-905b28687955,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-b9199240-ee27-478f-b1f0-adf165a7a97b,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-1e193e6d-c248-452b-bf86-453c78043cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-98f8d678-adfe-47cb-8714-013c0b353bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-99f45e2b-4fc6-4799-905c-b5a3aaf75ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-c283a50a-7dfc-43ec-94a1-885be5fe6b80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5085
