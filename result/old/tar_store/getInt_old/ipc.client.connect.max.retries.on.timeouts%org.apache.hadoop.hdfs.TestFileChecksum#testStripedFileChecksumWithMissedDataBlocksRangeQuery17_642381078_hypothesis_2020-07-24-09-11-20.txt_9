reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-337905084-172.17.0.4-1595581896684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33795,DS-aafdec1e-bd6f-4724-a6a2-a0e96a1efd00,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-6a3746ec-22a3-4430-b654-cb66837c3634,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-3320bc87-1e48-44ac-95d9-60d3bb90ac09,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-dd319bc5-1f2a-447f-bbbc-1203979b95ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-93ddc189-db90-4e66-ae8e-79f9b03a1c04,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-42cc994c-77f6-44b1-b292-ff908d473ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-80781d65-d606-469f-a662-fbedafafc285,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-82c5f00f-c64d-4c08-a937-e9d85b40d65f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-337905084-172.17.0.4-1595581896684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33795,DS-aafdec1e-bd6f-4724-a6a2-a0e96a1efd00,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-6a3746ec-22a3-4430-b654-cb66837c3634,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-3320bc87-1e48-44ac-95d9-60d3bb90ac09,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-dd319bc5-1f2a-447f-bbbc-1203979b95ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-93ddc189-db90-4e66-ae8e-79f9b03a1c04,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-42cc994c-77f6-44b1-b292-ff908d473ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-80781d65-d606-469f-a662-fbedafafc285,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-82c5f00f-c64d-4c08-a937-e9d85b40d65f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1383392479-172.17.0.4-1595581961228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39185,DS-997aa761-ec02-449d-80cf-261e5b39e7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-b8784e7f-c15e-4e4f-aae7-64635c2690da,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-0a0d7c83-f872-4144-811b-5afe0edf2b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-a6ae7d76-9a9d-4a93-b661-997c86a3e4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-d7715d3a-9c7d-44a6-8012-1576c41babbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-1194aa06-72ba-48a6-ba2a-99f8bb5fe13c,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-9683f1fd-d195-463e-83d5-10f0c28ba114,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-bfacbcb3-9ff9-4d3d-9675-b695cabb3c85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1383392479-172.17.0.4-1595581961228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39185,DS-997aa761-ec02-449d-80cf-261e5b39e7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-b8784e7f-c15e-4e4f-aae7-64635c2690da,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-0a0d7c83-f872-4144-811b-5afe0edf2b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-a6ae7d76-9a9d-4a93-b661-997c86a3e4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-d7715d3a-9c7d-44a6-8012-1576c41babbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-1194aa06-72ba-48a6-ba2a-99f8bb5fe13c,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-9683f1fd-d195-463e-83d5-10f0c28ba114,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-bfacbcb3-9ff9-4d3d-9675-b695cabb3c85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2001561294-172.17.0.4-1595582348204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42127,DS-2218e5e6-6c7a-47ea-9b03-c0d73e5a4b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-bfe26b4b-1c72-432e-9c54-49955ba7ab04,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-b87dcf57-dfdd-494b-8794-0b7763ea3e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-d0dd2131-f716-42ef-b229-1e2b02b03ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-856cbbbf-33af-4480-b926-143d10e629f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-90b1d8da-7d65-4697-9ea0-15f9f5e9339c,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-f3b028ff-2eaa-40e9-979b-6be426b69a47,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-ba06e19c-894b-42e6-92fe-a97689df8975,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2001561294-172.17.0.4-1595582348204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42127,DS-2218e5e6-6c7a-47ea-9b03-c0d73e5a4b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-bfe26b4b-1c72-432e-9c54-49955ba7ab04,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-b87dcf57-dfdd-494b-8794-0b7763ea3e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-d0dd2131-f716-42ef-b229-1e2b02b03ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-856cbbbf-33af-4480-b926-143d10e629f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-90b1d8da-7d65-4697-9ea0-15f9f5e9339c,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-f3b028ff-2eaa-40e9-979b-6be426b69a47,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-ba06e19c-894b-42e6-92fe-a97689df8975,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-483069518-172.17.0.4-1595582868358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38476,DS-0f8cf24d-2158-4adf-ae2f-47b8b4aa4e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-406acd97-faa8-4c0d-83de-f0638b7bc91b,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-8156d35d-c4ec-4442-a6c2-cfc91bfac31e,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-97906cd3-d516-4eae-b3a7-3aa2ae4b630a,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-c989d5af-8d68-4dd3-a7a4-708ea5b2019e,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-c13b49f4-6c4d-40cc-80e6-cee5a6536091,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-6d4a2395-327e-4ffc-8078-bf6972d1626f,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-b4ae5f6c-9bd6-46c1-afee-fd1965667f62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-483069518-172.17.0.4-1595582868358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38476,DS-0f8cf24d-2158-4adf-ae2f-47b8b4aa4e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-406acd97-faa8-4c0d-83de-f0638b7bc91b,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-8156d35d-c4ec-4442-a6c2-cfc91bfac31e,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-97906cd3-d516-4eae-b3a7-3aa2ae4b630a,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-c989d5af-8d68-4dd3-a7a4-708ea5b2019e,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-c13b49f4-6c4d-40cc-80e6-cee5a6536091,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-6d4a2395-327e-4ffc-8078-bf6972d1626f,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-b4ae5f6c-9bd6-46c1-afee-fd1965667f62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-59260868-172.17.0.4-1595582973812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34457,DS-e13aedf9-d206-46b4-8a08-11fa0e29e64f,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-adc937d4-44ef-42fb-8100-ce06dd38a93e,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-82f2a668-d4a2-4512-b2a9-ee3d285a1e84,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-87d2a308-a78c-4426-a64a-76cb09e5ed5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-55790111-074b-4cbe-acfe-bc0e84071105,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-5b659d6c-dd2f-478a-bb30-29e78fc53e22,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-6e555731-90ab-4ef1-a0f2-3195a5373086,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-408a1457-5fb9-4895-bff7-8290cd1e7f2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-59260868-172.17.0.4-1595582973812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34457,DS-e13aedf9-d206-46b4-8a08-11fa0e29e64f,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-adc937d4-44ef-42fb-8100-ce06dd38a93e,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-82f2a668-d4a2-4512-b2a9-ee3d285a1e84,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-87d2a308-a78c-4426-a64a-76cb09e5ed5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-55790111-074b-4cbe-acfe-bc0e84071105,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-5b659d6c-dd2f-478a-bb30-29e78fc53e22,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-6e555731-90ab-4ef1-a0f2-3195a5373086,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-408a1457-5fb9-4895-bff7-8290cd1e7f2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-870866837-172.17.0.4-1595583432085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36433,DS-2434b098-0e3f-4d16-a87a-e7595349751c,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-0e6228ab-1f71-46e5-b071-1255c0edb142,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-0240311d-e467-4cc9-a079-ab021cf84972,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-c145fee6-ada6-46b1-a943-0025e21b6b51,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-90a5f05a-b1ad-4ab0-94f7-9776667a8897,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-3710f827-f0f4-46f4-b270-d981f8671b95,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-5c6cea09-deda-4bba-a4f2-a998c759ec75,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-93b44828-5067-442f-868e-b64c3abc6f4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-870866837-172.17.0.4-1595583432085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36433,DS-2434b098-0e3f-4d16-a87a-e7595349751c,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-0e6228ab-1f71-46e5-b071-1255c0edb142,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-0240311d-e467-4cc9-a079-ab021cf84972,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-c145fee6-ada6-46b1-a943-0025e21b6b51,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-90a5f05a-b1ad-4ab0-94f7-9776667a8897,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-3710f827-f0f4-46f4-b270-d981f8671b95,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-5c6cea09-deda-4bba-a4f2-a998c759ec75,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-93b44828-5067-442f-868e-b64c3abc6f4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1394329783-172.17.0.4-1595583568620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41465,DS-d4b508b5-cd8d-4734-a4fa-4671a4c9f111,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-156909e9-9a9c-4cbf-b1ca-0c789009db9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-13b55b2c-fc3b-4205-afdf-fd5a297a2fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-108f09a1-6412-4fcb-9fdf-2bf749dcc298,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-1179caae-c5c0-4292-bfec-d0f0f21ed2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-c8f04d98-c4ca-4fc7-903c-ea7fe228c47a,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-e7b98bdb-4a2c-4b4e-8a04-d83f3abe0473,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-005d7e23-c484-4959-b90b-802561d8536b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1394329783-172.17.0.4-1595583568620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41465,DS-d4b508b5-cd8d-4734-a4fa-4671a4c9f111,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-156909e9-9a9c-4cbf-b1ca-0c789009db9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-13b55b2c-fc3b-4205-afdf-fd5a297a2fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-108f09a1-6412-4fcb-9fdf-2bf749dcc298,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-1179caae-c5c0-4292-bfec-d0f0f21ed2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-c8f04d98-c4ca-4fc7-903c-ea7fe228c47a,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-e7b98bdb-4a2c-4b4e-8a04-d83f3abe0473,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-005d7e23-c484-4959-b90b-802561d8536b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-327967577-172.17.0.4-1595583886429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45859,DS-0388242e-bebd-420a-9431-77ca6d198249,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-8d1cd006-e119-4cb6-8324-816df915f8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-1667b013-9ed5-407e-a981-340f121d42b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-2ec8260a-41b1-455f-9ad5-ddcdf5b4f977,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-d2dcc9c7-6b50-4034-b833-29f595a486f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-b50fbf81-03ca-46f3-a565-f4ad48719733,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-f0939d0c-0731-4a5f-adfa-0ca2afd083d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-ef084246-249d-40e9-88df-3764986db4b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-327967577-172.17.0.4-1595583886429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45859,DS-0388242e-bebd-420a-9431-77ca6d198249,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-8d1cd006-e119-4cb6-8324-816df915f8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-1667b013-9ed5-407e-a981-340f121d42b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-2ec8260a-41b1-455f-9ad5-ddcdf5b4f977,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-d2dcc9c7-6b50-4034-b833-29f595a486f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-b50fbf81-03ca-46f3-a565-f4ad48719733,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-f0939d0c-0731-4a5f-adfa-0ca2afd083d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-ef084246-249d-40e9-88df-3764986db4b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1972442599-172.17.0.4-1595584504624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40948,DS-3fb03a5d-4804-4ca4-849a-61212abfcef7,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-b9dc8bb4-1776-430d-bf4c-550544562f37,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-6459779f-b4d9-425a-a5ee-1acd40b7991c,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-fe5e7b4e-3015-4162-be84-833a4ed89952,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-a3d326f5-e854-42d6-a221-88cf1f33d7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-004590c0-d7a4-4cf9-ade8-07b66c654a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-d47b8b63-7ef9-462b-a8b2-04bd9c25114b,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-b8d97b12-8509-40f3-a02e-2a23ed102619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1972442599-172.17.0.4-1595584504624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40948,DS-3fb03a5d-4804-4ca4-849a-61212abfcef7,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-b9dc8bb4-1776-430d-bf4c-550544562f37,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-6459779f-b4d9-425a-a5ee-1acd40b7991c,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-fe5e7b4e-3015-4162-be84-833a4ed89952,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-a3d326f5-e854-42d6-a221-88cf1f33d7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-004590c0-d7a4-4cf9-ade8-07b66c654a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-d47b8b63-7ef9-462b-a8b2-04bd9c25114b,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-b8d97b12-8509-40f3-a02e-2a23ed102619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1182911082-172.17.0.4-1595584689074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36524,DS-7f6d4b90-07e8-4d54-b8ce-d4052999f738,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-9f71ebee-48d1-4a47-a726-7d00cec47948,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-f09e6811-797f-4c3c-918e-38a09a6fb3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-51cbd0e8-11c6-4f5f-8e5d-35204c0cf9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-ea4278b6-1e37-4ec3-8ec1-94d489185e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-7aebb1ae-e8ad-4d51-ba70-1aed64e4e273,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-9acb73d2-9562-4a43-9438-d60e64980d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-53bda1f4-0652-47bb-bc36-a22e43a2db9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1182911082-172.17.0.4-1595584689074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36524,DS-7f6d4b90-07e8-4d54-b8ce-d4052999f738,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-9f71ebee-48d1-4a47-a726-7d00cec47948,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-f09e6811-797f-4c3c-918e-38a09a6fb3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-51cbd0e8-11c6-4f5f-8e5d-35204c0cf9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-ea4278b6-1e37-4ec3-8ec1-94d489185e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-7aebb1ae-e8ad-4d51-ba70-1aed64e4e273,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-9acb73d2-9562-4a43-9438-d60e64980d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-53bda1f4-0652-47bb-bc36-a22e43a2db9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325757661-172.17.0.4-1595585317296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39197,DS-37b5200e-a464-462a-8eb7-da662f96893f,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-c8a0aa71-b8e1-4f61-a98b-42944b14faf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-861639a9-598f-4c68-a420-ff85e3088ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-cd0f1db8-2a67-48f0-a813-57d14b8a4bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-0cf115a9-5f05-44ce-b17e-7779bd03b142,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-f79fe718-ec9a-4a0a-a8b8-512baca981dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-d446aca5-3fa2-4db7-898f-74d6899fee64,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-83b05b0b-e415-4d59-be12-4c57da8896ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325757661-172.17.0.4-1595585317296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39197,DS-37b5200e-a464-462a-8eb7-da662f96893f,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-c8a0aa71-b8e1-4f61-a98b-42944b14faf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-861639a9-598f-4c68-a420-ff85e3088ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-cd0f1db8-2a67-48f0-a813-57d14b8a4bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-0cf115a9-5f05-44ce-b17e-7779bd03b142,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-f79fe718-ec9a-4a0a-a8b8-512baca981dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-d446aca5-3fa2-4db7-898f-74d6899fee64,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-83b05b0b-e415-4d59-be12-4c57da8896ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-730448930-172.17.0.4-1595586257872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39757,DS-7574ecf0-0133-49a9-a990-152f213b4473,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-6d046c93-9a4e-4271-aaf3-3d001c84d21c,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-8ebfda41-05e7-4ccd-8134-5867aadcebc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-e8ca9a55-2586-4046-8afd-5f3cdb2fabc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-8fd80fb7-db50-468d-b126-7fb790f30935,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-2a113f2f-cf24-4501-827f-f2c96a6f8a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-00705512-8ccb-48ff-aa69-e6839b90fc96,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-70138eb4-83e5-4694-b98b-9bb254483550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-730448930-172.17.0.4-1595586257872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39757,DS-7574ecf0-0133-49a9-a990-152f213b4473,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-6d046c93-9a4e-4271-aaf3-3d001c84d21c,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-8ebfda41-05e7-4ccd-8134-5867aadcebc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-e8ca9a55-2586-4046-8afd-5f3cdb2fabc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-8fd80fb7-db50-468d-b126-7fb790f30935,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-2a113f2f-cf24-4501-827f-f2c96a6f8a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-00705512-8ccb-48ff-aa69-e6839b90fc96,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-70138eb4-83e5-4694-b98b-9bb254483550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1160962618-172.17.0.4-1595586568494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33105,DS-539d26d5-73cb-42a8-85c7-45e53c0e2db6,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-c3991007-aff9-4a68-a339-ecdf92b42e13,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-8170f126-2f95-40b9-9eef-7c0613f8863f,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-176c45e9-806a-4e8b-91ab-f812d7696aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-c8be345a-8cef-4af0-abc3-e957c008b357,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-3bce87c6-df2d-467e-8745-fe6d8cea8833,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-ed5a2841-d897-42fe-a724-ef1110b3fd02,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-77e2e636-9682-43d1-9c30-ffdea2372740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1160962618-172.17.0.4-1595586568494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33105,DS-539d26d5-73cb-42a8-85c7-45e53c0e2db6,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-c3991007-aff9-4a68-a339-ecdf92b42e13,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-8170f126-2f95-40b9-9eef-7c0613f8863f,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-176c45e9-806a-4e8b-91ab-f812d7696aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-c8be345a-8cef-4af0-abc3-e957c008b357,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-3bce87c6-df2d-467e-8745-fe6d8cea8833,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-ed5a2841-d897-42fe-a724-ef1110b3fd02,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-77e2e636-9682-43d1-9c30-ffdea2372740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1185886021-172.17.0.4-1595586973068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46423,DS-7609d1d0-b323-4d6d-834a-27c396e37335,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-d0e5681e-e70d-44c0-b5d5-13e8c998a262,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-ade285ce-b32f-433b-b18e-152a3da6ad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-2cd5396d-1c8b-48c5-a544-abeb949514fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-ece9335e-a78d-46fb-bdf1-81b3b839b174,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-606139bc-f2f5-4975-b665-4ce84263ad23,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-c64e2db7-8df9-4da8-8299-6815fbfe9722,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-903c545a-f952-46e4-8e3a-fc7624cc9ee6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1185886021-172.17.0.4-1595586973068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46423,DS-7609d1d0-b323-4d6d-834a-27c396e37335,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-d0e5681e-e70d-44c0-b5d5-13e8c998a262,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-ade285ce-b32f-433b-b18e-152a3da6ad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-2cd5396d-1c8b-48c5-a544-abeb949514fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-ece9335e-a78d-46fb-bdf1-81b3b839b174,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-606139bc-f2f5-4975-b665-4ce84263ad23,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-c64e2db7-8df9-4da8-8299-6815fbfe9722,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-903c545a-f952-46e4-8e3a-fc7624cc9ee6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-229593024-172.17.0.4-1595587209188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41145,DS-1d92529a-7430-442c-bcde-2800eb80f8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-d06f509c-215b-4f71-9b33-1e1a7f25fe6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-52fc2485-fc04-478b-b334-31c8d34e8276,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-c26d8ae5-495a-4c7a-9f0b-560ea963ad4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-f79d174b-a430-44b8-82d7-1f90e455b7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-bce3faed-1e78-47b4-b067-d7de642b3ded,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-9878e6d7-e1e6-43c0-b1b6-90e9247df37e,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-4a73bd37-f85f-4770-a8d8-2acf84a8ddef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-229593024-172.17.0.4-1595587209188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41145,DS-1d92529a-7430-442c-bcde-2800eb80f8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-d06f509c-215b-4f71-9b33-1e1a7f25fe6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-52fc2485-fc04-478b-b334-31c8d34e8276,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-c26d8ae5-495a-4c7a-9f0b-560ea963ad4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-f79d174b-a430-44b8-82d7-1f90e455b7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-bce3faed-1e78-47b4-b067-d7de642b3ded,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-9878e6d7-e1e6-43c0-b1b6-90e9247df37e,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-4a73bd37-f85f-4770-a8d8-2acf84a8ddef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5385
