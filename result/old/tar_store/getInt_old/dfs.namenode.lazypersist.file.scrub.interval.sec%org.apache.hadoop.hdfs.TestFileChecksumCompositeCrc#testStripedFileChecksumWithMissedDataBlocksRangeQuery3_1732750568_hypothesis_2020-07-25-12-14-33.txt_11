reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-70052743-172.17.0.17-1595679983147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40384,DS-7585b086-84ba-44bf-a4bf-150144c88f84,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-fb8f5b47-b079-4d46-bea8-728a1fefd065,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-3eaca2b3-c65c-478b-ab61-ec5f888b3ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-1b30e64d-cb7f-41c8-aa8d-25fa5149dc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-bd596423-c8ce-44c0-ac1a-59892c5171a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-30ce56d7-0164-42ab-a483-751b718eca64,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-491a0c73-6b54-4bd2-ab13-836748ce2235,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-1189010d-4661-43cf-9c80-56cb90cfccdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-70052743-172.17.0.17-1595679983147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40384,DS-7585b086-84ba-44bf-a4bf-150144c88f84,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-fb8f5b47-b079-4d46-bea8-728a1fefd065,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-3eaca2b3-c65c-478b-ab61-ec5f888b3ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-1b30e64d-cb7f-41c8-aa8d-25fa5149dc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-bd596423-c8ce-44c0-ac1a-59892c5171a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-30ce56d7-0164-42ab-a483-751b718eca64,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-491a0c73-6b54-4bd2-ab13-836748ce2235,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-1189010d-4661-43cf-9c80-56cb90cfccdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031029582-172.17.0.17-1595680336184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33442,DS-91f7427b-a018-4d99-8714-201fbfa12d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-b5d47757-1ab1-43cf-8e94-734f6934cde2,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-72e2a94c-bb09-445e-875a-330f1230da74,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-791fb7c4-d34b-4afe-9112-6dd1edd88091,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-a58234c3-c905-4fde-a19e-0a31d6b8bffb,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-6afb8c8e-b1f9-452f-9d89-2265d244cf58,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-3ea9584a-8bf0-424c-946e-b6d3771925ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-b4227416-515a-46cd-9418-7cc73a3dd9b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031029582-172.17.0.17-1595680336184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33442,DS-91f7427b-a018-4d99-8714-201fbfa12d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-b5d47757-1ab1-43cf-8e94-734f6934cde2,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-72e2a94c-bb09-445e-875a-330f1230da74,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-791fb7c4-d34b-4afe-9112-6dd1edd88091,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-a58234c3-c905-4fde-a19e-0a31d6b8bffb,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-6afb8c8e-b1f9-452f-9d89-2265d244cf58,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-3ea9584a-8bf0-424c-946e-b6d3771925ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-b4227416-515a-46cd-9418-7cc73a3dd9b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99750172-172.17.0.17-1595680638285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37255,DS-0fab42c5-b8a5-4290-9864-5a587a5e314c,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-f2e62ea2-80b3-4e1e-a902-088d8aa6a5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-b624f34a-22c4-4c15-92bc-c3abe09b36bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-fb1343ef-0179-43f3-bd61-9c84366654a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-c9099936-4511-49e4-9e9a-8f267dc10574,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-39b16a8e-53db-4143-a37d-606cf08b9908,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-1d2db0c2-2b38-4df0-a1a4-3b6d3847f8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-712a1e67-58bc-4f94-9d9a-90e958cb48da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99750172-172.17.0.17-1595680638285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37255,DS-0fab42c5-b8a5-4290-9864-5a587a5e314c,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-f2e62ea2-80b3-4e1e-a902-088d8aa6a5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-b624f34a-22c4-4c15-92bc-c3abe09b36bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-fb1343ef-0179-43f3-bd61-9c84366654a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-c9099936-4511-49e4-9e9a-8f267dc10574,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-39b16a8e-53db-4143-a37d-606cf08b9908,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-1d2db0c2-2b38-4df0-a1a4-3b6d3847f8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-712a1e67-58bc-4f94-9d9a-90e958cb48da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270240588-172.17.0.17-1595680836622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45439,DS-02d7808c-16c9-4c5d-8c3b-fc6bc484cb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-0c0b6aec-37d3-43c9-97dc-44f952c63adb,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-20cfe440-7e2b-47b5-9bb2-2100bcd21566,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-c9a20a45-3e53-4df4-bbcd-3d3a97db1313,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-ca8f9dbc-377e-4813-8098-c4a6ad40b448,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-8e152692-751a-4fe6-8e0e-43ec877b961f,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-825c7bc6-a807-4a7e-9577-8b0c3e37f38d,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-7c80425a-ca6d-4770-970e-2b0d84af6218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270240588-172.17.0.17-1595680836622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45439,DS-02d7808c-16c9-4c5d-8c3b-fc6bc484cb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-0c0b6aec-37d3-43c9-97dc-44f952c63adb,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-20cfe440-7e2b-47b5-9bb2-2100bcd21566,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-c9a20a45-3e53-4df4-bbcd-3d3a97db1313,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-ca8f9dbc-377e-4813-8098-c4a6ad40b448,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-8e152692-751a-4fe6-8e0e-43ec877b961f,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-825c7bc6-a807-4a7e-9577-8b0c3e37f38d,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-7c80425a-ca6d-4770-970e-2b0d84af6218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047042655-172.17.0.17-1595680909309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39942,DS-432b7322-389f-4fb0-91a9-94b95e38aa7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-3c6c2d39-0b08-40c3-b597-d061bb136936,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-6b756982-e241-47df-a160-2e4fd23cb945,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-5de98e63-4cf3-4d00-ba24-33e5ef1a8796,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-d2701341-84fb-4104-a2fd-914d0de4af9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-1f447299-4bb2-4624-99a2-3e3d6b5b79e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-2a87c833-a44c-4662-b67c-070b19afcb86,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-082a64d5-229c-46cd-b2cb-c4c96d88d3a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047042655-172.17.0.17-1595680909309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39942,DS-432b7322-389f-4fb0-91a9-94b95e38aa7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-3c6c2d39-0b08-40c3-b597-d061bb136936,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-6b756982-e241-47df-a160-2e4fd23cb945,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-5de98e63-4cf3-4d00-ba24-33e5ef1a8796,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-d2701341-84fb-4104-a2fd-914d0de4af9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-1f447299-4bb2-4624-99a2-3e3d6b5b79e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-2a87c833-a44c-4662-b67c-070b19afcb86,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-082a64d5-229c-46cd-b2cb-c4c96d88d3a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-104729279-172.17.0.17-1595681053405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38940,DS-4dd3f3ae-374e-4fe4-917b-901bdae86ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-4d9c8f7e-a855-4131-a11c-7bf2c04c1c88,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-a8d23940-92a4-483f-b84c-1fa1c2af1a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-d103faa3-f92d-4869-9c19-79170445ec7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-9081e37c-b9f4-4b71-ad37-2c8d1dad161b,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-2938b2d7-9acb-41b6-bcc2-f4c5e36f672e,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-c459c7c0-fcd4-490b-875e-dd9bf3c6aa3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-4f15be87-47f5-4306-b723-c4bbb893b94d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-104729279-172.17.0.17-1595681053405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38940,DS-4dd3f3ae-374e-4fe4-917b-901bdae86ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-4d9c8f7e-a855-4131-a11c-7bf2c04c1c88,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-a8d23940-92a4-483f-b84c-1fa1c2af1a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-d103faa3-f92d-4869-9c19-79170445ec7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-9081e37c-b9f4-4b71-ad37-2c8d1dad161b,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-2938b2d7-9acb-41b6-bcc2-f4c5e36f672e,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-c459c7c0-fcd4-490b-875e-dd9bf3c6aa3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-4f15be87-47f5-4306-b723-c4bbb893b94d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1433892677-172.17.0.17-1595681124619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46218,DS-92afc58b-f9b4-4f0d-b7d4-e775b9317724,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-437594ed-a29c-4941-b0da-b8a05648b757,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-c8d3cbea-21b9-4933-928e-5a1a7fd03302,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-e4d6272f-6678-455d-abdc-e5710cc02e94,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-43b7ee0c-e85f-45dc-8f7a-e2581bd3b67f,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-93a2fac2-240c-4bf9-95cb-1caf73b2b152,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-1c1c0d78-d68a-4e96-aa1f-7e8e1200a935,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-f39015bb-96cc-4671-bb69-31d9b38a3e41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1433892677-172.17.0.17-1595681124619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46218,DS-92afc58b-f9b4-4f0d-b7d4-e775b9317724,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-437594ed-a29c-4941-b0da-b8a05648b757,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-c8d3cbea-21b9-4933-928e-5a1a7fd03302,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-e4d6272f-6678-455d-abdc-e5710cc02e94,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-43b7ee0c-e85f-45dc-8f7a-e2581bd3b67f,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-93a2fac2-240c-4bf9-95cb-1caf73b2b152,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-1c1c0d78-d68a-4e96-aa1f-7e8e1200a935,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-f39015bb-96cc-4671-bb69-31d9b38a3e41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1049524470-172.17.0.17-1595681201135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43703,DS-5e3ad593-3830-4944-b3c8-6fad154a7a14,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-4989d424-7070-4002-98c4-ae7911fb0bec,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-828e3674-54e7-49db-990e-bd883c4c0529,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-a77b6b23-2b68-420d-bb9d-d856fe0abeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-09d381fd-b188-415d-85e0-2cc419356102,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-7c5e58c1-c9a1-445c-b043-d9529af04115,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-be7f0ba0-3e7c-42ef-9381-c207762380cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-3df69255-462a-4574-9590-73646563b03f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1049524470-172.17.0.17-1595681201135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43703,DS-5e3ad593-3830-4944-b3c8-6fad154a7a14,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-4989d424-7070-4002-98c4-ae7911fb0bec,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-828e3674-54e7-49db-990e-bd883c4c0529,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-a77b6b23-2b68-420d-bb9d-d856fe0abeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-09d381fd-b188-415d-85e0-2cc419356102,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-7c5e58c1-c9a1-445c-b043-d9529af04115,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-be7f0ba0-3e7c-42ef-9381-c207762380cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-3df69255-462a-4574-9590-73646563b03f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1998977466-172.17.0.17-1595681438559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33395,DS-7398df2d-d5d5-4b48-b58a-47db5c938d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-60b40c5e-164f-4ffd-af50-1ae0d8444795,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-34b6f13f-8dd2-4166-b51d-42f59d223e56,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-dec319e1-463c-495a-921d-e72713245eac,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-845e589c-f015-473f-baa8-d96b0f544f85,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-6dbe721c-a965-4923-81a6-2c1def2fa653,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-84581299-5fc4-4db1-80a9-0b47dcc0ba96,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-9bfc68b9-0f56-4227-a421-26e9870d55bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1998977466-172.17.0.17-1595681438559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33395,DS-7398df2d-d5d5-4b48-b58a-47db5c938d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-60b40c5e-164f-4ffd-af50-1ae0d8444795,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-34b6f13f-8dd2-4166-b51d-42f59d223e56,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-dec319e1-463c-495a-921d-e72713245eac,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-845e589c-f015-473f-baa8-d96b0f544f85,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-6dbe721c-a965-4923-81a6-2c1def2fa653,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-84581299-5fc4-4db1-80a9-0b47dcc0ba96,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-9bfc68b9-0f56-4227-a421-26e9870d55bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404062234-172.17.0.17-1595681552207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38305,DS-373b42da-40fc-4b55-96d0-637d74c4da65,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-816b68dc-93de-4446-a4b9-a38fc3a57245,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-ff799af2-b9f4-4fe3-90ce-0e27048e0b20,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-639971c5-7916-43c9-8f0f-1e787e36f873,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-75fcfbe1-2e1b-4451-936f-a1970c2ee4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-f1a665c9-8b7c-4e0a-b857-77775dacad79,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-1905071b-c81b-45c4-ab42-cb46138b2624,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-df43a2df-ff1f-4f83-b831-e0eb7ed63fda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404062234-172.17.0.17-1595681552207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38305,DS-373b42da-40fc-4b55-96d0-637d74c4da65,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-816b68dc-93de-4446-a4b9-a38fc3a57245,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-ff799af2-b9f4-4fe3-90ce-0e27048e0b20,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-639971c5-7916-43c9-8f0f-1e787e36f873,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-75fcfbe1-2e1b-4451-936f-a1970c2ee4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-f1a665c9-8b7c-4e0a-b857-77775dacad79,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-1905071b-c81b-45c4-ab42-cb46138b2624,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-df43a2df-ff1f-4f83-b831-e0eb7ed63fda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603605400-172.17.0.17-1595681621990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46734,DS-2f989977-7c22-44a4-9853-c97cc9bf6bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-ada9b499-1448-4907-9e74-633a082caa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-f3e2d857-b650-403f-b8bc-8c073f4ca4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-6f75f646-bd74-4f38-8d6e-87a20eebc181,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-95dfafc0-5b42-4916-a217-02b00e218a95,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-a35d5c33-6cb0-4540-a758-88ff73e355e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-ae6b0714-3558-4e7d-bece-078354a6b54b,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-9444ee1a-d4e8-45fc-ab1b-1c087cb99e2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603605400-172.17.0.17-1595681621990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46734,DS-2f989977-7c22-44a4-9853-c97cc9bf6bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-ada9b499-1448-4907-9e74-633a082caa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-f3e2d857-b650-403f-b8bc-8c073f4ca4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-6f75f646-bd74-4f38-8d6e-87a20eebc181,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-95dfafc0-5b42-4916-a217-02b00e218a95,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-a35d5c33-6cb0-4540-a758-88ff73e355e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-ae6b0714-3558-4e7d-bece-078354a6b54b,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-9444ee1a-d4e8-45fc-ab1b-1c087cb99e2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1755364965-172.17.0.17-1595682229094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35707,DS-0479d2c5-b393-432b-8447-370e2e2aa47f,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-3f20ce49-83eb-4dcf-84e6-a3223a9cbd38,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-1ad516eb-83b0-47f7-b133-dd2123fea136,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-a54ff2ee-3779-4fb7-8031-b3b950f2d0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-4fbfb848-cec8-412f-aaad-3a7305911167,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-d1fc2e69-618e-46b6-8534-f938abb3f7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-ef976ef7-3e1b-41a3-be0a-f38ce0c9d5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-791b9431-d6dd-4f86-9257-ef0011e56f92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1755364965-172.17.0.17-1595682229094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35707,DS-0479d2c5-b393-432b-8447-370e2e2aa47f,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-3f20ce49-83eb-4dcf-84e6-a3223a9cbd38,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-1ad516eb-83b0-47f7-b133-dd2123fea136,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-a54ff2ee-3779-4fb7-8031-b3b950f2d0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-4fbfb848-cec8-412f-aaad-3a7305911167,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-d1fc2e69-618e-46b6-8534-f938abb3f7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-ef976ef7-3e1b-41a3-be0a-f38ce0c9d5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-791b9431-d6dd-4f86-9257-ef0011e56f92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500900729-172.17.0.17-1595682303236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45348,DS-4ce483a1-4835-4ea6-a856-76b90e975b42,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-a2816caa-24a1-4d6c-bc51-7212f993b65f,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-a1b1ca57-2163-45e6-b68f-8c7233461eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-8541af63-5b02-43a1-b642-cb4fc88ab0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-67a33b94-eaaa-476f-9f26-6aca6eae8649,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-e01fc847-ef6b-46ad-a13f-eaa08c7c0267,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-1972a193-d28d-4332-9e02-08a9c5e2e48c,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-aef5063f-4578-496d-a3e7-4a0fd1804519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500900729-172.17.0.17-1595682303236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45348,DS-4ce483a1-4835-4ea6-a856-76b90e975b42,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-a2816caa-24a1-4d6c-bc51-7212f993b65f,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-a1b1ca57-2163-45e6-b68f-8c7233461eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-8541af63-5b02-43a1-b642-cb4fc88ab0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-67a33b94-eaaa-476f-9f26-6aca6eae8649,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-e01fc847-ef6b-46ad-a13f-eaa08c7c0267,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-1972a193-d28d-4332-9e02-08a9c5e2e48c,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-aef5063f-4578-496d-a3e7-4a0fd1804519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062992703-172.17.0.17-1595682480829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35404,DS-c07e8c3b-b94a-4103-bd04-a3cf3d6e38d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-0fec6af4-0e6a-414b-8c35-049812dfa246,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-5f3c8bf8-40d4-4c5c-a1e1-d7c1472473e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-a58aa61a-7514-4c00-b66e-0c5c348be5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-dd529525-2928-49f3-98aa-98193a3f6657,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-c5423406-5b89-4666-85ce-b97748991e59,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-2be07631-ee62-4a39-80dc-1af4a78a2be4,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-0a1e2b77-59de-445f-9ccd-7593b9948d29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062992703-172.17.0.17-1595682480829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35404,DS-c07e8c3b-b94a-4103-bd04-a3cf3d6e38d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-0fec6af4-0e6a-414b-8c35-049812dfa246,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-5f3c8bf8-40d4-4c5c-a1e1-d7c1472473e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-a58aa61a-7514-4c00-b66e-0c5c348be5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-dd529525-2928-49f3-98aa-98193a3f6657,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-c5423406-5b89-4666-85ce-b97748991e59,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-2be07631-ee62-4a39-80dc-1af4a78a2be4,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-0a1e2b77-59de-445f-9ccd-7593b9948d29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-285475216-172.17.0.17-1595682521435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46082,DS-d543a880-e312-470b-b778-abf8a9a5afe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-7c022f9d-0592-4f07-a591-63ab8e5ee398,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-4f15fc81-8197-4ec5-b12b-1aa8a82919da,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-1c6cbe24-1715-4cc4-9080-d3d1221f5178,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-f8412d53-bc18-4aa0-a72f-efd369741b32,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-18abd727-84f9-47f1-987f-995335b467a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-d2b62af4-c107-41d2-b160-6f6741c6f6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-2efe9ec1-c18e-4b5e-b1da-c884155cbb0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-285475216-172.17.0.17-1595682521435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46082,DS-d543a880-e312-470b-b778-abf8a9a5afe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-7c022f9d-0592-4f07-a591-63ab8e5ee398,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-4f15fc81-8197-4ec5-b12b-1aa8a82919da,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-1c6cbe24-1715-4cc4-9080-d3d1221f5178,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-f8412d53-bc18-4aa0-a72f-efd369741b32,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-18abd727-84f9-47f1-987f-995335b467a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-d2b62af4-c107-41d2-b160-6f6741c6f6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-2efe9ec1-c18e-4b5e-b1da-c884155cbb0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-24573068-172.17.0.17-1595682599231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42789,DS-eb150ba5-fbaf-4ce8-9038-f6c20929d722,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-b55269bd-2b2c-4d62-ba09-dd42bf219377,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-65dd2a6f-c5fa-4d81-8493-dcf204c33029,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-5de1c2d3-e8c4-4440-a0b8-4444d8143892,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-a574fe15-e11c-4b34-b2be-26f08de1e980,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-31556370-ada3-4c80-8388-af48c2b9c67e,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-999a898b-b7f2-48ee-b98e-7d485982a0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-6f0cd269-baf7-4401-b45d-e1245cbc9d6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-24573068-172.17.0.17-1595682599231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42789,DS-eb150ba5-fbaf-4ce8-9038-f6c20929d722,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-b55269bd-2b2c-4d62-ba09-dd42bf219377,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-65dd2a6f-c5fa-4d81-8493-dcf204c33029,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-5de1c2d3-e8c4-4440-a0b8-4444d8143892,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-a574fe15-e11c-4b34-b2be-26f08de1e980,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-31556370-ada3-4c80-8388-af48c2b9c67e,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-999a898b-b7f2-48ee-b98e-7d485982a0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-6f0cd269-baf7-4401-b45d-e1245cbc9d6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012444358-172.17.0.17-1595682777544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34038,DS-4f144fe7-960a-43dc-b30f-8160b66b88d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-bbe7e7cc-fec3-4896-8a9e-1d105eb28efd,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-38d05f5e-5845-427b-9b5a-32c190cc048c,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-56f6bdfe-e3dc-4e1c-b711-78aedb95c768,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-98f68d99-d475-425a-b1d6-b91c1e7e20e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-680b6928-273b-453e-889a-385a529cebbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-f07ec293-c68f-456b-847d-1292320ba949,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-fc809f20-39c4-4c62-b2d2-1d18a0449d37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012444358-172.17.0.17-1595682777544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34038,DS-4f144fe7-960a-43dc-b30f-8160b66b88d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-bbe7e7cc-fec3-4896-8a9e-1d105eb28efd,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-38d05f5e-5845-427b-9b5a-32c190cc048c,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-56f6bdfe-e3dc-4e1c-b711-78aedb95c768,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-98f68d99-d475-425a-b1d6-b91c1e7e20e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-680b6928-273b-453e-889a-385a529cebbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-f07ec293-c68f-456b-847d-1292320ba949,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-fc809f20-39c4-4c62-b2d2-1d18a0449d37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976016415-172.17.0.17-1595683608306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46616,DS-a7b3bef6-3b63-44a8-b727-9f15260b2e01,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-f733ca56-a596-45cf-b685-b77f68af1f23,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-2ad11ebf-e266-4544-8fb2-30fb86575bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-97a56c81-c904-466d-a373-8a24ebd3aea4,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-53a4d426-0216-427b-956a-421000d2109e,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-76ad9500-aa18-4de5-8e69-06d40c9b4288,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-bf337e3c-068f-4615-a9fb-490d91dfcb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-daed4aff-b4c1-48d6-a517-a6486046ae06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976016415-172.17.0.17-1595683608306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46616,DS-a7b3bef6-3b63-44a8-b727-9f15260b2e01,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-f733ca56-a596-45cf-b685-b77f68af1f23,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-2ad11ebf-e266-4544-8fb2-30fb86575bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-97a56c81-c904-466d-a373-8a24ebd3aea4,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-53a4d426-0216-427b-956a-421000d2109e,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-76ad9500-aa18-4de5-8e69-06d40c9b4288,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-bf337e3c-068f-4615-a9fb-490d91dfcb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-daed4aff-b4c1-48d6-a517-a6486046ae06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246022567-172.17.0.17-1595683647841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33811,DS-534dd65b-0246-4c0a-9258-e1095fd15773,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-cc854d40-7f78-4b83-9f4e-d18e5d0939a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-ecdb9787-08b0-4fc8-abff-36d43afde8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-254d1e86-cfe7-407f-93b5-1a87a276fa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-f8394bc5-189e-4526-bd5d-dae9bdda5c92,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-6fa6d96f-5cc9-4c14-8111-8904d9bbc1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-3d15e7b4-1a65-428b-afa6-cc49ea84a779,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-17c75592-e8b9-4dcb-8b25-766882c2a86a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246022567-172.17.0.17-1595683647841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33811,DS-534dd65b-0246-4c0a-9258-e1095fd15773,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-cc854d40-7f78-4b83-9f4e-d18e5d0939a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-ecdb9787-08b0-4fc8-abff-36d43afde8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-254d1e86-cfe7-407f-93b5-1a87a276fa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-f8394bc5-189e-4526-bd5d-dae9bdda5c92,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-6fa6d96f-5cc9-4c14-8111-8904d9bbc1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-3d15e7b4-1a65-428b-afa6-cc49ea84a779,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-17c75592-e8b9-4dcb-8b25-766882c2a86a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903228030-172.17.0.17-1595683840802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44280,DS-445d5dc5-2d5e-4cc5-bccf-8e1814ae87cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-573757e9-06fb-48f7-8255-85cfc45714a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-598d3c68-e93d-4b0a-b815-afdd6f55dce4,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-70c57bbc-6712-43f7-8c7a-29dd4d8bfafa,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-81eddf91-6c23-4ae8-8cab-d685979a45f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-07ef96f7-c95c-4ac0-bb6b-74c22ad57568,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-49127cf5-6383-4660-b6d1-8ad38b3783f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-a806809b-0cd7-48de-b4fb-b49f4252739d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903228030-172.17.0.17-1595683840802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44280,DS-445d5dc5-2d5e-4cc5-bccf-8e1814ae87cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-573757e9-06fb-48f7-8255-85cfc45714a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-598d3c68-e93d-4b0a-b815-afdd6f55dce4,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-70c57bbc-6712-43f7-8c7a-29dd4d8bfafa,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-81eddf91-6c23-4ae8-8cab-d685979a45f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-07ef96f7-c95c-4ac0-bb6b-74c22ad57568,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-49127cf5-6383-4660-b6d1-8ad38b3783f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-a806809b-0cd7-48de-b4fb-b49f4252739d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-491507857-172.17.0.17-1595684708498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35059,DS-e5a8a58f-0964-4f0b-81a5-b90a08d79f11,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-974cb46a-2811-409a-a693-a2b5f73d8ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-ae618194-1166-4bf3-9814-59cb3db8951b,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-d0528688-8409-45e8-9ff0-c16c11d90a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-e88c30d3-3510-4e8a-b986-cf9fb4fa5f12,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-2256f566-fdd5-4900-8883-4077a8bb5f80,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-6cecaa0f-6901-4a57-95bd-c901d1cf701d,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-dfc86d8b-e2a8-49da-847d-bebb8e7ff0cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-491507857-172.17.0.17-1595684708498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35059,DS-e5a8a58f-0964-4f0b-81a5-b90a08d79f11,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-974cb46a-2811-409a-a693-a2b5f73d8ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-ae618194-1166-4bf3-9814-59cb3db8951b,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-d0528688-8409-45e8-9ff0-c16c11d90a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-e88c30d3-3510-4e8a-b986-cf9fb4fa5f12,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-2256f566-fdd5-4900-8883-4077a8bb5f80,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-6cecaa0f-6901-4a57-95bd-c901d1cf701d,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-dfc86d8b-e2a8-49da-847d-bebb8e7ff0cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5453
