reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-563465289-172.17.0.11-1595528733824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40633,DS-624bdd69-3ede-4671-b7c3-a4b0980e9f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-d0fb16b2-fd93-486f-abfb-44fd809a70fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-5517aa16-d8b7-4c92-b6a4-bcc4e94ee603,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-eae079c8-6838-4ff0-9cff-cd13ef6ab645,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-5f8ee816-ec91-4d75-a0e1-c1c34a1b6bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-10e49d0c-c5a2-48ff-8e37-448bf11fa735,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-b8798ee5-b2ed-44e3-b1c2-33cfc63fddd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-08611dd8-06d8-4687-bed9-a63d6d9b1521,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-563465289-172.17.0.11-1595528733824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40633,DS-624bdd69-3ede-4671-b7c3-a4b0980e9f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-d0fb16b2-fd93-486f-abfb-44fd809a70fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-5517aa16-d8b7-4c92-b6a4-bcc4e94ee603,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-eae079c8-6838-4ff0-9cff-cd13ef6ab645,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-5f8ee816-ec91-4d75-a0e1-c1c34a1b6bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-10e49d0c-c5a2-48ff-8e37-448bf11fa735,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-b8798ee5-b2ed-44e3-b1c2-33cfc63fddd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-08611dd8-06d8-4687-bed9-a63d6d9b1521,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-306667890-172.17.0.11-1595528858424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44285,DS-6952e321-558e-466d-8acb-11f2873c84f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-0932ef2f-e92b-45e6-a189-986847672ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-9fae38cd-130e-47f0-af8a-86d2a371a7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-83f6d041-f26d-4e9b-a9ec-a84b2b7bd597,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-e728123d-55a6-4ab8-af58-a394ca939aee,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-c298c5de-0578-45b7-8a3e-d1ce27cb1f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-7bdcad17-51a5-4ce0-aa79-3e89ed2a5135,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-6cff10ca-5053-41ea-b328-a191f05dcaef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-306667890-172.17.0.11-1595528858424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44285,DS-6952e321-558e-466d-8acb-11f2873c84f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-0932ef2f-e92b-45e6-a189-986847672ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-9fae38cd-130e-47f0-af8a-86d2a371a7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-83f6d041-f26d-4e9b-a9ec-a84b2b7bd597,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-e728123d-55a6-4ab8-af58-a394ca939aee,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-c298c5de-0578-45b7-8a3e-d1ce27cb1f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-7bdcad17-51a5-4ce0-aa79-3e89ed2a5135,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-6cff10ca-5053-41ea-b328-a191f05dcaef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1741576343-172.17.0.11-1595529047019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43621,DS-bb96248c-01ce-4b61-83f3-8647c47ad62c,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-d07d31df-91d8-411b-9b5c-f3f7040ac376,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-139491a4-1fe1-41d0-aa4d-4e353beb4a43,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-88a71648-5668-4131-8949-9cd5984fec5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-f588edf5-5910-4d31-96b7-5a5a676604b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-d238625e-bc63-4476-afca-b336a64696f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-7bc9f3d3-fc40-409b-92cb-7f153f43b48d,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-cc3c608f-0e74-450d-9be6-5a343ac187b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1741576343-172.17.0.11-1595529047019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43621,DS-bb96248c-01ce-4b61-83f3-8647c47ad62c,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-d07d31df-91d8-411b-9b5c-f3f7040ac376,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-139491a4-1fe1-41d0-aa4d-4e353beb4a43,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-88a71648-5668-4131-8949-9cd5984fec5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-f588edf5-5910-4d31-96b7-5a5a676604b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-d238625e-bc63-4476-afca-b336a64696f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-7bc9f3d3-fc40-409b-92cb-7f153f43b48d,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-cc3c608f-0e74-450d-9be6-5a343ac187b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927834056-172.17.0.11-1595529090347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36309,DS-582b2b13-030d-40cd-9333-af1be2dc2962,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-1e0da37d-df55-42c9-82b4-0a4f3fe5f09b,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-f2e5fd4b-52ef-40ed-a093-ee3e39d865ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-11bf680d-5fd8-47d5-a8eb-dea3f4db99ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-fb6f5d07-88ba-498e-b7dc-ce3fa7372c90,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-bc69d56b-6795-4d72-a532-300681da4f47,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-3b1cada6-e617-4c23-8ca4-e086e5d7ea65,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-25a28033-ae1d-466b-a7a0-846008ef5e3b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927834056-172.17.0.11-1595529090347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36309,DS-582b2b13-030d-40cd-9333-af1be2dc2962,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-1e0da37d-df55-42c9-82b4-0a4f3fe5f09b,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-f2e5fd4b-52ef-40ed-a093-ee3e39d865ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-11bf680d-5fd8-47d5-a8eb-dea3f4db99ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-fb6f5d07-88ba-498e-b7dc-ce3fa7372c90,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-bc69d56b-6795-4d72-a532-300681da4f47,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-3b1cada6-e617-4c23-8ca4-e086e5d7ea65,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-25a28033-ae1d-466b-a7a0-846008ef5e3b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086298616-172.17.0.11-1595529191144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44993,DS-f3572a50-e265-4996-801f-7ef8df2be865,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-0c55adf4-a83f-408a-a365-0ce0834f43e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-0b819317-0f49-42bc-b3b2-5f67b2014331,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-3db085fc-8fe4-42ab-b525-1e7897372980,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-8b9010a9-4646-4205-b6a9-d508d4e49d87,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-c491f64c-8828-4622-be45-b87e3c3123ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-a20c999d-9829-4e48-a207-67918b2fc469,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-94850fe5-89be-435e-90dd-4e447dc2d703,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086298616-172.17.0.11-1595529191144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44993,DS-f3572a50-e265-4996-801f-7ef8df2be865,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-0c55adf4-a83f-408a-a365-0ce0834f43e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-0b819317-0f49-42bc-b3b2-5f67b2014331,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-3db085fc-8fe4-42ab-b525-1e7897372980,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-8b9010a9-4646-4205-b6a9-d508d4e49d87,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-c491f64c-8828-4622-be45-b87e3c3123ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-a20c999d-9829-4e48-a207-67918b2fc469,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-94850fe5-89be-435e-90dd-4e447dc2d703,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432406552-172.17.0.11-1595529324810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41058,DS-4a01b4e6-ebde-49ba-9494-ddea110e3c78,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-53cfd79c-ad49-45e8-8446-573c8f500a52,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-63da073c-0f31-487c-8917-81aa9c5ba2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-4bd1d71f-47f9-481a-b253-0c29338f50d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-bd6eab22-438c-4fa2-8191-bdeef1825b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-a891f229-f306-4a2e-b4ff-c4350cb868fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-0ab66f18-c49c-45b2-b1d4-676252d733de,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-c7ab2b9d-eb01-45d5-ba37-75b1433a1362,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432406552-172.17.0.11-1595529324810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41058,DS-4a01b4e6-ebde-49ba-9494-ddea110e3c78,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-53cfd79c-ad49-45e8-8446-573c8f500a52,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-63da073c-0f31-487c-8917-81aa9c5ba2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-4bd1d71f-47f9-481a-b253-0c29338f50d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-bd6eab22-438c-4fa2-8191-bdeef1825b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-a891f229-f306-4a2e-b4ff-c4350cb868fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-0ab66f18-c49c-45b2-b1d4-676252d733de,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-c7ab2b9d-eb01-45d5-ba37-75b1433a1362,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-666608452-172.17.0.11-1595529410126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44890,DS-d3b03aa9-845d-4999-b18f-1353ac02f1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-4f47f9b0-57c0-444d-a78e-b6ed5ffdc1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-1750551d-984d-4ac9-938e-0a3d95b7c60d,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-22a9b1d6-398e-4766-ad32-96daabcb95c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-ac5a6e72-26f9-48cd-96e8-648e394bd950,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-c86b486e-b87a-4ce8-9377-68abffe85339,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-74d37151-725d-49e3-bfb8-449ee153bb38,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-fa0cc773-8f4a-48ba-b8c3-c1d8e3a371fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-666608452-172.17.0.11-1595529410126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44890,DS-d3b03aa9-845d-4999-b18f-1353ac02f1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-4f47f9b0-57c0-444d-a78e-b6ed5ffdc1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-1750551d-984d-4ac9-938e-0a3d95b7c60d,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-22a9b1d6-398e-4766-ad32-96daabcb95c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-ac5a6e72-26f9-48cd-96e8-648e394bd950,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-c86b486e-b87a-4ce8-9377-68abffe85339,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-74d37151-725d-49e3-bfb8-449ee153bb38,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-fa0cc773-8f4a-48ba-b8c3-c1d8e3a371fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182044692-172.17.0.11-1595529540637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42981,DS-120d0b36-0787-4a55-9aba-43caa3a356e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-e927b170-ba4f-4fb1-859d-a3bfeadad568,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-e67c57e2-77c2-4963-b926-69a04d33a95f,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-2e4b77d4-d071-430c-8eb9-941c51efe80c,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-e2c198f1-4301-4d4c-a634-800e446bb963,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-9339fe45-0610-4d4a-8865-02f4c2e19652,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-df8dc98d-8883-4296-9545-286029d628bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-9bf1e8b2-8488-4c35-8a3d-6254f87bd17a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182044692-172.17.0.11-1595529540637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42981,DS-120d0b36-0787-4a55-9aba-43caa3a356e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-e927b170-ba4f-4fb1-859d-a3bfeadad568,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-e67c57e2-77c2-4963-b926-69a04d33a95f,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-2e4b77d4-d071-430c-8eb9-941c51efe80c,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-e2c198f1-4301-4d4c-a634-800e446bb963,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-9339fe45-0610-4d4a-8865-02f4c2e19652,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-df8dc98d-8883-4296-9545-286029d628bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-9bf1e8b2-8488-4c35-8a3d-6254f87bd17a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1452263490-172.17.0.11-1595529677278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39164,DS-546301d4-b4f5-4b77-8b49-86c4a1a01447,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-59aec24f-adc4-42b0-b95f-e2e658cf65b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-65ad1757-3152-4b41-89fd-04a2f489c3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-57090eb8-5385-4265-a186-c641fb1aaecc,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-dcf255ba-480f-474f-bcc2-e1cb7f0c3efb,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-dd0bbcb4-07a9-4c80-ae21-b39b29e10a08,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-c06bc74d-75ce-4173-9d16-7784dc2fa813,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-dcd87ee8-0783-4f7a-8e7a-eadcffb6b651,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1452263490-172.17.0.11-1595529677278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39164,DS-546301d4-b4f5-4b77-8b49-86c4a1a01447,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-59aec24f-adc4-42b0-b95f-e2e658cf65b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-65ad1757-3152-4b41-89fd-04a2f489c3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-57090eb8-5385-4265-a186-c641fb1aaecc,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-dcf255ba-480f-474f-bcc2-e1cb7f0c3efb,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-dd0bbcb4-07a9-4c80-ae21-b39b29e10a08,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-c06bc74d-75ce-4173-9d16-7784dc2fa813,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-dcd87ee8-0783-4f7a-8e7a-eadcffb6b651,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-371972810-172.17.0.11-1595529719667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46252,DS-38be316d-1de8-4a58-9f4b-8f893078ad1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-d79f311c-65f5-4bd9-a4a8-b66bcd9e1f79,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-91b5c327-a0e1-4ee9-96d2-bb23132ba7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-8905a083-3bcf-4f69-bae2-c3cff7297b24,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-476b3cc3-8caf-47ef-ba8a-5afef47f57e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-ac646bc1-ce0e-4aef-aa68-5a92f8d7afc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-3d9723a3-44a3-4c3e-a886-ec3b6446059d,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-68efb4c5-a48c-4ecc-9227-1eba3f20cfc0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-371972810-172.17.0.11-1595529719667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46252,DS-38be316d-1de8-4a58-9f4b-8f893078ad1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-d79f311c-65f5-4bd9-a4a8-b66bcd9e1f79,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-91b5c327-a0e1-4ee9-96d2-bb23132ba7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-8905a083-3bcf-4f69-bae2-c3cff7297b24,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-476b3cc3-8caf-47ef-ba8a-5afef47f57e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-ac646bc1-ce0e-4aef-aa68-5a92f8d7afc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-3d9723a3-44a3-4c3e-a886-ec3b6446059d,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-68efb4c5-a48c-4ecc-9227-1eba3f20cfc0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294595753-172.17.0.11-1595529758303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34298,DS-1596c0d9-a94e-4fcf-a66c-3cc75a3d8dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-c5d2bd8a-7a2f-4bd2-8db7-701e29ea5b22,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-52008613-eebd-497e-8053-f7ae040db331,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-995f94b9-3ed1-4daa-b970-47f3c6b7bc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-8a64f61a-23d4-427d-a1f9-142b8341ef84,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-f87daa60-0bf8-487c-98b7-0a665f718d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-5a60f367-198b-4164-9eec-0dae0f6f0bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-ce7b602a-5408-49ec-b66f-967ffce50aa1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294595753-172.17.0.11-1595529758303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34298,DS-1596c0d9-a94e-4fcf-a66c-3cc75a3d8dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-c5d2bd8a-7a2f-4bd2-8db7-701e29ea5b22,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-52008613-eebd-497e-8053-f7ae040db331,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-995f94b9-3ed1-4daa-b970-47f3c6b7bc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-8a64f61a-23d4-427d-a1f9-142b8341ef84,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-f87daa60-0bf8-487c-98b7-0a665f718d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-5a60f367-198b-4164-9eec-0dae0f6f0bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-ce7b602a-5408-49ec-b66f-967ffce50aa1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628689055-172.17.0.11-1595530107203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39563,DS-cb691184-8edc-49f3-863b-ba0de3528f46,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-0d4945a8-9921-4e7c-a1e5-841ff11ee03f,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-346b106e-9e9b-4b98-9932-3becc6cb7b71,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-c71413ec-0f45-4200-9ad7-f266616e1afa,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-f06a0d7d-e35c-41b4-9d01-19deac6bba46,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-465d610b-0fea-42cf-b696-26a6cf0b9998,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-a19f11cc-e195-4aa9-8860-daa96b8013ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-4f1dcd5e-8792-4eb3-9388-9ff25d1cb2bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628689055-172.17.0.11-1595530107203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39563,DS-cb691184-8edc-49f3-863b-ba0de3528f46,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-0d4945a8-9921-4e7c-a1e5-841ff11ee03f,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-346b106e-9e9b-4b98-9932-3becc6cb7b71,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-c71413ec-0f45-4200-9ad7-f266616e1afa,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-f06a0d7d-e35c-41b4-9d01-19deac6bba46,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-465d610b-0fea-42cf-b696-26a6cf0b9998,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-a19f11cc-e195-4aa9-8860-daa96b8013ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-4f1dcd5e-8792-4eb3-9388-9ff25d1cb2bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1287857072-172.17.0.11-1595530153788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43603,DS-1a1b8b58-aa2a-434f-8e39-a1aa90709508,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-26f15bf8-3ea6-4b75-8fea-b9c70c03f4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-0f13457d-1613-4ab7-b79c-a49441c655f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-57cc30cd-a76b-4038-b952-3f2fa41408e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-13aac22e-8b8e-4383-a4fe-c950aef1b5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-1d36c180-a9f1-4572-8965-a26f3d40e17f,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-717ce9b4-fe54-460f-b7ce-f94f37cf4c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-1c6cef67-d887-417f-8533-7bf6916d1c3e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1287857072-172.17.0.11-1595530153788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43603,DS-1a1b8b58-aa2a-434f-8e39-a1aa90709508,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-26f15bf8-3ea6-4b75-8fea-b9c70c03f4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-0f13457d-1613-4ab7-b79c-a49441c655f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-57cc30cd-a76b-4038-b952-3f2fa41408e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-13aac22e-8b8e-4383-a4fe-c950aef1b5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-1d36c180-a9f1-4572-8965-a26f3d40e17f,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-717ce9b4-fe54-460f-b7ce-f94f37cf4c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-1c6cef67-d887-417f-8533-7bf6916d1c3e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-120469961-172.17.0.11-1595530275460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40872,DS-201b9f9b-4031-4b00-a5e2-19cca4f10a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-299a9bd9-c94c-4337-aa17-c6a21a56f2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-dc987203-c582-431a-82d1-13b8b583a26d,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-56c150ea-00ec-4555-81b1-7dae4c5307a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-ce9ec320-9365-4700-8c7f-618c4b0ccd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-dadac947-811f-44ee-a4d1-81afbc4d76c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-c70b83a0-6200-440e-a82b-36bdfe9b3e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-2775187c-5fe0-4fc2-9037-2b8180ab18c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-120469961-172.17.0.11-1595530275460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40872,DS-201b9f9b-4031-4b00-a5e2-19cca4f10a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-299a9bd9-c94c-4337-aa17-c6a21a56f2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-dc987203-c582-431a-82d1-13b8b583a26d,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-56c150ea-00ec-4555-81b1-7dae4c5307a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-ce9ec320-9365-4700-8c7f-618c4b0ccd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-dadac947-811f-44ee-a4d1-81afbc4d76c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-c70b83a0-6200-440e-a82b-36bdfe9b3e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-2775187c-5fe0-4fc2-9037-2b8180ab18c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-710030350-172.17.0.11-1595530332373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41385,DS-52d88d07-0a31-446a-affb-c30712401812,DISK], DatanodeInfoWithStorage[127.0.0.1:34692,DS-7a494937-97ac-4b66-a9f8-61122b77dfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-6f1efe26-4402-45db-9a94-543e69e8c771,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-5986328c-7f36-4538-8001-c51529ab33f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-217b3e4b-3d13-49e2-b810-1e5f251336db,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-46c4d6bb-1bcd-4448-b34f-492ae81238f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-74de6f6f-9068-4926-a8f2-f5fd8d63a39f,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-1ba2259a-3743-4d6b-b659-28bc74426ef8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-710030350-172.17.0.11-1595530332373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41385,DS-52d88d07-0a31-446a-affb-c30712401812,DISK], DatanodeInfoWithStorage[127.0.0.1:34692,DS-7a494937-97ac-4b66-a9f8-61122b77dfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-6f1efe26-4402-45db-9a94-543e69e8c771,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-5986328c-7f36-4538-8001-c51529ab33f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-217b3e4b-3d13-49e2-b810-1e5f251336db,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-46c4d6bb-1bcd-4448-b34f-492ae81238f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-74de6f6f-9068-4926-a8f2-f5fd8d63a39f,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-1ba2259a-3743-4d6b-b659-28bc74426ef8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088286420-172.17.0.11-1595530613202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41827,DS-24de798f-7e38-42e2-b289-0b1ac45dcadb,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-3ac02510-2e93-44cc-96c4-4012e5b3b0df,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-c52057fc-2e87-47cc-81d6-b230db1f5f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-c05e463f-cbe4-46e5-8d67-77f7cb4696cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-e466fe78-6a8f-46f8-bdfb-128a40916c11,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-f0bc6845-5ed0-401e-992f-6d42a96aee56,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-48cbb662-d004-4820-9626-21b3812018ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-af39ab02-79a6-478b-9e6f-21cd5f43c79d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088286420-172.17.0.11-1595530613202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41827,DS-24de798f-7e38-42e2-b289-0b1ac45dcadb,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-3ac02510-2e93-44cc-96c4-4012e5b3b0df,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-c52057fc-2e87-47cc-81d6-b230db1f5f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-c05e463f-cbe4-46e5-8d67-77f7cb4696cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-e466fe78-6a8f-46f8-bdfb-128a40916c11,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-f0bc6845-5ed0-401e-992f-6d42a96aee56,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-48cbb662-d004-4820-9626-21b3812018ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-af39ab02-79a6-478b-9e6f-21cd5f43c79d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988064314-172.17.0.11-1595530805457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40837,DS-7e029c06-0dbd-4235-8334-61ef0d469a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-3f2dee21-f454-4bd4-be65-a11beafbb0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-149c9c08-c0fa-4f1e-9bc9-28009978264e,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-64b5c4ca-68b0-4c1e-a53a-261de564ff53,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-d5da5c79-1946-458f-b414-0fbd90950414,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-d9411a37-ce75-4f1f-9795-5277c3c9be78,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-9c7386bd-2e86-413c-9115-8c5fb64b5c14,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-aaa65053-974b-4cda-8e36-ec8599e099e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988064314-172.17.0.11-1595530805457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40837,DS-7e029c06-0dbd-4235-8334-61ef0d469a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-3f2dee21-f454-4bd4-be65-a11beafbb0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-149c9c08-c0fa-4f1e-9bc9-28009978264e,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-64b5c4ca-68b0-4c1e-a53a-261de564ff53,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-d5da5c79-1946-458f-b414-0fbd90950414,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-d9411a37-ce75-4f1f-9795-5277c3c9be78,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-9c7386bd-2e86-413c-9115-8c5fb64b5c14,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-aaa65053-974b-4cda-8e36-ec8599e099e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-967713183-172.17.0.11-1595530886414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32926,DS-4f1f8fb1-1fe7-4858-ae8c-a1fcdbe7043c,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-729f5afa-96dd-4502-8006-3a110fc47ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-f8ecb5fc-356a-4029-abce-73b683644d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-cf1d9746-f85a-40a6-b228-0728d6b2b9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-7eb84cb2-4251-4f73-ae91-74e0a62c2e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-ecf8fbd1-fcf6-4ce7-8e75-5d562fdacd11,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-17c4aa5e-ed25-4ac5-bb31-7aeb17496a81,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-9cbbad8a-d27c-4536-b460-094683f7d67b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-967713183-172.17.0.11-1595530886414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32926,DS-4f1f8fb1-1fe7-4858-ae8c-a1fcdbe7043c,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-729f5afa-96dd-4502-8006-3a110fc47ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-f8ecb5fc-356a-4029-abce-73b683644d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-cf1d9746-f85a-40a6-b228-0728d6b2b9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-7eb84cb2-4251-4f73-ae91-74e0a62c2e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-ecf8fbd1-fcf6-4ce7-8e75-5d562fdacd11,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-17c4aa5e-ed25-4ac5-bb31-7aeb17496a81,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-9cbbad8a-d27c-4536-b460-094683f7d67b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-223411770-172.17.0.11-1595531194536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34250,DS-8a096d1a-2cb8-4252-b3e9-0570584a4c75,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-53068ab6-07d6-4edc-9ef0-07edc7ca4ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-5a406656-70ff-4111-9744-37633692acad,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-dfe823d1-56af-4714-abd8-29737f2d2668,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-292a2b42-51ba-4616-a4ec-b3faf23cba59,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-768ab1c5-8688-4b81-b143-a17ad0d585da,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-8ae672bb-9996-48e8-84ca-7edfaa99554b,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-185e50d5-3d2b-4a22-8172-a243fbe79825,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-223411770-172.17.0.11-1595531194536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34250,DS-8a096d1a-2cb8-4252-b3e9-0570584a4c75,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-53068ab6-07d6-4edc-9ef0-07edc7ca4ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-5a406656-70ff-4111-9744-37633692acad,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-dfe823d1-56af-4714-abd8-29737f2d2668,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-292a2b42-51ba-4616-a4ec-b3faf23cba59,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-768ab1c5-8688-4b81-b143-a17ad0d585da,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-8ae672bb-9996-48e8-84ca-7edfaa99554b,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-185e50d5-3d2b-4a22-8172-a243fbe79825,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970488827-172.17.0.11-1595531365126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40840,DS-386ae02e-3b57-4011-b532-2b5c957a118b,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-671dea00-41a1-4ce5-b7d9-0d643c276ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-dd847cc6-d1de-49b8-89a6-24fcef0f6baa,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-78bfff92-9de0-43a7-bd3c-40b3eec23efe,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-c5b61756-91f7-45c0-ae0d-160cb03b3ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-c52f54af-c476-4785-83cf-4c9d54322aef,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-a7930e6c-c22a-4655-905b-80f318246d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-c8f314d0-e187-4318-a83a-b9186450fc20,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970488827-172.17.0.11-1595531365126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40840,DS-386ae02e-3b57-4011-b532-2b5c957a118b,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-671dea00-41a1-4ce5-b7d9-0d643c276ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-dd847cc6-d1de-49b8-89a6-24fcef0f6baa,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-78bfff92-9de0-43a7-bd3c-40b3eec23efe,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-c5b61756-91f7-45c0-ae0d-160cb03b3ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-c52f54af-c476-4785-83cf-4c9d54322aef,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-a7930e6c-c22a-4655-905b-80f318246d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-c8f314d0-e187-4318-a83a-b9186450fc20,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148797407-172.17.0.11-1595531760551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35803,DS-d46047f6-6c59-42f7-8e4c-f56d706ee2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-cfcb82ab-648f-4d44-b3d9-35503498ef5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-f44fede5-2d84-4faf-920e-d7f8e366ae71,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-83aa7aaf-7f55-4868-9eef-832a89f20b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-4a4f8dc0-feaa-4ad6-886c-ee3cc0d417ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-f3634b17-0cc4-4341-8b8f-0944982f58de,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-f717303e-ae48-491b-89ad-66442936a28c,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-a76dffe6-0845-4e95-acb1-93bede30136d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148797407-172.17.0.11-1595531760551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35803,DS-d46047f6-6c59-42f7-8e4c-f56d706ee2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-cfcb82ab-648f-4d44-b3d9-35503498ef5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-f44fede5-2d84-4faf-920e-d7f8e366ae71,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-83aa7aaf-7f55-4868-9eef-832a89f20b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-4a4f8dc0-feaa-4ad6-886c-ee3cc0d417ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-f3634b17-0cc4-4341-8b8f-0944982f58de,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-f717303e-ae48-491b-89ad-66442936a28c,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-a76dffe6-0845-4e95-acb1-93bede30136d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-205491670-172.17.0.11-1595532027297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44867,DS-a9339b0e-78d8-4814-9641-49ec19f257fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-1191efe0-10ad-49c1-92a0-1be2f10b058e,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-fdc09af9-790b-422c-8d06-17001e001992,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-fc0b824e-46b7-422f-aafe-0773ad05ed7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-f386b77f-a45a-4ada-a65b-7fbcbf4359f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-b4ef82b4-7a61-4a88-9dee-a4cc1018b6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-69486bb9-9e82-4c6d-8498-c91e6189eca9,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-4006992c-0c1a-41e5-98c4-13dc45eab6c8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-205491670-172.17.0.11-1595532027297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44867,DS-a9339b0e-78d8-4814-9641-49ec19f257fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-1191efe0-10ad-49c1-92a0-1be2f10b058e,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-fdc09af9-790b-422c-8d06-17001e001992,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-fc0b824e-46b7-422f-aafe-0773ad05ed7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-f386b77f-a45a-4ada-a65b-7fbcbf4359f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-b4ef82b4-7a61-4a88-9dee-a4cc1018b6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-69486bb9-9e82-4c6d-8498-c91e6189eca9,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-4006992c-0c1a-41e5-98c4-13dc45eab6c8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365494610-172.17.0.11-1595532380961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35641,DS-b8c23d95-9122-4438-b704-e12a5333ea7a,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-3f04c4f8-d9ab-41d2-b766-1a142ce74d07,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-e5482076-8403-4839-bee6-8d5b17dc1f63,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-771fab2b-f530-4b1f-a6e2-96f44423e018,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-3bda56c0-fced-4368-b5de-63773e620452,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-ace0ab9c-479c-477d-893f-8ff9b38f5833,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-8afb3b5c-76d5-43a6-be24-527702e6a3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-295eae01-b140-4f9b-9a35-6fb68a7ac0ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365494610-172.17.0.11-1595532380961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35641,DS-b8c23d95-9122-4438-b704-e12a5333ea7a,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-3f04c4f8-d9ab-41d2-b766-1a142ce74d07,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-e5482076-8403-4839-bee6-8d5b17dc1f63,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-771fab2b-f530-4b1f-a6e2-96f44423e018,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-3bda56c0-fced-4368-b5de-63773e620452,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-ace0ab9c-479c-477d-893f-8ff9b38f5833,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-8afb3b5c-76d5-43a6-be24-527702e6a3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-295eae01-b140-4f9b-9a35-6fb68a7ac0ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-693160663-172.17.0.11-1595532744175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41893,DS-7f8739c8-54e3-4195-95c7-ba4b8c6437e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-3406573b-53b9-4b77-b401-b83f60dc7d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-b9e1ca62-9abd-4dda-a9f0-4fc88d4a4284,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-a065bb7e-a373-48a8-a558-1a46dae2a803,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-5e844ad4-085f-41d0-9a62-920f76682b32,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-fd727bc4-d74f-4c80-bac7-13904d81a1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-5e33c9bd-ca3d-41ec-b736-e71d76fc856e,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-c029d57d-cc5c-4e71-8213-8289f9630414,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-693160663-172.17.0.11-1595532744175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41893,DS-7f8739c8-54e3-4195-95c7-ba4b8c6437e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-3406573b-53b9-4b77-b401-b83f60dc7d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-b9e1ca62-9abd-4dda-a9f0-4fc88d4a4284,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-a065bb7e-a373-48a8-a558-1a46dae2a803,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-5e844ad4-085f-41d0-9a62-920f76682b32,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-fd727bc4-d74f-4c80-bac7-13904d81a1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-5e33c9bd-ca3d-41ec-b736-e71d76fc856e,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-c029d57d-cc5c-4e71-8213-8289f9630414,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1898592911-172.17.0.11-1595532872481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46243,DS-2c4af286-c4f7-42c6-8afc-111cb6cc4a11,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-549dac3f-bbc9-401d-87d0-c4b081aca344,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-f8fcb3e2-0f91-4c6e-bd85-1f8ce25dab72,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-8e44ead0-4bf2-4a9e-9715-2600fbf52e49,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-240a753f-6ea9-429b-a140-588a5866a34e,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-35b667e4-2ef5-4167-8b53-e26e63ba348e,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-cedd9e42-edc9-4f48-ba84-287397fd907c,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-a0a47c9b-8511-4d8d-a0fc-b41780a81080,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1898592911-172.17.0.11-1595532872481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46243,DS-2c4af286-c4f7-42c6-8afc-111cb6cc4a11,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-549dac3f-bbc9-401d-87d0-c4b081aca344,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-f8fcb3e2-0f91-4c6e-bd85-1f8ce25dab72,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-8e44ead0-4bf2-4a9e-9715-2600fbf52e49,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-240a753f-6ea9-429b-a140-588a5866a34e,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-35b667e4-2ef5-4167-8b53-e26e63ba348e,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-cedd9e42-edc9-4f48-ba84-287397fd907c,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-a0a47c9b-8511-4d8d-a0fc-b41780a81080,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058421731-172.17.0.11-1595532914376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41828,DS-a846fcbb-b0b3-46a5-893f-2a5d970bb6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-a015e353-14b0-4115-884a-16a408baf116,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-34bddadf-9cbd-4997-b8d2-026863a00df0,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-a3c2df31-9959-45e2-b7f5-cabe9e2b7a58,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-7e869493-999d-47d0-a033-ef5a1a17f22c,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-ab544428-c73f-48f7-8a11-82c57f648d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-eed381f2-7c51-4720-9129-24b1d5b46fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-c07d796f-9e5d-49da-8244-07a8c1d88b02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058421731-172.17.0.11-1595532914376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41828,DS-a846fcbb-b0b3-46a5-893f-2a5d970bb6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-a015e353-14b0-4115-884a-16a408baf116,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-34bddadf-9cbd-4997-b8d2-026863a00df0,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-a3c2df31-9959-45e2-b7f5-cabe9e2b7a58,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-7e869493-999d-47d0-a033-ef5a1a17f22c,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-ab544428-c73f-48f7-8a11-82c57f648d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-eed381f2-7c51-4720-9129-24b1d5b46fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-c07d796f-9e5d-49da-8244-07a8c1d88b02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-644747608-172.17.0.11-1595532951936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46691,DS-3fcad592-d165-4895-8889-ed6695d17cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-f9cc015f-a4bd-4162-b55f-7a2ef368eaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-d1baffc5-1806-4db6-83a3-11f4151b08dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-18284e6b-a8da-45b7-af45-9c918250186c,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-7d1a19de-2b34-45fe-8511-0040032a818d,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-ada49dea-a570-4b08-8f5a-8a3cc53d347a,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-238e825e-188f-4823-848f-ffebcdb611ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-a4dcdff1-333d-48b5-80b2-5f09d1a34fc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-644747608-172.17.0.11-1595532951936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46691,DS-3fcad592-d165-4895-8889-ed6695d17cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-f9cc015f-a4bd-4162-b55f-7a2ef368eaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-d1baffc5-1806-4db6-83a3-11f4151b08dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-18284e6b-a8da-45b7-af45-9c918250186c,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-7d1a19de-2b34-45fe-8511-0040032a818d,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-ada49dea-a570-4b08-8f5a-8a3cc53d347a,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-238e825e-188f-4823-848f-ffebcdb611ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-a4dcdff1-333d-48b5-80b2-5f09d1a34fc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416839645-172.17.0.11-1595533083294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36558,DS-f6720fb0-a73a-4afe-bdfb-ebcf99390bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-aa9e0c33-489e-4a29-8e4b-93464eca5602,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-1e737e88-0243-4475-b82c-78dfdb9c5e43,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-13da43d6-40ec-4cbd-9823-ede06d5d986c,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-54c5fc27-a778-4ff7-9f01-daf31bcaa1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-69bc8d9b-637c-4f14-b90d-54e6c7ed6238,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-b997e131-179a-4f92-a20c-08787578097c,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-56eca92d-2f94-4eac-a624-88ae03713f20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416839645-172.17.0.11-1595533083294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36558,DS-f6720fb0-a73a-4afe-bdfb-ebcf99390bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-aa9e0c33-489e-4a29-8e4b-93464eca5602,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-1e737e88-0243-4475-b82c-78dfdb9c5e43,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-13da43d6-40ec-4cbd-9823-ede06d5d986c,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-54c5fc27-a778-4ff7-9f01-daf31bcaa1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-69bc8d9b-637c-4f14-b90d-54e6c7ed6238,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-b997e131-179a-4f92-a20c-08787578097c,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-56eca92d-2f94-4eac-a624-88ae03713f20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-415866331-172.17.0.11-1595533116306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37407,DS-22ee8a36-1ae1-4ac3-8239-30410355440d,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-c3d168ec-822c-4a62-89cc-943b21baecbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-a933c92c-734f-4bec-ac6c-4da7013d6769,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-e442e3a4-d3dc-44b3-a03c-239bd1de220d,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-08f8e8fd-1cd2-4a51-908c-5ed7e8daa6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-fe0712d2-5027-40b0-a30c-40a5f31e23fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-f82cd16f-60d1-418f-a22d-eac5adefbfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-cd5853a2-01a3-474b-8bc1-45c7867f8aa1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-415866331-172.17.0.11-1595533116306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37407,DS-22ee8a36-1ae1-4ac3-8239-30410355440d,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-c3d168ec-822c-4a62-89cc-943b21baecbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-a933c92c-734f-4bec-ac6c-4da7013d6769,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-e442e3a4-d3dc-44b3-a03c-239bd1de220d,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-08f8e8fd-1cd2-4a51-908c-5ed7e8daa6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-fe0712d2-5027-40b0-a30c-40a5f31e23fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-f82cd16f-60d1-418f-a22d-eac5adefbfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-cd5853a2-01a3-474b-8bc1-45c7867f8aa1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885690218-172.17.0.11-1595533195031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37494,DS-cd8faa28-ebc9-45ac-b68e-7116d2d118a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-cb3acd5e-4c78-45a8-a800-103e887ddc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-32ab8356-1423-4616-81c3-5001d64b42bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-17079cb8-e8c3-4af3-9942-92949e330f87,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-b125969b-c3cd-41ae-94e5-923f626aecb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-d1776619-07da-48ed-8043-733c5715ef1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-d999e09c-8287-43a3-8a8f-306c7e3c80f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-20bf2106-8ef2-4782-898b-1df6b371a005,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885690218-172.17.0.11-1595533195031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37494,DS-cd8faa28-ebc9-45ac-b68e-7116d2d118a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-cb3acd5e-4c78-45a8-a800-103e887ddc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-32ab8356-1423-4616-81c3-5001d64b42bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-17079cb8-e8c3-4af3-9942-92949e330f87,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-b125969b-c3cd-41ae-94e5-923f626aecb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-d1776619-07da-48ed-8043-733c5715ef1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-d999e09c-8287-43a3-8a8f-306c7e3c80f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-20bf2106-8ef2-4782-898b-1df6b371a005,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910564796-172.17.0.11-1595533377962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43255,DS-47f87501-3c5b-403c-88c3-075ea0e105d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-d70771c1-097d-49d2-9be3-4a458ce36986,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-c23ae847-a4cb-4664-893a-f3d68c6404b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-330ed25b-9a95-4e4f-9ae8-535fbe778a04,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-cfb012b2-8b88-4a21-bb5f-e8bdef28e9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-5c209a1d-c63a-420d-9c4e-39ed0a813049,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-b3029dd2-5a0d-462d-b71e-90a2f0e65983,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-b4bcc11b-1117-4981-8147-e0122777a321,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910564796-172.17.0.11-1595533377962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43255,DS-47f87501-3c5b-403c-88c3-075ea0e105d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-d70771c1-097d-49d2-9be3-4a458ce36986,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-c23ae847-a4cb-4664-893a-f3d68c6404b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-330ed25b-9a95-4e4f-9ae8-535fbe778a04,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-cfb012b2-8b88-4a21-bb5f-e8bdef28e9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-5c209a1d-c63a-420d-9c4e-39ed0a813049,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-b3029dd2-5a0d-462d-b71e-90a2f0e65983,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-b4bcc11b-1117-4981-8147-e0122777a321,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789808976-172.17.0.11-1595533425565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34777,DS-f08bcdd4-7142-475c-86c9-af813ef0c747,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-7a882653-ddd3-4eb6-bcc1-2d50f848a9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-7fbcf0be-04e1-4349-a3f0-00d005504d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-34845c63-6b91-4977-8f53-4b38eaa2c2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-494cf720-0a3e-42cb-be79-d4399455f193,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-6bc1bbcf-3118-4aca-b7cc-74d780e10d39,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-962b5a23-ef73-47a1-b43e-18837b9072f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-fb962b7a-8ef6-49d2-88c5-5b892c9f77fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789808976-172.17.0.11-1595533425565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34777,DS-f08bcdd4-7142-475c-86c9-af813ef0c747,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-7a882653-ddd3-4eb6-bcc1-2d50f848a9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-7fbcf0be-04e1-4349-a3f0-00d005504d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-34845c63-6b91-4977-8f53-4b38eaa2c2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-494cf720-0a3e-42cb-be79-d4399455f193,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-6bc1bbcf-3118-4aca-b7cc-74d780e10d39,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-962b5a23-ef73-47a1-b43e-18837b9072f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-fb962b7a-8ef6-49d2-88c5-5b892c9f77fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-973016010-172.17.0.11-1595533591196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37401,DS-514b73ca-bbcb-41ec-87df-f9228d03ba1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-dddb4c21-c30f-4401-b888-42c2b8db710c,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-382db18c-460d-406d-bb89-1993571e6b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-7b42e3cb-f063-4864-96bd-8157c104aba4,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-7687a0ab-4397-45cd-9d57-419a60eac751,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-621edf94-0210-4eda-9c17-91e5e788795a,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-773efa60-9a36-4e72-873a-9c364b531847,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-8832555b-8b7a-45b4-98d7-ed036869676d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-973016010-172.17.0.11-1595533591196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37401,DS-514b73ca-bbcb-41ec-87df-f9228d03ba1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-dddb4c21-c30f-4401-b888-42c2b8db710c,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-382db18c-460d-406d-bb89-1993571e6b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-7b42e3cb-f063-4864-96bd-8157c104aba4,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-7687a0ab-4397-45cd-9d57-419a60eac751,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-621edf94-0210-4eda-9c17-91e5e788795a,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-773efa60-9a36-4e72-873a-9c364b531847,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-8832555b-8b7a-45b4-98d7-ed036869676d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963621758-172.17.0.11-1595533632317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37664,DS-78ba488d-53d8-493f-b275-48d38428ad74,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-5313f82f-2c41-4978-b3bd-ae4e94de63f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-0f6c8211-066e-456e-89db-ec5ea2a0d8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-6ea75643-06ea-4eb4-bcf3-53ef8648af4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-fea87d82-fc50-46d2-9e86-4b8bd548262b,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-31c1e387-07cb-4cb8-a271-172b82c9975f,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-be9b6712-ee8b-4534-bb63-6a1df6f344f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-92c2c38a-cf85-4504-9f84-b5575ce046a3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963621758-172.17.0.11-1595533632317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37664,DS-78ba488d-53d8-493f-b275-48d38428ad74,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-5313f82f-2c41-4978-b3bd-ae4e94de63f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-0f6c8211-066e-456e-89db-ec5ea2a0d8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-6ea75643-06ea-4eb4-bcf3-53ef8648af4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-fea87d82-fc50-46d2-9e86-4b8bd548262b,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-31c1e387-07cb-4cb8-a271-172b82c9975f,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-be9b6712-ee8b-4534-bb63-6a1df6f344f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-92c2c38a-cf85-4504-9f84-b5575ce046a3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434538822-172.17.0.11-1595533675469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43407,DS-5647dec1-d747-44ef-b9f5-1a37521e0932,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-f50fb306-9c99-480f-8ac0-5e73685512fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-466b76e2-4c6a-4e32-af5a-8825bfbf7363,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-a9fcc187-4ccc-45b1-8de0-fb5318b1f9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-0acb451b-4f71-4856-b1a9-176ff896f95a,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-0f6b370e-1e2d-4a2f-b877-93011f0c55d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-939aadc7-e508-45c2-a1f8-c98c086fbc26,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-73c48f15-15c7-4420-bdf3-7e61b12a2941,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434538822-172.17.0.11-1595533675469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43407,DS-5647dec1-d747-44ef-b9f5-1a37521e0932,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-f50fb306-9c99-480f-8ac0-5e73685512fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-466b76e2-4c6a-4e32-af5a-8825bfbf7363,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-a9fcc187-4ccc-45b1-8de0-fb5318b1f9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-0acb451b-4f71-4856-b1a9-176ff896f95a,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-0f6b370e-1e2d-4a2f-b877-93011f0c55d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-939aadc7-e508-45c2-a1f8-c98c086fbc26,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-73c48f15-15c7-4420-bdf3-7e61b12a2941,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-965930293-172.17.0.11-1595533810550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42836,DS-43329d0e-cdbf-4382-88a3-dde7c199790f,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-c7ebb8f5-db73-4bc6-a7fd-5d10cebeecb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-6380f9f8-ff97-4917-ac5a-705760d23e09,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-ab5e2cdd-6679-472e-b41e-afa853e185a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-794d1881-9a89-4e6d-8d69-cba2bdc32028,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-b1e5f2b2-305b-4bd8-ba92-f65078e23956,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-d95919ff-af2a-455a-8080-4201fb676ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-95271e7e-bcf8-41d3-895f-ea638b1d0a94,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-965930293-172.17.0.11-1595533810550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42836,DS-43329d0e-cdbf-4382-88a3-dde7c199790f,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-c7ebb8f5-db73-4bc6-a7fd-5d10cebeecb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-6380f9f8-ff97-4917-ac5a-705760d23e09,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-ab5e2cdd-6679-472e-b41e-afa853e185a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-794d1881-9a89-4e6d-8d69-cba2bdc32028,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-b1e5f2b2-305b-4bd8-ba92-f65078e23956,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-d95919ff-af2a-455a-8080-4201fb676ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-95271e7e-bcf8-41d3-895f-ea638b1d0a94,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1699297086-172.17.0.11-1595533903115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43639,DS-1f0eaa59-3287-4b5c-bab7-eceef3bdc28e,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-7fa288b3-d671-44d5-bf5a-b31ed3f62ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-5dff6e8a-bb05-436c-af72-25cd860a681a,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-2d4b774e-9683-4053-945f-6a4ceb2ca3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-26270064-f210-4a2c-a16f-0dd7fac43149,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-0bc08bcc-0ed5-45c7-beee-7f0606168a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-bef8c572-84e0-4057-8f9d-aebebc8000df,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-553535bc-5c35-48b6-a268-cdbb9119ec80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1699297086-172.17.0.11-1595533903115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43639,DS-1f0eaa59-3287-4b5c-bab7-eceef3bdc28e,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-7fa288b3-d671-44d5-bf5a-b31ed3f62ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-5dff6e8a-bb05-436c-af72-25cd860a681a,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-2d4b774e-9683-4053-945f-6a4ceb2ca3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-26270064-f210-4a2c-a16f-0dd7fac43149,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-0bc08bcc-0ed5-45c7-beee-7f0606168a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-bef8c572-84e0-4057-8f9d-aebebc8000df,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-553535bc-5c35-48b6-a268-cdbb9119ec80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571714469-172.17.0.11-1595534407771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33809,DS-4b43ac2d-940b-4c53-947e-2e9a81770b73,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-1e58d7f6-4876-42ef-8588-7ee0fe27ad3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-3d5686a8-0690-4075-8294-073c74a5fcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-596c8099-ad92-4fd1-bb5c-17e9f35ff2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-2d5708c3-9aa8-4484-a4ee-976610306dea,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-d13c58ae-846f-4d86-bdee-18830cd6ca46,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-e0cc6eb2-71aa-4a2d-8a57-ee3caac35aad,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-ce5e81a4-f19c-4c91-ab19-d5628e6763cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571714469-172.17.0.11-1595534407771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33809,DS-4b43ac2d-940b-4c53-947e-2e9a81770b73,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-1e58d7f6-4876-42ef-8588-7ee0fe27ad3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-3d5686a8-0690-4075-8294-073c74a5fcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-596c8099-ad92-4fd1-bb5c-17e9f35ff2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-2d5708c3-9aa8-4484-a4ee-976610306dea,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-d13c58ae-846f-4d86-bdee-18830cd6ca46,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-e0cc6eb2-71aa-4a2d-8a57-ee3caac35aad,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-ce5e81a4-f19c-4c91-ab19-d5628e6763cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1033795340-172.17.0.11-1595534578539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43799,DS-920e972d-88a6-40f2-9f67-04ae9f692f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-0e5fc8e4-7264-4a69-99a7-95a523395967,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-bd9ad58f-6ff3-4a53-8b1e-93636e695ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-f1f00ff2-d1ca-48c1-a23e-e6427b488f29,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-4516b878-2e62-4e9d-90f5-b391678cd896,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-436817a5-edaf-4088-946a-136788970f36,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-2b361b1e-bb7c-4453-8aa1-e176ceaee4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-1d49081d-af8f-4c0a-8d81-0e5c6617041c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1033795340-172.17.0.11-1595534578539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43799,DS-920e972d-88a6-40f2-9f67-04ae9f692f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-0e5fc8e4-7264-4a69-99a7-95a523395967,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-bd9ad58f-6ff3-4a53-8b1e-93636e695ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-f1f00ff2-d1ca-48c1-a23e-e6427b488f29,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-4516b878-2e62-4e9d-90f5-b391678cd896,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-436817a5-edaf-4088-946a-136788970f36,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-2b361b1e-bb7c-4453-8aa1-e176ceaee4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-1d49081d-af8f-4c0a-8d81-0e5c6617041c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374797124-172.17.0.11-1595534713971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33275,DS-713e3e63-a549-4f95-8090-a341af45dfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-3347d475-53e1-4365-8468-317b7d8c769c,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-0d9599f6-1dbc-4f08-b2f7-dcc2797977ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-f846fcdd-584f-4b29-a1c4-6e5daed132e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-160cd4d9-f775-434d-a3f6-5c75d7e39167,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-6fa65b95-bfd9-41a0-b894-f221f8b6da39,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-85989438-c967-4790-b9f5-1f31f8d0f967,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-f2b696aa-2589-4c6e-8498-6b98ab62c270,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374797124-172.17.0.11-1595534713971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33275,DS-713e3e63-a549-4f95-8090-a341af45dfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-3347d475-53e1-4365-8468-317b7d8c769c,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-0d9599f6-1dbc-4f08-b2f7-dcc2797977ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-f846fcdd-584f-4b29-a1c4-6e5daed132e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-160cd4d9-f775-434d-a3f6-5c75d7e39167,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-6fa65b95-bfd9-41a0-b894-f221f8b6da39,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-85989438-c967-4790-b9f5-1f31f8d0f967,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-f2b696aa-2589-4c6e-8498-6b98ab62c270,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884260326-172.17.0.11-1595534894942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40188,DS-21795b2b-f744-4e88-b9b7-09bd9258b9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-03753986-646e-45b9-869b-98a79adff48a,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-432554c1-4671-46f5-b231-50ce50deccef,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-62d9e73d-cac7-4880-bbe2-95b5fe612f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-5f91e241-8668-40a1-8679-e91ac732e0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-95bd1909-970b-44b7-9596-409a26b24442,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-2aa4d6b4-7f07-4953-805a-081ef92ab59d,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-14f4e66b-4250-4fb6-b87e-3fd4f3f6f7ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884260326-172.17.0.11-1595534894942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40188,DS-21795b2b-f744-4e88-b9b7-09bd9258b9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-03753986-646e-45b9-869b-98a79adff48a,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-432554c1-4671-46f5-b231-50ce50deccef,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-62d9e73d-cac7-4880-bbe2-95b5fe612f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-5f91e241-8668-40a1-8679-e91ac732e0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-95bd1909-970b-44b7-9596-409a26b24442,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-2aa4d6b4-7f07-4953-805a-081ef92ab59d,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-14f4e66b-4250-4fb6-b87e-3fd4f3f6f7ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343053220-172.17.0.11-1595534936359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34458,DS-28969d14-42a4-4765-92af-bb85d9cd2eac,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-c3a4eedd-55cd-43c7-86fb-0ec9a10c9844,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-9683831a-7531-4abc-8b70-fb9ee2936370,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-59616555-c478-4327-ae3f-c19e2a5ca449,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-e0f83413-c318-43fd-9b1f-77d71a3c4771,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-1c0b79d2-c445-4edd-8398-34a29b0bfa48,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-9d92ff05-cc89-49c9-ae5b-797f52b7d00b,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-325e94a4-5e4e-4a06-a163-f16129954a4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343053220-172.17.0.11-1595534936359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34458,DS-28969d14-42a4-4765-92af-bb85d9cd2eac,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-c3a4eedd-55cd-43c7-86fb-0ec9a10c9844,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-9683831a-7531-4abc-8b70-fb9ee2936370,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-59616555-c478-4327-ae3f-c19e2a5ca449,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-e0f83413-c318-43fd-9b1f-77d71a3c4771,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-1c0b79d2-c445-4edd-8398-34a29b0bfa48,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-9d92ff05-cc89-49c9-ae5b-797f52b7d00b,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-325e94a4-5e4e-4a06-a163-f16129954a4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 16 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 6636
