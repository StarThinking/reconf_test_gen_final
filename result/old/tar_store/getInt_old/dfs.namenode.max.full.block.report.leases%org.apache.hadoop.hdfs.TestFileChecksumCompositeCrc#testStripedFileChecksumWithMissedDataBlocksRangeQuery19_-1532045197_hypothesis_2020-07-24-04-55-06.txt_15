reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 10
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 10
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-435215530-172.17.0.21-1595566522701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42473,DS-e783f124-74c0-4336-9b24-f68b9c6af3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-6bd5d057-8c1e-405e-8639-72d138f3d0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-90525a38-a807-4ed5-bf7e-52632e36b85c,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-0289cb3b-6558-4261-b6b6-dc414cefb006,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-2dfd25c9-6589-483d-8591-b5dcfd1e2aee,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-fc02eae2-b5eb-47df-adfe-7f2acb39e572,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-db6bec9d-6d07-4b6f-9da3-a4ec5e46abb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-c4ea6709-de32-4220-a54f-8ec8e67f7c7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-435215530-172.17.0.21-1595566522701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42473,DS-e783f124-74c0-4336-9b24-f68b9c6af3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-6bd5d057-8c1e-405e-8639-72d138f3d0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-90525a38-a807-4ed5-bf7e-52632e36b85c,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-0289cb3b-6558-4261-b6b6-dc414cefb006,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-2dfd25c9-6589-483d-8591-b5dcfd1e2aee,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-fc02eae2-b5eb-47df-adfe-7f2acb39e572,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-db6bec9d-6d07-4b6f-9da3-a4ec5e46abb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-c4ea6709-de32-4220-a54f-8ec8e67f7c7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 10
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-796246838-172.17.0.21-1595566948451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44943,DS-58408674-4574-4a91-a7ba-1726438e7169,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-141d978e-16bc-4847-b597-338876e4c56f,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-33005b28-893f-4c97-b879-f9bd08459220,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-8b5eb0bb-a2ac-4e0f-9ca5-61bf90e2e4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-6f22b473-e4bb-44fb-b66f-5ff71159f29e,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-4a903c9a-4feb-4233-ab32-a88d09e6ad4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-74b91acf-fbb6-412e-8204-5965122e2ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-b18b7747-eed8-4510-b1e4-9e5d70ef21ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-796246838-172.17.0.21-1595566948451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44943,DS-58408674-4574-4a91-a7ba-1726438e7169,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-141d978e-16bc-4847-b597-338876e4c56f,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-33005b28-893f-4c97-b879-f9bd08459220,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-8b5eb0bb-a2ac-4e0f-9ca5-61bf90e2e4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-6f22b473-e4bb-44fb-b66f-5ff71159f29e,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-4a903c9a-4feb-4233-ab32-a88d09e6ad4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-74b91acf-fbb6-412e-8204-5965122e2ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-b18b7747-eed8-4510-b1e4-9e5d70ef21ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 10
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-174259409-172.17.0.21-1595568523518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38649,DS-60b1c6a5-bd74-4c1f-a429-c3b745a829fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-473a0626-20b5-4c8b-842d-3b70b0752692,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-4aa3fda5-6a59-4f9d-90ce-720c0ce3c678,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-4ea8190f-a26d-4be0-9393-eb8c7852ccdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-72d3af27-7ae4-4c80-b6e1-ffcba4379448,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-9deb5a5f-3d6b-4971-9e8a-8c5c40670e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-b5d858d1-b99c-4463-a155-a6d244724400,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-e09b3b6f-8375-4f18-ae68-1038b6ece6ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-174259409-172.17.0.21-1595568523518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38649,DS-60b1c6a5-bd74-4c1f-a429-c3b745a829fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-473a0626-20b5-4c8b-842d-3b70b0752692,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-4aa3fda5-6a59-4f9d-90ce-720c0ce3c678,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-4ea8190f-a26d-4be0-9393-eb8c7852ccdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-72d3af27-7ae4-4c80-b6e1-ffcba4379448,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-9deb5a5f-3d6b-4971-9e8a-8c5c40670e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-b5d858d1-b99c-4463-a155-a6d244724400,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-e09b3b6f-8375-4f18-ae68-1038b6ece6ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 10
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1023895-172.17.0.21-1595569524227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44569,DS-e3963200-1616-4227-bef1-5512b2bd1af5,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-65f6d68b-a11c-4fa4-87ed-641c0826d1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-11d79d2f-a2f4-4dc2-b37b-ec3aa91a8457,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-5f98d2de-ff3d-4f77-b4af-721af3f9ee3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-6c6c2551-0713-4121-93c3-4bfec99c5a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-da5b98b4-e9f2-4b0f-92ac-d36f4879e662,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-b8be6738-3ba6-450a-9393-3e55a1a6f15d,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-e41c8058-ca0e-48f9-b559-1534ad912897,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1023895-172.17.0.21-1595569524227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44569,DS-e3963200-1616-4227-bef1-5512b2bd1af5,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-65f6d68b-a11c-4fa4-87ed-641c0826d1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-11d79d2f-a2f4-4dc2-b37b-ec3aa91a8457,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-5f98d2de-ff3d-4f77-b4af-721af3f9ee3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-6c6c2551-0713-4121-93c3-4bfec99c5a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-da5b98b4-e9f2-4b0f-92ac-d36f4879e662,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-b8be6738-3ba6-450a-9393-3e55a1a6f15d,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-e41c8058-ca0e-48f9-b559-1534ad912897,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 10
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1224748213-172.17.0.21-1595569758931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45259,DS-dabf6bca-6e9f-49b8-bc58-1ea9a8a892dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-389a771c-d081-44ca-8071-a4290de31aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-76f6e45b-3854-4d0e-ac8a-f5c68531679b,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-30ceb2cf-1a8b-41a9-9221-79a810144034,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-85727029-623b-426b-b699-b13cedeba66a,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-b5b657f6-77c3-43a8-ac5e-6a0635f4cdef,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-789a41ce-d2d1-4016-8a3f-edadfe978f84,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-6421f2f8-6da0-4b03-a1ae-cabb72195dd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1224748213-172.17.0.21-1595569758931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45259,DS-dabf6bca-6e9f-49b8-bc58-1ea9a8a892dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-389a771c-d081-44ca-8071-a4290de31aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-76f6e45b-3854-4d0e-ac8a-f5c68531679b,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-30ceb2cf-1a8b-41a9-9221-79a810144034,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-85727029-623b-426b-b699-b13cedeba66a,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-b5b657f6-77c3-43a8-ac5e-6a0635f4cdef,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-789a41ce-d2d1-4016-8a3f-edadfe978f84,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-6421f2f8-6da0-4b03-a1ae-cabb72195dd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 10
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1768064130-172.17.0.21-1595569969631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35898,DS-4a4f0424-8749-4cad-8074-0b909d556e62,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-0d9b4de0-fff9-4199-8592-d960c24861aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-2df9916d-9fd0-4870-a0cd-688da5681a30,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-3915d981-e23e-4449-b431-5b29c342cc3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-684166f5-2059-4b96-bd5f-a161a03d56af,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-3ad5ac15-01d2-4776-8698-9fb5a3dd9d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-992d4825-6927-4cbb-8bdc-c4a46774d92d,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-d9ec50a9-d4c8-44b6-a50c-2f4bf759448d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1768064130-172.17.0.21-1595569969631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35898,DS-4a4f0424-8749-4cad-8074-0b909d556e62,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-0d9b4de0-fff9-4199-8592-d960c24861aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-2df9916d-9fd0-4870-a0cd-688da5681a30,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-3915d981-e23e-4449-b431-5b29c342cc3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-684166f5-2059-4b96-bd5f-a161a03d56af,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-3ad5ac15-01d2-4776-8698-9fb5a3dd9d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-992d4825-6927-4cbb-8bdc-c4a46774d92d,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-d9ec50a9-d4c8-44b6-a50c-2f4bf759448d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 10
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1329254225-172.17.0.21-1595570048418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38863,DS-d91b479a-06b5-428a-9d3e-93445f4dbb72,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-4e236a9b-c418-40d1-9ef8-1c8b73cb4f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-0b1ab595-ed28-491e-9169-52c9a7c72753,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-71b0f4a2-bd9d-4577-9371-8dd1e055fc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-522f1556-57ae-4b26-a399-9a94c8653258,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-d1faaba7-a76e-458b-ae40-670d0d6ddcea,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-3a6e1aa7-e74b-4bdb-8fd5-4ac4f6d830af,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-4774751d-3daa-4e49-b04a-124f8222ce2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1329254225-172.17.0.21-1595570048418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38863,DS-d91b479a-06b5-428a-9d3e-93445f4dbb72,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-4e236a9b-c418-40d1-9ef8-1c8b73cb4f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-0b1ab595-ed28-491e-9169-52c9a7c72753,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-71b0f4a2-bd9d-4577-9371-8dd1e055fc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-522f1556-57ae-4b26-a399-9a94c8653258,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-d1faaba7-a76e-458b-ae40-670d0d6ddcea,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-3a6e1aa7-e74b-4bdb-8fd5-4ac4f6d830af,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-4774751d-3daa-4e49-b04a-124f8222ce2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 10
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797416370-172.17.0.21-1595571058664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38708,DS-5f80713a-bfce-4dfa-9849-10ed17dfc23a,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-ae7391f8-709f-43a4-bcba-ec84c3badbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-ad673e62-d963-499b-8d8a-6f51694afee7,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-fe639c3f-1711-4bac-ac91-351e7ce96798,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-795da7e5-08c6-4e09-b9ed-0e94a6b07a74,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-24c007e6-501a-419b-a799-1a98449820f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-1795d050-431b-4850-98d0-98c1f642c1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-ec1bee08-d87a-4c17-ba90-5d446c77f265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797416370-172.17.0.21-1595571058664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38708,DS-5f80713a-bfce-4dfa-9849-10ed17dfc23a,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-ae7391f8-709f-43a4-bcba-ec84c3badbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-ad673e62-d963-499b-8d8a-6f51694afee7,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-fe639c3f-1711-4bac-ac91-351e7ce96798,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-795da7e5-08c6-4e09-b9ed-0e94a6b07a74,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-24c007e6-501a-419b-a799-1a98449820f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-1795d050-431b-4850-98d0-98c1f642c1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-ec1bee08-d87a-4c17-ba90-5d446c77f265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 10
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-651047598-172.17.0.21-1595571126064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44790,DS-bbcdae1a-8155-434a-8fd6-083bae5fafe1,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-76dd65f3-e31f-4e09-9d61-f020d78b0a73,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-d1719f6b-67a2-497e-89ce-66d14b557640,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-389d10d2-41c5-450a-8f0d-17a2c57244fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-52bbb1f6-88fb-4607-b434-28953600383b,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-bb4f4cd9-34ab-4444-8042-868d538cd1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-53e351cb-dc1d-46cf-a2e8-348ec51ff749,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-9ca7f6af-c2cb-4727-8501-2c413a18a07b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-651047598-172.17.0.21-1595571126064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44790,DS-bbcdae1a-8155-434a-8fd6-083bae5fafe1,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-76dd65f3-e31f-4e09-9d61-f020d78b0a73,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-d1719f6b-67a2-497e-89ce-66d14b557640,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-389d10d2-41c5-450a-8f0d-17a2c57244fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-52bbb1f6-88fb-4607-b434-28953600383b,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-bb4f4cd9-34ab-4444-8042-868d538cd1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-53e351cb-dc1d-46cf-a2e8-348ec51ff749,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-9ca7f6af-c2cb-4727-8501-2c413a18a07b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 10
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839049152-172.17.0.21-1595571162266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42605,DS-0786544f-da6b-4c0c-9bec-73c14eeed600,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-1aa58a12-dd9a-4731-876d-161e74e11b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-a8782a37-a898-46aa-a48f-a4fffe8a2722,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-70fb7746-93f3-4edd-b452-280a7c191a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-cc83390e-eb3c-4a9b-8940-ebe6307f339b,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-309c5724-9b57-46b1-94ab-2483d3d0eae4,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-69d748d9-c23b-491f-8a96-e2a693a09e00,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-4c9248e4-d7f9-4c79-9540-04a2ca1699c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839049152-172.17.0.21-1595571162266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42605,DS-0786544f-da6b-4c0c-9bec-73c14eeed600,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-1aa58a12-dd9a-4731-876d-161e74e11b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-a8782a37-a898-46aa-a48f-a4fffe8a2722,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-70fb7746-93f3-4edd-b452-280a7c191a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-cc83390e-eb3c-4a9b-8940-ebe6307f339b,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-309c5724-9b57-46b1-94ab-2483d3d0eae4,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-69d748d9-c23b-491f-8a96-e2a693a09e00,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-4c9248e4-d7f9-4c79-9540-04a2ca1699c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 10
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1431792996-172.17.0.21-1595571312095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38952,DS-3fb7062b-72ce-48ef-a55d-975fc718d270,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-d6cd33b3-884e-49f3-822c-908c5748533d,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-af814ce2-bdde-40e3-8143-480845fd9318,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-98ffbae5-8a5c-436b-bac2-1d2f9788b09e,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-986f0743-a994-4c94-896d-853d35a58b55,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-a3f0a404-1931-4db2-9b4e-f578788db506,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-e1e150dc-8233-4dfb-a316-149f1ab58e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-07d9ad93-3482-4268-992f-d94200ca6bcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1431792996-172.17.0.21-1595571312095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38952,DS-3fb7062b-72ce-48ef-a55d-975fc718d270,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-d6cd33b3-884e-49f3-822c-908c5748533d,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-af814ce2-bdde-40e3-8143-480845fd9318,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-98ffbae5-8a5c-436b-bac2-1d2f9788b09e,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-986f0743-a994-4c94-896d-853d35a58b55,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-a3f0a404-1931-4db2-9b4e-f578788db506,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-e1e150dc-8233-4dfb-a316-149f1ab58e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-07d9ad93-3482-4268-992f-d94200ca6bcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 10
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1799130902-172.17.0.21-1595571384439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38541,DS-7198d473-14c4-4c04-b798-acb689b7e62e,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-918203d5-8dfa-4e44-a321-aa23b1386493,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-6398e403-e02b-4eae-b1bd-9a19c093e7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-0ecbabff-01c2-4f20-85dd-9b9638addc16,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-6883415e-f82d-4a4d-9686-7c7cc0a4307f,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-22999d9c-7f53-420e-9791-e8ddc121f64b,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-dc5826fe-d49e-4867-b9ba-e73a7d9b18d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-372e117b-6893-4c5e-8eec-e554166c2b4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1799130902-172.17.0.21-1595571384439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38541,DS-7198d473-14c4-4c04-b798-acb689b7e62e,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-918203d5-8dfa-4e44-a321-aa23b1386493,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-6398e403-e02b-4eae-b1bd-9a19c093e7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-0ecbabff-01c2-4f20-85dd-9b9638addc16,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-6883415e-f82d-4a4d-9686-7c7cc0a4307f,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-22999d9c-7f53-420e-9791-e8ddc121f64b,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-dc5826fe-d49e-4867-b9ba-e73a7d9b18d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-372e117b-6893-4c5e-8eec-e554166c2b4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 10
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1494300612-172.17.0.21-1595571527991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34336,DS-3c7139d4-4c7f-4da4-95c2-e0fc9e69dc56,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-dea96e06-31bf-4292-9aee-f60cd8220e74,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-c76063ae-1f8c-457d-93a6-26193ead7499,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-f9611cb1-4b76-438e-8aa8-fea4a986246d,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-e49741e9-e272-445f-bea4-ac65c62b3ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-3310ec1e-8ae4-4a8b-9303-65994faf094b,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-307396f0-fd3e-4310-b036-0fff45a91916,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-7bf5fd47-9f47-4b5d-8e6e-9178f054b22d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1494300612-172.17.0.21-1595571527991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34336,DS-3c7139d4-4c7f-4da4-95c2-e0fc9e69dc56,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-dea96e06-31bf-4292-9aee-f60cd8220e74,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-c76063ae-1f8c-457d-93a6-26193ead7499,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-f9611cb1-4b76-438e-8aa8-fea4a986246d,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-e49741e9-e272-445f-bea4-ac65c62b3ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-3310ec1e-8ae4-4a8b-9303-65994faf094b,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-307396f0-fd3e-4310-b036-0fff45a91916,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-7bf5fd47-9f47-4b5d-8e6e-9178f054b22d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 10
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-416813638-172.17.0.21-1595571690435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39363,DS-1f5a9582-cc2d-41c9-a0ea-1999ff3dc068,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-39c82745-1570-4b04-8175-75cd523941b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-22c19019-5b87-4956-8834-55f615e9cf91,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-5cbbf674-6268-4d06-80b1-5851acda08b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-22cc93b0-4699-4b8d-a303-3f6a0fa746bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-ac1b8c41-9342-415e-a8d8-022629e587a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-b2337965-4d0a-41c2-aba7-f602cd55a8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-768e9f7d-56b4-43f9-9c70-8c699724e254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-416813638-172.17.0.21-1595571690435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39363,DS-1f5a9582-cc2d-41c9-a0ea-1999ff3dc068,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-39c82745-1570-4b04-8175-75cd523941b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-22c19019-5b87-4956-8834-55f615e9cf91,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-5cbbf674-6268-4d06-80b1-5851acda08b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-22cc93b0-4699-4b8d-a303-3f6a0fa746bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-ac1b8c41-9342-415e-a8d8-022629e587a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-b2337965-4d0a-41c2-aba7-f602cd55a8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-768e9f7d-56b4-43f9-9c70-8c699724e254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5265
