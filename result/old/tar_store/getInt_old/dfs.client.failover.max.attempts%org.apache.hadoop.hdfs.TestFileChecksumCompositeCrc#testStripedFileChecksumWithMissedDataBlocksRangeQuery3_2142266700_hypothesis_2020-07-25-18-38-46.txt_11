reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102690728-172.17.0.4-1595702588148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35013,DS-407c2c3e-3c07-4fbe-b64d-ddc6833463a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-f22d6571-cbe4-4579-b36c-6b4cb3e33d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-5bf588c0-803d-4ac8-a2ad-43b00ccf779b,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-a97b3962-3932-407e-9f5b-4f1dfdc8e498,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-540c0396-5a2d-44f3-813f-eb8e7a2818f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-a7117293-afd3-49c4-884e-35722479a022,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-bfeda75e-d191-41df-940b-2c880fe5a647,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-dda6ddd0-f048-476f-9f48-19a50efff2d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102690728-172.17.0.4-1595702588148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35013,DS-407c2c3e-3c07-4fbe-b64d-ddc6833463a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-f22d6571-cbe4-4579-b36c-6b4cb3e33d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-5bf588c0-803d-4ac8-a2ad-43b00ccf779b,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-a97b3962-3932-407e-9f5b-4f1dfdc8e498,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-540c0396-5a2d-44f3-813f-eb8e7a2818f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-a7117293-afd3-49c4-884e-35722479a022,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-bfeda75e-d191-41df-940b-2c880fe5a647,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-dda6ddd0-f048-476f-9f48-19a50efff2d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891111815-172.17.0.4-1595702765405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41962,DS-560f835f-7acb-4dff-90f1-24177853eecc,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-151723d8-1f52-46d7-9b29-396fe9ac7489,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-96c09568-9a8d-42b9-a5dc-06d138d832d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-32fa2e81-ae71-4fb1-8195-7c0a5c0381d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-d5feb121-b1a8-4632-856c-44ec569dff77,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-09f5e8e1-e7bc-4ead-976b-d9fa18bcdbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-c231e7e0-3830-4e8f-986d-84573982bde6,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-1dcb0f2b-cae4-43ca-8bb2-5a99822648dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891111815-172.17.0.4-1595702765405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41962,DS-560f835f-7acb-4dff-90f1-24177853eecc,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-151723d8-1f52-46d7-9b29-396fe9ac7489,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-96c09568-9a8d-42b9-a5dc-06d138d832d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-32fa2e81-ae71-4fb1-8195-7c0a5c0381d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-d5feb121-b1a8-4632-856c-44ec569dff77,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-09f5e8e1-e7bc-4ead-976b-d9fa18bcdbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-c231e7e0-3830-4e8f-986d-84573982bde6,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-1dcb0f2b-cae4-43ca-8bb2-5a99822648dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714152873-172.17.0.4-1595703531838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46488,DS-bd122268-1fdc-489b-89df-0eefd2152720,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-9c75bceb-e6af-4881-af0d-1229d35d0ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-ef9aecac-8a6c-4741-8ba1-e48c5ce2f5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-7c5f0811-9b90-4bbf-97f8-8256dee22112,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-82e50db0-215a-4a04-8698-07dcd61dc581,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-7890e731-7b3a-4fc9-aa33-3f82e85bd78b,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-55b2abfa-1b62-47df-84e7-5924082c8561,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-fea70a29-d925-4dc5-b637-161d7b47d288,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714152873-172.17.0.4-1595703531838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46488,DS-bd122268-1fdc-489b-89df-0eefd2152720,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-9c75bceb-e6af-4881-af0d-1229d35d0ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-ef9aecac-8a6c-4741-8ba1-e48c5ce2f5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-7c5f0811-9b90-4bbf-97f8-8256dee22112,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-82e50db0-215a-4a04-8698-07dcd61dc581,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-7890e731-7b3a-4fc9-aa33-3f82e85bd78b,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-55b2abfa-1b62-47df-84e7-5924082c8561,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-fea70a29-d925-4dc5-b637-161d7b47d288,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803189723-172.17.0.4-1595704194365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43218,DS-3775a08f-c960-4f19-8f42-34ca42d23420,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-15d60215-6be5-4fd4-80b2-47ef028dd822,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-645f132e-7498-4cc2-a7f8-5e95a44bbdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-8aa65d54-08d6-48b8-a762-6e29491b1cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-fb25ca9a-56d0-4612-8365-a50a8a30bf47,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-ea616a67-ebf7-458e-8eaf-9fe12f494652,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-0261d4a9-2030-4508-8183-7000bf2df929,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-2bd389d8-ef67-4e37-b100-4df5558cab7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803189723-172.17.0.4-1595704194365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43218,DS-3775a08f-c960-4f19-8f42-34ca42d23420,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-15d60215-6be5-4fd4-80b2-47ef028dd822,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-645f132e-7498-4cc2-a7f8-5e95a44bbdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-8aa65d54-08d6-48b8-a762-6e29491b1cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-fb25ca9a-56d0-4612-8365-a50a8a30bf47,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-ea616a67-ebf7-458e-8eaf-9fe12f494652,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-0261d4a9-2030-4508-8183-7000bf2df929,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-2bd389d8-ef67-4e37-b100-4df5558cab7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862562472-172.17.0.4-1595704311748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40917,DS-845fd819-6aec-4beb-9434-72c668438deb,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-a7006ab8-baee-42f7-8ff5-14d130e45b14,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-725cd4c1-a682-480c-a90c-0e6f4ae2236f,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-98fccf9e-c1d8-4097-bd9e-5e0d402f3fab,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-4244265c-ca67-4ff6-ae04-67000b8a567f,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-f9f2e283-8456-4eee-9d7a-dc9a49d699e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-11fab2c6-18e9-4675-942d-a17e3d72a4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-f9b031fd-9f25-4c65-9d04-c98e459dfe2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862562472-172.17.0.4-1595704311748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40917,DS-845fd819-6aec-4beb-9434-72c668438deb,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-a7006ab8-baee-42f7-8ff5-14d130e45b14,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-725cd4c1-a682-480c-a90c-0e6f4ae2236f,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-98fccf9e-c1d8-4097-bd9e-5e0d402f3fab,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-4244265c-ca67-4ff6-ae04-67000b8a567f,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-f9f2e283-8456-4eee-9d7a-dc9a49d699e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-11fab2c6-18e9-4675-942d-a17e3d72a4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-f9b031fd-9f25-4c65-9d04-c98e459dfe2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99115793-172.17.0.4-1595704561106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36670,DS-0f08adeb-8259-4727-b343-82073a82d29e,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-7ddc6123-df63-42c7-88d6-3955fa81ce84,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-a5ff4670-27d3-437b-bf18-03dcd963aff5,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-732839eb-361b-4f15-af93-abb79b7818a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-58c5fa48-a314-4983-8004-1150558f772f,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-81da5dec-60c1-43a4-b841-c38656e3feb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-a1027574-b15e-4b6a-aa8e-c13c1a1538d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-ccd3fe5f-c5f5-40c3-be31-db112e9c9022,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99115793-172.17.0.4-1595704561106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36670,DS-0f08adeb-8259-4727-b343-82073a82d29e,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-7ddc6123-df63-42c7-88d6-3955fa81ce84,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-a5ff4670-27d3-437b-bf18-03dcd963aff5,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-732839eb-361b-4f15-af93-abb79b7818a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-58c5fa48-a314-4983-8004-1150558f772f,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-81da5dec-60c1-43a4-b841-c38656e3feb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-a1027574-b15e-4b6a-aa8e-c13c1a1538d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-ccd3fe5f-c5f5-40c3-be31-db112e9c9022,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310923015-172.17.0.4-1595705363297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34642,DS-5d339959-fd7b-4243-99f7-c291b757a068,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-69add2a3-639a-4ff5-a2ad-a4d3f58e99a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-9c831413-d3da-413c-a41a-70699c59aa2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-51e31ac9-0610-4811-a17f-91426f4b89ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-ff748bef-38e6-43ca-ae7a-c4ae1b8dc261,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-5bade276-ba61-48e8-961b-8f6bdcd0012b,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-6e88eb0b-3aef-4460-b1ee-397eef8722ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-6f5557a2-3082-4c87-8875-bc5be32c46bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310923015-172.17.0.4-1595705363297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34642,DS-5d339959-fd7b-4243-99f7-c291b757a068,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-69add2a3-639a-4ff5-a2ad-a4d3f58e99a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-9c831413-d3da-413c-a41a-70699c59aa2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-51e31ac9-0610-4811-a17f-91426f4b89ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-ff748bef-38e6-43ca-ae7a-c4ae1b8dc261,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-5bade276-ba61-48e8-961b-8f6bdcd0012b,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-6e88eb0b-3aef-4460-b1ee-397eef8722ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-6f5557a2-3082-4c87-8875-bc5be32c46bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685824599-172.17.0.4-1595706632339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46433,DS-0f9acce1-efbb-4767-870d-c2b7eb16a37a,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-1deeca94-65c1-404e-a04f-286783e7f1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-28065c81-7ce8-484e-bddc-9228025bc15a,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-3be77e69-70c0-40a5-8d8e-2c00d8409cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-5d883a71-6ed7-46e9-ab5e-914d882e0dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-a1d18f4c-2825-49b3-adb4-519f896841b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-205b6561-88ff-4827-a9ce-ecbd81fef49e,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-ba7c2596-e305-4b6f-a352-1c3ba9550944,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685824599-172.17.0.4-1595706632339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46433,DS-0f9acce1-efbb-4767-870d-c2b7eb16a37a,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-1deeca94-65c1-404e-a04f-286783e7f1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-28065c81-7ce8-484e-bddc-9228025bc15a,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-3be77e69-70c0-40a5-8d8e-2c00d8409cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-5d883a71-6ed7-46e9-ab5e-914d882e0dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-a1d18f4c-2825-49b3-adb4-519f896841b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-205b6561-88ff-4827-a9ce-ecbd81fef49e,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-ba7c2596-e305-4b6f-a352-1c3ba9550944,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899287725-172.17.0.4-1595706869799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45088,DS-bf745311-a6b4-4400-8d1c-82a1afc028b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-0e39436a-36d3-49a4-a05b-cc58df7266ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-1c9e7f21-a9a3-419f-a35c-d08a05d92294,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-c51440e3-3175-4c4b-a271-2a063d717ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-3b1afb75-fb26-4146-8608-35e3c80be0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-3515d501-9861-499d-b397-5835ac3d708e,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-07737fa3-f14e-4f9d-87c2-7a412e7a2cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-ef4aac1a-c9c9-47d5-b93b-8dc199dc1986,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899287725-172.17.0.4-1595706869799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45088,DS-bf745311-a6b4-4400-8d1c-82a1afc028b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-0e39436a-36d3-49a4-a05b-cc58df7266ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-1c9e7f21-a9a3-419f-a35c-d08a05d92294,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-c51440e3-3175-4c4b-a271-2a063d717ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-3b1afb75-fb26-4146-8608-35e3c80be0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-3515d501-9861-499d-b397-5835ac3d708e,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-07737fa3-f14e-4f9d-87c2-7a412e7a2cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-ef4aac1a-c9c9-47d5-b93b-8dc199dc1986,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: false positive !!!
Total execution time in seconds : 4568
