reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137893556-172.17.0.8-1595655399755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35270,DS-8b3ebed5-3a82-4369-ac10-45a2a234d7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-4e94b514-07da-4067-a4ad-7e7360ba9b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-53ac96a2-6bdb-4d67-9d2c-dfefdec9ef70,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-a03f8242-0b1f-45ca-8160-7c19e05f7991,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-10f0a133-3914-4954-9d04-5765c06efc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-c0d6ff4a-b81e-494a-acaa-a0ea7e876288,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-91a3058c-00c1-4fba-a8bc-c0e8683625c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-cbf670a4-d765-47cc-a3b6-a1ec420a2042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137893556-172.17.0.8-1595655399755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35270,DS-8b3ebed5-3a82-4369-ac10-45a2a234d7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-4e94b514-07da-4067-a4ad-7e7360ba9b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-53ac96a2-6bdb-4d67-9d2c-dfefdec9ef70,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-a03f8242-0b1f-45ca-8160-7c19e05f7991,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-10f0a133-3914-4954-9d04-5765c06efc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-c0d6ff4a-b81e-494a-acaa-a0ea7e876288,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-91a3058c-00c1-4fba-a8bc-c0e8683625c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-cbf670a4-d765-47cc-a3b6-a1ec420a2042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1524842819-172.17.0.8-1595655471797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46836,DS-83191bf0-d971-498d-b1e9-4bb904f71aba,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-ac1fa4d5-10ad-4c70-a563-8100cb583a81,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-337c65bf-0f87-41ef-8958-cfbc7834ff02,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-8c40a79a-5433-40b5-901f-7873c67a7371,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-f079ec65-ecdb-48d6-be7f-773cea7504f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-907dd759-7123-4455-af1d-37cf433470ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-9090e80c-ab3d-4002-9582-47f6796f8ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-be1f5e7e-7be8-4969-b71b-fb36506f6607,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1524842819-172.17.0.8-1595655471797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46836,DS-83191bf0-d971-498d-b1e9-4bb904f71aba,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-ac1fa4d5-10ad-4c70-a563-8100cb583a81,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-337c65bf-0f87-41ef-8958-cfbc7834ff02,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-8c40a79a-5433-40b5-901f-7873c67a7371,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-f079ec65-ecdb-48d6-be7f-773cea7504f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-907dd759-7123-4455-af1d-37cf433470ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-9090e80c-ab3d-4002-9582-47f6796f8ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-be1f5e7e-7be8-4969-b71b-fb36506f6607,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953167719-172.17.0.8-1595655510758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42031,DS-ab4c8c9b-0336-43e2-9506-dc40c4b4fbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-0592d1c0-221a-4a64-801d-7703a809a7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-9b0aa0af-9513-40cc-a13a-dfbafa9a09c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-e4231df0-b4cf-400e-950a-2a297637e63b,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-82acd07a-0d2e-4dfc-a188-81237b40442f,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-d1407695-21a4-461a-9bcf-511f45d112a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-f24b6a8e-ca9b-4876-9efe-1298dcbbd9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-df21281a-c918-4da1-b29c-ac587cf68039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953167719-172.17.0.8-1595655510758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42031,DS-ab4c8c9b-0336-43e2-9506-dc40c4b4fbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-0592d1c0-221a-4a64-801d-7703a809a7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-9b0aa0af-9513-40cc-a13a-dfbafa9a09c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-e4231df0-b4cf-400e-950a-2a297637e63b,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-82acd07a-0d2e-4dfc-a188-81237b40442f,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-d1407695-21a4-461a-9bcf-511f45d112a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-f24b6a8e-ca9b-4876-9efe-1298dcbbd9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-df21281a-c918-4da1-b29c-ac587cf68039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1329003553-172.17.0.8-1595656604618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40133,DS-6bff77c0-41ad-4024-8b74-8dadec6df3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-575f61b7-1939-43c2-b80a-782ebc41efb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-72732455-0862-4cae-9bbf-1b16bfaeb7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-3ba5e8fb-a99a-4419-9764-be5ad36f42c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-31504e21-2091-497f-a37f-c5abee101fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-51441af7-8f0a-44fc-b12c-7363834e333e,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-46e7c2c9-a842-4ba4-911e-817ba5c809f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-79a16aad-b55a-4d25-872e-20315bd51501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1329003553-172.17.0.8-1595656604618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40133,DS-6bff77c0-41ad-4024-8b74-8dadec6df3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-575f61b7-1939-43c2-b80a-782ebc41efb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-72732455-0862-4cae-9bbf-1b16bfaeb7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-3ba5e8fb-a99a-4419-9764-be5ad36f42c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-31504e21-2091-497f-a37f-c5abee101fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-51441af7-8f0a-44fc-b12c-7363834e333e,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-46e7c2c9-a842-4ba4-911e-817ba5c809f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-79a16aad-b55a-4d25-872e-20315bd51501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316312597-172.17.0.8-1595656729533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38253,DS-2e333a33-d020-4be2-b367-2c0ab7308dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-df55a945-190e-45b2-8596-c993477fadc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-49bf3d80-7dd6-408d-b079-81db4578b4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-01d7872e-3780-4a5a-a9d5-ef67886d62ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-d343de6d-b9ae-419b-841c-9c044f563f99,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-2c5c6e07-7aa7-4ce9-9362-9f5e0f3af568,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-4ce882e5-f31b-4ea6-a21a-15012376a51e,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-0b3f90d3-73cf-47cc-8db3-ee26f08245ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316312597-172.17.0.8-1595656729533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38253,DS-2e333a33-d020-4be2-b367-2c0ab7308dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-df55a945-190e-45b2-8596-c993477fadc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-49bf3d80-7dd6-408d-b079-81db4578b4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-01d7872e-3780-4a5a-a9d5-ef67886d62ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-d343de6d-b9ae-419b-841c-9c044f563f99,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-2c5c6e07-7aa7-4ce9-9362-9f5e0f3af568,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-4ce882e5-f31b-4ea6-a21a-15012376a51e,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-0b3f90d3-73cf-47cc-8db3-ee26f08245ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-729990949-172.17.0.8-1595656834898:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42619,DS-448c27ed-a75e-4e99-9838-a72ad0d7b1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-32bf9b54-f56f-46f2-9916-ff796d64f2df,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-4b495ae9-75c8-466f-ab69-2eb36e57515b,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-3932b5b2-f877-4fee-a14d-35650d6e266e,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-d7b99fc6-ed2b-4370-9099-74f31beded65,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-e27b7bb6-49f5-4ae6-824b-0bf80640f9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-4ce7c621-62ae-4bb0-836e-cd83814744c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-84c1960b-293b-496e-b096-ef31d188b162,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-729990949-172.17.0.8-1595656834898:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42619,DS-448c27ed-a75e-4e99-9838-a72ad0d7b1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-32bf9b54-f56f-46f2-9916-ff796d64f2df,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-4b495ae9-75c8-466f-ab69-2eb36e57515b,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-3932b5b2-f877-4fee-a14d-35650d6e266e,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-d7b99fc6-ed2b-4370-9099-74f31beded65,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-e27b7bb6-49f5-4ae6-824b-0bf80640f9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-4ce7c621-62ae-4bb0-836e-cd83814744c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-84c1960b-293b-496e-b096-ef31d188b162,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1415853896-172.17.0.8-1595657263405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41006,DS-b484e77f-dbd4-4065-968a-fa68f360f56f,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-3e3dcf0f-94a4-402e-a4f8-1d44b56fad45,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-a8633b20-65a4-4f71-b765-1436c5331d05,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-a3a3a84e-7215-4c1d-8447-b6a6fd87e8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-f4a5f163-a444-42ff-af74-6d0f4f079e25,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-b9a43074-2f19-4b4d-adc0-f10368fd2d32,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-280f7a6f-fdcf-42d5-8db7-9fca3bf5f206,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-3e468057-4599-4d3b-963c-70ba62142091,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1415853896-172.17.0.8-1595657263405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41006,DS-b484e77f-dbd4-4065-968a-fa68f360f56f,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-3e3dcf0f-94a4-402e-a4f8-1d44b56fad45,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-a8633b20-65a4-4f71-b765-1436c5331d05,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-a3a3a84e-7215-4c1d-8447-b6a6fd87e8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-f4a5f163-a444-42ff-af74-6d0f4f079e25,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-b9a43074-2f19-4b4d-adc0-f10368fd2d32,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-280f7a6f-fdcf-42d5-8db7-9fca3bf5f206,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-3e468057-4599-4d3b-963c-70ba62142091,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1563195112-172.17.0.8-1595658502200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34193,DS-037193f9-c554-410b-975d-e07177be98d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-0c068096-82a0-42cc-98d8-d2e5c8ffc87f,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-53138231-eed5-4cc6-8455-c9a1731c16d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-5d46dd47-d8dc-4367-98a2-5fddb77d22bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-dbc8dd68-ddb5-4c5b-b0d1-82cb9b8fa23c,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-fffa1217-fe80-4547-b9b8-59b5626df668,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-686ac572-a10b-4b8c-b3d4-f60659cd2a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-cf7c0828-e532-4884-886d-fc34df42c6a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1563195112-172.17.0.8-1595658502200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34193,DS-037193f9-c554-410b-975d-e07177be98d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-0c068096-82a0-42cc-98d8-d2e5c8ffc87f,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-53138231-eed5-4cc6-8455-c9a1731c16d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-5d46dd47-d8dc-4367-98a2-5fddb77d22bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-dbc8dd68-ddb5-4c5b-b0d1-82cb9b8fa23c,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-fffa1217-fe80-4547-b9b8-59b5626df668,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-686ac572-a10b-4b8c-b3d4-f60659cd2a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-cf7c0828-e532-4884-886d-fc34df42c6a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1995665861-172.17.0.8-1595658640551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32929,DS-79937655-acd8-4687-aa14-0240f772aab3,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-63c84322-e1cb-4e9c-a46f-69b95f393db7,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-9863cd31-927a-474c-946e-bedb3d5af97b,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-de71b285-e090-4d7a-aba6-2f94b0c02416,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-49699d8f-04a7-4922-9456-dbe9985c6038,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-242a426a-4f83-48f6-bfaf-e92e0bd88ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-0bcf51b8-ea26-4e57-9ee9-039bc5bad5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-ff0ef944-0329-4554-a887-d1f22a86c6eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1995665861-172.17.0.8-1595658640551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32929,DS-79937655-acd8-4687-aa14-0240f772aab3,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-63c84322-e1cb-4e9c-a46f-69b95f393db7,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-9863cd31-927a-474c-946e-bedb3d5af97b,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-de71b285-e090-4d7a-aba6-2f94b0c02416,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-49699d8f-04a7-4922-9456-dbe9985c6038,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-242a426a-4f83-48f6-bfaf-e92e0bd88ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-0bcf51b8-ea26-4e57-9ee9-039bc5bad5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-ff0ef944-0329-4554-a887-d1f22a86c6eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-662854727-172.17.0.8-1595658678315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32931,DS-3b77f356-71bf-4e32-a15b-aebacbb05bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-e9902c2f-a712-4651-aeeb-2e14b12fde4f,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-4c7f792d-421d-45ac-abda-47ad609d9c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-c8ecb216-a072-4e07-88e9-a26df4ae1418,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-8e2d801d-9673-42d9-8221-0bd52691e20d,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-a1408488-fe77-4c25-8dbe-7a2c921eaa31,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-4ccf3afe-4c2b-4dcd-94b1-f4b4cce9d040,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-5f875767-1dc2-4f22-8e06-e4c29a6bbf9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-662854727-172.17.0.8-1595658678315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32931,DS-3b77f356-71bf-4e32-a15b-aebacbb05bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-e9902c2f-a712-4651-aeeb-2e14b12fde4f,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-4c7f792d-421d-45ac-abda-47ad609d9c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-c8ecb216-a072-4e07-88e9-a26df4ae1418,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-8e2d801d-9673-42d9-8221-0bd52691e20d,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-a1408488-fe77-4c25-8dbe-7a2c921eaa31,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-4ccf3afe-4c2b-4dcd-94b1-f4b4cce9d040,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-5f875767-1dc2-4f22-8e06-e4c29a6bbf9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-319645801-172.17.0.8-1595658841943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36933,DS-6558ac65-5ac8-45c7-a431-673e1586cebb,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-55d09987-cbb2-4c6a-81c4-fb0156b26a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-a2615634-bb13-404f-8a18-57a34327dc86,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-5eee9225-b758-40a8-96b0-94142e06051f,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-16249f7e-97c5-4e02-9c87-e93c453bc6de,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-ffd32ccc-bb5d-417c-b8be-864f086aaa57,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-42019954-bf44-4a60-b9b2-e242545fa86b,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-329cb7a7-d81b-4da9-acd6-b2f9944a713b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-319645801-172.17.0.8-1595658841943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36933,DS-6558ac65-5ac8-45c7-a431-673e1586cebb,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-55d09987-cbb2-4c6a-81c4-fb0156b26a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-a2615634-bb13-404f-8a18-57a34327dc86,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-5eee9225-b758-40a8-96b0-94142e06051f,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-16249f7e-97c5-4e02-9c87-e93c453bc6de,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-ffd32ccc-bb5d-417c-b8be-864f086aaa57,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-42019954-bf44-4a60-b9b2-e242545fa86b,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-329cb7a7-d81b-4da9-acd6-b2f9944a713b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1400121672-172.17.0.8-1595659028788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37907,DS-f9d8377d-1acf-432b-9748-b788c950f2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-7fbd9cc5-1d25-4755-ada4-8b0a2e59de13,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-f666ceb6-0735-484e-b455-c915fcfd2c69,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-1533ef90-d294-42bb-9304-7991ce20673e,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-0d0308f0-092a-470a-85ec-0551cded3011,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-f3cb29d0-7e37-4bd2-bdf8-86a4a0574eac,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-3fc674c0-bbc4-49b1-ab2a-999ea9bee7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-6dba8467-dfbe-4a5d-8978-965a867defb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1400121672-172.17.0.8-1595659028788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37907,DS-f9d8377d-1acf-432b-9748-b788c950f2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-7fbd9cc5-1d25-4755-ada4-8b0a2e59de13,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-f666ceb6-0735-484e-b455-c915fcfd2c69,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-1533ef90-d294-42bb-9304-7991ce20673e,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-0d0308f0-092a-470a-85ec-0551cded3011,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-f3cb29d0-7e37-4bd2-bdf8-86a4a0574eac,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-3fc674c0-bbc4-49b1-ab2a-999ea9bee7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-6dba8467-dfbe-4a5d-8978-965a867defb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-87216617-172.17.0.8-1595659106357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43818,DS-f22f007d-493e-4cd1-813c-9b519789ecec,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-35615df0-cdf9-486e-89d0-8039ed8e0a09,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-6f1f3948-5fdd-4f38-8cc0-a869581502bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-44f2b3e1-d2a8-4765-b1f2-35aa7fba9f30,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-689016c7-5981-413a-bb51-60aef8d3b1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-7dfe5c46-7fba-4c38-bb33-b9b7b7cd5268,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-58280e8e-adb3-4877-af4c-96b7a655173e,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-671e576d-fe6d-43f3-9829-801de338ca53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-87216617-172.17.0.8-1595659106357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43818,DS-f22f007d-493e-4cd1-813c-9b519789ecec,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-35615df0-cdf9-486e-89d0-8039ed8e0a09,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-6f1f3948-5fdd-4f38-8cc0-a869581502bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-44f2b3e1-d2a8-4765-b1f2-35aa7fba9f30,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-689016c7-5981-413a-bb51-60aef8d3b1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-7dfe5c46-7fba-4c38-bb33-b9b7b7cd5268,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-58280e8e-adb3-4877-af4c-96b7a655173e,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-671e576d-fe6d-43f3-9829-801de338ca53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-259425625-172.17.0.8-1595659490551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32787,DS-dc0922cf-e464-4b8b-b976-e586e363b53d,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-56ca709f-c785-477f-9363-4e4f417e0ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-77edd340-08f1-41d3-a791-de44e05f03fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-a823ce7c-ae76-40eb-83fc-76e1036cdcaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-d39e315c-96cd-46bf-ad59-8b06a5c8eb35,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-5572c2f5-25e7-4f03-8a82-23b87b6251f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-e4a3d93f-3d74-4d47-adff-25de799e3eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-5ec4980c-9821-4032-9f27-5947d243a394,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-259425625-172.17.0.8-1595659490551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32787,DS-dc0922cf-e464-4b8b-b976-e586e363b53d,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-56ca709f-c785-477f-9363-4e4f417e0ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-77edd340-08f1-41d3-a791-de44e05f03fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-a823ce7c-ae76-40eb-83fc-76e1036cdcaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-d39e315c-96cd-46bf-ad59-8b06a5c8eb35,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-5572c2f5-25e7-4f03-8a82-23b87b6251f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-e4a3d93f-3d74-4d47-adff-25de799e3eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-5ec4980c-9821-4032-9f27-5947d243a394,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1941489837-172.17.0.8-1595660000531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42420,DS-0c0cc6fe-51b6-4c56-bd4e-739d13358eff,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-0a5f944a-0b43-46ab-a50f-8ae59bf3f217,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-817deb9e-d870-4794-aced-5bb8c6595082,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-afa6bc0e-72e0-4407-a628-d0fbf3a510a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-368fb318-bbab-4d24-99a5-0b8a7aa9f563,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-f2bceaf7-3359-4120-bc2c-2b5ef3bdd1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-e7c6ebbf-47e0-4b5d-a22a-d10fa5f61ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-acd1e9de-1a62-45fa-ad2f-33b2e5fc98fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1941489837-172.17.0.8-1595660000531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42420,DS-0c0cc6fe-51b6-4c56-bd4e-739d13358eff,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-0a5f944a-0b43-46ab-a50f-8ae59bf3f217,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-817deb9e-d870-4794-aced-5bb8c6595082,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-afa6bc0e-72e0-4407-a628-d0fbf3a510a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-368fb318-bbab-4d24-99a5-0b8a7aa9f563,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-f2bceaf7-3359-4120-bc2c-2b5ef3bdd1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-e7c6ebbf-47e0-4b5d-a22a-d10fa5f61ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-acd1e9de-1a62-45fa-ad2f-33b2e5fc98fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039899844-172.17.0.8-1595660033381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37272,DS-a3f5a0fa-61d9-44b8-8cfe-81ca78b4c4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-46109c39-ca0b-4d18-96c1-ab3aabe6d175,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-04a265a4-8fb3-46af-b7fe-6b06adf82770,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-603599ab-b60b-46b8-bf31-7e81024cb6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-1999609a-974a-4d98-9b0c-13c1db6f286f,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-52fcfafc-a05e-4162-bcdf-20a03d3ce63b,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-c3956096-dcee-4a32-9743-e0a5d4f2653e,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-ff07a5d5-565c-4b08-8382-9003ce31813c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039899844-172.17.0.8-1595660033381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37272,DS-a3f5a0fa-61d9-44b8-8cfe-81ca78b4c4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-46109c39-ca0b-4d18-96c1-ab3aabe6d175,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-04a265a4-8fb3-46af-b7fe-6b06adf82770,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-603599ab-b60b-46b8-bf31-7e81024cb6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-1999609a-974a-4d98-9b0c-13c1db6f286f,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-52fcfafc-a05e-4162-bcdf-20a03d3ce63b,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-c3956096-dcee-4a32-9743-e0a5d4f2653e,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-ff07a5d5-565c-4b08-8382-9003ce31813c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1938175850-172.17.0.8-1595660336617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33503,DS-f2b10ca1-7469-4174-8fab-779602901e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-3e159610-839c-4109-9e10-d68eae20a55d,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-9e2fde65-5d3b-44f2-95c3-82b4a3b78cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-c4b3a13a-4569-4640-b4c8-1fc2b2d6eb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-e0a64637-0d5a-4c8e-bc01-ef38b40d181c,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-ededb7fc-d2fd-47f4-8e68-8d8d994ba0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-75294d6b-0025-4621-9ca7-5a77ae3b7adc,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-03bc9561-2163-4b6d-a72c-946f55a3168e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1938175850-172.17.0.8-1595660336617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33503,DS-f2b10ca1-7469-4174-8fab-779602901e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-3e159610-839c-4109-9e10-d68eae20a55d,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-9e2fde65-5d3b-44f2-95c3-82b4a3b78cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-c4b3a13a-4569-4640-b4c8-1fc2b2d6eb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-e0a64637-0d5a-4c8e-bc01-ef38b40d181c,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-ededb7fc-d2fd-47f4-8e68-8d8d994ba0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-75294d6b-0025-4621-9ca7-5a77ae3b7adc,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-03bc9561-2163-4b6d-a72c-946f55a3168e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1090424599-172.17.0.8-1595660445482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43297,DS-3290804e-75b2-4ff9-b63b-5be78091e6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-a37874e6-2261-435a-8333-ccb591f84d31,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-fb140e7a-e888-4eb7-a749-1bb1d9874d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-586a951f-e106-4036-b5c3-633fb6025f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-70a3638b-8c13-4c8c-8b26-f95ae8c191c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-0fe88674-63cd-467d-8ba6-c696983e6d20,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-c7442654-d0ba-4d5d-a717-a589691beb81,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-576783b1-6476-4872-90d3-f0179e346f36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1090424599-172.17.0.8-1595660445482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43297,DS-3290804e-75b2-4ff9-b63b-5be78091e6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-a37874e6-2261-435a-8333-ccb591f84d31,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-fb140e7a-e888-4eb7-a749-1bb1d9874d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-586a951f-e106-4036-b5c3-633fb6025f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-70a3638b-8c13-4c8c-8b26-f95ae8c191c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-0fe88674-63cd-467d-8ba6-c696983e6d20,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-c7442654-d0ba-4d5d-a717-a589691beb81,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-576783b1-6476-4872-90d3-f0179e346f36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1265325367-172.17.0.8-1595660519636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43925,DS-1573f7cc-e187-4062-befc-8903e014f224,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-324b8991-97a5-48e7-93a7-ac848e0f5cde,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-6ec93c55-b85f-4113-9ca6-ff168932d635,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-48361f8f-7ce2-4263-b52b-de336edd1b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-32e9284a-98fb-4ca7-973f-43351277a20e,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-2cabe497-aa68-4aaf-abc4-88ba377b2e99,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-01a4736e-8650-460f-8fb6-7aaf5a1afdda,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-0ce0982b-853d-453a-ad6f-8cb9d239ef2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1265325367-172.17.0.8-1595660519636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43925,DS-1573f7cc-e187-4062-befc-8903e014f224,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-324b8991-97a5-48e7-93a7-ac848e0f5cde,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-6ec93c55-b85f-4113-9ca6-ff168932d635,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-48361f8f-7ce2-4263-b52b-de336edd1b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-32e9284a-98fb-4ca7-973f-43351277a20e,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-2cabe497-aa68-4aaf-abc4-88ba377b2e99,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-01a4736e-8650-460f-8fb6-7aaf5a1afdda,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-0ce0982b-853d-453a-ad6f-8cb9d239ef2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: might be true error
Total execution time in seconds : 5157
