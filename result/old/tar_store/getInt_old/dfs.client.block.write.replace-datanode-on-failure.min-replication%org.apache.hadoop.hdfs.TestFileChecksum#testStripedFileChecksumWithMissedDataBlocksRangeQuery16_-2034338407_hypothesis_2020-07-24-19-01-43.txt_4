reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-195492329-172.17.0.4-1595618194519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34595,DS-239c5782-8cd2-459d-ac16-2baf980eddb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-3989193a-87f0-4ab5-a803-c1001bf09784,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-e28105fa-7a54-4147-b987-05af7ecc6cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-814b4abe-7b1c-41a0-be88-334322ec4846,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-ce3546d3-b271-4edf-885a-979f696e70da,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-2b11d156-9dce-428e-84f0-b29cd33b6d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-6d9acc0c-8312-4b87-bdcc-6695d0b2977a,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-e1e138df-08de-492f-a7c1-0b6f74f41081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-195492329-172.17.0.4-1595618194519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34595,DS-239c5782-8cd2-459d-ac16-2baf980eddb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-3989193a-87f0-4ab5-a803-c1001bf09784,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-e28105fa-7a54-4147-b987-05af7ecc6cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-814b4abe-7b1c-41a0-be88-334322ec4846,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-ce3546d3-b271-4edf-885a-979f696e70da,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-2b11d156-9dce-428e-84f0-b29cd33b6d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-6d9acc0c-8312-4b87-bdcc-6695d0b2977a,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-e1e138df-08de-492f-a7c1-0b6f74f41081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-948587838-172.17.0.4-1595618267992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45522,DS-631ec818-9d95-4e1a-8b13-a24f7da7deba,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-e078f240-ebbe-49d6-aad1-f1d19e283a33,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-cffc2453-123f-4e75-8b65-0291152c5e66,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-7f5fa905-4051-4994-8d8e-10b661092bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-3f8fd7ef-206d-4331-9e94-1bfae8e95f67,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-1b9b13f5-7347-4fdc-8cdd-858a7ced3a44,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-e66260e4-1856-4e6c-b778-d40818e852d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-dad81dca-b60e-4cbd-84a0-1c7da4c5ec68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-948587838-172.17.0.4-1595618267992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45522,DS-631ec818-9d95-4e1a-8b13-a24f7da7deba,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-e078f240-ebbe-49d6-aad1-f1d19e283a33,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-cffc2453-123f-4e75-8b65-0291152c5e66,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-7f5fa905-4051-4994-8d8e-10b661092bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-3f8fd7ef-206d-4331-9e94-1bfae8e95f67,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-1b9b13f5-7347-4fdc-8cdd-858a7ced3a44,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-e66260e4-1856-4e6c-b778-d40818e852d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-dad81dca-b60e-4cbd-84a0-1c7da4c5ec68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-766464903-172.17.0.4-1595618474012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34866,DS-edd01cdb-ea3b-46d8-b515-30bd5e47d3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-8deca7f6-6cdf-4c01-8050-1bf0e354f22c,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-74c7454b-2466-4e45-9bf1-9be89a1b9e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-1e4769f3-b9bb-45c6-b60b-9e7d1e042a95,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-08bffbaa-1f98-44cb-94ad-919b23bc7f58,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-33a1e228-b357-4c37-8dc2-662b8f1b0b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-8d1fee05-6969-48bc-8dff-bc8e44fdbd10,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-474283f3-adae-48b2-ad9b-945d81343305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-766464903-172.17.0.4-1595618474012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34866,DS-edd01cdb-ea3b-46d8-b515-30bd5e47d3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-8deca7f6-6cdf-4c01-8050-1bf0e354f22c,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-74c7454b-2466-4e45-9bf1-9be89a1b9e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-1e4769f3-b9bb-45c6-b60b-9e7d1e042a95,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-08bffbaa-1f98-44cb-94ad-919b23bc7f58,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-33a1e228-b357-4c37-8dc2-662b8f1b0b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-8d1fee05-6969-48bc-8dff-bc8e44fdbd10,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-474283f3-adae-48b2-ad9b-945d81343305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-849715073-172.17.0.4-1595619269033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34772,DS-e617f1cc-82ab-4ab0-b11b-6a27b3216d91,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-70b4675a-a342-4fa3-b52d-5cc3a2014ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-6598f4f4-e3ed-43f3-9faa-163c7025d2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-5592ab04-e120-49ba-89f3-458f9148374b,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-682cfc3c-9f22-4ff9-b9af-2bf199b30704,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-07a93a2a-5ec3-486c-99c0-e3179db847e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-bf90fa3c-c478-44f2-96f4-0b7d46441556,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-7e21ef50-d380-490c-aee6-d6529c4b22f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-849715073-172.17.0.4-1595619269033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34772,DS-e617f1cc-82ab-4ab0-b11b-6a27b3216d91,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-70b4675a-a342-4fa3-b52d-5cc3a2014ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-6598f4f4-e3ed-43f3-9faa-163c7025d2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-5592ab04-e120-49ba-89f3-458f9148374b,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-682cfc3c-9f22-4ff9-b9af-2bf199b30704,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-07a93a2a-5ec3-486c-99c0-e3179db847e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-bf90fa3c-c478-44f2-96f4-0b7d46441556,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-7e21ef50-d380-490c-aee6-d6529c4b22f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588134929-172.17.0.4-1595619929624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43226,DS-c7558570-9be3-4569-911e-c38f674ae6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-a6dc4839-3873-4d6e-b798-02d09d741ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-a96d53c3-e8e2-4e1f-b267-2a8ab518c64d,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-0ad0ed38-f25d-417b-9b5c-764ad11814e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-45788669-1be3-46f6-970a-27e5b73e01b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-a1bdaa20-9075-48ad-8145-d57e45f3f624,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-424fb452-15a0-442f-9e83-fac37251c76e,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-28f29caf-288a-48a6-9ee3-bf49b72486fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588134929-172.17.0.4-1595619929624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43226,DS-c7558570-9be3-4569-911e-c38f674ae6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-a6dc4839-3873-4d6e-b798-02d09d741ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-a96d53c3-e8e2-4e1f-b267-2a8ab518c64d,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-0ad0ed38-f25d-417b-9b5c-764ad11814e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-45788669-1be3-46f6-970a-27e5b73e01b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-a1bdaa20-9075-48ad-8145-d57e45f3f624,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-424fb452-15a0-442f-9e83-fac37251c76e,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-28f29caf-288a-48a6-9ee3-bf49b72486fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1540141335-172.17.0.4-1595620074163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39205,DS-100c0a31-58ec-4066-b861-c76fad09c903,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-449517ad-5cc4-4211-aff6-cdd8ce0fb9be,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-8a30f8e6-687e-45f1-a61f-b96298e2980d,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-d0a409c0-b362-42f3-bc24-74c84fb11f89,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-f32057d6-4cd7-43c5-b2f6-f4e4756e0dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-fad5db56-4a7b-4e80-ab84-93f9e6f6de7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-f0290422-0de4-48a0-bc28-7df110b72bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-a42ce5b9-c8ae-49fd-9181-94776b478f4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1540141335-172.17.0.4-1595620074163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39205,DS-100c0a31-58ec-4066-b861-c76fad09c903,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-449517ad-5cc4-4211-aff6-cdd8ce0fb9be,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-8a30f8e6-687e-45f1-a61f-b96298e2980d,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-d0a409c0-b362-42f3-bc24-74c84fb11f89,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-f32057d6-4cd7-43c5-b2f6-f4e4756e0dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-fad5db56-4a7b-4e80-ab84-93f9e6f6de7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-f0290422-0de4-48a0-bc28-7df110b72bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-a42ce5b9-c8ae-49fd-9181-94776b478f4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-558165785-172.17.0.4-1595620262309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35149,DS-5e8226c3-5590-447c-baa6-1f2fd4955a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-146c4601-d5f8-43d9-b50e-8976414ed1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-4e3efd4a-31d1-4bc4-9215-29da07c500d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-c9fc24bf-063e-4e6e-a2c8-f05a3360c544,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-30061a66-eabc-409c-84ff-2a477e073069,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-5a84a8f4-d29f-4342-8a10-8e8a5cda82b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-d002ce36-aca1-47dc-bfbd-7112b4188e31,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-f4d3b098-cd99-46d6-b2e5-166171b295fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-558165785-172.17.0.4-1595620262309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35149,DS-5e8226c3-5590-447c-baa6-1f2fd4955a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-146c4601-d5f8-43d9-b50e-8976414ed1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-4e3efd4a-31d1-4bc4-9215-29da07c500d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-c9fc24bf-063e-4e6e-a2c8-f05a3360c544,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-30061a66-eabc-409c-84ff-2a477e073069,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-5a84a8f4-d29f-4342-8a10-8e8a5cda82b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-d002ce36-aca1-47dc-bfbd-7112b4188e31,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-f4d3b098-cd99-46d6-b2e5-166171b295fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1399989651-172.17.0.4-1595620643639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36432,DS-f89d38f1-bc75-40c9-a36d-09d7b1884133,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-71df6e0c-d780-4292-9841-67e90e1d9167,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-9f71135b-f6b8-49f0-889f-52bb388977ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-470eb226-2030-4cad-8e49-09f238de3c54,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-dad2655a-a6a5-4b20-9342-31ac70a41b59,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-6865622f-3df9-48c3-948b-22ecf1419eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-9c98f769-f067-423a-a19b-1ca69efb5612,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-00d5dee6-75e3-4520-8caa-e68028df6953,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1399989651-172.17.0.4-1595620643639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36432,DS-f89d38f1-bc75-40c9-a36d-09d7b1884133,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-71df6e0c-d780-4292-9841-67e90e1d9167,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-9f71135b-f6b8-49f0-889f-52bb388977ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-470eb226-2030-4cad-8e49-09f238de3c54,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-dad2655a-a6a5-4b20-9342-31ac70a41b59,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-6865622f-3df9-48c3-948b-22ecf1419eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-9c98f769-f067-423a-a19b-1ca69efb5612,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-00d5dee6-75e3-4520-8caa-e68028df6953,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311396596-172.17.0.4-1595620856552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40616,DS-78b1b7a6-c072-4610-8e6c-47a9aeea4dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-121c9dd3-7a34-408b-84fa-056741a05fac,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-61e98729-d4f3-456c-9c92-060ba96ad7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-44e82992-8013-436b-aea6-79d450e9a1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-de2f2e1f-5f16-4cfd-a973-65cb173dcbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-276dc718-1384-4843-a46b-cf3709568551,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-5f7d78a0-0671-4361-8437-3ab8e63ca668,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-51cad108-9822-4ec6-baac-d7f8650e5db4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311396596-172.17.0.4-1595620856552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40616,DS-78b1b7a6-c072-4610-8e6c-47a9aeea4dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-121c9dd3-7a34-408b-84fa-056741a05fac,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-61e98729-d4f3-456c-9c92-060ba96ad7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-44e82992-8013-436b-aea6-79d450e9a1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-de2f2e1f-5f16-4cfd-a973-65cb173dcbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-276dc718-1384-4843-a46b-cf3709568551,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-5f7d78a0-0671-4361-8437-3ab8e63ca668,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-51cad108-9822-4ec6-baac-d7f8650e5db4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1952227803-172.17.0.4-1595621111861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38715,DS-e0df198d-b83f-4535-adc2-2ee1eb493f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-907e0cf7-fb82-428d-89e8-066dc5468041,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-28f85665-1e0e-45df-a48d-7af2dcbc3693,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-e693a791-e194-48f0-bc50-3144d3888ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-673ef4c5-8aa7-403c-bbbc-85aa8fc622de,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-466f17c0-5a9d-4980-8b60-32f903e0bbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-75275a77-c259-42e4-af98-672ca0fa9123,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-e8d53845-8140-442b-95b9-45285f70c9be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1952227803-172.17.0.4-1595621111861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38715,DS-e0df198d-b83f-4535-adc2-2ee1eb493f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-907e0cf7-fb82-428d-89e8-066dc5468041,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-28f85665-1e0e-45df-a48d-7af2dcbc3693,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-e693a791-e194-48f0-bc50-3144d3888ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-673ef4c5-8aa7-403c-bbbc-85aa8fc622de,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-466f17c0-5a9d-4980-8b60-32f903e0bbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-75275a77-c259-42e4-af98-672ca0fa9123,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-e8d53845-8140-442b-95b9-45285f70c9be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904622503-172.17.0.4-1595621324492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39266,DS-65503442-8439-48b9-87f3-d3bdd97d3bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-0223ed92-edb4-4850-9503-d86297614c29,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-7fea2e59-0e02-490f-bba3-4ec25e2ca2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-625854f1-9ce4-4501-91f2-abe70da654cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-6fc2c51c-e8f0-41ec-ac4f-9c5e54e66d74,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-17deae84-2254-4797-a140-bfdef7a1cda2,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-021e0b56-688d-47ba-88f9-947c981e1180,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-e638489c-c68a-4a63-9fb3-b30b1241ba77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904622503-172.17.0.4-1595621324492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39266,DS-65503442-8439-48b9-87f3-d3bdd97d3bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-0223ed92-edb4-4850-9503-d86297614c29,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-7fea2e59-0e02-490f-bba3-4ec25e2ca2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-625854f1-9ce4-4501-91f2-abe70da654cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-6fc2c51c-e8f0-41ec-ac4f-9c5e54e66d74,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-17deae84-2254-4797-a140-bfdef7a1cda2,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-021e0b56-688d-47ba-88f9-947c981e1180,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-e638489c-c68a-4a63-9fb3-b30b1241ba77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1065583492-172.17.0.4-1595622000492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38182,DS-0023c5e0-9a68-4bd9-aa20-420cf9e2b911,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-b51863a7-0a8d-43db-a37f-a3f08bb328ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-c57cfa30-8fb1-4119-ab5e-4a3ce95ed384,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-85f5ed45-7d14-4e27-a951-ef958fc5e8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-845c410a-0be8-4abd-a51f-d75e3564cc00,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-09bc8db7-7739-45e3-98b1-7c2edbf64141,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-5ba112e8-75d2-4904-b184-d49227a3d21c,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-d0a78439-3abc-4e5d-9f42-2ff485695d9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1065583492-172.17.0.4-1595622000492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38182,DS-0023c5e0-9a68-4bd9-aa20-420cf9e2b911,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-b51863a7-0a8d-43db-a37f-a3f08bb328ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-c57cfa30-8fb1-4119-ab5e-4a3ce95ed384,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-85f5ed45-7d14-4e27-a951-ef958fc5e8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-845c410a-0be8-4abd-a51f-d75e3564cc00,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-09bc8db7-7739-45e3-98b1-7c2edbf64141,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-5ba112e8-75d2-4904-b184-d49227a3d21c,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-d0a78439-3abc-4e5d-9f42-2ff485695d9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5291
