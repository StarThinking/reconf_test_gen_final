reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785270774-172.17.0.15-1595492054906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35946,DS-29a1455b-c1af-43e2-a293-995243b243b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-b37c3e56-8c19-410f-9b33-805a60516972,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-38b89e7e-ecdd-4316-88a5-91fcf1172347,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-92bd3146-a97e-4123-9c38-b87349f0398f,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-0d2377af-457e-4450-bdb4-28ceb77fd6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-577fc405-618f-42fa-9021-80347283d9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-033839f4-5aa3-4ad8-8c65-1b6bd0456a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-91603eef-c0d7-4a13-9ce2-3798822fc25a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785270774-172.17.0.15-1595492054906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35946,DS-29a1455b-c1af-43e2-a293-995243b243b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-b37c3e56-8c19-410f-9b33-805a60516972,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-38b89e7e-ecdd-4316-88a5-91fcf1172347,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-92bd3146-a97e-4123-9c38-b87349f0398f,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-0d2377af-457e-4450-bdb4-28ceb77fd6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-577fc405-618f-42fa-9021-80347283d9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-033839f4-5aa3-4ad8-8c65-1b6bd0456a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-91603eef-c0d7-4a13-9ce2-3798822fc25a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-475056612-172.17.0.15-1595492091743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41574,DS-d601b4c0-fb5d-4f84-a8be-19a99bedbf18,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-a30bcead-ac6c-4836-976e-93f5422ef11c,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-db1a689e-5713-457d-9cbc-061da522941e,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-435cb9d3-d557-4767-ba50-154997bb8893,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-c4b592ea-b357-449f-9042-e9c16640512b,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-18ce9def-9ad4-4682-9d7d-70bf20453bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-e3d057ac-cdb8-4e85-b4bf-5a9d4a7adb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-a0fdc4a2-0566-4483-8f65-637a27e62820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-475056612-172.17.0.15-1595492091743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41574,DS-d601b4c0-fb5d-4f84-a8be-19a99bedbf18,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-a30bcead-ac6c-4836-976e-93f5422ef11c,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-db1a689e-5713-457d-9cbc-061da522941e,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-435cb9d3-d557-4767-ba50-154997bb8893,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-c4b592ea-b357-449f-9042-e9c16640512b,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-18ce9def-9ad4-4682-9d7d-70bf20453bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-e3d057ac-cdb8-4e85-b4bf-5a9d4a7adb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-a0fdc4a2-0566-4483-8f65-637a27e62820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671386830-172.17.0.15-1595492129202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45478,DS-56659847-2cf5-4c07-8446-c4643b422082,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-68f48601-0d90-4a17-bb8c-30871efa67af,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-23fb9da2-711c-4062-83ac-39b5d34c6099,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-d2b0ea51-4ba3-484c-bfbd-ad50829a4584,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-953df45e-2e3e-4197-b82e-7d41acc163eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-5adf624a-9d7e-43bf-84ca-92d906191537,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-c75add19-4c4c-4c0c-95c8-aff8b1ec22c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-d80c63f0-b43e-40b3-bc14-d7104d4af29a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671386830-172.17.0.15-1595492129202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45478,DS-56659847-2cf5-4c07-8446-c4643b422082,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-68f48601-0d90-4a17-bb8c-30871efa67af,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-23fb9da2-711c-4062-83ac-39b5d34c6099,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-d2b0ea51-4ba3-484c-bfbd-ad50829a4584,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-953df45e-2e3e-4197-b82e-7d41acc163eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-5adf624a-9d7e-43bf-84ca-92d906191537,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-c75add19-4c4c-4c0c-95c8-aff8b1ec22c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-d80c63f0-b43e-40b3-bc14-d7104d4af29a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204492967-172.17.0.15-1595492372128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36636,DS-a7e733ee-67c4-463a-bf92-dad3fc733dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-dd386756-3640-4a5e-a6e0-6a74cd575ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-24d46a83-eea4-4466-aacb-834e0c3c12ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-86fcbdc8-4e79-4cc7-bc4e-00d399a66e19,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-bddc8d7c-95a9-4c53-a1c0-9bb690d1bffa,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-139d20b0-bbe7-45d1-afd7-90c4aee48bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-a8f88619-8885-4e57-bb9c-37b2a3d659e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-5249cf45-f185-4a00-a795-21cf56bb8039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204492967-172.17.0.15-1595492372128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36636,DS-a7e733ee-67c4-463a-bf92-dad3fc733dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-dd386756-3640-4a5e-a6e0-6a74cd575ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-24d46a83-eea4-4466-aacb-834e0c3c12ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-86fcbdc8-4e79-4cc7-bc4e-00d399a66e19,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-bddc8d7c-95a9-4c53-a1c0-9bb690d1bffa,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-139d20b0-bbe7-45d1-afd7-90c4aee48bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-a8f88619-8885-4e57-bb9c-37b2a3d659e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-5249cf45-f185-4a00-a795-21cf56bb8039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1603698303-172.17.0.15-1595492512198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33182,DS-cd4cbf93-7a0a-4978-9b93-182139f2a511,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-1a4279ed-4e3a-4473-9076-1886aa8dfd80,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-43f5be21-98f1-4207-8796-4ba4f8fb8a64,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-c3fd9985-5cde-4b36-9534-df71e0aa84e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-56bbe122-ee7d-4f94-bda4-b8ce8af27219,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-b52f21d9-27f1-45c4-8943-7453565b16c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-3583d0b0-342f-429b-a413-88a1dc635051,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-89ec5fc0-9462-488a-b768-c592ada7de55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1603698303-172.17.0.15-1595492512198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33182,DS-cd4cbf93-7a0a-4978-9b93-182139f2a511,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-1a4279ed-4e3a-4473-9076-1886aa8dfd80,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-43f5be21-98f1-4207-8796-4ba4f8fb8a64,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-c3fd9985-5cde-4b36-9534-df71e0aa84e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-56bbe122-ee7d-4f94-bda4-b8ce8af27219,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-b52f21d9-27f1-45c4-8943-7453565b16c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-3583d0b0-342f-429b-a413-88a1dc635051,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-89ec5fc0-9462-488a-b768-c592ada7de55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1156933053-172.17.0.15-1595492607161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45333,DS-45c6f766-67ed-48aa-bb5f-5d3d24a19356,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-566eefca-52d6-4526-8ac0-ef9653166ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-3d960d66-c12e-400a-9c32-cda6c01f7fba,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-25eccb5d-2a8e-4f49-8b3c-2f4fd26504c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-c00c3444-189e-4b54-b4e0-8f41a7b1c72b,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-683a869e-6c90-44a5-a71d-9d44fa72a2df,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-4d3de0ce-bb04-46fc-ab9a-2d53d5962f63,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-3434e251-7156-4937-b12e-788a4e35ac75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1156933053-172.17.0.15-1595492607161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45333,DS-45c6f766-67ed-48aa-bb5f-5d3d24a19356,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-566eefca-52d6-4526-8ac0-ef9653166ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-3d960d66-c12e-400a-9c32-cda6c01f7fba,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-25eccb5d-2a8e-4f49-8b3c-2f4fd26504c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-c00c3444-189e-4b54-b4e0-8f41a7b1c72b,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-683a869e-6c90-44a5-a71d-9d44fa72a2df,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-4d3de0ce-bb04-46fc-ab9a-2d53d5962f63,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-3434e251-7156-4937-b12e-788a4e35ac75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1637944362-172.17.0.15-1595493146684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36940,DS-cddfe2b0-0de1-4f48-98df-2cd8c51224cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-05865f95-f5fd-490d-b98d-b70371623488,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-44f43ada-7142-4571-bd1f-2e6b487235a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-fbbdf328-e97a-49f7-bf43-cbbf22bab9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-b77eb4b7-9d86-4a48-a0ba-74a96103feef,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-29ff3982-254f-4676-ab49-1462c623ae7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-251ca2b9-0a7a-4d39-a49f-7a952a2a673d,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-f7efc1c4-0915-48ef-86ea-2597c7e117b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1637944362-172.17.0.15-1595493146684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36940,DS-cddfe2b0-0de1-4f48-98df-2cd8c51224cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-05865f95-f5fd-490d-b98d-b70371623488,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-44f43ada-7142-4571-bd1f-2e6b487235a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-fbbdf328-e97a-49f7-bf43-cbbf22bab9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-b77eb4b7-9d86-4a48-a0ba-74a96103feef,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-29ff3982-254f-4676-ab49-1462c623ae7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-251ca2b9-0a7a-4d39-a49f-7a952a2a673d,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-f7efc1c4-0915-48ef-86ea-2597c7e117b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787135770-172.17.0.15-1595493239906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32982,DS-12888dae-1f27-42cf-834e-bc2afa353a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-e65642bb-2a05-4032-bbc5-f74d7af28eab,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-d482fd31-d741-467f-aca1-cefd39186474,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-1e2479ff-9471-4118-b66b-bee41833c10d,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-82f27716-6a1b-4e68-b38d-a365a3286d14,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-6d4ee59d-f537-4be8-9235-95bbaa656046,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-747b50d6-bc03-4802-a69c-db26ed7891a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-04e5d451-1057-4bfc-b77a-fc8bfc35142d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787135770-172.17.0.15-1595493239906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32982,DS-12888dae-1f27-42cf-834e-bc2afa353a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-e65642bb-2a05-4032-bbc5-f74d7af28eab,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-d482fd31-d741-467f-aca1-cefd39186474,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-1e2479ff-9471-4118-b66b-bee41833c10d,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-82f27716-6a1b-4e68-b38d-a365a3286d14,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-6d4ee59d-f537-4be8-9235-95bbaa656046,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-747b50d6-bc03-4802-a69c-db26ed7891a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-04e5d451-1057-4bfc-b77a-fc8bfc35142d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1669506681-172.17.0.15-1595493530858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37696,DS-762ab619-0a73-483f-928a-640c90a7d982,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-0a6c0804-b117-4c13-b5c9-1f014e529141,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-207f064b-f82e-4a0d-aaca-eacea72e0021,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-02c8c5d5-2dd0-432f-bcd6-00181be97117,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-25fc4378-293d-4089-96d1-bb35ecb9a2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-b9fda80f-6e2e-4a78-9177-16230deb787f,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-fc049595-8716-46c0-9f32-b95338c27c75,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-296a337d-55a6-4dfd-9f7f-ec722a7a21c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1669506681-172.17.0.15-1595493530858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37696,DS-762ab619-0a73-483f-928a-640c90a7d982,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-0a6c0804-b117-4c13-b5c9-1f014e529141,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-207f064b-f82e-4a0d-aaca-eacea72e0021,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-02c8c5d5-2dd0-432f-bcd6-00181be97117,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-25fc4378-293d-4089-96d1-bb35ecb9a2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-b9fda80f-6e2e-4a78-9177-16230deb787f,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-fc049595-8716-46c0-9f32-b95338c27c75,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-296a337d-55a6-4dfd-9f7f-ec722a7a21c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1543304932-172.17.0.15-1595494092922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44883,DS-9a274218-255a-4a66-a24f-377788babe2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-17facf85-a280-4c9a-9ff0-8352abba59a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-1d8dfee6-0596-459b-9227-9eaa62e4148a,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-aee426cb-aa6c-42e7-806d-81263328e540,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-e878ff8b-bc95-4907-ab1c-f79be00027d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-5b909813-c3bc-447d-939f-c6fa1ceda4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-26f3b045-a448-41d8-94e6-890c446803af,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-988be313-d49b-423b-b728-fee9369c3da6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1543304932-172.17.0.15-1595494092922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44883,DS-9a274218-255a-4a66-a24f-377788babe2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-17facf85-a280-4c9a-9ff0-8352abba59a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-1d8dfee6-0596-459b-9227-9eaa62e4148a,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-aee426cb-aa6c-42e7-806d-81263328e540,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-e878ff8b-bc95-4907-ab1c-f79be00027d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-5b909813-c3bc-447d-939f-c6fa1ceda4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-26f3b045-a448-41d8-94e6-890c446803af,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-988be313-d49b-423b-b728-fee9369c3da6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-343256148-172.17.0.15-1595494772349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33940,DS-0395230e-0d7b-47a2-a3fe-7a9b8d1c02a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-a243112e-c534-4bfb-801e-5bd1a05041f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-a330de7b-9a02-458f-b847-e40132863acf,DISK], DatanodeInfoWithStorage[127.0.0.1:44749,DS-b52f8f47-d015-413e-a3e8-68f0654928f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-0771c42f-a438-4908-837b-d72b199fc542,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-705cab1a-0318-49b2-a3fd-143d858d27bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-0e21821b-3093-4b0a-aec8-5f26d11a7a60,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-7c64e02b-ec25-4100-90f2-11a8debe17a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-343256148-172.17.0.15-1595494772349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33940,DS-0395230e-0d7b-47a2-a3fe-7a9b8d1c02a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-a243112e-c534-4bfb-801e-5bd1a05041f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-a330de7b-9a02-458f-b847-e40132863acf,DISK], DatanodeInfoWithStorage[127.0.0.1:44749,DS-b52f8f47-d015-413e-a3e8-68f0654928f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-0771c42f-a438-4908-837b-d72b199fc542,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-705cab1a-0318-49b2-a3fd-143d858d27bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-0e21821b-3093-4b0a-aec8-5f26d11a7a60,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-7c64e02b-ec25-4100-90f2-11a8debe17a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1744970152-172.17.0.15-1595494944459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43168,DS-8d0e91f2-0a84-4120-9362-8f57653f13a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-5031cb9b-99af-477b-8f3a-eeefcf71afaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-03662746-1ccb-406c-ba48-5a2e1e8d774b,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-89b6a08e-6944-4ec0-87bc-639285d8abf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-d390c75e-e1fe-4ae3-88fd-25768055e28c,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-bc69501a-2bb3-4f70-8238-ffa5b87a31a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-8ddd64ce-7e06-4a21-8f20-04d590709c18,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-2334a053-5acc-42ec-b012-a83e38f2937b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1744970152-172.17.0.15-1595494944459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43168,DS-8d0e91f2-0a84-4120-9362-8f57653f13a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-5031cb9b-99af-477b-8f3a-eeefcf71afaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-03662746-1ccb-406c-ba48-5a2e1e8d774b,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-89b6a08e-6944-4ec0-87bc-639285d8abf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-d390c75e-e1fe-4ae3-88fd-25768055e28c,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-bc69501a-2bb3-4f70-8238-ffa5b87a31a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-8ddd64ce-7e06-4a21-8f20-04d590709c18,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-2334a053-5acc-42ec-b012-a83e38f2937b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057029402-172.17.0.15-1595495081669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45784,DS-cd2c701f-3a4f-4a1c-9a6d-736cc5863321,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-e2eae8e9-c8ca-4172-903f-00a9c05f724d,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-169b7129-43f8-48c8-8af2-269052965d10,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-451a876b-c7f6-4f5b-b8d3-4f5175fd26d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-91d7bdff-5501-44ce-8e63-d3d88313280b,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-45604315-9ac2-4869-bac4-b7478dfeeefd,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-9cb811c4-8f75-4ef6-b974-d64b5e9b5932,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-734db695-e32e-4d14-b6c6-312cba3d413f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057029402-172.17.0.15-1595495081669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45784,DS-cd2c701f-3a4f-4a1c-9a6d-736cc5863321,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-e2eae8e9-c8ca-4172-903f-00a9c05f724d,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-169b7129-43f8-48c8-8af2-269052965d10,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-451a876b-c7f6-4f5b-b8d3-4f5175fd26d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-91d7bdff-5501-44ce-8e63-d3d88313280b,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-45604315-9ac2-4869-bac4-b7478dfeeefd,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-9cb811c4-8f75-4ef6-b974-d64b5e9b5932,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-734db695-e32e-4d14-b6c6-312cba3d413f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1278423276-172.17.0.15-1595495938414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39701,DS-0a6d7fb4-5d27-4fa8-afad-5b3c3bbf3ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-e7a0f9b5-69ca-4f60-8cf3-b7f6180cfe31,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-98bcf384-110b-4e17-9e39-ba58a61b732a,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-9e80b845-5bb0-4202-8c5c-458db1c121a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-eeb12b67-7019-414c-bb53-4acb8a9b51f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-c4806d19-938e-4788-823a-065df03d7e64,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-4b856257-da05-4385-9e4e-098d6c146fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-786decc5-55f0-40a0-b8fd-a3fed5c89d10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1278423276-172.17.0.15-1595495938414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39701,DS-0a6d7fb4-5d27-4fa8-afad-5b3c3bbf3ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-e7a0f9b5-69ca-4f60-8cf3-b7f6180cfe31,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-98bcf384-110b-4e17-9e39-ba58a61b732a,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-9e80b845-5bb0-4202-8c5c-458db1c121a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-eeb12b67-7019-414c-bb53-4acb8a9b51f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-c4806d19-938e-4788-823a-065df03d7e64,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-4b856257-da05-4385-9e4e-098d6c146fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-786decc5-55f0-40a0-b8fd-a3fed5c89d10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1854882343-172.17.0.15-1595496213128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35876,DS-4d98e02d-39b8-468c-800c-a622ae4c34a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-23762482-a439-4e49-b000-861c57edb8da,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-11dd2b98-910e-474a-80eb-d2f36725a5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-9c9fe023-1cc7-4293-826b-e65d82e103f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-030da154-a36e-4a7e-9bba-f1ca7c6190bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-842312bf-6b38-468b-869c-d589f1555ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-8888bbed-f476-4120-b100-05a3f11b42c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-b835b2f1-9f17-4a4d-ad8a-a922099904a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1854882343-172.17.0.15-1595496213128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35876,DS-4d98e02d-39b8-468c-800c-a622ae4c34a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-23762482-a439-4e49-b000-861c57edb8da,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-11dd2b98-910e-474a-80eb-d2f36725a5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-9c9fe023-1cc7-4293-826b-e65d82e103f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-030da154-a36e-4a7e-9bba-f1ca7c6190bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-842312bf-6b38-468b-869c-d589f1555ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-8888bbed-f476-4120-b100-05a3f11b42c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-b835b2f1-9f17-4a4d-ad8a-a922099904a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1111917027-172.17.0.15-1595496552719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35331,DS-e7eed7ab-8b23-450b-8241-e4762d371437,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-4cc3e5f0-2331-4220-95bc-4d3396428395,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-1e1ed37d-d447-45e1-8825-f69c0163d15c,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-1d6a7e64-02a5-450b-970d-20abc6e856e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-2c18eb67-77f1-46d7-9498-0d8cc1c70b13,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-c3a0a543-9d18-40f0-8d7c-c67066011495,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-220afb29-e50d-4180-993b-ab850285b449,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-20da4d8c-8c67-4a9a-9ff7-d81cdfa6fc52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1111917027-172.17.0.15-1595496552719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35331,DS-e7eed7ab-8b23-450b-8241-e4762d371437,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-4cc3e5f0-2331-4220-95bc-4d3396428395,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-1e1ed37d-d447-45e1-8825-f69c0163d15c,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-1d6a7e64-02a5-450b-970d-20abc6e856e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-2c18eb67-77f1-46d7-9498-0d8cc1c70b13,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-c3a0a543-9d18-40f0-8d7c-c67066011495,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-220afb29-e50d-4180-993b-ab850285b449,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-20da4d8c-8c67-4a9a-9ff7-d81cdfa6fc52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 4945
