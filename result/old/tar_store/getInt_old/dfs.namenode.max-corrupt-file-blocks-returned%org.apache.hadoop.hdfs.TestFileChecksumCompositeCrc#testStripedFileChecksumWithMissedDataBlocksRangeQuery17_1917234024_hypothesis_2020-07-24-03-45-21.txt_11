reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2091775113-172.17.0.14-1595562406781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33812,DS-7ea6db5d-5d51-46fd-ad8d-d22401708393,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-e4d60453-0336-4c13-b114-81e9450a846a,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-c7e23dfc-259b-4ce9-b3b1-5398168adf29,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-510e7809-c78d-4694-8fe9-8434ecdee487,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-1a8334bf-6fa5-403c-9b91-5c6f9b99f6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-0cab871c-0263-4f06-9a9e-30f3da5d01f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-821efd9c-e422-47c4-94bd-90a6afc62a20,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-c00c9181-e549-4db1-b0d0-60cf9d79cee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2091775113-172.17.0.14-1595562406781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33812,DS-7ea6db5d-5d51-46fd-ad8d-d22401708393,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-e4d60453-0336-4c13-b114-81e9450a846a,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-c7e23dfc-259b-4ce9-b3b1-5398168adf29,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-510e7809-c78d-4694-8fe9-8434ecdee487,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-1a8334bf-6fa5-403c-9b91-5c6f9b99f6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-0cab871c-0263-4f06-9a9e-30f3da5d01f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-821efd9c-e422-47c4-94bd-90a6afc62a20,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-c00c9181-e549-4db1-b0d0-60cf9d79cee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-618258076-172.17.0.14-1595562588588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42394,DS-c07071ee-1afa-4d45-92dd-abdf387bd89d,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-fdd8fa60-adfd-46f6-ac35-6aaf0097dcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-c6cdac61-646f-4c45-93e1-0f839337b11b,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-3a67c615-bd88-4f28-8ef1-f59c3741324d,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-1ad73ccb-c215-4235-bada-da746ad303bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-f49bffdb-1a98-4bad-93d7-f2d3852bbe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-93dcbf40-2bf4-4126-b502-d19a9e6f8ace,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-c9692c97-97a9-4ccd-8a01-d0c9332dfd81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-618258076-172.17.0.14-1595562588588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42394,DS-c07071ee-1afa-4d45-92dd-abdf387bd89d,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-fdd8fa60-adfd-46f6-ac35-6aaf0097dcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-c6cdac61-646f-4c45-93e1-0f839337b11b,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-3a67c615-bd88-4f28-8ef1-f59c3741324d,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-1ad73ccb-c215-4235-bada-da746ad303bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-f49bffdb-1a98-4bad-93d7-f2d3852bbe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-93dcbf40-2bf4-4126-b502-d19a9e6f8ace,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-c9692c97-97a9-4ccd-8a01-d0c9332dfd81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-782152556-172.17.0.14-1595562649544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36396,DS-b726d872-546b-4a8e-803b-40cb37b49cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-bc1f7030-294f-4c7f-9c99-747cac98c8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-d041435e-2935-4fd2-974f-2541463ef333,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-efce93f3-7a73-4111-b673-2e40be9d8ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-45b182ee-fa75-43ee-b261-28f9642ae74b,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-a65ed5d3-58f8-4c03-9765-832e66319557,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-453025e8-dbc0-4247-af5b-f9c3416dcb21,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-3eebf2f6-2b72-4d6d-93d3-d95a6718a1b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-782152556-172.17.0.14-1595562649544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36396,DS-b726d872-546b-4a8e-803b-40cb37b49cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-bc1f7030-294f-4c7f-9c99-747cac98c8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-d041435e-2935-4fd2-974f-2541463ef333,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-efce93f3-7a73-4111-b673-2e40be9d8ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-45b182ee-fa75-43ee-b261-28f9642ae74b,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-a65ed5d3-58f8-4c03-9765-832e66319557,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-453025e8-dbc0-4247-af5b-f9c3416dcb21,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-3eebf2f6-2b72-4d6d-93d3-d95a6718a1b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-959624171-172.17.0.14-1595563006056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34799,DS-f4cd9bcb-c5fe-4473-9542-e38e114033de,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-d9c46824-9493-49c2-b546-f2721b0c7de7,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-856f17cf-2eb1-4857-b271-7793eb2683ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-1b4a71d4-1f19-4d68-9128-494b0dd48668,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-784daec0-5a87-4e58-8c5f-0c02c97f03c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-b8f0d4c5-a2ea-412e-a261-36999c3df85a,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-7da3d10f-bbd0-451d-85b2-288aa4b911d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-e8dff270-625a-4456-a791-5ab05b7f4f1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-959624171-172.17.0.14-1595563006056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34799,DS-f4cd9bcb-c5fe-4473-9542-e38e114033de,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-d9c46824-9493-49c2-b546-f2721b0c7de7,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-856f17cf-2eb1-4857-b271-7793eb2683ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-1b4a71d4-1f19-4d68-9128-494b0dd48668,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-784daec0-5a87-4e58-8c5f-0c02c97f03c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-b8f0d4c5-a2ea-412e-a261-36999c3df85a,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-7da3d10f-bbd0-451d-85b2-288aa4b911d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-e8dff270-625a-4456-a791-5ab05b7f4f1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1073031683-172.17.0.14-1595563071979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39257,DS-a0fbbef1-500a-4bb6-8861-471ae68c8ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-2b83de89-3169-4250-b57e-bc3a6ef0931f,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-0337c752-1e1d-4284-aa1c-1dd9a6489de7,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-5dbd8d19-bbfa-459d-a36e-97790e2d29b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-83f54035-a68e-42ed-bb2c-bedb0210ff3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-09e4466b-7443-4d81-898c-60ee1da880d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-ef3fb7ef-fd1b-4a2b-916d-b908c984a04b,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-8af2b94b-f9bd-4f4b-8d19-20e51631c171,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1073031683-172.17.0.14-1595563071979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39257,DS-a0fbbef1-500a-4bb6-8861-471ae68c8ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-2b83de89-3169-4250-b57e-bc3a6ef0931f,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-0337c752-1e1d-4284-aa1c-1dd9a6489de7,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-5dbd8d19-bbfa-459d-a36e-97790e2d29b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-83f54035-a68e-42ed-bb2c-bedb0210ff3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-09e4466b-7443-4d81-898c-60ee1da880d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-ef3fb7ef-fd1b-4a2b-916d-b908c984a04b,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-8af2b94b-f9bd-4f4b-8d19-20e51631c171,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1291279519-172.17.0.14-1595563159532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39244,DS-8b5184c8-61cf-4a27-90f1-c25dd4cd76f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-12d6eefd-3b37-496b-9117-2d0515eed2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-442345f4-9c7c-4aec-affe-1fe1b2816797,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-3e5cd9df-be77-4386-9da9-3f397cf7714e,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-3c690956-bcb3-42b1-a8d0-d4466a02a24f,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-01f7b266-23e5-4f0f-97ca-442f3a7f96a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-c17f219a-34f1-4890-a161-9f91dbe6a2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-698f2920-7970-4d4d-bb26-8010d7d9a4e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1291279519-172.17.0.14-1595563159532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39244,DS-8b5184c8-61cf-4a27-90f1-c25dd4cd76f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-12d6eefd-3b37-496b-9117-2d0515eed2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-442345f4-9c7c-4aec-affe-1fe1b2816797,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-3e5cd9df-be77-4386-9da9-3f397cf7714e,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-3c690956-bcb3-42b1-a8d0-d4466a02a24f,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-01f7b266-23e5-4f0f-97ca-442f3a7f96a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-c17f219a-34f1-4890-a161-9f91dbe6a2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-698f2920-7970-4d4d-bb26-8010d7d9a4e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-260361678-172.17.0.14-1595563514904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39785,DS-3f95bdc6-4fc6-4a1a-bedd-131f781c8805,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-66318d5e-c3aa-47b0-a01e-00b235fccb40,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-73362d63-3671-4e8d-9b45-d95eba657ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-ee28a225-0791-44fd-b1ba-7ee602f58219,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-32ecbc88-359e-4cfd-8795-8a134b48d7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-b4f065a1-168f-4bb7-8ff4-e68ebb18dffc,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-cea48c12-757a-43d6-a1b8-2bd240c9c1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-ecaf56c2-f1f6-442a-8364-6902a5552035,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-260361678-172.17.0.14-1595563514904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39785,DS-3f95bdc6-4fc6-4a1a-bedd-131f781c8805,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-66318d5e-c3aa-47b0-a01e-00b235fccb40,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-73362d63-3671-4e8d-9b45-d95eba657ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-ee28a225-0791-44fd-b1ba-7ee602f58219,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-32ecbc88-359e-4cfd-8795-8a134b48d7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-b4f065a1-168f-4bb7-8ff4-e68ebb18dffc,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-cea48c12-757a-43d6-a1b8-2bd240c9c1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-ecaf56c2-f1f6-442a-8364-6902a5552035,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2129080878-172.17.0.14-1595563642815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40228,DS-11f40454-ed4f-4ca8-a716-da89fbd93ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-67b8d1ff-97d3-489a-80f6-4c1149cf6fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-487c0e96-8ac8-4242-aa1f-2f95dd870699,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-44f2509d-6353-45c9-98a6-fbb11352ec6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-a4e31828-a757-479c-8ade-a265bf214bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-a745361d-9948-4d79-b430-439bf3e2fdb1,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-3d165190-310b-468f-8232-f60c709ee45a,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-243e343d-b7ba-4d47-82c2-3a2e9bf4d7fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2129080878-172.17.0.14-1595563642815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40228,DS-11f40454-ed4f-4ca8-a716-da89fbd93ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-67b8d1ff-97d3-489a-80f6-4c1149cf6fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-487c0e96-8ac8-4242-aa1f-2f95dd870699,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-44f2509d-6353-45c9-98a6-fbb11352ec6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-a4e31828-a757-479c-8ade-a265bf214bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-a745361d-9948-4d79-b430-439bf3e2fdb1,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-3d165190-310b-468f-8232-f60c709ee45a,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-243e343d-b7ba-4d47-82c2-3a2e9bf4d7fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-246828537-172.17.0.14-1595563885609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45576,DS-7758354e-d25f-4573-82fd-2e293fcaef9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-a7134a1c-97a8-48c9-a317-37d9d9e11865,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-e3b5ffe7-a245-4a6b-895b-2712b99e4f02,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-406ca627-2d37-4a2f-8eba-2aec814d4eba,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-4b345e76-26de-49e6-906f-96d186579f43,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-fa51a3d5-b89a-41b1-96fa-ffabb0f1333a,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-a2fab23a-6643-4d39-b540-dcc76863173d,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-035d4a10-ef91-4efe-a4af-50bae21d92cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-246828537-172.17.0.14-1595563885609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45576,DS-7758354e-d25f-4573-82fd-2e293fcaef9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-a7134a1c-97a8-48c9-a317-37d9d9e11865,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-e3b5ffe7-a245-4a6b-895b-2712b99e4f02,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-406ca627-2d37-4a2f-8eba-2aec814d4eba,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-4b345e76-26de-49e6-906f-96d186579f43,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-fa51a3d5-b89a-41b1-96fa-ffabb0f1333a,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-a2fab23a-6643-4d39-b540-dcc76863173d,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-035d4a10-ef91-4efe-a4af-50bae21d92cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1681143246-172.17.0.14-1595564164024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36337,DS-9545574a-c352-485e-ae3b-ddbeed8df3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-5f1513ae-b899-453b-9864-534b57c9a178,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-2ac54445-eb88-4c05-9640-9ba27166accc,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-75be9e1a-007c-4e6e-a465-ad304dc90bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-85566711-564d-4e88-8413-686d7e679cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-fb89698d-f20a-4642-8eaa-b56271143589,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-72311462-486d-4bbe-b855-dc021e33a9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-3a82846c-b77c-4707-8507-8b3cc181b427,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1681143246-172.17.0.14-1595564164024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36337,DS-9545574a-c352-485e-ae3b-ddbeed8df3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-5f1513ae-b899-453b-9864-534b57c9a178,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-2ac54445-eb88-4c05-9640-9ba27166accc,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-75be9e1a-007c-4e6e-a465-ad304dc90bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-85566711-564d-4e88-8413-686d7e679cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-fb89698d-f20a-4642-8eaa-b56271143589,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-72311462-486d-4bbe-b855-dc021e33a9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-3a82846c-b77c-4707-8507-8b3cc181b427,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-864450539-172.17.0.14-1595565308550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42195,DS-357e38f1-35b6-467a-8ddd-1658ac0a9c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-2aaed94c-6aaf-4f83-b9bd-a2220f9f606a,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-c47daf6d-746a-427d-abe0-539b37c167e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-14c3d501-e3b5-4f9f-bbdb-b1082f7358eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-c64fcf4c-89d5-46fb-8c7d-eea85155a944,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-f1f3d18c-7789-4f1d-8894-514d32b6843c,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-533dae54-5697-4ddd-9ffa-e2d93e3385a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-9d4e04f8-8494-4a02-a1bf-5619818da5f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-864450539-172.17.0.14-1595565308550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42195,DS-357e38f1-35b6-467a-8ddd-1658ac0a9c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-2aaed94c-6aaf-4f83-b9bd-a2220f9f606a,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-c47daf6d-746a-427d-abe0-539b37c167e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-14c3d501-e3b5-4f9f-bbdb-b1082f7358eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-c64fcf4c-89d5-46fb-8c7d-eea85155a944,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-f1f3d18c-7789-4f1d-8894-514d32b6843c,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-533dae54-5697-4ddd-9ffa-e2d93e3385a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-9d4e04f8-8494-4a02-a1bf-5619818da5f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-582208592-172.17.0.14-1595565448135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38175,DS-3341bcc0-a367-48d3-bf4c-aac15fe795eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-f79c9d5d-f37f-4d0c-a27c-7a17859884b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-bd107df4-392c-4f58-95cd-5bcbe6ba9df1,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-d53d6793-f0fd-445b-a2ef-5d05c2178168,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-b81c8bfb-1d2d-42ba-a597-3d8e8f3fa5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-5d03eba7-3418-44c9-b13e-2f0415883cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-e706960a-3bc8-4b8a-bcdd-831115c85fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-97496f99-a2d4-42d1-8f1c-e8a8df708a30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-582208592-172.17.0.14-1595565448135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38175,DS-3341bcc0-a367-48d3-bf4c-aac15fe795eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-f79c9d5d-f37f-4d0c-a27c-7a17859884b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-bd107df4-392c-4f58-95cd-5bcbe6ba9df1,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-d53d6793-f0fd-445b-a2ef-5d05c2178168,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-b81c8bfb-1d2d-42ba-a597-3d8e8f3fa5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-5d03eba7-3418-44c9-b13e-2f0415883cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-e706960a-3bc8-4b8a-bcdd-831115c85fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-97496f99-a2d4-42d1-8f1c-e8a8df708a30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-607214404-172.17.0.14-1595566141857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35803,DS-cc1a96b3-9b3a-4daf-a6e4-16a29e2e1acf,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-0c21fdae-c5a5-496b-b116-8a06159f77a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-4d71eed5-72fa-47c4-af4e-f54cbcf7bc48,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-469a017b-f6d0-4054-bdad-d29413434739,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-d5256144-75ed-41b9-9a44-f589a916d41a,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-b323245e-7615-4de6-aa0e-00a0ca4f70d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-d70ab6c4-3f2b-4758-a224-c1a43987f97b,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-a33ce5b1-c770-4509-a168-b77f9fabce03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-607214404-172.17.0.14-1595566141857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35803,DS-cc1a96b3-9b3a-4daf-a6e4-16a29e2e1acf,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-0c21fdae-c5a5-496b-b116-8a06159f77a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-4d71eed5-72fa-47c4-af4e-f54cbcf7bc48,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-469a017b-f6d0-4054-bdad-d29413434739,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-d5256144-75ed-41b9-9a44-f589a916d41a,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-b323245e-7615-4de6-aa0e-00a0ca4f70d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-d70ab6c4-3f2b-4758-a224-c1a43987f97b,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-a33ce5b1-c770-4509-a168-b77f9fabce03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-184064268-172.17.0.14-1595566427053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44350,DS-e705f1ee-5b5d-40ea-9250-4a15b806dad5,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-e1842738-6698-402a-a6d0-bb5e041f1ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-10fb790e-fecf-4199-8225-aca88fc38ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-61b73826-9b76-4c2e-b520-73b26a6cdff1,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-f13ed6d4-74aa-414c-964c-d74f6defc139,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-4c2a7711-d0a5-4b66-862f-aec1c820d3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-f5350784-fee3-46a1-ae49-8ae143eb1c83,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-dfcf9d69-b956-459a-a2f7-9fef2b289498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-184064268-172.17.0.14-1595566427053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44350,DS-e705f1ee-5b5d-40ea-9250-4a15b806dad5,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-e1842738-6698-402a-a6d0-bb5e041f1ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-10fb790e-fecf-4199-8225-aca88fc38ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-61b73826-9b76-4c2e-b520-73b26a6cdff1,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-f13ed6d4-74aa-414c-964c-d74f6defc139,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-4c2a7711-d0a5-4b66-862f-aec1c820d3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-f5350784-fee3-46a1-ae49-8ae143eb1c83,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-dfcf9d69-b956-459a-a2f7-9fef2b289498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-625337133-172.17.0.14-1595566796701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40185,DS-e6583955-4f55-4410-bf5e-d222be344986,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-56e6f800-a0fa-483b-b536-fe8734133eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-275643a8-c61a-4a6f-9a19-bf9607318d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-90d697c9-8a4e-4931-843e-965294175f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-8a365dbc-66fd-4959-bbfb-04e206c3bdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-7a4e4682-d16f-4f53-9a53-779ce47ee2db,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-75e74492-e0c0-4ee4-b2e1-ee2f405219ac,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-bd2b3aa0-899a-4b2b-8e65-9ee4854b200f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-625337133-172.17.0.14-1595566796701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40185,DS-e6583955-4f55-4410-bf5e-d222be344986,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-56e6f800-a0fa-483b-b536-fe8734133eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-275643a8-c61a-4a6f-9a19-bf9607318d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-90d697c9-8a4e-4931-843e-965294175f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-8a365dbc-66fd-4959-bbfb-04e206c3bdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-7a4e4682-d16f-4f53-9a53-779ce47ee2db,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-75e74492-e0c0-4ee4-b2e1-ee2f405219ac,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-bd2b3aa0-899a-4b2b-8e65-9ee4854b200f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 4693
